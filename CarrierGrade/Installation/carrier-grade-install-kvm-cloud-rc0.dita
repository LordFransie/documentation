<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic1107">
<title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 1.1: Deploying the KVM Region</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HP Helion Openstack 1.1"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Storage Architect"/>
<othermeta name="role" content="Michael B,"/>
<othermeta name="product-version1" content="HP Helion Openstack 1.1"/>
</metadata>
</prolog>
<body>


 <!--./CarrierGrade/Installation/carrier-grade-install-pb-hlm-cloud.md-->
 <!--permalink: /helion/openstack/carrier/install/pb/hlm-cloud/-->
<p>After the HLM VM is up and running and HP Helion OpenStack is installed, use the following steps
      to deploy the KVM region.</p>
  <section><title>Deploy the KVM region</title><p>To deploy the KVM:</p>
        <ol><li>Login to HLM VM.</li>
        <li>Change to the <codeph>cg-hlm/hlm-build</codeph> directory.</li>
        <li>Execute the following command: <codeblock>./hlm_prepare-env.sh</codeblock></li>
        <li>Deploy and configure the cloud services using the following command:
          <codeblock>cd
<b>hnewcloud &lt;cloud_name&gt; Denver</b> </codeblock></li>
        <li> Change to the cloud directory, based on the name you entered above.
          <codeblock>cd &lt;cloudname&gt; </codeblock> Where &lt;cloudname&gt; is the name you
          assigned to the cloud.</li>
        <li>Provision the controller nodes by providing necessary values in the
            <codeph>node-provision.json</codeph> file using the following command:
          <codeblock>hprovision &lt;cloudname&gt;</codeblock> Where &lt;cloudname&gt; is the name
          you assigned to the cloud. Please take a note of interface when shows up for the
          interfaces. You might need this information later in the installation. </li>
        <li>After the nodes are provisioned, make sure sure the <codeph>nodes.json</codeph> file was
          generated and password-less SSH connection can be established to these nodes from HLM
          VM</li>
      </ol>
    </section>
  <section><title>Edit JSON Files</title>
  <p>The following json files need to be updated as required for your networking infrastructure.</p>   
    <ul><li>environment.json</li>
      <li>lnet-control-data.json (optional: only if your BLS is on separate interface)</li>
      <li>definition.json</li></ul>
  </section>
    <section><title>Roll in Cinder backend changes</title>
      <ol><li>Change to the <parmname>cinder/blocks</parmname> directory for your cloud:
        <codeblock>cd ~/&lt;cloudname&gt;/services/cinder/blocks</codeblock>
        Where &lt;cloudname&gt; is the name you assigned to the cloud.</li>
        <li>Copy the <codeph>cinder_conf_default.hp3parSample</codeph> file to
            <codeph>cinder_conf_default</codeph> file and edit the file to configure to 3PAR
          settings. For example:
          <codeblock>--3PAR details (connectivity is still being worked upon ETA 06/22/2015. 
hp3par_api_url=https://&lt;hp3par_ip&gt;:8080/api/v1
hp3par_username=&lt;hp3par_user&gt;
hp3par_password=&lt;hp3par_user_password
hp3par_cpg=bronze
san_ip=&lt;san_ip>
san_login=&lt;san_user>
san_password=&lt;san_password>
hp3par_iscsi_ips=&lt;iscsi_ip1&gt;,&lt;iscsi_ip2&gt;,&lt;iscsi_ip3&gt;,&lt;iscsi_ip4&gt;
volume_driver=cinder.volume.drivers.san.hp.hp_3par_iscsi.HP3PARISCSIDriver
hp3par_debug=False
hp3par_iscsi_chap_enabled=false
hp3par_snapshot_retention=48
hp3par_snapshot_expiration=72</codeblock></li>
     
<li>Execute the HP Helion OpenStack Configuration Processor using the following command:
  <codeblock>cfgproc -d definition.json</codeblock></li>
        <li>Initialize network interfaces.
          <codeblock>hnetinit HCGCloud</codeblock></li>
<li>Deploy cloud
  <codeblock>hdeploy HCGCloud</codeblock></li>    
              </ol>
      <p>Once cloud deployment is successfully complete, 2 controller nodes in the KVM region.</p>
    </section>
  <section><title>Bring Up Controller-0 in the KVM Region</title> 
    <ol><li>Make sure other nodes to be used in KVM region are shutdown.</li>
      <li>Attach the <codeph>wr-iso</codeph> to designated controller node:
        <!-- hide, internal only? Vinod
          <ol id="ol_i3q_hmg_ms">
        <li> LR1: uploaded to
              <codeblock>15.204.209.7 C:\WR-Drops\2015-06-05-Drop3\2015-06-05-Drop3\Titanium-Server-host-installer-15.05-b10.iso</codeblock></li>
        <li>LR4: uploaded to
              <codeblock>15.215.66.56 E:\Builds\WR-Drop-3\2015-06-05-Drop3\Titanium-Server-host-installer-15.05-b10.iso</codeblock></li></ol> -->
          </li>
    
      <li>Follow the install wizard. Select the Graphics mode for the controller only. Do not select <codeph>Controller+Compute</codeph>.</li>
      <li>After the reboot, log in as user name <codeph>wrsroot</codeph> and password  <codeph>wrsroot</codeph>. Make sure you change the password.</li>
      <li>Temporarily assign an IP address to the PXE NIC - eth0. Use the IP you have reserved for the KVM PXE.
        <codeblock>ip addr add &lt;CIDR> dev eth0
ifconfig eth0 up</codeblock></li>
      <li> Set the default gateway to the PXE network gateway
        <codeblock>route add default gw 192.168.101.1</codeblock></li>
      <li>Copy the following files to the <codeph>/home/wrsroot/</codeph> directory of the
          controller-0:
          <pre>TS_15.05_PATCH_0001.patch  # HLM VM /root/cg-hlm/windriver-files</pre><pre>region_config              # HLM VM ~/&lt;cloud_name&gt;/clouds/build40/001/stage/windriver-config</pre><pre>cakey.pem                  # HLM VM ~&lt;cloud_name&gt;/clouds/build40/001/stage/windriver-config</pre><pre>license.lic                # LR4: E:\Builds\WR-2015-06-05-Drop3 License file received/procured</pre><pre>helion_branding-v1.2.tgz   # HLM VM /root/cg-hlm/windriver-files</pre></li>
     
      <li>Move the <codeph>helion_branding-v1.2.tgz</codeph> to <codeph>/opt/branding</codeph> on
          the controller-0 </li>
   
      <li>Apply the requried patches on controller-0:
          <codeblock>sudo wrs-patch upload /home/wrsroot/TS_15.05_PATCH_0001.patch
sudo wrs-patch apply TS_15.05_PATCH_0001
sudo wrs-patch install-local
sudo reboot       </codeblock></li>
   
   <li>Install the KVM region coud:
     <codeblock>sudo config_region</codeblock>
     Ignore the message which displays during <codeph>Config_region</codeph> process.
      <codeblock>Step 9 of 29 [####  ]dm-6 WRITE SAME failed. Manually seroing.</codeblock></li>

      <li>After <codeph>controller-0</codeph> is deployed, deploy the remaining nodes as
            <codeph>controller-1</codeph> and <codeph>compute-'n'</codeph>.
          <pre>system host-add --hostname controller-1 --personality controller --mgmt_mac &lt;mgmt_mac&gt; --bm_mac &lt;bm_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt; --bm_password &lt;ilo_password&gt;</pre><pre>system host-add --hostname &lt;unique-compute-name&gt; --personality compute --mgmt_mac &lt;mgmt_mac&gt; --mgmt_ip &lt;mgmt_ip&gt; --bm_mac &lt;ilo_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt;  --bm_password &lt;ilo_password&gt;</pre></li>
        <li>While registering compute nodes, make sure you specify the <codeph>mgmt_ip</codeph>.
          This IP should from the KVM CLM range (refer to the <codeph>region_config</codeph> file) and must not
          overlap controller IPs. It is save to start after a block of 10 IPs.</li> 
        <li>Set the controller-1 and compute-0 to <codeph>One-time PXE boot from network</codeph>.</li>

      <li>PXE boot all the registered nodes.</li> 
      
      <li><xref href="../AdminGuideNew/Dashboard/carrier-grade.dashboard.launch.dita#topic1160">Log
            in to the Horizon interface</xref> and monitor the status of nodes being PXE booted.
          After succesful PXE boot, Operational State as Disabled and Availability State as Online
          in the Admin &gt; Inventory page</li>
      
      <li>For each compute node in the ineventory, do the following<ol id="ul_gss_srg_ms">
            <li>Create Infra interface. See <xref
                href="../AdminGuideNew/HostManagement/carrier-grade-admin-wr-host-management-inventory-detail-interfaces.dita#topic6151"
              /></li>
            <li>Create a Provider Network. See <xref
                href="../AdminGuideNew/Networks/carrier-grade.dashboard.network.admin.create.provider.dita#topic3878"
              />.</li>
            <li>Create VLAN Ranges on the provider network using the <b>Create Segmentation
                Range</b> option. See <xref
                href="../AdminGuideNew/Networks/carrier-grade.dashboard.network.admin.create.segment.dita#topic2171"
              />.</li>
            <li>Create data interface. Due to latest networking changes, ensure you create data
              interface either of the following AE mode is tied to each interface:
              <codeblock>eth2 and eth3 - Active/Standby
eth4 and eth5 - Balanced XOR / Layer 2</codeblock></li></ol></li>
    
      
      <li><xref
            href="../AdminGuideNew/HostManagement/carrier-grade-admin-wr-host-management-host-lock.dita#topic3241"
            >Unlock the compute nodes</xref>. Compute nodes will reboot. Keep polling the status on
          the inventory page to show <b>Available</b> and <b>Online</b>.</li> 
        
      <li>Access the Horizon dashboard using the CAN network IP (HTTPS). By default, Horizon is
          restricted to access the CAN network using the CLM network as the default gateway You can
          workaround this, use SSH to access each controller node and update the filters:
          <codeblock>echo 0 > /proc/sys/net/ipv4/conf/default/rp_filter
echo 0 > /proc/sys/net/ipv4/conf/all/rp_filter
echo 0 > /proc/sys/net/ipv4/conf/eth0.&lt;CAN_VLAN_ID&gt;/rp_filter
echo 0 > /proc/sys/net/ipv4/conf/eth0.&lt;CLM_VLAN_ID&gt;/rp_filter
echo 1 > /proc/sys/net/ipv4/ip_forward </codeblock></li>
    </ol>
  </section>
  <section id="next-step"> <title>Next Step</title>
    <p>
        <xref href="carrier-grade-install-pb-workarounds.dita">Post-Installation Tasks</xref>
      </p>
  </section>
  
  <section>
<p>
  <xref type="section" href="#topic1107"> Return to Top </xref>
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
</body>
</topic>
