---
layout: default
title: "HP Helion OpenStack&#174; 1.1.1 customer provided certificates"
permalink: /helion/openstack/1.1.1/customer-provided-certificates/
product: commercial.ga
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.1.1
role1: Systems Administrator 
role2: Cloud Architect 
role3: Storage Administrator 
role4: Network Administrator 
role5: Service Developer 
role6: Cloud Administrator 
role7: Application Developer 
role8: Network Engineer 
authors: Nancy M.

---
<!--UNDER REVISION-->

<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>

<!-- <p style="font-size: small;"> <a href="/helion/openstack/1.1/services/">&#9664; PREV</a> | <a href="/helion/openstack/1.1/services/overview/">&#9650; UP</a>"> NEXT &#9654</a> </p> -->

# HP Helion OpenStack&#174; 1.1.1: Configuring support for customer-provided certificates

Use this procedure to configure Helion to use customer provided certificate for all endpoints.


This write-up explains how to split up the existing load balancer to terminate SSL connections with a client provided server certificate and re-encrypt to service backends served by stunnel proxies. In addition, we add the client provided trust chain to the ECA trust file. This is so that none of the services needs any changing. However, they may need to be restarted.

###Target Audience:
Professional service engineers


###The problem:
Endpoints currently serve ECA signed certs and these cannot be validated without the ECA CA cert installed in client machines.

###The proposed solution:
<ol><li>	Install the supplied certificate’s trust chain (CA certificates) to all overcloud, undercloud and seed nodes.
</li><li>	Restart all openstack services in all nodes.
</li><li>	Configure haproxy to use the supplied certificate to terminate the TLS connections and re-encrypt to service nodes. Restart haproxy after reconfiguration.</li></ol>
The above steps are described in detail in the following sections.

##Updating certificate store in overcloud nodes

The services use the endpoints to talk to other services and they'll fail validation as they're designed to pick up the ECA cert from a file location. They need to be told to trust the client provided server certificate. Ideally, if the cert was signed by a well-known CA, we wouldn't have to do it. But libraries behave differently, and in the presence of venvs, we decided to hardcode the cacert location in 1.1.1. So our suggested procedure is to have both public CA signed cert and internal CA such as HPIT signed certs in a single file.

###Getting a customer certificate
To get a customer certificate you need to follow a procedure similar to this:
<ol><li>	Create a private key.
</li><li>	Create a CSR (Certificate Request) for the customer facing VIP where the customer certificate will be installed.
</li><li>	Send the CSR to the customer’s CA and have it signed and returned to you as a certificate.
</li><li>	Insert the private key into the certificate file.
</li><li>	Copy the certificate to a location in all three controllers. (Eg: /root/tmp/edge_server.pem)</li></ol>

###Creating a private key and a CSR
The following bash snippet shows how to create a private key and a CSR in a single command. This is meant to be an example and you may have to edit it to get the values you want in.
<pre>COMMON_NAME='1.1.1.1';
openssl req -newkey rsa:2048 -nodes -keyout server_key.pem -out server_csr.pem \
    -subj "/CN=${COMMON_NAME}" -config <(echo -e "[ req ]
    distinguished_name = req_distinguished_name
    req_extensions = v3_req
    [ req_distinguished_name ]                                                                                                                                                                                                                                                                                                 
    CN = ${COMMON_NAME}
    [ v3_req ]
    basicConstraints = CA:FALSE
    keyUsage = nonRepudiation, digitalSignature, keyEncipherment
    subjectAltName = @alt_names
    [ alt_names ]
    IP.1 = 192.0.2.22
    IP.2 = 192.0.2.23 ")</pre>

###A note on the certificate formats
A customer provided certificate can be of various combinations of formats
<ul><li>	A key and a PEM encoded certificate
</li><li>	A key and a DER encoded certificate
</li><li>	A DER encoded PFX file
</li><li>	Trust chain included in the same file as the certificate
</li><li>	Trust chain in a separate file</li></ul>

For the consumption of haproxy:
<ol><li>	The certificate needs to be in a PEM format
</li><li>	The key should be in the same file
</li></ol>
The order of entities within the certificate file:
<ol><li>	Key
</li><li>	PEM encoded certificate</li></ol>

For the deployed CA certificates inside the cluster, (AKA what goes inside ephemeralca-cacert.crt):
<ol><li>	The original CA certificate from the ECA
</li><li>	The trust chain (Eg HPIT CA certificate) supplied by the customer. You may need to extract this content from the supplied certificate.</li></ol>

To convert from DER format to PEM format:
	<pre>openssl x509 -inform der -in certificate.der -out certificate.pem</pre>

To convert from PFX format to PEM format:
	<pre>openssl pkcs12 -in keyStore.pfx -out keyStore.pem -nodes</pre>


Once you have the certificate and the CA certificate in the appropriate formats, append external_cacert.pem to /usr/local/share/ca-certificates/ephemeralca-cacert.crt on all overcloud nodes, undercloud node and the seed. After each concatenation update the certificate store.

<pre>cat external_ca_certificate.pem >> /usr/local/share/ca-certificates/ephemeralca-cacert.crt
update-ca-certificates --fresh</pre>

This will make certain that all libraries that worked with ECA will continue to work. 

Also append it to seed:/root/eca.crt
	<pre>cat external_ca_certificate.pem >> /root/eca.crt</pre>

This will make sure that the trust chain update would persist across update.

###Restarting Services
All openstack services on all nodes need to be restarted to reread the trust chains. 

###Reconfiguring HAProxy
Currently we use the haproxy as a software load balancer to tunnel TLS traffic to the service nodes. Haproxy listens on the VIP. A sample configuration goes like this:
<pre>listen nova_osapi
  bind 192.0.2.22:8774
  server overcloud-controller0-v7jcp33imqgf 192.0.2.28:8774 check inter 6000 rise 2 fall 5  check-ssl ca-file /etc/ssl/certs/ca-certificates.crt</pre>

We propose to let haproxy terminate the TLS traffic and re-encrypt it back to the service backend. We can then use the client provided server cert instead of the short-lived ECA certificates. The resulting configuration will look like this:

<pre>listen nova_osapi
  bind 192.0.2.22:8774 ssl crt /root/tmp/edge_server.pem
  server overcloud-controller0-v7jcp33imqgf 192.0.2.28:8774 check inter 6000 rise 2 fall 5  check-ssl ca-file /etc/ssl/certs/ca-certificates.crt ssl</pre>

Note that there are two changes (highlighted):
<ol><li>	The bind command now specifies the server cert. This cert needs to have both the private key and the cert in this single file.</li>
<li>The backend needs and extra keyword 'ssl' to tell that it needs to talk to a TLS backend. Previously this wasn't needed as it was in tunnel mode.</li>

<li>These changes have to be done for each of the service stanzas that needs changing. All controller haproxy.cfg needs to be updated.</li></ol>

The following commands are given as examples to make the change for the haproxy.cfg. Please note that this will only work in a pristine haproxy configuration. It doesn’t handle corner cases.

<pre>sed '/^[[:space:]][[:space:]]bind/ s/$/ ssl crt \/root\/tmp\/edge_server.pem /' haproxy.cfg >ha1
sed '/^[[:space:]][[:space:]]server overcloud/ s/$/ ssl /' ha1 >ha2
mv haproxy.cfg  haproxy.cfg.orig
mv ha2 haproxy.cfg</pre>

Please note that you need to verify the following:

<ol><li>	If you’re fixing up a 1.1 system, mysql (port 3306) and rabbitmq (port 5671) will not have been over TLS. So you need to revert the changes made by the sed command to that of the original haproxy file.
</li><li>	We don’t want to put the metadata agent endpoint on the customer certificate. Please revert the changes made by the sed commands for the ‘listen nova_metadata’ stanza.
</li><li>	Novnc_proxy (port 6080) has had the liveness checks turned off. You need to add the check-ssl line as highlighted in yellow below for each of the lines starting with server in the stanza.
</li></ol>
Change
<pre>listen nova_novncproxy
  bind 192.0.2.22:6080 ssl crt /root/tmp/customer.pem
  option httpchk GET /
  maxconn 1500
  server overcloud-ce-controller-controller0-52vmts6crbsw 192.0.2.26:6080 check inter 2000 rise 2 fall 5 ssl</pre>

to
<pre>listen nova_novncproxy
  bind 192.0.2.22:6080 ssl crt /root/tmp/customer.pem
  option httpchk GET /
  maxconn 1500
  server overcloud-ce-controller-controller0-52vmts6crbsw 192.0.2.26:6080 check inter 2000 rise 2 fall 5  check-ssl ca-file /etc/ssl/certs/ca-certificates.crt ssl</pre>


At the end restart haproxy service to let the change take effect.

###Service restarts
Some services may need to be restarted. Currently we’re aware of the need to restart the following
<ul><li>	Nova-api on all controller nodes
</li><li>	Swift proxy server on all swift controller nodes.
</li><li>	Memcached on nodes.</li></ul>

###Caveats in the proposed solution
<ol><li>	If update is run then the system will be put back to the original state. If haproxy.cfg was backed up externally, then it makes it easier to reapply. However, one cannot just copy it as other things might have changed. Please follow the procedure to update haproxy.cfg again.</li></ol>

###Post-fix checklist
<ol><li>	Verify that the endpoint gives out the correct certificate.
echo | openssl s_client -connect 192.0.2.22:8774 | openssl x509 -text -noout|less
</li><li>	Verify that the service can be reached. For example, for nova:
nova flavor-list (to verify db connectivity from nova-api)
nova image-list (to verify glance connectivity from nova-api) 
</li><li>	Point the browser to VIP:1993 and check the haproxy service status.
</li><li>	Test with keystone tools that use java libraries. This is just to make sure the customer provided cert is good. You need to request for a new customer certificate if you find any version issues. The ECA certs are v3 compliant and have subjectAltNames.</li></ol>
Check-list after an update
<<ol><li>	Check /usr/local/share/ca-certificates/ephemeralca-cacert.crt has the client certificate trust chain. You can check the modulus using an openssl command, but easiest is to just pull up a backed up ephemeralca-cacert.crt file and diff it.
</li><li>	Check if haproxy stanzas are as expected.</li></ol>

###POSSIBLE OPTIMIZATION OF THIS PROCEDURE FOR SYSTEMS BUILT FROM SCRATCH OR BEING UPDATED
If one is set to supply the eca.crt and eca.key, instead of relying on the build generated eca credentials, then it’s possible to append the customer’s server certificate trust chain into the eca.crt. Then run the installer. This will negate the need to update the certs everywhere and restart services. Only change required then would be to change the haproxy configuration and restart haproxy on all controllers.
<ol><li>	Bring up the seed VM.
</li><li>	Append the customer supplied cert's trust chain to seed:/root/eca.crt. This is assuming the eca.key and eca.crt are being supplied to the installer.
</li><li>	Run the installer
</li><li>	Copy the customer supplied cert to all controllers
</li><li>	Run the two sed commands and update the haproxy config on all controllers
</li><li>	Restart haproxy to pick up the changes.
</li></ol>




----
