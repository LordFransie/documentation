---
layout: default
title: "HP Helion OpenStack: Add and Remove Nodes"
permalink: /helion/openstack/1.1/install/add/nodes/
product: commercial.ga
product-version1: HP Helion OpenStack 1.1
role1: Storage Administrator
role2: Storage Architect
authors: Binamra S, 

---
<!--PUBLISHED-->


<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>

<!--
<p style="font-size: small;"> <a href="/helion/openstack/1.1/install-beta/prereqs/">&#9664; PREV</a> | <a href="/helion/openstack/1.1/install-beta-overview/">&#9650; UP</a> | <a href="/helion/openstack/1.1/install-beta/vsa/">NEXT &#9654;</a> </p>
-->

# HP Helion OpenStack&#174; 1.1: Add (Scale-Out) and Remove (Scale-In) Nodes on KVM Hypervisors
[See the Helion OpenStack 1.0 version of this page](/helion/openstack/install/add/nodes/)

<!---This document describes the steps to add and remove nodes (scale in or scale out the VSA and Compute nodes) on an already installed overcloud-->
By default, HP Helion Openstack cloud deploys a two node (termed as start-up swift nodes) Swift cluster as part of its deployment.

This document describes the steps to add (Scale Out) or remove (Scale In) nodes (KVM Compute Nodes) to an already-installed overcloud on a KVM hypervisor. 

- [Prerequisites](#pre)
- [Add compute nodes](#add)
- [Remove nodes](#remove)

## Prerequisites ## {#pre}

Before you begin, ensure the following:

- The seed VM, undercloud and overcloud are installed using the HP Helion OpenStack installer.

## Add compute nodes ## {#add}

New compute nodes can be added to an already-installed overcloud. You can add nodes in any of the following scenarios:

- [Configure compute nodes to pre-allocated empty baremetal nodes](#pre-allocated)
- [Enroll a new baremetal and then add nodes](#non-allocated)

### Configure compute nodes to pre-allocated empty baremetal nodes ### {#pre-allocated}

You can enroll (add) nodes that that are present in baremetal.csv but have not been used, perform the following steps:


1. SSH to the seed VM as `root`:

 		ssh root@<IP Address>

2. Edit the scale counts in JSON environment variables file (`kvm-custom-ips.json`) that was used during the initial installation to define the appropriate scale number:

		"compute_scale":<number of compute nodes>,

3. Source the environment variables file that you updated:  

		source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/kvm-custom-ips.json

4. Run the installer script:

		bash -x tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud 2>&1 | tee update.log


### Enroll a new baremetal node and then configure compute nodes ### {#non-allocated}

To add new compute nodes that were not present during the initial installation process, first enroll the baremetal node and then configure the new node.

1. Log in to the seed VM:

		ssh root@<IP Address>

2. Make the respective Baremetal entry in `/root/baremetal.csv`.   
	<!---If the `/root/overcloud-config.json` is not present, copy the overcloud template config file to `/root/overcloud-config.json`: 
		cp /root/tripleo/tripleo-incubator/scripts/ee-config.json /root/overcloud-config.json-->
**Add the node to baremetal.csv at the end.**

    The full syntax is documented above. Make sure it is at the end of the file as it is a new node.
3. Edit the scale counts in JSON environment variables file (`kvm-custom-ips.json`) that was used during the initial installation to define the appropriate scale number:

		"compute_scale":<number of compute nodes>,

4. Source the environment variables file that you updated:  

		source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/kvm-custom-ips.json

5. Run the installer script:

		bash -x tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud 2>&1 | tee update.log


   This will register a new ironic node and create a new nova instance and a new heat stack.


## Remove nodes {#remove}

To remove a node:

1. SSH to the undercloud VM:

		ssh root@<IP Address>

2. If using trickle (default):
   Identify the MAC address of the node to be deleted

		

3. identify the ironic 'Node UUID'

		ironic port-list --detail

4. identify the nova instance 'Instance UUID' associated with the ironic Node UUID and, from that, identify the heat stack associated with the nova instance


		ironic node-list

5. the instance name will be something like:

		overcloud-ce-novacompute0-NovaCompute0-aztnviyoamsc
   so the stack name will be:

		overcloud-ce-novacompute0



1. Run

		heat stack-delete <stackname>

6. Wait for stack to be deleted, running the following command until it is gone:

		heat stack-list 

1. Delete node

		ironic node-delete <ironic_nodeid>

8. 	Mark the node as 'deleted' in baremetal.csv. Change the 'role' from 'OvercloudCompute' to 'OvercloudCompute:deleted'. **Note: DO NOT DELETE THIS LINE**, you must edit it instead.
    For example:

		78:e7:d1:22:52:9e,administrator,password,192.168.11.7,12,32768,2048,OvercloudCompute,IPMI

    becomes:

		78:e7:d1:22:52:9e,administrator,password,192.168.11.7,12,32768,2048,OvercloudCompute:deleted,IPMI


When hp&#95;ced&#95;installer --update-overcloud is run again, the node will be skipped in all operations.

**Note**: Do not decrease the value of *overcloud_computescale*
 in the JSON environment variables file (e.g. *kvm-custom-ips.json*) when
 removing a node. 

**Note:** If you receive warnings from Icinga after node removal, see [Troubleshooting Node Removal](/helion/openstack/1.1/services/troubleshooting/overcloud/)

----

     
