---
layout: default
title: "HP Helion OpenStack&#174; Troubleshooting Ephemeral Partitions"
permalink: /helion/openstack/1.1/services/troubleshooting/ephemeral_partitions/
product: commercial.ga
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.1
role1: Systems Administrator 
role2: Cloud Architect 
role3: Storage Administrator 
role4: Network Administrator 
role5: Service Developer 
role6: Cloud Administrator 
role7: Application Developer 
role8: Network Engineer 
authors: Paul F

---
<!--PUBLISHED-->

<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>
<!--

<p style="font-size: small;"> <a href="/helion/openstack/1.1/services/object/overview/">&#9664; PREV</a> | <a href="/helion/openstack/1.1/services/overview/">&#9650; UP</a> | <a href="/helion/openstack/1.1/services/reporting/overview/"> NEXT &#9654</a> </p> --->


# HP Helion OpenStack&#174; 1.1 Troubleshooting Ephemeral Partitions

HP Helion OpenStack&#174; is an OpenStack technology coupled with a version of Linux&#174; provided by HP. This topic describes all the known issues that you might encounter. To help you resolve these issues, we have provided possible solutions.

## An ephemeral partition fails to unmount ##


If during an update, you receive the following error message:


        The ephemeral storage of this system failed to be cleaned up properly and processes or files are still in use. The previous ansible play should have information to help troubleshoot this issue.


The most likely reason the partition failed to unmount is due to a process still holding a file handle on the partition. This normally happens when a process has failed to stop (where stop is issued by the Ansible playbook) or has been restarted (by `cron` for example) after the stop was issued. 

To find out which process is still running:

1. Log onto the failed nodes and enter:

	    ssh heat-admin@10.23.67.139 
    	$ sudo su -
    	root@overcloud-ce-controller-swiftstorage0-h7t3467lf7fx:~# lsof /mnt
    	COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME 
		stunnel4 33047 root   24w   REG8,1  4812923 62128141 /mnt/state/var/log/stunnel4/helion_stunnel.log


	In the above example `stunnel4` has failed to stop. 

2. To stop the process and verify nothing is holding a file reference on `/mnt` enter:    
    
	    root@overcloud-ce-controller-swiftstorage0-h7t3467lf7fx:~# pkill stunnel4
	    root@overcloud-ce-controller-swiftstorage0-h7t3467lf7fx:~# lsof /mnt
	    root@overcloud-ce-controller-swiftstorage0-h7t3467lf7fx:~# 
    
3. Follow the procedure to restart `mysql` and `rabbitmq` from the *Tripleo-ansible Troubleshooting Guide*.
 Once restarted, re-run the overcloud ansible playbook and not the `update_oc.sh` script


