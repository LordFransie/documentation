---
layout: default
title: "HP Helion OpenStack&#174; Ceph Integration"
permalink: /helion/openstack/1.1/services/ceph/overview/
product: commercial.ga
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.1
role1: Storage Engineer
role2: Storage Architect 
role3: Storage Administrator 
role4: Storage Engineer
role5: Service Developer 
role6: Cloud Administrator 
role7: Application Developer 
authors: Paul F

---
<!--PUBLISHED-->

<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>

<!--
<p style="font-size: small;"> <a href="/helion/openstack/1.1/services/object/overview/">&#9664; PREV</a> | <a href="/helion/openstack/1.1/services/overview/">&#9650; UP</a> | <a href="/helion/openstack/1.1/services/swift/deployment-scale-out/"> NEXT &#9654</a> </p>
-->

# HP Helion OpenStack&reg; 1.1: Ceph Integration Overview#

The HP Helion OpenStack 1.0 Ceph Storage Solution provides an unified scalable and stable Storage Solution for the management of Helion OpenStack Glance Images, Nova Boot Volumes, Cinder persistent Volumes. The Solution also supports User backup and archive workloads to the Swift API writing to the same unified Ceph storage platform. This Solution is supported by HP.

Ceph can fulfill all storage requirements in an OpenStack deployment; it is integrated with Glance, Cinder and Nova for block storage and can directly provide integrated, Swift compatible, multi-tenant object storage. It also supports Keystone integration with Ceph RADOS Gateway.

<img src="media/cephimplementation50.png">

## About Ceph ## {#about}

Ceph is an Open Source, scalable, software defined storage system running on HP Servers which provides block and object storage with unified management.

The main Use Case and integration point between HP Helion OpenStack Enterprise Edition and Ceph is block consumption of Ceph's RADOS Block Device, here within described as RBD. The secondary Use Case and integration point between User Application Archive and Backup Workloads running externally or in Virtual Machines in HP Helion OpenStack is object consumption of Ceph RADOS Gateway. The Ceph radosgw presents a REST interface with extensions offering compatibility with Swift API, hence existing Applications with integrations to the HP Helion OpenStack Swift API may port seamlessly from a OpenStack Swift backend storage platform and the Ceph Solution.

Other supported HP Storage options to consider are HP Helion OpenStack Swift for Object Storage, and HP VSA and HP 3PAR for Block Storage solutions.

### Block Storage

The Ceph Block Device is a network attached device that may be presented to the HP Helion OpenStack Controller and Compute Nodes for Glance, Nova and Cinder storage utilization.

### Object Storage

The Ceph RADOS Gateway is a REST API that supports Swift API. HP is supporting Object Storage primarily for User workloads: ranging from COTS Applications running in virtual machines such as MySQL frequently needing to archive tar files to a reliable and resilient archive, to custom LOB Solutions that require frequent and aggressive snapshots orchestrated in a consistency group across many VM and external baremetal systems.

### Ceph Cluster
The Ceph Object Storage Daemon, here within described as OSD,
stores data, handles data replication, recovery, rebalancing, and
provides information to Ceph monitors by checking other Ceph OSD
Daemons for a heartbeat.

### Ceph Object Gateway

Ceph object gateway is built on librgw to provide applications with a RESTful gateway to Ceph storage clusters. Ceph object storage supports two interfaces:
Swift-compatible: Provides object storage functionality with a large subset of the OpenStack Swift API. HP Supports this interface and 3rd party integrations with the Swift API.
S3-compatible: Provides object storage functionality with a large subset of the Amazon S3 RESTful API. This is not supported by HP as part of the Solution, but it has passed minimal API testing.

Helion OpenStack Virtual Machine Access to Ceph Storage Diagram

<img src="media/cephstorage">

## Hardware Recommendations for the Ceph Cluster {#hardware}

For a Production Environment, the following is HP's current Hardware Recommendations in a production environment.

<table style="text-align: left; vertical-align: top; width:1000px;">
<tr style="background-color: #C8C8C8;">
<th>Process</th><th>Criteria</th><th>Minimum Recommended Server quantity</th></tr>
<tr><td>Ceph-OSD</td><td> 3 x 15 HP ProLiant SL4540 Gen8 Servers</td><td>5</td></tr>
<tr><td>Ceph-Mon</td><td>HP ProLiant DL360p Gen8 Servers</td><td>3</td></tr>
<tr><td>Ceph-Admin</td><td>HP ProLiant DL360p Gen8 Servers</td><td>1*</td></tr>
<tr><td>Ceph-RADOSGW</td><td>HP ProLiant DL360p Gen8 Servers</td><td>1*</td></tr>
<tr><td></td><td>10 GbE Networking running on HP 5900AF switches</td><td>1</td></tr>
<tr><td></td><td>1 GbE Networking running on an HP 2920 switch</td><td>
1</td></tr>
</table>

***Note:** If the Resiliency SLA for the User Archive or Backup Use Cases cannot tolerate downtime of the Ceph RADOS Gateway, then consider adding additional Servers with an external Load Balancer.

### Detailed Example Deployment {#deployment}

<table style="text-align: left; vertical-align: top; width:1000px;">
<tr style="background-color: #C8C8C8;">
<th>HP Helion Openstack</th><th>CEPH Monitor/GateWays</th><th>OSDs (6x15 SL4540)</th></tr>
<tr><td>12 ProLiant DL360p Gen8 with 12 cores each</td><td>4x HP ProLiant DL360p Gen8 with 12 cores</td><td>6 x HP 3xSL4540 Gen8 with 16 cores each</td></tr>
<tr><td>2 x E5-2667 (Intel Xeon 2.9GHz 15M Cache)</td><td>2 x E5-2667 (Intel Xeon 2.9GHz 15M Cache)</td><td></td><td>2 x E5-2470 (Intel Xeon 2.3GHz 20M Cache)</td></tr>
<tr><td>64 GB - 8 x HP 8GB 1Rx4 PC3-12800R</td><td>64 GB - 8 x HP 8GB 1Rx4 PC3-12800R</td><td>96 GB - 12 x HP 8GB 2Rx4 PC3L-10600R</td></tr>
<tr><td>3.6 TB - 4 x HP 900GB 6G SAS 10K 2.5in SC ENT HDD</td><td>1 TB - 2 x HP 500GB 6G SAS 10K 2.5in SC ENT HDD</td><td>45 TB - 15 x HP 3TB 6G SAS 7.2K 3.5in SC MDL HDD</td></tr>
<tr><td>1 x HP 512MB FBWC for P-Series Smart Array</td><td>1 x HP 512MB FBWC for P-Series Smart Array</td><td>1TB - 2 x HP 500GB 6G SATA 7.2K 2.5in SC MDL HDD</td></tr>
<tr><td>2 x HP dual port 10GbE</td><td>2 x HP dual port 10GbE</td><td>2 x HP 2GB P-seris Smart Array FBWC</td></tr>
<tr><td></td><td></td><td>2 x HP Smart Array P420i Mez Ctrllr FIO Kit</td></tr>
<tr><td></td><td></td><td>1 x HP 10G IO Module (2x1GbE 2x10GbE)</td></tr>
</table>

## For more information

[Ceph Architecture Reference](/helion/openstack/1.1/services/object/ceph/archref/)


<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>

----
