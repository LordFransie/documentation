---
layout: default
title: "HP Helion OpenStack&#174; 1.1: Removing and replacing a failed Overcloud Controller"
permalink: /helion/openstack/1.1/removing/failedovercloud/
product: commercial.ga
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.1
role1: Systems Administrator 
role2: Cloud Architect 
role3: Storage Administrator 
role4: Network Administrator 
role5: Service Developer 
role6: Cloud Administrator 
role7: Application Developer 
role8: Network Engineer 
authors: Stephen H, Nancy M

---
<!--PUBLISHED-->


<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>
<!--
<p style="font-size: small;"> <a href="/helion/openstack/1.1/">&#9664; PREV | <a href="/helion/openstack/1.1/">&#9650; UP</a> | <a href="/helion/openstack/1.1/faq/">NEXT &#9654; </a></p>
-->

# HP Helion OpenStack&#174; 1.1: Removing and Replacing a Failed Overcloud Controller
[See the Helion OpenStack 1.0 version of this page](/helion/openstack/removing/failedovercloud/)

The three-node Overcloud Controller cluster provides a highly available Cloud Control Plane. In the event of a single point of failure in any one of the Controller nodes, the following procedures will allow you to recover that functionality.

In the rare event that your deployed operating cloud incurs an irrecoverable hardware failure in one of the Controller Servers, you will have to:

* Decommission the failed server (not covered here)
* Add a new server into your cloud (not covered here)
* Remove the failed controller from the Heat configuration
* Add the new controller to the configuration and deploy it
* [Clean up the environment](#cleanup)

The following steps are to be run on the seed, as root unless stated otherwise and assume that the bash shell is being used. They are based on the default install and you should not need to alter any of the commands or variables given unless stated otherwise.

There are some differences in the procedure for removing/replacing nodes depending on which controller is replaced:

- Controller0: By default, controller0 is the bootstrap controller. Controller1 is temporarily flagged as the bootstrap controller when controller0 is removed. See [Removing and replacing controller0](#controller0).

- Controller1: By default, nodes are contiguous, so some editing of the templates is required for non-contiguous nodes. See [Removing and replacing controller1](#controller1).

- Controller2: This is the most straightforward case; the CONTROLSCALE can be adjusted to remove the failed controller and deploy a new one. See [Removing and replacing controller2](#controller2).

## Removing and replacing controller0 {#controller0)

The following sections provide instructions on how to remove and replace a failed `controller0` node.


### Remove the failed controller0 


1. Ensure that `controller0` is stopped.

2. Configure the overcloud NTP server to one appropriate for the site.
 
		export OVERCLOUD_NTP_SERVER=16.110.135.123 # Use an NTP server appropriate for your environment
		
3. Set some environment variables (these should not need amending).

		export TRIPLEO_ROOT=~root/tripleo
		export TE_DATAFILE=$TRIPLEO_ROOT/ce_env.json
		export PATH=$PATH:$TRIPLEO_ROOT/bin:$TRIPLEO_ROOT/tripleo-incubator/scripts
		source $TRIPLEO_ROOT/tripleo-incubator/undercloudrc
		OVERCLOUD_EXTRA_CONFIG=$(hp_ced_load_passthrough.sh -v -p overcloud -x overcloud-complete)
		get_ce_env() {
		    local var=$1
		    cat ~/tripleo/ce_env.json \
		        | jq ".overcloud.${var}" \
		        | sed -e "s/\"//g"
		}
		COMPUTESCALE=$(get_ce_env computescale)
		SOSWIFTPROXYSCALE=$(get_ce_env soswiftproxyscale)
		SOSWIFTSTORAGESCALE=$(get_ce_env soswiftstoragescale)
		SWIFTSTORAGESCALE=$(get_ce_env swiftstoragescale)
		VSASTORAGESCALE=$(get_ce_env vsastoragescale)


4. Save the existing controller template prior to generating a new one.

		cp -p $TRIPLEO_ROOT/tripleo-heat-templates/trickle/overcloud-ce-controller ~root/

	Controller2 will temporarily become the bootstrap controller. We need to flag that the initialization has already been completed. 

5. On `controller2`, create the flag file that indicates  that the initialization has already been completed. Also ensure the nova-manage.log is owned by Nova.

		mkdir -p /mnt/state/var/lib/boot-stack/
		touch /mnt/state/var/lib/boot-stack/init-openstack.ok
		touch /mnt/state/var/log/nova/nova-manage.log
		chown nova:nova /mnt/state/var/log/nova/nova-manage.log

<!---If CORE-1797 is not fixed, we need to patch rabbit start up.    -->

6. Patch the rabbit start up:

		remaining_controllers=$(nova list \
		    | grep overcloud-ce-controller-controller \
		    | grep -v controller0 \
		    | cut -f 7 -d"|" \
		    | cut -f 2 -d"=")
		rabbit_post_configure="/opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		ssh_sudo="ssh heat-admin@controller_ip sudo"
		save_original="cp -p $rabbit_post_configure ~root/"
		patch_rabbitmq="sed -i '2aexit 0' $rabbit_post_configure"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$save_original" <<< $remaining_controllers
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$patch_rabbitmq" <<< $remaining_controllers	
	

7. Remove the failed node from the rabbit cluster (this assumes that the `rabbitmq-server` is no longer running on `controller2`, but this should be the case since we halted it as the first step). On any remaining controller, run the following command:

		rabbitmqctl cluster_status # show the name of the failed controller
		rabbitmqctl forget_cluster_node &#60;node> # the full rabbit name of the failed node as it appeared in the above output (including 'rabbit@..')


	Note the ID of the failed node for use in some of the clean-up steps in [Clean up the environment](#cleanup). 
8. On the seed node, execute the following command:

		# set the nova node id for use later
		failed_node_id=$(nova list --minimal | grep controller-controller0 | cut -d '|' -f 2)
		ironic_failed_node_id=$(ironic node-show --instance $failed_node_id | grep " uuid" | cut -f3 -d"|" | sed 's/\s//')

9. Reduce the number of overcloud nodes by 1 and remove the failed node from the overcloud template.

		cd $TRIPLEO_ROOT/tripleo-heat-templates/
		export CONTROLSCALE="2"
		make overcloud-ce-trickle

	The template will have been created with `controller0` and `controller1`. 

10. Change `controller0` references to `controller2`.

		sed -i 's/controller0/controller2/g' trickle/overcloud-ce-controller

11. Using Trickle, deploy the Heat template to remove the node.

		prep-for-trickle -z trickle/overcloud-ce-controller stack-update \
		    -e /root/tripleo/overcloud-env.json \
		    -t 360 \
		    -f /root/tripleo/tripleo-heat-templates/trickle/overcloud-ce-controller \
		    -P "ExtraConfig=${OVERCLOUD_EXTRA_CONFIG}" overcloud-ce-controller

	Monitor status (it might take a few minutes for the status to change to `UPDATE_COMPLETE`).

		watch -d heat stack-list

### Add a replacement controller0

1. Ensure the new node is available in Ironic.

2. Restore the original template configuration from the copy we saved earlier.

		cd $TRIPLEO_ROOT/tripleo-heat-templates/
		cp ~root/overcloud-ce-controller trickle/

3. Edit the template so that the bootstrap node remains `controller2`. 

		sed -i '/bootstrap_nodeid/,/nodeid/s/controller./controller2/' trickle/overcloud-ce-controller

	<!-- If CORE-1797 is not fixed, remove rabbit patch from above, here -->

4. Remove the rabbit patch you added in **Remove the failed controller**.

		restore_original="cp -p ~root/51-rabbitmq /opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$restore_original" <<< $remaining_controllers

5. Increase the scale parameter back to its original value.

		export CONTROLSCALE=3

6. Deploy Heat templates via trickle to provision the new node.

		prep-for-trickle -z trickle/overcloud-ce-controller stack-update \
		    -e /root/tripleo/overcloud-env.json \
		    -t 360 \
		    -f /root/tripleo/tripleo-heat-templates/trickle/overcloud-ce-controller \
		    -P "ExtraConfig=${OVERCLOUD_EXTRA_CONFIG}" overcloud-ce-controller

7. Monitor the status (it might take a few minutes for the status to change to `UPDATE_COMPLETE`).

		watch -d heat stack-list

### Reinstating controller0 as the bootstrap node 

1. On controller0, add the flag that indicates the cluster has been initialized.

		mkdir -p /mnt/state/var/lib/boot-stack/
		touch /mnt/state/var/lib/boot-stack/init-openstack.ok

3. On controller2, stop and disable the singleton services.

		stop nova-consoleauth ceilometer-alarm-evaluator ceilometer-alarm-notifier ceilometer-agent-central
		cd /var/lib/os-svc-enable-upstart/
		rm nova-consoleauth.enable ceilometer-alarm-evaluator.enable ceilometer-alarm-notifier.enable ceilometer-agent-central.enable
		rm /etc/apache2/sites-enabled/sherpa.conf

3. Run the installer script, passing in the update-overcloud parameter. 

		tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud --skip-demo

4. When the script completes successfully, the stack will be ready for use with the replacement controller. Proceed to  the section: [Clean up the environment](#cleanup).

<!--  stop  -->

### Removing and replacing controller1 {#controller1}

The following sections provide instructions on how to remove and replace a failed `controller1` node.

### Remove the failed controller

1. Make sure `controller1` is halted.

2. Configure the overcloud NTP server to one appropriate for the site.

		export OVERCLOUD_NTP_SERVER=16.110.135.123 # Use an NTP server appropriate for your environment

3. Set some environment variables (these should not need amending).

		export TRIPLEO_ROOT=~root/tripleo
		export TE_DATAFILE=$TRIPLEO_ROOT/ce_env.json
		export PATH=$PATH:$TRIPLEO_ROOT/bin:$TRIPLEO_ROOT/tripleo-incubator/scripts
		source $TRIPLEO_ROOT/tripleo-incubator/undercloudrc
		OVERCLOUD_EXTRA_CONFIG=$(hp_ced_load_passthrough.sh -v -p overcloud -x overcloud-compute)
		get_ce_env() {
		    local var=$1
		    cat ~/tripleo/ce_env.json \
		        | jq ".overcloud.${var}" \
		        | sed -e "s/\"//g"
		}
		COMPUTESCALE=$(get_ce_env computescale)
		SOSWIFTPROXYSCALE=$(get_ce_env soswiftproxyscale)
		SOSWIFTSTORAGESCALE=$(get_ce_env soswiftstoragescale)
		SWIFTSTORAGESCALE=$(get_ce_env swiftstoragescale)
		VSASTORAGESCALE=$(get_ce_env vsastoragescale)

4. Save the existing controller template prior to generating a new one.

		cp -p $TRIPLEO_ROOT/tripleo-heat-templates/trickle/overcloud-ce-controller ~root

	<!--If CORE-1797 is not fixed, we need to patch rabbit startup. here -->

5. Patch the rabbit start up:

		remaining_controllers=$(nova list \
		    | grep overcloud-ce-controller-controller \
		    | grep -v controller1 \
		    | cut -f 7 -d"|" \
		    | cut -f 2 -d"=")
		ssh_sudo="ssh heat-admin@controller_ip sudo"
		rabbit_post_configure="/opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		save_original="cp -p $rabbit_post_configure ~root/"
		patch_rabbitmq="sed -i '1aexit 0' $rabbit_post_configure"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$save_original" <<< $remaining_controllers
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$patch_rabbitmq" <<< $remaining_controllers

6. Make sure that `rabbitmq-server` is not running on `controller2` . 

7. Remove the failed node from the rabbit cluster On any remaining controller, do the following:

		rabbitmqctl cluster_status # show the name of the failed controller
		rabbitmqctl forget_cluster_node <node> # the full rabbit name of the failed node as it appeared in the above output (including 'rabbit@..')

	Note the ID of the failed node for use in some of the clean-up steps in [Clean up the environment](#cleanup). 

8. On the seed node, execute the following command:

		# set the nova node id for use later
		failed_node_id=$(nova list --minimal | grep controller-controller1 | cut -d '|' -f 2)
		ironic_failed_node_id=$(ironic node-show --instance $failed_node_id | grep " uuid" | cut -f3 -d"|" | sed 's/\s//')

9 Reduce the number of overcloud nodes by 1 and remove the failed node from the overcloud template.

		cd $TRIPLEO_ROOT/tripleo-heat-templates/
		export CONTROLSCALE="2"
		make overcloud-ce-trickle

	The template will have been created with controller0 and controller1. 

10. Change `controller1` references to `controller2`.

		sed -i 's/controller1/controller2/g' trickle/overcloud-ce-controller

11. Using trickle, deploy the Heat template to remove the node.

		prep-for-trickle -z trickle/overcloud-ce-controller stack-update \
		    -e /root/tripleo/overcloud-env.json \
		    -t 360 \
		    -f /root/tripleo/tripleo-heat-templates/trickle/overcloud-ce-controller\
		    -P "ExtraConfig=${OVERCLOUD_EXTRA_CONFIG}" overcloud-ce-controller

12. Monitor the status (it might take a few minutes for the status to become `UPDATE_COMPLETE`).

		watch -d heat stack-list

### Add a replacement controller

1. Ensure the new node is available in Ironic.

2. Restore the original template configuration from the copy we saved earlier.

		cd $TRIPLEO_ROOT/tripleo-heat-templates/
		cp ~root/overcloud-ce-controller trickle/

	<!-- If CORE-1797 is not fixed, remove rabbit patch from above. -->

3. Remove the rabbit patch you added in **Remove the failed controller**:

		restore_original="cp -p ~root/51-rabbitmq /opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$restore_original" <<< $remaining_controllers

4. Increase the scale parameter back to its original value.

		export CONTROLSCALE=3

5. Deploy Heat templates to provision the new node.


		hp_ced_install.sh --update-overcloud --skip-demo


When the script completes successfully, the stack will be available for use with the replacement controller. Continue to the section [Clean up the environment](#cleanup).

## Removing and replacing controller2 {#controller2}

###Remove the failed controller

1. Ensure controller2 is halted. 

2. Configure the overcloud NTP server to one appropriate for the site.

		export OVERCLOUD_NTP_SERVER=16.110.135.123 # Use an NTP server appropriate for your environment

3. Set some environment variables (these should not need amending).

		export TRIPLEO_ROOT=~root/tripleo
		export TE_DATAFILE=$TRIPLEO_ROOT/ce_env.json
		export PATH=$PATH:$TRIPLEO_ROOT/bin:$TRIPLEO_ROOT/tripleo-incubator/scripts
		source $TRIPLEO_ROOT/tripleo-incubator/undercloudrc
		OVERCLOUD_EXTRA_CONFIG=$(hp_ced_load_passthrough.sh -v -p overcloud -x overcloud-compute)
		get_ce_env() {
		    local var=$1
		    cat ~/tripleo/ce_env.json \
		        | jq ".overcloud.${var}" \
		        | sed -e "s/\"//g"
		}
		COMPUTESCALE=$(get_ce_env computescale)
		SOSWIFTPROXYSCALE=$(get_ce_env soswiftproxyscale)
		SOSWIFTSTORAGESCALE=$(get_ce_env soswiftstoragescale)
		SWIFTSTORAGESCALE=$(get_ce_env swiftstoragescale)
		VSASTORAGESCALE=$(get_ce_env vsastoragescale)

	<!-- If CORE-1797 is not fixed, we need to patch rabbit startup. -->

5. Patch the rabbit start up.

		remaining_controllers=$(nova list \
		    | grep overcloud-ce-controller-controller \
		    | grep -v controller2 \
		    | cut -f 7 -d"|" \
		    | cut -f 2 -d"=")
		ssh_sudo="ssh heat-admin@controller_ip sudo"
		rabbit_post_configure="/opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		save_original="cp -p $rabbit_post_configure ~root/"
		patch_rabbitmq="sed -i '1aexit 0' $rabbit_post_configure"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$save_original" <<< $remaining_controllers
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$patch_rabbitmq" <<< $remaining_controllers

6. Make sure that `rabbitmq-server` is not running on `controller2` . 

7. Remove the failed node from the rabbit cluster On any remaining controller, do the following:

		rabbitmqctl cluster_status # show the name of the failed controller
		rabbitmqctl forget_cluster_node <node> # the full rabbit name of the failed node as it appeared in the above output (including 'rabbit@..')

	Note the ID of the failed node for use in some of the clean-up steps in [Clean up the environment](#cleanup). 
8. On the seed node, execute the following command:

		# set the nova node id for use later
		failed_node_id=$(nova list --minimal | grep controller-controller2 | cut -d '|' -f 2)
		ironic_failed_node_id=$(ironic node-show --instance $failed_node_id | grep " uuid" | cut -f3 -d"|" | sed 's/\s//')

9. Reduce the number of overcloud nodes by 1 and remove the failed node from the overcloud template.

		cd $TRIPLEO_ROOT/tripleo-heat-templates/
		export CONTROLSCALE="2"
		make overcloud-ce-trickle

	<!--If CORE-2875 is not fixed, work around that by replacing invalid references to controller2 to controller1.-->

10. Replace invalid references to `controller2` to `controller1`.

		sed -i 's/controller2$/controller1/' trickle/overcloud-ce-controller

11. Using trickle, deploy the heat template to remove the failed controller.

		prep-for-trickle -z trickle/overcloud-ce-controller stack-update \
		    -e /root/tripleo/overcloud-env.json \
		    -t 360 \
		    -f /root/tripleo/tripleo-heat-templates/trickle/overcloud-ce-controller \
		    -P "ExtraConfig=${OVERCLOUD_EXTRA_CONFIG}" overcloud-ce-controller

12. Monitor status (it might take a few minutes for the update to complete).

		watch -d heat stack-list


### Add a replacement controller

1. Ensure the new node is available in Ironic.

	<!--If CORE-1797 is not fixed, remove rabbit patch from above. -->

2. Remove the rabbit patch you added in **Remove the failed controller**:

		restore_original="scp -p ~root/51-rabbitmq /opt/stack/os-config-refresh/post-configure.d/51-rabbitmq"
		xargs -d" " -n 1 -I controller_ip $ssh_sudo "$restore_original" <<< $remaining_controllers

3. Increase the scale parameter back to its original value and redeploy the overcloud.

		cd $TRIPLEO_ROOT
		export CONTROLSCALE=3
		tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud --skip-demo

When the script completes successfully, the stack will be ready for use with the replacement controller. Proceed to the section [Clean up the environment](#cleanup).



## Clean up the environment after controller removal and replacement {#cleanup}

1. Remove the failed node from Ironic.

		# show the failed node in ironic (using the failed_node_id variable from above)
		ironic node-show --instance $failed_node_id
		# remove the failed node from ironic, using the uuid
		ironic node-delete $ironic_failed_node_id

2. Remove the Nova service entries for the failed controller. This should be done on the new controller.

		# display service list for controllers, including only the failed ones (replace controllerX with controller0, controller1, or controller2 as appropriate)
		nova-manage service list | grep controllerX | grep XXX
		# set a variable to the failed host name from above
		failed_host=&#60;name>
		# remove the failed node
		nova-manage service disable --service=nova-conductor --host=$failed_host
		nova-manage service disable --service=nova-cert --host=$failed_host
		nova-manage service disable --service=nova-scheduler --host=$failed_host
		nova-manage service disable --service=nova-consoleauth --host=$failed_host

3. Remove the failed node from Icinga monitoring. Run the following on the undercloud.

		cd /etc/check_mk/conf.d
		# when running the command below, replace <ip of failed controller> with the ip addressrm <ip of failed controller>.mk
		rm <ip of failed controller>.mk
		# show the monitored hosts
		check_mk --list-hosts

4. Replace the node in Ironic

		ironic node-create -d pxe_ipmitool -p cpus=<CPUS> -p memory_mb=<memory> -p local_gb=<gb> -p cpu_arch=amd64 -p capabilities=<ROLE> -i ipmi_address=<IP> -i ipmi_username=<USER> -i ipmi_password=<user_pwd> 

The procedure to remove and replace the controller is now complete.

<!-- left off here 841  -->
#Controller troubleshooting 

* If a Heat stack-update appears to be taking a long time (30 minutes or longer), see [HP Helion OpenStack&#174; Troubleshooting Controller Nodes](/helion/openstack/1.1/services/troubleshooting/controller/)

* If you receive warnings from Icinga after node removal, see [Troubleshooting Node Removal](/helion/openstack/1.1/services/troubleshooting/overcloud/)



<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593;</a>
