---
layout: default
title: "HP Helion OpenStack&#174; HP Helion Ceph-Glance Interoperability"
permalink: /helion/openstack/1.1/ceph-hp-helion-openstack-glance-ceph-interoperability/
product: commercial
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.1
role1: Storage Engineer
role2: Storage Architect 
role3: Storage Administrator 
role4: Storage Engineer
role5: Service Developer 
role6: Cloud Administrator 
role7: Application Developer 
authors: Paul F

---
<!--PUBLISHED-->


<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>
<!--
<p style="font-size: small;"> <a href="/helion/openstack/1.1/install-beta/kvm/">&#9664; PREV</a> | <a href="/helion/openstack/1.1/install-beta-overview/">&#9650; UP</a> | <a href="/helion/openstack/1.1/install-beta/esx/">NEXT &#9654;</a> </p>
-->


# HP Helion OpenStack&#174; 1.1 Glance-Ceph Interoperability

Image Operations (Glance), Volume Storage (Cinder) and Compute (Nova)  files are stored on Ceph RADOS Block Device (RBD). The benefit of storing Glance images, Cinder volume, and Nova nodes on RDB are:

* Snapshots
* Live migration
* Recovery
* Copy-on-write Clones from Glance images to Cinder volumes


For Glance-Ceph integration, the Helion OpenStack Ceph Configuration service performs the following steps. For more details about the process of integrating a Ceph storage cluster with Glance, refer to  [Ceph documentation](http://ceph.com/docs/master/rbd/rbd-openstack/?highlight=openstack%20glance)

The following steps are automatically performed when you download and execute `Ceph_client` script from the controller and compute nodes as per the readme file in the tar file.

1. Create a new Ceph pool to store Glance images.

		ceph osd pool create &#60;glance pool name> &#60;pg-num>

	Example:

		ceph osd pool create helion-ceph-glance 100

2. Change `glance-api.conf` to reference the Ceph rbd storage only on overcloud controller nodes. 

	The following sample displays the `glance-api.conf` references to the Ceph rbd storage only on overcloud controller nodes. 

		# For ceph integration
		
		default_store = rbd
		rbd_store_user = glance
		rbd_store_pool = helion-ceph-glance
		show_image_direct_url = True
		known_stores = glance.store.filesystem.Store, glance.store.swift.Store, glance.store.rbd.Store
		
		#Enable debug for troubleshooting only
		#debug = True
		#verbose = True

3. Create symbolic or softlinks to the relevant files on overcloud controller nodes.

		ln -s /usr/lib/python2.7/dist-packages/rados* /opt/stack/venvs/openstack/lib/python2.7/site-packages/.
		ln -s /usr/lib/python2.7/dist-packages/rbd* /opt/stack/venvs/openstack/lib/python2.7/site-packages/.

5. Restart Glance services on all the overcloud controller nodes.

		service glance-api restart
		service glance-reg restart
		glance-manage db_sync

6. Create a sample Glance RAW image on any controller nodes. 

		glance image-create --name RImg --is-public=true --disk-format=raw --container-format=bare --file cirros-0.3.2-x86_64-disk.raw


	Raw data format is used with RBD for instant image snapshots and protection. For more details, refer to [ceph documentation](http://ceph.com/docs/master/rbd/qemu-rbd/?highlight=raw)

	For the image conversion, use a conversion tool like qemu-img to convert one image format to another. 
	
	For example:

		qemu-img convert -f {source-format} -O {output-format} {source-filename} {output-filename}
		
		qemu-img convert -f qcow2 -O raw cirros-0.3.2-x86_64-disk.img cirros-0.3.2-x86_64-disk.raw
		
		glance image-create --name RImg --is-public=true --disk-format=raw --container-format=bare --file cirros-0.3.2-x86_64-disk.raw

7. Ensure that the uploaded Glance image is available in the Dashboard (Horizon) UI and correctly stored in the appropriate pool in Ceph.

		rbd ls -l <glance pool name>
		
		glance image-list

	You can also login to Horzion UI and view the changes.

8. If problem occur in any of the above steps, do the following:
	* Enable logging in `glance-api.conf`  
	* Restart Glance services and re-run the problem step. 
	* Collect Glance debug logs in the  `/var/log/glance` directory 
	* Contact HP support team for inputs. 


###Ceph Glance Clone Copy on Write

To clone an image quickly and easily, Ceph implements Clone Copy on Write from the Protected Snapshot. During the image import in Glance, images are snapshotted and protected, clones are quickly created from the snapshot and a volume is created from an image. For more details, see [http://ceph.com/docs/master/dev/rbd-layering/?highlight=rbd%20layering](http://ceph.com/docs/master/dev/rbd-layering/?highlight=rbd%20layering).


The following steps are automatically performed when you download and execute `Ceph_client` script from the controller and compute nodes as per the readme file in the tar file.

1. Edit the `cinder.conf` file on all overcloud controller nodes.

		glance_api_version=2

2. Restart the Cinder services on all overcloud controller nodes.

		service cinder-volume restart
		service cinder-scheduler restart
		service cinder-api restart
	<!--
	3. To create Glance image, enter:

		glance image-create

	Note that Clone COW is achieved when the image is in RAW format. To convert from one format to another, use a onversion tool like qemu-img. 

	For example:

		qemu-img convert -f {source-format} -O {output-format} {source-filename} {output-filename}
		qemu-img convert -f qcow2 -O raw cirros-0.3.2-x86_64-disk.img cirros-0.3.2-x86_64-disk.raw
		glance image-create -??-name RImg -??-is-public=true -??-disk-format=raw -??-container-format=bare -??-file cirros-0.3.2-x86_64-disk.raw

	4. Create the Cinder volume from the Glance image created on step 1 on any controller node.

		cinder create -image-id <glance image id> -??-display-name RVol 2

	5. Ensure that the Cinder volume created is available at `rbd` pool

		rbd ls -l <cinder pool name>
		
		cinder list

	6. Track clones to demonstrate the copy-on-write feature by first listing snapshots of Glance images and then listing the children of the snapshot

		rbd -??-pool <glance pool name> snap ls <glance image id>
		
		rbd -??-pool <glance pool name> children -??-image <glance image id> -??-snap <snap name>
		
		rbd children <glance pool name>/<glance-image id>@<snap name>
-->
7. If you have any problems in any of the above steps, do the following:

	* Enable logging in `glance-api.conf` and `cinder.conf`. 
	* Restart Glance and Cinder services and re-run problem step. 
	* Collect Glance debug logs in `/var/log/glance` directory and Cinder debug logs in `/var/log/upstart` directory.
	*  Contact HP support team for inputs.
	
## Next Steps

[Ceph Cinder Storage]( /helion/openstack/1.1/ceph-hp-helion-openstack-cinder-storage/)



<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>
