---
layout: default
title: "Open Source and Third-Party Software License Agreements"
permalink: /helion/devplatform/3rd-party-license-agreements/
product: devplatform

---
<!--PUBLISHED-->

<script> 

function PageRefresh { 
onLoad="window.refresh"
}

PageRefresh();

</script>

<!--
<p style="font-size: small;"> <a href="/helion/openstack/eula/">&#9664; PREV | <a href="/helion/openstack/">&#9650; UP</a> | <a href="/helion/openstack/siteindex/">NEXT &#9654;</a> </p>
-->

<h1 id="hp-helion-openstack-beta-open-source-and-third-party-software-license-agreements">HP Helion Development Platform Open Source and Third-Party Software License Agreements</h1>

The Open Source and Third-Party Software License Agreements for HP Helion Development Platform are available as a PDF download

 <a href="http://g867c39a921f179b9eb3ba7424144b70a.cdn.hpcloudsvc.com/source/DP_Thirdparty v2.pdf">Download the PDF document.</a>


---
layout: default-devplatform
title: "Quick Start Developer Trial"
permalink: /helion/devplatform/ALS-developer-trial-quick-start/
product: devplatform

---
<!--PUBLISHED-->

#HP Helion Development Platform: Quick Start Developer Trial#
<a name="top"></a>
This document explains the process to install and configure Helion Development Platform Application Lifecycle Service (ALS) in the public cloud. This is the fastest way to create a sandbox environment to evaluate the HP Helion Development Platform.

ALS Cluster creation is enabled by using an ALS Constructor, a Virtual Machine (VM) image pre-loaded with configuration and orchestration software.  This image is available in every public cloud account.

After you create your public cloud account, you will use the ALS Constructor to configure and create your cluster.  At the end of the process, you will have an endpoint URL that you can use to deploy your apps.
The document covers the following sections:

- [Prerequisites](#pre)
- [Installing your Quick Start Developer Trial](#install)
- [After you Install](#after)

##Prerequisites {#pre}
Before you start the installation and configuration process, ensure that you have a user account on an <a href="https://horizon.hpcloud.com/register" target="_blank">HP Helion Public Cloud</a>. Take advantage of the <a href="http://www.hpcloud.com/cloud-credit" target="_blank">trial offer</a> to get started at no cost. You will be asked to provide a phone number for verification and a credit card to keep on file. Please keep your username and password handy as you will be entering them in the steps below.

##Installing your Quick Start Developer Trial {#install}
1. Log into the Horizon Console using the HP Helion Public Cloud username and password that you created during signup.
2. Create a new project, if you don't already have one.
3. If you have not already created a network with public internet access inside of your account, then you will need to do so as your ALS cluster will need such a network.  This step only needs to be performed one time as part of the initial configuration of your HP Helion Public Cloud account.  To create a network, please follow [these directions](/hpcloudconsole/#Createanetwork).
4. Change to the **US East Region** in the Horizon Console. <br><img src="media/quickstartA.png"/><br><br>

 
5. Create a new **Compute** instance in the US East region.<br><img src="media/quickstartB.png"/><br><br>
6. Click on the  **+ Launch Instance** button to open the launch instance dialog.<br><img src="media/quickstartC.png"/><br><br>

7. On the resulting dialog, fill out the details and select **Boot from image** to enable selection of the Constructor VM.  The selections shown below are good defaults.<br><img src="media/quickstartD.png"/><br><br>
 
8. Select the **HP Helion Development Platform Application Lifecycle Service Installer** option from the images list. Note that the version number at the end of the image name may vary as newer versions are released.<br><img src="media/quickstartE.png"/><br><br>

9. Next, you will need to provide a key pair for this VM in the **Access & Security** section. If a key pair has already been created and imported, skip to step 10. If a key pair has not been created and imported, create one:
	- By clicking on the **+** (plus) button and following the instructions in the resulting dialog (pictured below).<br><img src="media/quickstartF.png"/>
	- By using a tool such as PuTTY (on a PC) and following the [instructions here](http://kb.siteground.com/how_to_generate_an_ssh_key_on_windows_using_putty/).
1. Click **Import Key Pair** and then the **Launch**   button. <br>For more details on key pairs in the public cloud, please read [the HPCloud Community article](http://community.hpcloud.com/article/managing-your-key-pairs-0).<br><img src="media/quickstartG.png"/><br><br>
2. Now we can assign a floating IP address to the installer VM that you just created.  You can do that from the **More** button under **Actions**.  Choose any available IP address in the resulting dialog and make note of it for the next step. When you're done, click the **Associate** button.<br><img src="media/quickstartH.png"/><br><br>
 
3. SSH into the installer VM with the user **debian** and the SSH key you selected when you started the virtual machine. You can do that on a Mac/UNIX machine with the ssh command. In this example, you named your private key *cloud.key* and you chose an IP address of 15.126.234.185

		ssh -i cloud.key debian@15.126.234.185




1.  Run the configuration script to create your cluster.conf configuration file using the following command:

		python ./trial_configure.py

1.  You'll be prompted for configuration information that will be used to build your developer trial.
	- **OpenStack&reg; Username** This is the username for your HP Public Cloud account.
	- **OpenStack Password** This is the password for your HP Public Cloud account.
	- **Tenant ID** If you have multiple values, select one.
	- **Network ID** If you have multiple values, select one.
	- **Image ID** If you have multiple values, select one.
	- **Cluster Prefix** Give your developer trial a prefix.
	- **Services** Enter a comma-separated list of services (e.g. mysql, redis, rabbit).
	- **First user's admin email** The login account for your new developer trial.
	- **First user's password** The password for your new developer trial.

1. After you have answered the script's question, the values are saved to the *cluster.conf* configuration file on the local filesystem. The script will then ask if you want to proceed with the creation of your trial cluster.<br><img src="media/quickstartH.png"/>
	- If you specify **Y**, the cluster creation process will begin.
	- If you specify **N**, you will be returned to the OS prompt. You can subsequently run the cluster creation by using the following command:

			python ./assemble.py

3. After the assemble script creates the cluster, it presents you with the ALS Console URL with which you can login to your browser. This URL will have the form *api.<IPAddress>.xip.io*  For example, *api.255.255.255.255.xip.io* <BR> The cluster will be running on a single virtual machine in your account that will have a name ending in "-core" prefixed with 5 random characters.  For example: **acxpq-core**. 
4. If an error occurs or you want to terminate the cluster, run the following command. This command deletes your VMs, releases the floating IP addresses, and removes the cluster security groups: 

		python ./assemble.py -D 

5. Once your install is complete, and if you do not want to use the automated tear-down capabilities of the Constructor, you can terminate the Constructor VM.

##After you install {#after}

Once the installation completes, you can load the ALS Console at the URL obtained in step 15 using the first username and first password you specified in step 13. After you log into the Console, you can access the [ALS User Documentation](/als/v1/user/) for instructions to create users and deploy applications.
You may be presented with text that warns or notes that the site has a self-signed certificate. When loaded in a browser, you may get a display indicating that this sight is not *trusted*.


Your infrastructure is now ready for development. You can find some simple sample development tasks in our [workbook](/helion/devplatform/appdev/) section. This area will will be updated continuously with more languages and samples, so please stop by often to see the newest content.
 
----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*


---
layout: default-devplatform
title: "HP Helion Development Platform Documentation for Application Developers"
permalink: /helion/devplatform/appdev/
product: devplatform

---
<!--PUBLISHED-->
#Resources for Application Developers

HP has created a series of small, simplified sample applications to help you understand and exercise the Development Platform services.

Each sample builds on the previous one and all source code is provided for you to build, deploy, and take apart. Each sample is provided in multiple languages.
 
##Prerequisites - Before you begin
In order to download and deploy these sample applications, you must have the necessary framework installed and configured.

- HP Helion OpenStack&reg; [cloud deployed](/helion/openstack/install/overview/)
- Application Lifecycle Service [Cluster](/helion/devplatform/deploy) available with MySQL and RabbitMQ enabled.
	- You can also quickly setup a cluster in the free and publicly available Helion cloud as part of the [Quick Start Developer Trial](/helion/devplatform/ALS-developer-trial-quick-start/): 
- Logon and password credentials for the cluster.
- Access to the [Helion command-line interface (CLI)](/als/v1/user/client/)
- (Optional) Access to the Eclipse [deployment plugin](/helion/devplatform/eclipse/).

##Sample code {#sample}
For best results, work with each sample in the order in which they are provided, as each one builds on the knowledge provided in the previous sample. 
###Java {#java}
1. [Hello World](/helion/devplatform/workbook/helloworld/java/) <br>
The Hello World sample is as simple as it gets: Hello World! 

2. [Working with Databases](/helion/devplatform/workbook/database/java/) <br>
Create a database and execute a query against it. <br>

3. [Working with Messaging](/helion/devplatform/workbook/messaging/java/)<br> Enter, send, and display a brief message.<br> 

More Helion [Java](/als/v1/user/deploy/languages/java/) references.

###Node {#node}
1.  [Hello World](/helion/devplatform/workbook/helloworld/node/)<br>
The Hello World sample is as simple as it gets: Hello World! 

2. [Working with Databases](/helion/devplatform/workbook/database/node/) <br>
Create a database and execute a query against it.<br> 


3. [Working with Messaging](/helion/devplatform/workbook/messaging/node/)<br> Enter, send, and display a brief message.<br> 

More Helion [Node](/als/v1/user/deploy/languages/node/) references.
 
###PHP {#PHP}
1.  [Hello World](/helion/devplatform/workbook/helloworld/php/) <br>
The Hello World sample is as simple as it gets: Hello World! 

2. [Working with Databases](/helion/devplatform/workbook/database/php/) <br>
Create a database and execute a query against it.<br>

3. [Working with Messaging](/helion/devplatform/workbook/messaging/php/)<br> Enter, send, and display a brief message.<br> 

More Helion [PHP](/als/v1/user/deploy/languages/php/) references.

###Other references
- [Installing the Marketplace](/helion/devplatform/marketplace)
- [ALS command-line interface (CLI) reference](/als/v1/user/reference/client-ref/#command-ref-client)
- [Application Lifecycle Service (ALS) User's Guide](/als/v1/user/)
- [Remote Debugging](/als/v1/user/deploy/app-debug/)
- [The Management Console](/als/v1/user/console/)
- [Logs, Streams, and Drains](/als/v1/user/deploy/app-logs/)

###Best practices

- [The 12-Factor App](http://12factor.net/)
- [Tips from Cloud Foundry&trade;](http://docs.cloudfoundry.org/devguide/deploy-apps/prepare-to-deploy.html)

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation or the OpenStack community.*
---
layout: default-devplatform
title: "Connecting the Database Service with ALS"
permalink: /helion/devplatform/connectdatabase/
product: devplatform

---
<!--PUBLISHED-->

#Connecting the Database Service with the Application Lifecycle Service
If a more durable or scalable MySQL database service is needed, ensure your ALS cluster is configured to use a database instance or master/slave pair provided by the Database Service. This is an option at cluster create time.

<img src="media/databaseALS.png"/>

ALS cluster create wizard

##Configuration {#configure} 
Alternatively, if the Database Service was not integrated with the cluster at the time of cluster creation, the administrator of the ALS cluster can switch from the unmanaged MySQL service to the managed Database Service using the following kato commands:

1. Enable the root user on the database instance you want to join to the ALS cluster
2.	SSH to the ALS cluster instances and use the kato admin client. 
3.	Set the endpoint details including hostname, port, root user, and password:
	
		$ kato config set mysql_node mysql/host 10.5.120.101
		$ kato config set mysql_node mysql/port 3306
		$ kato config set mysql_node mysql/user root
		$ kato config set mysql_node mysql/pass CorrectHorseBatteryStaple
1. Increase the timeout settings to make the [*thin*](http://code.macournoyer.com/thin/) mysql\_gateway connect reliably to the database instance. 
2. Run the following commands:

    	$ kato config set mysql_node connection_wait_timeout 100
    	$ kato config set mysql_node keep_alive_interval 60

The way in which you deploy applications does not change between the managed and unmanaged versions of the MySQL service. A developer connects to and interacts with the MySQL database in exactly the same way regardless of which service is used.

The benefits of the unmanaged service include a lighter footprint (fewer virtual machines) and no dependency on the Database Service being configured and available. The managed service provides full lifecycle management and scalability, capabilities not found in the unmanaged service.

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*


 
---
layout: default-devplatform
title: "Working with the Database Service"
permalink: /helion/devplatform/createdatabase/
product: devplatform

---
<!--PUBLISHED-->

#Working with the Database Service 
The database service provides lifecycle services for MySQL database instances. Lifecycle services include provisioning, configuration, patching, backups, restores, and monitoring that can be administered from either a CLI interface, RESTful APIs or the Horizon dashboard. 

These instances can then be utilized by your applications to provide standard datastore/back-end functionality. <!--For more information on database access please refer to //Document: Database access.--> 

The following topics explain how to create and manage a database:

- [Create a database instance](#create)
- [Create a database backup](#backup)
- [Replicate a database](#replicate)
- [Attach a Floating IP](#floatIP)

##Prerequisites
1. Install the [HP Helion Development Platform](/helion/devplatform/install/). 
2. [Configure](/helion/devplatform/install/#install-database) the database service.

##Create a database instance {#create}
1. Log into the Horizon console.

2. Under your project, open the Database panel and then click the **Instances** tab. <br><img src="media/createDBinstance1.png"/>

2. Click **Launch Instance**.

3. In the **Details** tab, specify the following options: 
	- **Instance Name** - the name of the MySQL instance to create 
	- **Flavor** - the size of the instance to host the database on<br><img src="media/createDBinstance2.png"/>
	- **Volume Size** - the size of the volume to host the data on (in GB). Note: this **cannot** be changed later.
	- **Datastore** - the MySQL database version to create
	- **Availability Zone** (optional) the availability zone that the database will be created in.<br><img src="media/createDBinstance1.png"/>

4.	Under the **Networking** tab, specify the network to associate the database instance with. This is required and should be the same network that any application that accesses the database is on. <br><img src="media/createDBinstance3.png"/>
5.	Optional - Specify the initial database to create on the database instance. This option can be used to pre-populate the instance with a database and a user for that database.  <br><img src="media/createDBinstance4.png"/>
6.	Click **Launch**.
7.	In the **Database** tab, open the **Instances** panel. This panel displays the status of the newly created database instance. <br><img src="media/createDBinstance5.png"/>
8.	Once the database instance has reached **Active** status, the instance is ready to use.

##Create a database backup<a name="backup"></a>
The following section will demonstrate how to back up an existing database instance. This will take a backup of the entire database instance. If necessary, the backup can be restored to a new instance at a later time. 

1.	Log in to the Horizon console.
2.	Under your project, open the **Database** panel and then click the **Instances** tab.
3.	A list of active database instances will be displayed. Identify the database instance to back up and click **Create Backup** next to that instance.<br><img src="media/createDBinstance6.png"/>	
3.	In the **Backup Database** dialog, specify the following information:
	- **Name** - the name of the backup to create. This name will help you identify the backup in the future.
	- **Database Instance** - The database instance that will be backed up.
	- **Description** - a text description of the backup (optional).
	- **Parent Backup** - if a previous backup of this database instance exists. it is possible to take an incremental backup. An incremental backup will process faster because it only stores the differences between the two. Select the previous backup if an incremental backup is desired.<br><img src="media/createDBinstance7.png"/>
4.	Click **Backup**.
5.	In the **Database** panel, click the **Backups** tab to view all existing backups, including the newly-created backup.<br><img src="media/createDBinstance8.png"/>

##Replicate a database {#replicate}
Replicating a database creates a slave for your instance that replicates every action on the master. Creating a database instance that is automatically replicated results in more durable data and can prevent data loss in a disaster scenario.

###Prerequisites###
To follow this guide, you must have already [created](#create) a database instance that will be the master database.  

###Steps###
1.	Log in to the Horizon console.
2.	Under your project, open the **Database** panel and then click the **Instances** tab.<br><img src="media/createDBinstance9.png"/>	
2.	Click **Launch Instance**.
3.	In the **Details** tab, specify the following options:
	- **Instance Name** - the name of the MySQL instance that will be the slave instance.
	- **Flavor** - the size of the instance to host the slave database on.
	- **Volume Size**- the size of the volume to host the data on (in GB). Note: this **cannot** be changed later. 
	- **Datastore** - the MySQL datastore version to create.
	- **Availability Zone** (optional) - the availability zone that the database will be created in. For replication, it is important for this to be in a different availability zone than the master.<br><img src="media/createDBinstance10.png"/>
4.	Under the **Networking** tab, specify the network to associate the database instance with. This is required and should be the same network that any application that accesses the database is on.<br><img src="media/createDBinstance11.png"/>
5.	Click the **Advanced** tab  and then use the **Replicate from Instance** drop-down to select the master instance to replicate.<br><img src="media/createDBinstance12.png"/>
6.	Click **Launch** to create the replica.<br><img src="media/createDBinstance13.png"/>

##Attaching a Floating IP to the Database Instance {#floatIP}
It is possible to attach a floating IP address to a database instance – this will make it possible to access your instance from outside of your cloud environment. 

To create a database with a floating IP address follow these steps from the command line. Note the following instructions require that you use the Trove CLI to create a database instance.

For more information on using the Trove CLI, refer to the [More Resources](#more) section at the end of this guide.

1.	Pre-provision a port on the network that the instance will be attached to using the neutron CLI. Note down the port-id of the port created:
	
		$ neutron port-create <network-id>
	
2.	When creating the trove instance pass in the port id as the nic parameter:
	
		$ trove create <name> <flavor-id> --size <size> --nic port-id=<port-id>
	
6.	Create a Floating IP using neutron and attach it to the port provisioned in step 1:
	
		$ neutron floatingip-create <floating-network>
		$ neutron floatingip-associate <floating-ip-id> <port-id>

##More Resources {#more}

- More information on [Trove](http://docs.openstack.org/developer/trove/).
- More information on [using the Trove CLI]( https://community.hpcloud.com/article/creating-and-configuring-database-instance) to create a database instance.

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*


 
---
layout: default-devplatform
title: "Deploying the Application Lifecycle Service"
permalink: /helion/devplatform/deploy/
product: devplatform

---
<!--PUBLISHED-->
#HP Helion Development Platform: Configuring and Deploying an Application Lifecycle Service Cluster
This document explains the process to configure and deploy an Application Lifecycle Service (ALS) cluster from the Horizon user interface.

The document covers the following sections:

- [Prerequisites](#prereq)
- [Configuring and Deploying  an ALS Cluster](#configure)

##Prerequisites {#prereq}
You need to have [installed](/helion/devplatform/install/) the Helion Development Platform.

##Configuring an ALS Cluster {#configure}
1.	In the Horizon UI, from the **Project** tab, open the **Application Lifecycle Service** tab, and select the **Clusters** sub-tab.<br><img src="media/ALSConfig1.png"/>
 
2.	Click on the **Create Cluster** button to bring up the **Create Cluster** dialog.<br><img src="media/ALSConfig2.png"/>
 
3.	Fill out required fields in the Details tab of the Create Cluster dialog, including
	- **Title** - name of cluster
	- **Prefix** - DNS acceptable hostname string (not fully qualified DNS name) used to name the virtual machines created for the cluster.
	- **Admin Email**
	- **Admin Password**
	- **Availability Zone** - where the cluster will be created.
	- **DEA flavor** - [Droplet Execution Agents (DEAs)](http://docs.cloudfoundry.org/concepts/architecture/execution-agent.html) are responsible for running and staging applications in ALS. DEA flavors specify different amounts of RAM available per DEA instance, ranging from 0.5GB to 16GB. <br>**Note**: ALS DEA Nodes must be *m1.medium* or larger. Sizes *m1.tiny* and *m1.small* are too small to support the ALS Virtual Machine Image and will trigger an error state.
	- **DEA Instance Count** - the number of DEA instances to use in the cluster.
	- **Key Pair** - required for authentication.

4.	Click on the **Networking** tab of the Create Cluster dialog and drag an available network to the **Selected Networks** area.<br><img src="media/ALSConfig3.png"/>

5.	Select the **Application Services** tab of the **Create Cluster** dialog, and choose the application services to enable in the cluster.<br><img src="media/ALSConfig4.png"/>

6.	Select the **Database** tab of the **Create** **Cluster** dialog, and choose the databases to enable in the cluster. Detailed notes on how to create or connect to an OpenStack&reg; MySQL database can be found [here](/helion/devplatform/connectdatabase/). <br><img src="media/ALSConfig5.png"/>
 
7.	Click on the **Create** button. You will see the cluster building as shown below.<br><img src="media/ALSConfig6.png"/>
 
8.	Once the cluster has been built, you can access it by clicking on the URL of the created cluster, which can be reached in the **Clusters** view or by the **Cluster Details** page. <br><img src="media/ALSConfig7.png"/>
 
1. The [Application Lifecycle Service Documentation ](/als/v1/) provides an overview of how to administer and use the configured cluster, which opens up in a separate tab and requires the admin credentials set in step 3 to access and provision.

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
title: "Using the Eclipse Deployment Plugin"
permalink: /helion/devplatform/eclipse/
product: devplatform

---
<!--PUBLISHED-->
#Using the Eclipse Development Plugin
If you're building apps in Eclipse, use this plugin to configure, package, and deploy your app directly to HP Helion Development Platform.

Follow the steps outlined in this document to get the plugin up and running and to deploy one of the sample apps.

Before you begin, we recommend having [Eclipse IDE for Java EE developers](https://www.eclipse.org/downloads/packages/eclipse-ide-java-ee-developers/lunasr1) installed along with the Java Runtime Environment and [JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you'd like to deploy the Java samples we provide.

##Installation

1. Open the Eclipse IDE and install the plugin through the **Eclipse Marketplace** dialog.  You can find this dialog by clicking on **Help** and then **Eclipse Marketplace**.<br><img src="media/eclipseA.png"/>
2. Type in the text **Helion** and hit **go** to find the Helion Eclipse plugin in the marketplace.
3. Click on **Install** and follow the prompts to install the **HP Helion Development Platform Eclipse Plugin**.<br><img src="media/eclipse2.png"/>
4. Once the packages are discovered, ensure **HP Helion Development Platform** is checked and click **Confirm**.<br><img src="media/eclipse3.png"/>
3. Accept the license agreement and Finish the wizard.
4. You will be prompted to restart Eclipse.  
##Setup/Configuration

1. Once Eclipse has reloaded, open the Servers window by navigating to Window-> Show View-> Servers. Note that if you have a different version of Eclipse, you might need to go to Window -> Show View -> Other -> Servers.<br><img src="media/eclipse4.png"/>
2. Launch the HP Helion Development Platform plugin by clicking on the **Add New Server** link in the Servers window.  
2. Select **HP Helion Development Platform** from the tree view and click **Next**.<br><img src="media/eclipse5.png"/><img src="media/eclipse6.png"/>
3. Add a new Cloud URL by hitting the Manage Cloud button.  Enter the URL of your ALS cluster and give it a name. If you don't have an ALS cluster set up, the fastest way to create one is to use the [Quick Start Developer Trial](/helion/devplatform/ALS-developer-trial-quick-start/) in the public cloud.<br><img src="media/eclipse7.png"/>
- **Note**: You may receive a warning that the peer is not authenticated, this is expected behavior as ALS images use a self-signed certificate. Select Yes when prompted with this error message.
	<img src="media/eclipse8.png"/>
4. Enter the credentials used to access your ALS cluster in the resulting dialog and then click **Validate Account** to ensure that the plugin can access the URL.
	- **Note**: If you encounter issues validating the connection, ensure that your proxy settings are configured correctly, and that you have access to the ALS cluster endpoint. Contact your IT Administrator for more help regarding network settings and trouble shooting.
  	<img src="media/eclipse8.png"/>
6. Note that you might get a warning about the site using a *self-signed certificate*.
6. Click **Next** to list your organizations and spaces. Pick an organization and space to work with in this connection and click **Yes** to import them into the IDE.  Click **Finish**.  If you do not have an organization or space set up, please create those through your ALS console by visiting the endpoint URL in a browser window.
6. Now you should see **Helion Development Platform** as a configured Server in your IDE.  You can explore the apps that have been deployed already, or continue reading to learn how to deploy a sample app.

##Usage
In order to demonstrate how the plugin works, we'll use a simple Java sample app that connects to a MySQL service.  If you'd like to follow along, [download and install](https://github.com/HelionDevPlatform/helion-mysql-java) the sample on your development machine.  If not, please skip the following 5 steps.

1. Start by adding a new project. Right-click on Project Explorer and select **New** > **Dynamic Web Project**. Name the project **MySQLSample** and then click **Finish**.<br><img src="media/eclipse9.png"/>
3. Right-click the new MySQLSample project and import the sample app by clicking on **Import** > **Import**.<br><img src="media/eclipse10.png"/>
4. Then import the sample app through your preferred method.  In this case we'll import from a directory on the file system.  Make sure that you click on the checkbox to import all files in the directory. Then click **Finish**.<br><img src="media/eclipse11.png"/>
5. If you'd like to modify the sample and build it locally, ensure that all references can be resolved.  This sample uses javax.servlet and net.sourceforge.argo.  Note that they are declared in the POM.xml file.  To resolve these references, navigate to the files with reference warnings and click on the red squiggle.  Alternatively, if you have [Maven installed](http://www.eclipse.org/m2e) in Eclipse, you can build with Maven to resolve the references.<br><img src="media/eclipse12.png"/>
6. For this sample, you also need to import two external jar files.  You can find the javax.servlet.* modules in the Java EE SDK under the Glassfish directory.  The Argo modules can be downloaded [here](http://argo.sourceforge.net/downloads.html).<br><img src="media/eclipse13.png"/>

###Deploy sample
Now that our Sample app is set up, let's deploy it using the Helion Development Platform plugin.  

1. Right-click the project in Project Explorer and select Configure > Enable as Cloud Foundry App.<br><img src="media/eclipse14.png"/>
2. We'll deploy this app to the Helion Development Platform by right-clicking on the project and selecting **Run As** > **Run on Server**.<br><img src="media/eclipse15.png"/>
2. Select **Helion Development Platform** and click **Next**.  You can check the box to skip this step in future deployments.<br><img src="media/eclipse16.png"/>
3. Next specify a name for your app and optionally pick a specific custom buildpack.  You can save these settings to your manifest if you'd deploy using the command-line tools in the future.  Since this is a standard Java applet, we'll stick with the default buildpack that is built into Helion Development Platform.<br><img src="media/eclipse17.png"/>
4. You can see the deployment progressing in the console.<br><img src="media/eclipse18.png"/>

Once your app is deployed, you can use the plugin to interact with it directly from Eclipse.  You can select Show Console to bring up the ALS console.  You can view the app in the browser by selecting Open Home Page and you can also stop/restart/remove it.<br><img src="media/eclipse19.png"/>

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default
title: "HP Helion Development Platform Software License Terms" 
permalink: /helion/devplatform/eula/
product: devplatform

---
<!--PUBLISHED-->

<!--
<p style="font-size: small;"> <a href="/helion/openstack/glossary/">&#9664; PREV | <a href="/helion/openstack/">&#9650; UP</a> | <a href="/helion/openstack/3rd-party-license-agreements/"> NEXT &#9654;</a> </p>
-->

# HP Helion Development Platform Software License Terms

- [Part 1: HP End User License Agreement](#eula)
- [Part 2: Additional License Authorizations for Software](#auth)
- [Part 3: Ancillary and Open Source Software for Software](#ancilliary)

##  Part 1: HP End User License Agreement {#eula}

**1. Applicability.** This end user license agreement (the "Agreement") governs the use of accompanying HP Helion Development Platform Software ("Software"), unless it is subject to a separate agreement between you and Hewlett-Packard Company and its subsidiaries ("HP"). By downloading, copying, or using the Software you agree to this Agreement.

**2. Terms.** This Agreement includes supporting material accompanying the Software or referenced by HP, which may be software license information, additional license authorizations, software specifications, published warranties, supplier terms, open source software licenses and similar content ("Supporting Material"). Additional license authorizations are below and at [HP Helion Development Platform Open Source and Third-Party Software License Agreements](/helion/devplatform/3rd-party-license-agreements/).

**3. Authorization**. If you agree to this Agreement on behalf of another person or entity, you warrant you have authority to do so.

**4. Consumer Rights.** If you obtained Software as a consumer, nothing in this Agreement affects your statutory rights.

**5. Electronic Delivery.** HP may elect to deliver Software and related software product or license information by electronic transmission or download.

**6. License Grant.** If you abide by this Agreement, HP grants you a non-exclusive, non-transferable license to use one copy of the version or release of the accompanying Software for your Internal Use only; this license is subject to any specific software licensing information that is in the Software product or its Supporting Material.
Your use is subject to the following restrictions, unless specifically allowed in Supporting Material:


-You may not use Software to provide products or services to third parties.
-You may not make copies and distribute, resell, sublicense or provide access to the Software to third parties.
-You may not download and use patches, enhancements, bug fixes, or similar updates unless you have a license to the underlying Software. However, such license doesn't automatically give you a right to receive such updates and HP reserves the right to make such updates only available to customers with support contracts.
-You may not copy Software or make it available on a public or external distributed network.
-You may not allow access on an intranet unless it is restricted to authorized users.
-You may make one copy of the software for archival purposes or when it is an essential step in authorized use.
-You may not modify, reverse engineer, disassemble, decrypt, decompile, or make derivative works of Software except as permitted by law. 


**7. Remote Monitoring.** Some software may require keys or other technical protection measures and HP may monitor your compliance with the Agreement, remotely or otherwise. If HP makes a license management program for recording and reporting license usage information, you will use such program no later than 180 days from the date it's made available.

**8. Ownership.** No transfer of ownership of any intellectual property will occur under this Agreement..

**9. Copyright Notices.** You must reproduce copyright notices on software and documentation for authorized copies.

**10. 90-day Limited Warranty for HP Software.**  HP-branded software is free of malware at the time of delivery; if you notify HP within 90 days of delivery of non-conformance to this warranty, HP will replace your copy. This Agreement states all remedies for warranty claims.  
-HP does not warrant that the operation of software will be uninterrupted or error free, or that software will operate in hardware and software combinations other than as authorized by HP in Supporting Material. To the extent permitted by law, HP disclaims all other warranties.


**11. Intellectual Property Rights Infringement.** Except for those components subject to third party license terms as provided in Section 14(e) of this Part 1, HP will defend and/or settle any claims against you that allege that HP-branded software as supplied under this Agreement infringes the intellectual property rights of a third party. HP will rely on your prompt notification of the claim and cooperation with our defense. HP may modify the software so as to be non-infringing and materially equivalent, or we may procure a license. If these options are not available, we will refund to you the amount paid for the affected product in the first year or the depreciated value thereafter, and HP will have no further obligations under this Section 11 for your continued use of the software. HP is not responsible for claims resulting from any unauthorized use of the software.

**12. Limitation of Liability.** HP's liability to you under this Agreement is limited to the amount actually paid by you to HP for the relevant software, except for amounts in Section 11 ("Intellectual Property Rights Infringement"). Neither you nor HP will be liable for lost revenues or profits, downtime costs, loss or damage to data or indirect, special or consequential costs or damages. This provision does not limit either party's liability for: unauthorized use of intellectual property, death or bodily injury caused by their negligence; acts of fraud; willful repudiation of the Agreement; or any liability that may not be excluded or limited by applicable law..

**13. Termination.** This Agreement is effective until terminated or in the case of a limited-term license, upon expiration; however, your rights under this Agreement terminate if you fail to comply with it. Immediately upon termination or expiration, you will destroy the software and documentation and any copies, or return them to HP. You may keep one copy of software and documentation for archival purposes. We may ask you to certify in writing you have complied with this section. Warranty disclaimers, the limitation of liability, this section on termination, and Section 14 ("General") will survive termination.

**14. General.**
	
a. Assignment. You may not assign this Agreement without prior written consent of HP, payment of transfer fees and compliance with HP's software license transfer policies. Authorized assignments will terminate your license to the software and you must deliver software and documentation and copies thereof to the assignee. The assignee will agree in writing to this Agreement. You may only transfer firmware if you transfer associated hardware.
	
b.  U.S. Government. If the software is licensed to you for use in the performance of a U.S. Government prime contract or subcontract, you agree that, consistent with FAR 12.211 and 12.212, commercial computer software, computer software documentation and technical data for commercial items are licensed under HP's standard commercial license.
	
c. Global Trade Compliance. You agree to comply with the trade-related laws and regulations of the U.S. and other national governments. If you export, import or otherwise transfer products provided under this Agreement, you will be responsible for obtaining any required export or import authorizations. You confirm that you are not located in a country that is subject to trade control sanctions (currently Cuba, Iran, N. Korea, N. Sudan, and Syria) and further agree that you will not retransfer the products to any such country. HP may suspend its performance under this Agreement to the extent required by laws applicable to either party.
	
d. Audit. HP may audit you for compliance with the software license terms. Upon reasonable notice, HP may conduct an audit during normal business hours (with the auditor's costs being at HP's expense). If an audit reveals underpayments then you will pay to HP such underpayments. If underpayments discovered exceed five (5) percent, you will reimburse HP for the auditor costs
	
e Third Party and Open Source Components. To the extent any component of the software is subject to any third party license terms, including open source license terms, then those third party license terms or open source license terms shall govern with respect to the subject component; otherwise, the terms of this Agreement shall govern.   
	
f. Notices. Written notices under this Agreement may be provided to HP via the method provided in the Supporting Material or if none, via "contact HP" site on [www.hp.com](www.hp.com).
	
g. Governing Law. This Agreement will be governed by the laws of the state of California, U.S.A., excluding rules as to choice and conflict of law. You and HP agree that the United Nations Convention on Contracts for the International Sale of Goods will not apply.
	
e. Force Majeure. Neither party will be liable for performance delays nor for non-performance due to causes beyond its reasonable control, except for payment obligations.
	
f. Entire Agreement. This Agreement represents our entire understanding with respect to its subject matter and supersedes any previous communication or agreements that may exist.  Modifications to the Agreement will be made only through a written amendment signed by both parties. If HP doesn't exercise its rights under this Agreement, such delay is not a waiver of its rights.
	
**15. Australian Consumers.** If you acquired the software as a consumer within the meaning of the 'Australian Consumer Law' under the Australian Competition and Consumer Act 2010 (Cth) then despite any other provision of this Agreement, the terms at this URL apply:  [http://www.hp.com/go/SWLicensing](http://www.hp.com/go/SWLicensing).


<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>

## Part 2: Additional License Authorizations for Software ## {#auth}

This Part 2 includes Additional License Authorizations (ALA) for the Software.  You may use the Software in accordance with the terms of this ALA in addition to the terms of your agreement with HP, or in the absence of such agreement, the HP End User License Agreement (EULA) in Part 1 above as well as the Ancillary and Open Source Software license terms listed in Part 3.  You may also be referred to as &ldquo;Customer&rdquo; below.

### Definitions ###

Capitalized terms not otherwise defined in this Additional License Authorizations document are defined in the governing Agreement.



**Commercial Service Provider**	means a Customer acting as a third party service provider contracted by an end user to provide commercial services to that end user.

**Development Platform**	means a collection of services that run on top of an HP Helion OpenStack Cloud Fabric that are configured and operated to create a development and application runtime environment.

**HP Helion OpenStack  Cloud Fabric**	means a collection of physical and virtual operating system environments using HP Helion OpenStack® Software that are configured and operated as a unit to provide virtualization, networking, website, storage and file services.

**HP Helion OpenStack® Software**	means an HP Helion OpenStack® software product used for building, managing and consuming cloud services 

**Internal Use**	means use of the Software for purposes of supporting Customer's internal business operations or functions.

**Physical Server**	means a single, physical hardware server or other computer but is not a Virtual Machine.

**Use**	means to use, install, store, load, execute and display the Software in accordance with the particular license(s) purchased by Customer.

**Virtual Machine(s) **	means a computer that does not physically exist but is simulated by another computer.



### Additional License Terms ###

**1.	Software:** 
Subject to Customer's compliance with the terms and conditions of this Agreement, HP grants to Customer a non-exclusive, limited, non-sublicenseable, non-transferable, revocable license to Use Software to create, configure and operate a development and application runtime environment on a per Physical Server basis for the term as specified in the purchase agreement.  
 
- Per Server License: Following purchase, this per-server license is to be assigned to a Physical Server that is properly licensed to Use HP Helion OpenStack® Software.  After assigning this license, you may Use the Software on these Physical Servers in order to create your Development Platform on top of your HP Helion OpenStack Cloud Fabric

**2. Other Terms:**

**a. Trademarks.**  Notwithstanding anything to the contrary in this Section, you may not distribute the Software or components of the Software using HP trademarks unless permitted to do so under a separate written agreement with HP.

**b. Assigning Licenses:**  Before you can Use the Software to deploy your Development Platform, you must assign the per-Physical Server license to a Physical Server that is already validly licensed to run the HP Helion OpenStack Cloud Fabric. Each Physical Server to which you assign a license is a licensed host server. 

**c. Commercial Service Providers:** You must have an active HP Partner One agreement, Cloud Agile Service Provider agreement, Helion Network agreement or other HP resale or service provider agreement in order to resell Software or provide commercial services using the Software.  If you do not have an active reseller or service provider agreement you may only use the Software for Internal Use purposes.  

**d. Compliance and Audit:**  HP shall have the right to audit the customer's use of the Software at HP's expense and in accordance with any agreement between the parties related to confidentiality.

**e. Confidentiality:** The Software contains confidential and proprietary information of HP (&ldquo;Confidential Information&rdquo;). Customer will hold in confidence and not use or disclose any Confidential Information, except as expressly permitted in the Agreement. To the extent this restriction is not prohibited under applicable law, and except as specifically authorized under in writing by HP, customer shall not disclose to any third party the results of (i) any performance benchmarks you run on the Software, or any portion thereof, or (ii) specific detailed comparisons you make between the Software, or any portion thereof, and any product owned by you or a third-party product.

**f. Copyright Notices:** Customer must reproduce all copyright notices that appear in or on the Software (including documentation) on all permitted copies or adaptions.  Copies of documentation are limited to internal use..

**g. Delivery:** Customer agrees to accept the Software upon receipt.  

**h. Outsourcing Software Management:**  You may install and run the Software on your Physical Servers that are under the day-to-day management and control of third parties, provided all such Physical Servers and other devices are and remain fully dedicated to your use. You are responsible for all of the obligations under this Agreement regardless of the physical location of the hardware upon which the Software is used.

**i. Reassigning Licenses:**  You may not reassign Software licenses to a substitute Physical Server on a short-term basis (within 90 days of the last assignment) unless the licensed Physical Server has been retired due to permanent hardware failure.

**j. Rights to use other versions:**  You may create, store, install, run or access a copy or instance of a prior version of the Software in place of the latest release of the Software. The permitted use of an earlier version does not extend the support lifecycle of the earlier version.

**k. Third Party Licenses:**  You are responsible for complying with all terms of use for any third party software, content, service or website you load, create or access when using the Software.  

**l. Updates and Supplements:**  We may update or supplement the Software. If so, you may use that update or supplement with the Software, subject to any additional terms that accompany the update or supplement.

**m.** The OpenStack word mark and the Square O Design, together or apart, are trademarks or registered trademarks of OpenStack Foundation in the United States and other countries, and are used with the OpenStack Foundation's permission.


<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>

## Part 3: Ancillary and Open Source Software for Software ## {#ancilliary}

Additional license authorizations related to ancillary, third party and open source software components are available at:  [HP Helion Development Platform Open Source and Third-Party Software License Agreements](/helion/openstack/3rd-party-license-agreements/). 


<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>
---
layout: default-devplatform
title: "HP Helion Development Platform Documentation"
permalink: /helion/devplatform/
product: devplatform

---
<!--PUBLISHED-->

# HP Helion Development Platform Documentation

Welcome! The HP Helion Development Platform is a Platform-as-a-Service (PaaS) that helps developers build great cloud-native applications across private and public clouds.  Based on [Cloud Foundry](http://cloudfoundry.org/index.html)&trade; and fully integrated with [HP Helion OpenStack](/helion/openstack/)&reg;, the HP Helion Development Platform is open and interoperable, ensuring that developers can focus on building the right app for any environment.

This documentation will help you get up to speed on the  Helion Development Platform as a Developer or Administrator.

##Platform Overview

The [Application Lifecycle Service (ALS)](/als/v1/) is a Cloud Foundry-based, managed runtime environment for applications. 

- It supports [Java](/helion/devplatform/appdev/#java), [Node](/helion/devplatform/appdev/#node), [PHP](/helion/devplatform/appdev/#PHP), and other language runtimes.
- It provides easy access to services like MySQL, PostgreSQL, RabbitMQ, and Memcache.
- It allows Disk, Memory and Placement Zone constraints to be set per application.
- It provides auto-scaling and application log drains.
 
The Application Lifecycle Service is [installed](/helion/devplatform/install/) as part of the Helion Development Platform. You can explore this service by setting up a [Quick Start Developer Trial](/helion/devplatform/ALS-developer-trial-quick-start/) in the public cloud.

##Application Services
The HP Helion Development Platform provides additional Application Services that integrate into the Application Lifecycle Service. These currently include:

###Database as a Service 

- An implementation of OpenStack Trove, [Database as a Service](/helion/devplatform/createdatabase/) provides scalable and reliable cloud database provisioning functionality for both relational and non-relational databases.  
- The Database service provides a simple and easy way to access and utilize features in a database without the overhead of administration.  

The [Database as a Service](/helion/devplatform/connectdatabase/) is optionally [installed and configured](/helion/devplatform/install/#install-database) as part of the Helion Development Platform. If not installed as part of the platform, you can install it and then configure it for [use from within the Application Lifecycle Service](/helion/devplatform/connectdatabase/).

<table style="vertical-align: top; width: 650px; background-color: white; border: 0px;">
<tr style="border: 0px;vertical-align: top;"><td style="border: 0px;"><a href="install/#install-database">Install</a><br></td><td style="border: 0px; align: right;"><a href="createdatabase">Provision</a><br><a href="connectdatabase">Connect with ALS</a></td></tr>
</table>
###Messaging Service (Beta)

The [Messaging Service](/helion/devplatform/messageservice/)  provides developers with the ability to provision RabbitMQ clusters using a wizard-based UI directly from Horizon.

- The Messaging Service integrates with Keystone to remove the need to create separate credentials for RabbitMQ access. 
- The Messaging Service allows developers to focus on building their apps without worrying about installing, configuring, and troubleshooting RabbitMQ.

The Messaging Service is optionally installed as part of the Helion Development Platform. If not installed as part of the platform, you can [install](/helion/devplatform/install/#install-messaging) it and then [configure](/helion/devplatform/messageservice/) it for [use from within the Application Development Platform](/helion/devplatform/msgaas/als).

<table style="vertical-align: top; width: 650px; background-color: white; border: 0px;">
<tr style="border: 0px;vertical-align: top;"><td style="border: 0px;"><a href="install/#install-messaging">Install</a><br></td><td style="border: 0px; align: right;"><a href="messageservice">Provision</a><br><a href="msgaas/als">Connect with ALS</a></td></tr>
</table>

###The Marketplace (Beta)

The [Marketplace](/helion/devplatform/marketplace/) (Beta) is a product catalog that will be used to deliver the best of breed applications and services required to support world-class, enterprise-grade applications.

- It automates installation and enablement of supported applications and services.
- The Beta version allows you to install an instance of Vertica Community Edition.

The Marketplace is optionally installed as part of the Helion Development Platform, you can [install](/helion/devplatform/install/#install-marketplace) and [use](/helion/devplatform/marketplace/) it to easily install applications and services to accelerate your development efforts.

<table style="vertical-align: top; width: 650px; background-color: white; border: 0px;">
<tr style="border: 0px;vertical-align: top;"><td style="border: 0px;"><a href="install/#install-marketplace">Install</a><br></td><td style="border: 0px; align: right;"><a href="marketplace">Provision</a></td></tr>
</table>

##Platform Tools
The Helion Development Platform is accessible via the following tools: 

**Helion Command-Line Interface (CLI)**<br>

Use the Helion CLI to deploy your app to the development platform through the command line. [Setup](/als/v1/user/client/#helion-client-setup) instructions are available for here both Windows&reg; and Unix/Mac operating systems.

**Eclipse Plugin**<br>
 If your developers work in the Eclipse IDE, [install and use](/helion/devplatform/eclipse/) the Eclipse plug-in to quickly configure the Helion Development Platform as a deployment target for your app. 

##Installation Options
Most of the Helion Development Platform documentation assumes that you've already provisioned an environment where you can deploy your apps. There are two ways to deploy Development Platform technology:
 
- **Quick Start Developer Trial**: The fastest way to set up a functional Helion Development Platform environment is the [Quick Start Developer Trial](/helion/devplatform/ALS-developer-trial-quick-start/) (sandbox) on the public cloud.
- **Standard Installation**: Install a [Commercial HP Helion OpenStack](/helion/openstack/install/overview/)&reg; cloud and then [install](/helion/devplatform/install/) the Helion Development Platform.  

----------
###[Resources for Application Developers](/helion/devplatform/appdev/)
  
###[Resources for ITOps](/helion/devplatform/sysadmin/)
  
<!--### [Resources for OpenStack Integration, Extension, and Service Development](/helion/devplatform/servicedev/) -->

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
 
---
layout: default-devplatform
title: "HP Helion OpenStack Development Platform Installation"
permalink: /helion/devplatform/install/
product: devplatform

---
<!--PUBLISHED-->

# HP Helion Development Platform Installation and Configuration

The HP Helion Development Platform currently contains four products: Application Lifecycle Service (ALS), Marketplace Service, Messaging Service and Database Service.

The following topics explain how to install and configure the HP Helion Development Platform.

* [Prerequisites](#prerequisites)
* [Installing the HP Helion Development Platform](#installing-the-hp-helion-development-platform)
* [Install the Messaging Service](#install-messaging)
* [Install the Application Lifecycle Service](#install-als)
* [Install the Database Service](#install-database)
* [Install the Marketplace Service](#install-marketplace)
* [Troubleshooting](#troubleshooting)

## <a name="prerequisites"></a>Prerequisites

The HP Helion Development Platform is installed in the HP Helion OpenStack [overcloud](http://docs.hpcloud.com/helion/openstack/glossary/#o-jumplink-span).  The HP Helion Development Platform has the same prerequisites as [HP Helion OpenStack](http://docs.hpcloud.com/helion/openstack/install/prereqs/).

The system running the installer needs to have Python 2.7. Most modern operating systems include this as part of their base toolkit. This document is geared toward a Linux operating system but this does not preclude the installer from running on other operating systems with some minor modifications to the command-line statements herein.
 
The installer requires the following packages. If they are not found, it will prompt you to install them.

* python-dev 
* libffi-dev 
* libssl-dev 
* python-virtualenv
* python-pip

    
## <a name="installing-the-hp-helion-development-platform">Installing the HP Helion Development Platform</a>

### Downloading and unpacking the installation file

The installation of the HP Helion Development Platform for the HP Helion OpenStack is provided as a small compressed tar file.  The images for the actual services will be downloaded at the installers request.

You can register and download the package from the [Helion Download Network](https://helion.hpwsportal.com).

To begin the installation, unpack the tar file:

    # tar -zxvf hp_helion_devplatform_commercial.tar.gz.csu
    
This creates and populates a `dev-platform-installer` directory.

    # cd dev-platform-installer
    
### Preparing to run the installer

If your network uses a proxy, it may be necessary to set the proxy shell variable.

	# export https_proxy=<ip address or url of http proxy> 

Run this command to prepare the installer and ensure prerequisites are met. By default the Username is "admin", the Tenant Name is "admin" and the Region is "regionOne":

    # ./DevelopmentPlatform_Setup.sh -p {admin_user_password} -a {auth_host_ip_address}
    
 Optionally, you can specify the Username, Tenant and Region
    
    # ./DevelopmentPlatform_Setup.sh -p {admin_user_password} -a {auth_host_ip_address} -u {username} -t {tenant_name} -r {region_name}
    
 The install script also has a help feature
 
 	# ./DevelopmentPlatform_Setup.sh -h
 	
After the install command completes, you should see the following output from the command:

Once the installation is complete, you should see the following output:

    2014-06-17 16:53:19.765       INFO Install Complete

## <a name="install-messaging"></a>Install the Messaging Service
This section provides details on installing the Messaging service from the Development Platform.

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the **Admin** panel in Horizon and select **Development Platform**. Finally, click **Configure Services**.

2. Click the **Connect** button on the **Configure Services** screen and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Messaging Service

1. In the **Configure Services** panel locate the Messaging (Beta) item in the Configure Services table and select **Download Service** and wait for the download to complete.

2. Once the download is complete, click the **Configure Service** button to configure the Messaging Service and wait for the configuration step to complete.

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Messaging (Beta)** panel under the current Project to begin using the Messaging Service.

##Install the Application Lifecycle Service (ALS) {#install-als}
This section provides details on installing the Application Lifecycle service from the Development Platform.

### Prerequisites

For ALS to install dependencies for deployed applications, you must provide ALS with outbound Internet connectivity. If an HTTP Proxy is required for Internet downloads, follow the instructions in the [Administration Guide](http://docs.hpcloud.com/als/v1/admin/server/configuration/#http-proxy).

### Connect to the Download Service

1. Open Horizon and login as the "Admin" user. Then click on the **Admin** panel in Horizon and select **Development Platform**. Finally, click on **Configure Services**.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Application Lifecycle Service

1. In the **Configure Services** panel locate the Application Lifecycle Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

2. Once the download is complete, click the **Configure Service** button to configure the Application Lifecycle Service and wait for the configuration step to complete.

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Application Lifecycle Service** panel under the current Project to being using Application Lifecycle Services.

## Install the Database Service {#install-database}
This section provides details on installing the Database Service from the Development Platform.

### Prerequisites

#### Availability Zones

To configure the **Database Service** in a highly available manner, it is necessary to create separate availability zones for the compute hosts in the service. The following steps show how to create three availability zones and assign a compute host to the zone.

1. Connect to an overcloud controller node and execute the following commands to create three availability zones named: "AZ-1", "AZ-2" and "AZ-3".
 
		 nova aggregate-create aggregate-AZ-1 AZ-1 
		 nova aggregate-create aggregate-AZ-2 AZ-2	
		 nova aggregate-create aggregate-AZ-3 AZ-3
 
2. Validate that the availability zones were correctly created by issuing the following command. 
 
		 nova aggregate-list
 
6. The following commands will add a compute host to your newly created availability zones. Issue this command for every compute host that you wish to associate with an availability zone. 
 
		 nova aggregate-add-host <id> <hostname>
 
10. The following command can be used to list all availability zones and the compute hosts associated with them. 
 
		 nova availability-zone-list 

#### Quotas

The **Database Service** will be installed into the admin tenant of the Helion OpenStack overcloud and the admin tenant must have sufficient quota available and unused resources for the service to use. To check existing quota availability, log-in to Horizon as the **admin** user and open the **Overview** panel under the **Compute** tab.

If you are not configuring the Database Service to be highly available you must have the following quota available:

|Resource | Usage |
|--------------|-------------:|
|Floating IPs|            6|
|Instances|               6|         
|Networks|              2|
|RAM (GB)|               24|
|Routers|                  2|
|Security Groups|    6|
|Volumes|                 4|
|Volume Storage (GB)| 160|
	
If you have setup Availability Zones and plan to install the Database Service in a highly available configuration you must have the following quota available:

|Resource | Usage |
|--------------|-------------:|
|Floating IPs|            16|
|Instances|               16|         
|Networks|                  2|
|RAM (GB)|               64|
|Routers|                   2|
|Security Groups|    6|
|Volumes|                 4|
|Volume Storage (GB)| 160|

In addition to the quota mentioned above, for every database instance that is created by a user, the necessary resources to create that instance will be deducted from the admin tenant quota. The users database service quota will also be affected.

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the admin panel in Horizon and select the **Development Platform** panel under Admin. Then click on the **Configure Services** sub-panel.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Database Service

In the **Configure Services** panel locate the Database Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

#### Configuring the Database Service

1. Once the download is complete, click the **Configure Service** button to begin configuration of the service. In the configuration dialog, specify the following configuration options:

	**Key Pair (Required)** - Key Pair to install on all instances created as part of the database service. The public key can be used by an admin to get SSH access to all instances.

	**External Network (Required)** - Network Name for the network that has external network access. For HP Helion OpenStack this network is named 'ext-net'

	**NTP Server IP** - IP Address to an NTP server to use if instances will not have outbound access to the internet. 

	**Service User Password (Required)** - The password for the Admin user that is currently logged in. This password **MUST** match the password used to login to Horizon.

	**Icinga User Password (Required)** - Specify a password for the Icinga service that is created as part of the install. Keep this password for future use.

	**Volume Type (Required)** - The volume type to use when creating database instances.

	**Enable HA** - Specify if the database service is to be setup in an HA configuration. If selected, each component of the service will have three instances created and active at all times.

	**RabbitMQ IP Address (Required)** - Specify the IP address of the central Helion OpenStack Logstash server.

2. After all configuration options have been provided, select the **Configure** button to complete the configuration step. Wait for the configuration step to complete and the status to change to **Configured**.
3. The following steps will configure the load balancer to take advantage of the highly available database service. Only execute these steps if you have configured Availability Zones and selected the "Enable HA" option when configuring the **Database Service**. To perform the following steps you must be connected to the undercloud node.
	
	1. Identify the API server IPs on the SVC network:

			$ nova list | awk '/trove[0-9]*_api/{ print $12 }' | cut -d "=" -f 2
		You should have as many API servers (and IPs) as you have AZs in your Helion OpenStack install.

	2. Identify the Virtual IP used by the controller nodes to be able to load balance the Helion 	OpenStack services:
			
			$ keystone endpoint-list | awk '/8779/{ print $6}' | egrep -o "[0-9]+.[0-9]+.[0-9]+.[0-9]+"

	3. Update configuration on each of the Helion OpenStack controller nodes by connecting to the controller and doing the following:

		a. Edit the /etc/haproxy/manual/paas.cfg and add the following lines. The last line should be repeated once for each API server identified in step 1. 
	
				listen trove_api
				bind <Virtual IP from step 2>:8779
				server trove-trove<n>_api-<uniqueid> <API server n's IP Address> check inter 2000 rise 2 fall 5

		b. Edit the /etc/iptables/iptables file and add to the end of it:

				-I INPUT -p tcp --dport 8779 -j ACCEPT

		c. Run the following command as root:

				$ sudo iptables -I INPUT -p tcp --dport 8779 -j ACCEPT
				
		d. Reload the haproxy service configuration
		
				$ sudo service haproxy reload

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Database** panel under the current Project to being using Database Service.

##Install the Marketplace Service {#install-marketplace}
This section provides details on installing the Marketplace service from the Development Platform.

### Prerequisites

The **Marketplace Service** will be installed into the admin tenant of the Helion OpenStack overcloud and the admin tenant must have sufficient quota available and unused for the resources the service uses. To check existing quota availability, log-in to Horizon as the **admin** user and open the **Overview** panel under the **Compute** tab.

|Resource | Usage      | 
|--------------|-------------:|
|Floating IPs|           16|
|Instances|                4|         
|Networks|                1|
|RAM (GB)|               8|
|Routers|                   2|
|Security Groups|   4|

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the admin panel in Horizon and select the **Development Platform** Panel under Admin. Then click on the **Configure Services** sub-panel.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Marketplace Service

In the **Configure Services** panel locate the Marketplace Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

#### Configuring the Marketplace Service

1. Once the download is complete, click the **Configure Service** button to begin configuration of the service. In the configuration dialog, specify the following configuration options:

	**Key Pair (Required)** - Key Pair to install on all instances created as part of the marketplace service. The public key can be used by an admin to get SSH access to all instances.

	**External Network (Required)** - Network Name for the network that has external network access. For HP Helion OpenStack this network is named 'ext-net'

	**NTP Server IP** - IP Address to an NTP server to use if instances will not have outbound access to the internet. 

	**Service User Password (Required)** - The password for the Admin user that is currently logged in. This password **MUST** match the password used to login to Horizon.

	**Subnet Range** - The subnet to use for Marketplace
	
## <a name="troubleshooting"></a>Troubleshooting

### Service is stuck in download

There are several situations in which a download will not complete.  One cause which is documented, is because the `tmp` directory ran out of space. There is a prerequisite to mount the `tmp` directory to a larger partition.  If you have completed this and it is still failing to download then we will need to reset the download. In the current release, this requires a manual process.

As the "admin" user, in the "admin" tenant, click on **Project**, then **Object Store**. Open the "sherpa-cache" folder and delete the wscatalog.<id> folder which contains the cached download. The service should now be available to download again.

### Staging Cache & App HTTP Proxy

The Application Lifecycle Service caches all application dependencies that are downloaded by module managers that support the HTTP_PROXY environment variable (e.g. pip, PyPM, PPM, NPM, etc). This is limited to 100MB of in-memory cache.

1. If you have an upstream HTTP proxy that deployed applications and the staging system need to traverse to access the internet execute the following command on all DEA nodes:

		$ kato op upstream_proxy set 192.168.0.99:3128
			
1. To later remove the proxy setting:

		$ kato op upstream_proxy delete <proxy_addr>
			
2. To set an HTTP proxy exclusively for apps, add an environment/app_http_proxysetting in the dea_ng config using kato config set. For example:
			
		$ kato config set dea_ng environment/app_http_proxy 10.0.0.47:3000
			
Adding this configuration sets the 'http_proxy' environment variable within all subsequently created application containers.


----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
 

---
layout: default-devplatform
title: "Helion Development Platform Installation and Configuration"
permalink: /helion/devplatform/install/old
product: devplatform

---
<!--PUBLISHED-->

#HP Helion Development Platform Installation and Configuration

The HP Helion Development Platform installs four services:

- Messaging Service
- Application Lifecycle Service (ALS)
- Database Service
- Marketplace Service

The following topics explain how to install and configure each section of the HP Helion Development Platform:

- [Prerequisites](#prereq)
- [Installing the HP Helion Development Platform](#install)
- [Installing the Messaging Service](#message)
- [Installing the Application Lifecycle Service (ALS)](#als)
- [Installing the Database Service](#database)
- [Installing the Marketplace Service](#marketplace)

##Prerequisites {#prereq}
The HP Helion Development Platform requires[HP Helion OpenStack](http://docs.hpcloud.com/helion/openstack/install/prereqs/)&reg; and has the same prerequisites. 

The system running the Installer must have Python 2.7.

Most modern operating systems include Python as part of their base toolkit. The information presented here is geared toward a Linux operating system; however, the Installer will also run on other operating systems with some minor modifications to the command-line statements.

The Installer requires the following packages:

- python-dev
- libffi-dev
- libssl-dev
- python-virtualenv
- python-pip

When installing, if the packages are not found, the Installer will prompt you to install them.

##Installing the HP Helion Development Platform  {#install}
This section provides instructions to:

- Download and unpack the installation file
- Prepare to run the Installer
- Edit the Development Platform configuration
- Activate the Installer
- Run the Installer

###Downloading and Unpacking the Installation file {#unpack}
The installation of the HP Helion Development Platform is provided as a small compressed *tar* file. The images for the actual services are downloaded at the Installer's request.

You can register and download the package from the Helion Download Network at:
[https://helion.hpwsportal.com/#/Home/Show](https://helion.hpwsportal.com/#/Home/Show)

To begin the installation:

1.	Unpack the tar file:

    	# tar -zxvf hp_helion_devplatform_commercial.tar.gz.csu

3.	Verify the creation (and population) of a dev-platform-installer directory.

    	# cd dev-platform-installer

###Preparing to Run the Installer {#prepare}
1.	If your network uses a proxy, it may be necessary to set the proxy shell variable:

		# export https_proxy=<ip address or url of http proxy> 
2.	Run this command to prepare the installer and ensure prerequisites are met. If necessary, you can specify the Username, Tenant, and Region.
By default the options are set to:
	- **Username** = admin
	- **Tenant** **name** = admin
	- **Region** = regionOne 

    		#./DevelopmentPlatform_Setup.sh -p {admin_user_password} -a {auth_host_ip_address} -u {username} -t {tenant_name} -r {region name}

1.	If you need additional information about installation you can use the Help feature:
	
		 #./DevelopmentPlatform_Setup.sh -h
    
2.	After the install command completes, verify the following output:

		2014-06-17 16:53:19.765 INFO Install Complete

##Installing the Messaging Service {#message}
This section provides the steps to install the Messaging Service from the Development Platform.

###Connecting to the Download Service

To connect to the Download Service:


1. Open the Horizon console and log in as an Admin user.
2.	Click the **Admin** tab and then click the **Development Platform** tab.
4.	Click the **Configure Services** sub-tab and then click **Connect**.
6.	Click **Sign-up** and complete the sign-up process if you do not yet have an account.
7.	Enter your username and password for the [Helion Download Network](https://helion.hpwsportal.com/#/Home/Show).
###Downloading and Configuring the Messaging Service
To download and configure the Messaging Service:


1. In the **Configure Services** tab, go to the **Configure Services** table and locate the** Messaging Service**.
2.	Select **Download Service** and wait for the download to complete.
3.	Once the download is complete, click **Configure Service**.
4.	Wait for the configuration step to complete.
5.	Log out from the Horizon console.
6.	Log back into the Horizon console as a non-admin user.
7.	Under the current project, click the **Messaging** tab to begin using the Messaging Service.

##Installing the Application Lifecycle Service (ALS) {#als}
This section provides the steps to install the Application Lifecycle Service from the Development Platform.

###Connecting to the Download Service
To connect to the Download Service:


1. Open the Horizon console and log in as an Admin user.
2.	Click the **Admin** tab and then click the **Development Platform** tab.
4.	Click the **Configure Services** sub-tab and then click **Connect**.
6.	Click **Sign-up** and complete the sign-up process if you do not yet have an account.
7.	Enter your username and password for the [Helion Download Network](https://helion.hpwsportal.com/#/Home/Show).
###Downloading and Configuring the Application Lifecycle Service
To download and configure the Application Lifecycle Service:


1. In the **Configure Services** tab, go to the **Configure Services** table and locate the **Application Lifecycle Service**.
2.	Select **Download Service** and wait for the download to complete.
3.	Once the download is complete, click **Configure Service**.
4.	Wait for the configuration step to complete.
5.	Log out from the Horizon console.
6.	Log back into the Horizon console as a non-admin user.
7.	Under the current project, click the Application Lifecycle Service tab to begin using the Application Lifecycle Service.
##Installing the Database Service {#database}
This section provides the steps to install the Database Service from the Development Platform.
###Prerequisites
There are two prerequisites to install the Database Service: 


- Availability Zones
- Quotas

##Creating Availability Zones

To configure the Database Service in a highly available manner, you must create Availability Zones for the compute hosts in the service.

The following steps describe how to create three Availability Zones and then assign a compute host to the zone:



1. Connect to an overcloud controller node and execute the following commands to create three Availability Zones named: AZ-1, AZ-2, and AZ-3 

		nova aggregate-create aggregate-AZ-1 AZ-1 
		nova aggregate-create aggregate-AZ-2 AZ-2 
		nova aggregate-create aggregate-AZ-3 AZ-3
	 
1.	Validate that the Availability Zones were correctly created by issuing the following command to list them:
	
		nova aggregate-list

2.	Add a compute host to your newly created Availability Zone by issuing the following command:
	
		nova aggregate-add-host <id> <hostname>
	**NOTE**: Perform this step for each compute host that you want to associate with an Availability Zone.
1.	Verify the Availability Zones by issuing the following command to list all zones and the compute hosts associated with them:

    	nova availability-zone-list

###Quotas
The Database Service is installed in the Admin Tenant of the HP Helion OpenStack installation. 

The Admin Tenant must have sufficient quota available and unused for the resources that the Database Service uses.
To check the existing quota availability:


1. Log on to Horizon as the Admin.
2.	Click the **Compute** tab and then open the **Overview** panel.
3.	If you are not configuring the Database Service to be highly available, you must have the following quotas available:
	- Instances: 6
	- RAM: 24GB
	- Floating IPs: 6
	- Volumes: 4
	- Volume Storage: 160GB

4. If you have set up Availability Zones and plan to install the Database Service in a highly available configuration, you must have the following quotas available:
	- Instances: 16 
	- RAM 64GB 
	- Floating IPs: 16 
	- Volumes: 4 
	- Volume Storage: 160GB

###Connecting to the Download Service
To connect to the Download Service:


1. Open the Horizon console and log in as an Admin user.
2.	Click the **Admin** tab and then click the **Development Platform** tab.
4.	Click the **Configure Services** sub-tab and then click **Connect**.
6.	Click **Sign-up** and complete the sign-up process if you do not yet have an account.
7.	Enter your username and password for the [Helion Download Network](https://helion.hpwsportal.com/#/Home/Show).
###Downloading and Configuring the Database Service
To download the Database Service:


1. In the **Configure Services** tab, go to the **Configure Services** table and locate the Database Service.
2. Click **Download Service** and wait for the download to complete.
3. Once the download is complete, click **Configure Service**.
2.	In the Configuration dialog, specify the following configuration options:
	- **Key Pair** (Required) -The Key Pair to install on all instances created as part of the Database Service. An Admin can use the public key to get SSH access to all instances.
	- **External Network** (Required) -The Network Name for the network that has external network access. For HP Helion OpenStack Commercial Edition, this network is named ext-net.
	- **NTP Server IP** -The IP Address to an NTP server to use if instances will not have outbound access to the Internet.
	- **Service User Password**(Required) -The password for the Admin user that is currently logged in. This password MUST match the password used to log in to Horizon.
	- **Pool User Password** (Required) -Specify a password for the pool user that is created as part of the installation. Keep this password for future use.
	- **Icinga User Password** (Required) -Specify a password for the Icinga Service that is created as part of the installation. Keep this password for future use.
	- **Volume Type** (Required) -The volume type to use when creating database instances.
	- **Enable HA** -Specify if the Database Service is to be setup in an HA configuration. If selected, each component of the service will have three instances created, and will be active at all times.
	- **RabbitMQ IP Address** (Required) -Specify the IP address of the central Helion OpenStack Logstash Server.
3.	After you provide the information for all of the configuration options, click **Configure**. Wait for the configuration status to change to **Configured**.

##Configuring the Load Balancer for the Database Service<a name=""></a>
The steps in this section configure the Load Balancer to take advantage of the highly available Database Service.

Perform these steps **only** if you have configured the Availability Zones and configured the Database Service with the *Enable HA* option.

You must be connected to the undercloud node to perform the following steps:

1. Identify the API server IPs on the SVC network by running this command:
 
		$ nova list | awk '/trove[0-9]*_api/{print $12 }' | cut -d "=" -f 2

	You should have as many API servers (and IPs) as you have Available Zones in your HP Helion OpenStack installation.
1.	Identify the Virtual IP that the controller nodes use to load balance the Helion OpenStack services by running this command:

		$ keystone endpoint-list | awk '/8779/{print $6}' | egrep -0 "[0-9]+.[0-9]+.[0-9]+.[0-9]+."

2.	Update the configuration on each of the Helion OpenStack controller nodes by connecting to the controller and performing these steps:

	A.	Edit the */etc/haproxy/manual/paas.cfg* file. <br>Add the following lines, repeating the last line once for each API server you identified in Step 1:

    		listen trove_api
    		bind <Virtual IP from step 2>:8779
    		server trove-trove<n>_api<uniqueid> <API server ns IP Address> check
    		inter 2000 rise 2 fall 5

	B. Edit the */etc/iptables/iptables* file.<br>Add to the end of it:
	
			-I INPUT -p -tcp --dport 8779 -j ACCEPT

  	C. Run the following command as *root*:
  		
			$ iptables -I INPUT -p tcp --dport 8779 -j ACCEPT

  	D. Reload the haproxy service configuration:
  		
			$ sudo service haproxy reload
	
1.	Log out from the Horizon panel.
2.	Log back into the Horizon panel as a non-admin user.
3.	Under the current project, click the Database tab to begin using the Database Service.

##Installing the Marketplace Service {#marketplace}
This section provides the steps to install the Marketplace Service from the Development Platform.

###Quotas
The Marketplace Service is installed in the Admin Tenant of the HP Helion OpenStack installation. The Admin Tenant must have sufficient quota available and unused for the resources that the Marketplace Service uses.

To check the existing quota availability:

1. Log on to Horizon as Admin.
2.	Click the **Compute** tab and then open the **Overview** panel.
3.	Ensure that the Admin Tenant has enough quota available to create four small instances.
###Connecting to the Download Service

To connect to the Download Service:


1. Open the Horizon console and log in as an Admin user.
2.	Click the **Admin** tab and then click the **Development Platform** tab.
4.	Click the **Configure Services** sub-tab and then click **Connect**.
6.	Click **Sign-up** and complete the sign-up process if you do not yet have an account.
7.	Enter your username and password for the [Helion Download Network](https://helion.hpwsportal.com/#/Home/Show).
###Downloading and Configuring the Marketplace Service
To download the Marketplace Service:


1. In the **Configure Services** tab, go to the **Configure Services** table and locate the Application Lifecycle Service For HP Helion OpenStack.
2.	Click **Download Service** and wait for the download to complete.
3. Once the download is complete, click **Configure Service**.
2.	In the configuration dialog, specify the following configuration options:
	- **Key Pair** (Required) -- The Key Pair to install on all instances created as part of the Marketplace Service. An Admin can use the public key to get SSH access to all instances.
	- **External Network** (Required) -- The Network Name for the network that has external network access. For HP Helion OpenStack Commercial Edition, this network is named ext-net.
	- **NTP Server IP** -- The IP Address to an NTP server to use if instances will not have outbound access to the Internet.
	- **Service User Password** (Required) -- The password for the Admin user that is currently logged in. This password MUST match the password used to log in to Horizon.
	- **Subnet Range** -- The subnet to use for the Marketplace Service.

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*

---
layout: default-devplatform
title: "Working with the Marketplace"
permalink: /helion/devplatform/marketplace/
product: devplatform

---
<!--PUBLISHED-->
#The Marketplace (Beta)
The Marketplace, currently in beta, is a repository where teams can download the latest services they need to accelerate development of their applications. In its beta incarnation, the Marketplace has a single application: the Vertica 7 Community Edition. 

The following topics explain how to install and deploy an instance of Vertica 7 Community Edition:

- [Marketplace concepts](#concepts)
- [Prerequisites](#prereq)
- [Installing a package](#install)
- [Deploying an environment](#create)
- [Creating a Deployed Instance of an Application](#deploy)
- [Deployment Notes](#notes)

## <a name="concepts"></a>Marketplace Concepts
The Marketplace deploys packages of services and applications to specified environments. 

- The term **Application** actually covers applications and services that can reside in the Marketplace. For the purposes of this documentation, we will use the term Application even though we are deploying a database, which is a service. 
- **Packages** are zip files that contain instructions for Application deployment.
- **Environments** are groups of Applications managed by a single tenant. Applications within a single Environment *may* be logically related to one another, but do not have to be.  Applications in different Environments are always independent from one another. 

##<a name="prereq"></a>Prerequisites
Install the Marketplace component of the [HP Helion Development Platform](/helion/devplatform/install/) during the Development Platform install process.

##<a name="install"></a>Installing a Package
In this example, the package being installed is the Vertica 7 Community Edition package. 

###<a name="create"></a>Create a Target Environment
1. Log into Horizon and open the **Marketplace** panel under your Project. Click on **Application Catalog**, and then click on the Environments tab. 
 

	<img src="media/marketplace1.png"/>

1. Click the **Create Environment** button.  

	<img src="media/marketplace2.png"/>

1. After the environment has been created, your view should look like this:

	<img src="media/marketplace3.png"/>
 

###<a name="deploy"></a>Create a Deployed Instance of an Application
The following section will show how to create an instance of Vertica 7 Community Edition in the environment created above.

1. Log in to the Horizon console and open the **Marketplace** panel under your Project. Click on **Application Catalog** and then click on the **Applications** tab. You will see the Vertica 7 Community Edition package.
 
	<img src="media/marketplace4.png"/>


1. Click the Add to Env button from within the Vertica 7 Community Edition section. You will see an **Add Application to &lt;selected environment name&gt;** dialog. Agree to the Terms and Conditions, then scroll down to the bottom of the dialog and click on the Next button.


	<img src="media/marketplace5.png"/>


1. The **Add Application to &lt;selected environment&gt;** dialog will come up. Fill out
	- **Application name** - can be anything
	
	- **Flavor** for instances, can be:
		- m1.medium
		- m1.large
		- m1.xlarge
	4. Select the **image** to use. In this case there is only one image, the Vertica 7 Community Edition (Debian) image. 
	5. Add a keypair if you don't have one already, by selecting the **+** link. If you are adding a keypair, you will be prompted to supply a name and a public key. You can generate a public key in &#42;nix using <a href="http://linux.die.net/man/1/ssh-keygen">ssh-keygen</a> or Windows&reg; using <a href="http://the.earth.li/~sgtatham/putty/0.63/htmldoc/Chapter8.html#pubkey-puttygen">puTTYgen</a>. Insert public key text and click the **Import Key Pair** button.

	<img src="media/marketplace6.png"/>
 
4. Supply a database name and a password, complying with the on-page instructions and then click the **Next** button.

	<img src="media/marketplace7.png"/>

1. You will be prompted to add the Application you have created to the environment you selected. Click **Create** to continue. 
 
	<img src="media/marketplace8.png"/>


1. You will see that Vertica 7 Community Edition has been installed in the test1 environment. Note that the Environment has **not** been deployed yet. That is the next step.

	<img src="media/marketplace9.png"/>

1. To deploy the environment, click on the  **Deploy This Environment** button. Expect deployment to take between 5 and 10 minutes. 

	<img src="media/marketplace10.png"/>

1. When this process has completed, you will see that the Vertica 7 Community Edition is available for consumption. Connection information is given in the **last operation** column.

	<img src="media/marketplace11.png"/>
 
###<a name="notes"></a>Deployment Notes
This section discusses some of the details of deployment that you may encounter.



1. Environments cannot be deployed unless there is at least one Application in the Environment. 
2. Deploying an Application to an Environment that has already been deployed follows the same flow as above.
	- In order to instantiate a newly-configured application, re-deploy its Environment.
	- When an Environment is re-deployed, all applications it contains will be re-deployed. 


 
----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*


---
layout: default-devplatform
title: "HP Helion Development Platform Related Documentation"
permalink: /helion/devplatform/related-topics/
product: devplatform

---
<!--PUBLISHED-->

#HP Helion Development Platform Related Documentation

The HP Helion Development Platform is based on Cloud Foundry&trade; and OpenStack&reg; technology along with an HP-configured Linux operating system.

You can find related information on the following sites:


- [Cloud Foundry](http://docs.cloudfoundry.org/)
- OpenStack [Trove](https://wiki.openstack.org/wiki/Trove)

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default-devplatform
title: "HP Helion Development Platform Release Notes"
permalink: /helion/devplatform/release-notes/
product: devplatform

---
<!--PUBLISHED-->

#HP Helion Development Platform Release Notes


The following release notes are for the HP Helion Development Platform 1.0 released on 10/14/2014. We hope you enjoy the release!
Known Issues:

1. **Intermittent Authentication Errors from Keystone**. Some requests to keystone will intermittently fail to authenticate. Retrying the request will generally succeed. This is a known issue and will be fixed in the next release.

1. **Database Service will not install if there are more than three availability zones**. You need to have only three availability zones to install the database service.

1. **Database Instance deletion not available from the Horizon UI**. The Horizon UI is not able to delete database instances. This is a known issue and will be fixed in the next release.

2. **Password Field is not used when creating a RabbitMQ cluster**. The password field in the Horizon panel is not necessary when creating a RabbitMQ cluster, and will be ignored. This is a known issue and will be fixed in the next release.

3. **Download PEM not working in the RabbitMQ Panel for the Messaging Service**. In Safari browsers the download PEM button results in an error. 

4. **RabbitMQ cluster creation fails when a floating IP pool has not been selected**. You must select a floating IP pool when creating a RabbitMQ cluster in the messaging service.

5. **Using the correct network to connect to an ALS cluster**. When pushing applications to ALS, you will be presented with two domains for the new application (unless additional domains have been added by the ALS cluster administrator): a xip.io address such as 10.0.0.1.xip.io, and a local domain such as hphelion-xyz.local. When connecting to the ALS Cluster over a network only the xip.io domain will allow clients to connect to the deployed application, choose this option you they have assigned custom domains to you cluster.

7. **Small DEAs can run out of disk space**. The ALS Seed Node Images in 1.0 are shipped in a frozen 10 gigabyte size, resulting in a limited amount of disk space available for applications and services. This can result in highly active clusters failing over time due to a lack of disk space. It is recommended to allocate more 4 gigabyte DEAs rather than fewer larger DEAs.



----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default-devplatform
title: "HP Helion Development Platform Documentation for  ITOps"
permalink: /helion/devplatform/sysadmin/
product: devplatform

---
<!--PUBLISHED-->
#Resources for ITOps {#sysadmin}

##Installation

* [HP Helion OpenStack&reg; Installation](/helion/openstack/install/overview/)
* [Development Platform Installation and Configuration](/helion/devplatform/install/)
* [Application Lifecycle Service (ALS) Information](/als/v1/)
* [Application Lifecycle Service Client Installation](/als/v1/user/client/)
* [Installing the Marketplace](/helion/devplatform/marketplace)

##Administration
Access control is role-based, with each role granting permissions in either an organization or an application space. To create users and manage user roles, use the ALS  [Command Line Interface (CLI)](/als/v1/user/reference/client-ref/). For more information, see [Organizations](/als/v1/user/reference/client-ref/#organizations).

- [Application Lifecycle Service (ALS) Administrators Guide](/als/v1/admin/)
- [Management Console](/als/v1/user/console/)
- [Logs, Streams, and Drains](/als/v1/user/deploy/app-logs/)

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default-devplatform
title: "Using the Messaging Service with ALS"
permalink: /helion/devplatform/msgaas/als/
product: devplatform

---
<!--PUBLISHED-->
#Using the Messaging Service with ALS

The Messaging Service provides on-demand RabbitMQ clusters and enables automatic access to the RabbitMQ management console. RabbitMQ is also available within ALS as a single-instance, unmanaged service. If your application relies on high message throughput or if you want to move an application from dev/test into production, you should strongly consider using the Messaging Service instead of the RabbitMQ service embedded with ALS.  

If the Helion OpenStack&reg; cloud was configured with three availability zones, the Messaging Service will automatically deploy the cluster across all three so that the cluster is resilient to server, VM, or availability zone failures.

##Prerequisites

To use the Messaging Service ALS, you need to:

1. [Create a RabbitMQ cluster](/helion/devplatform/messageservice/#create) from the OpenStack Dashboard if a cluster does not already exist. 
2.	Once a cluster has been created, you can connect an application deployed to ALS with the Messaging Service.
3.	To connect, you must create an environment variable in the *manifest.yml* file of the application you wish to connect to the Messaging Service. This will tell your application how to connect to the cluster using AMQP. The environment variable can be named anything you prefer. We will use **MQ\_URL** in this example.
	1.	The connection string and MQ_URL value will look something like: 

			amqps://username:password@ipaddress:5671/%2f

	1. The username and password for a RabbitMQ cluster are the same credentials used to create the cluster. 
		- Alternately, you can add other accounts to the cluster using the RabbitMQ management console. The RabbitMQ management console is accessible from the  Horizon Management Console.
	2. The new environment variable can then be inserted into a block within your *manifest.yml* file like so:

			env: 
			  MQ_URL: amqps:/username:password@ipaddress:5671/%2f

4.	You can then connect your application to the cluster by choosing from a long list of [available AMQP client libraries](http://www.rabbitmq.com/devtools.html). Your app will reference and parse the **MQ\_URL** variable to connect to the cluster.

##Connecting to the Messaging Service with PHP
This code section shows how to retrieve the connection information for the RabbitMQ cluster from the application's environment variable, **MQ\_URL**. The code then creates a queue, an exchange, posts the message to the queue, reads the message from the queue, and then writes it back out to the user.

	$url = parse_url(getenv('MQ_URL'));
	$conn = new AMQPConnection($url['host'], $url['port'], $url['user'], $url['pass'], substr($url['path'], 1));
	$ch = $conn->channel();
	
	// Create a queue
	$queue = 'basic_get_queue';
	$ch->queue_declare($queue, false, true, false, false);
	
	// Create an exchange
	$exchange = 'amq.direct';
	$ch->exchange_declare($exchange, 'direct', true, true, false);
	$ch->queue_bind($queue, $exchange);
	
	// Publish the user's message
	$msg_body = $_POST["message"];
	$msg = new AMQPMessage($msg_body, array('content_type' => 'text/plain', 'delivery_mode' => 2));
	$ch->basic_publish($msg, $exchange);
	
	// Retrieve the message that was sent
	$retrived_msg = $ch->basic_get($queue);
	$msgContents = $retrived_msg->body;
	echo $msgContents;
	$ch->basic_ack($retrived_msg->delivery_info['delivery_tag']);
	
	$ch->close();
	$conn->close();



If you're using the Messaging Service instead of the embedded unmanaged RabbitMQ service, you do not need to specify anything other than the environment variables in your *manifest.yml* file. If you are using the unmanaged RabbitMQ service, you **must** specify this dependency under **Services:** in the *manifest.yml* file.


----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*


 
---
layout: default-devplatform
title: "Using the Messaging Service"
permalink: /helion/devplatform/messageservice/
product: devplatform

---
<!--PUBLISHED-->

#Using the RabbitMQ Messaging Service#

The Messaging service is a key aspect of applications architected for the cloud as it helps to create scalable and distributed applications. This is achieved by enabling your software applications and services to communicate with each other as sub-components of a larger-scale application while allowing you to incorporate data from users, devices, and data streams. 

The Messaging service (beta) provisions RabbitMQ clusters that can be used for robust messaging in applications. 

The following topics explain how to create and manage a RabbitMQ instance:

- [Creating a RabbitMQ cluster](#create) 
- [Deleting a RabbitMQ cluster](#delete)
- [Managing a RabbitMQ cluster](#manage)

###Prerequisites###

1. Install the [HP Helion Development Platform](/helion/devplatform/install/). 
2. [Configure](/helion/devplatform/install/#install-database) the services.

##Creating a RabbitMQ Cluster {#create}
The following guide will demonstrate how to deploy a multi-node RabbitMQ cluster using the Messaging Service.

1.	Log into Horizon and open the **Messaging (Beta)** panel under your project. Click on the **RabbitMQ** tab.
2.	Click the **Create Cluster** button.<br><img src="media/usingRMQ1.png"/>
3.	In the Create RabbitMQ dialog, specify the following information:
	- **Cluster Name** - A name for the cluster that will be created.
	- **Number of Cluster Instances** - the number of instances of RabbitMQ to have in the cluster. This can be 1, 3 or 5.
	- **Flavor of Cluster Instances** - The flavor size to use when creating the RabbitMQ instances in the cluster.
	- **Network** - The network to join the cluster to. This should be the network that your application will use to connect to the cluster.
	- **SSH Key Pair** - A key pair to use when connecting to the cluster. You can choose to create one if one does not already exist.
	- **Floating IP Pool** - A pool to choose a floating IP from to assign to the cluster.
	- **SSL Credentials** - The certificate to use when interacting with RabbitMQ in the cluster.
	- **Password for user** - The password for the user that is currently logged in.

 
3.	Click the **Launch** button.

4.	Open the **RabbitMQ** tab under the **Messaging (Beta)** panel and identify the **RabbitMQ** cluster from the list that was created in the previous step. Wait for the cluster to go to the **Complete** state<br><img src="media/usingRMQ2.png"/>

5.	Your cluster is now ready to use.

##Deleting a RabbitMQ Cluster {#delete}
The following guide will demonstrate how to delete an existing RabbitMQ cluster.

1.	Log in to Horizon and open the **Messaging (Beta)** panel under your project. Click on the **RabbitMQ** tab.
2.	Identify the **RabbitMQ** cluster to delete from the list.
3.	Click the **More** button and then the **Delete Cluster** button.

##Managing a RabbitMQ Cluster {#manage}
RabbitMQ clusters have a built-in dashboard for managing the cluster; this allows you to view the current state and health of the cluster. The following steps will demonstrate how to manage an existing cluster.

1.	Log in to Horizon and open the **Messaging (Beta)** panel under you project. Click on the **RabbitMQ** tab.
2.	Identify the RabbitMQ cluster that you will manage from the clusters listed in the **Clusters** table.
3.	Click on **Manage Cluster** next to your cluster.<br><img src="media/usingRMQ3.png"/>
4.	A new browser window will open with the log-in screen for the RabbitMQ cluster. Enter the same username and password you used to log in to HP Helion OpenStack&reg; when creating the RabbitMQ cluster and select **Login**.<br><img src="media/usingRMQ4.png"/>
5.	The management console for RabbitMQ will open. In the management console you can perform tasks such as monitor the queues and message rates, check resource usage on the instances, manage user accounts, and many others.  <br><img src="media/usingRMQ5.png"/>

##More Information


- For more information on using RabbitMQ and managing the RabbitMQ cluster, visit the [RabbitMQ documentation site](https://www.rabbitmq.com/documentation.html).

- For more information using HP Helion OpenStack, visit the [documentation page](http://docs.hpcloud.com/helion/openstack/).

<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*

---
layout: default
title: "HP Helion OpenStack Development Platform Installation"
permalink: /helion/devplatform/install/commercial/
product: devplatform

---
<!--PUBLISHED-->
# HP Helion Development Platform Commercial Installation and Configuration

The HP Helion Development Platform currently contains four products: Application Lifecycle Service (ALS), Marketplace Service, Messaging Service and Database Service.

The following topics explain how to install and configure the HP Helion Development Platform.

* [Prerequisites](#prerequisites)

* [Installing the HP Helion Development Platform](#installing-the-hp-helion-development-platform)

* [Install the Messaging Service](#install-messaging)

* [Install the Application Lifecycle Service](#install-als)

* [Install the Database Service](#install-database)

* [Install the Marketplace Service](#install-marketplace)

* [Troubleshooting](#troubleshooting)

## Prerequisites<a name="prerequisites"></a>

The HP Helion Development Platform is installed in the overcloud of HP Helion OpenStack Community Edition - Baremetal.  The HP Helion Development Platform has the same prerequisites as HP Helion OpenStack Community Edition - Baremetal.

The system running the installer needs to have Python 2.7. Most modern operating systems include this as part of their base toolkit. This document is geared toward a Linux operating system but this does not preclude the installer from running on other operating systems with some minor modifications to the command-line statements herein.
 
The installer requires the following packages. If they are not found, it will prompt you to install them.

* python-dev 
* libffi-dev 
* libssl-dev 
* python-virtualenv
* python-pip

    
## Installing the HP Helion Development Platform<a name="installing-the-hp-helion-development-platform"></a>

### Downloading and unpacking the installation file

The installation of the HP Helion Development Platform for the HP Helion OpenStack Commercial Edition is provided as a small compressed tar file.  The images for the actual services will be downloaded at the installers request.

You can register and download the package from the following URL:

[HP Helion Development Platform](https://helion.hpwsportal.com/#/Product/%7B%22productId%22%3A%221245%22%7D/Show)

To begin the installation, unpack the tar file:

    # tar -zxvf hp_helion_devplatform_commercial.tar.gz.csu
    
This creates and populates a `dev-platform-installer` directory.

    # cd dev-platform-installer
    
### Preparing to run the installer

If your network uses a proxy, it may be necessary to set the proxy shell variable.

	# export https_proxy=<ip address or url of http proxy> 

Run this command to prepare the installer and ensure prerequisites are met. By default the Username is "admin", the Tenant Name is "admin" and the Region is "regionOne":

    # ./DevelopmentPlatform_Setup.sh -p {admin_user_password} -a {auth_host_ip_address}
    
 Optionally, you can specify the Username, Tenant and Region
    
    # ./DevelopmentPlatform_Setup.sh -p {admin_user_password} -a {auth_host_ip_address} -u {username} -t {tenant_name} -r {region_name}
    
 The install script also has a help feature
 
 	# ./DevelopmentPlatform_Setup.sh -h
 	
After the install command completes, you should see the following output from the command:

Once the installation is complete, you should see the following output:

    2014-06-17 16:53:19.765       INFO Install Complete

## Install the Messaging Service<a name="install-messaging"></a>
This section provides details on installing the Messaging service from the Development Platform.

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the **Admin** panel in Horizon and select **Development Platform**. Finally, click **Configure Services**.

2. Click the **Connect** button on the **Configure Services** screen and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Messaging Service

1. In the **Configure Services** panel locate the Messaging (Beta) item in the Configure Services table and select **Download Service** and wait for the download to complete.

2. Once the download is complete, click the **Configure Service** button to configure the Messaging Service and wait for the configuration step to complete.

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Messaging (Beta)** panel under the current Project to begin using the Messaging Service.

## Install the Application Lifecycle Service (ALS)<a name="install-als"></a>
This section provides details on installing the Application Lifecycle service from the Development Platform.

### Prerequisites

For ALS to install dependencies for deployed applications, you must provide ALS with outbound Internet connectivity. This process is documented in Step 7 of ["Starting the seed and building your cloud"](http://docs.hpcloud.com/helion/community/install/#startseed) in the baremetal installation instructions.  If an HTTP Proxy is required for Internet downloads, follow the instructions in the [Administration Guide](http://docs.hpcloud.com/als/v1/admin/server/configuration/#http-proxy).

### Connect to the Download Service

1. Open Horizon and login as the "Admin" user. Then click on the **Admin** panel in Horizon and select **Development Platform**. Finally, click on **Configure Services**.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Application Lifecycle Service

1. In the **Configure Services** panel locate the Application Lifecycle Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

2. Once the download is complete, click the **Configure Service** button to configure the Application Lifecycle Service and wait for the configuration step to complete.

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Application Lifecycle Service** panel under the current Project to being using Application Lifecycle Services.

## Install the Database Service<a name="install-database"></a>
This section provides details on installing the Database Service from the Development Platform.

### Prerequisites

#### Availability Zones

To configure the **Database Service** in a highly available manner, it is necessary to create separate availability zones for the compute hosts in the service. The following steps show how to create three availability zones and assign a compute host to the zone.

1. Connect to an overcloud controller node and execute the following commands to create three availability zones named: "AZ-1", "AZ-2" and "AZ-3". 
	
		nova aggregate-create aggregate-AZ-1 AZ-1
		nova aggregate-create aggregate-AZ-2 AZ-2
		nova aggregate-create aggregate-AZ-3 AZ-3
		
 2. Validate that the availability zones were correctly created by issuing the following command.
 	
 		nova aggregate-list
 
3. The following commands will add a compute host to your newly created availability zones. Issue this command for every compute host that you wish to associate with an availability zone.
	
		nova aggregate-add-host <id> <hostname>
 
4. The following command can be used to list all availability zones and the compute hosts associated with them.

		nova availability-zone-list

#### Quotas

The **Database Service** will be installed into the admin tenant of the Helion OpenStack overcloud and the admin tenant must have sufficient quota available and unused resources for the service to use. To check existing quota availability, log-in to Horizon as the **admin** user and open the **Overview** panel under the **Compute** tab.

If you are not configuring the Database Service to be highly available you must have the following quota available:
	
|Resource | Usage |
|--------------|-------------:|
|Floating IPs|            6|
|Instances|               6|         
|Networks|              2|
|RAM (GB)|               24|
|Routers|                  2|
|Security Groups|    6|
|Volumes|                 4|
|Volume Storage (GB)| 160|
	
If you have setup Availability Zones and plan to install the Database Service in a highly available configuration you must have the following quota available:

|Resource | Usage |
|--------------|-------------:|
|Floating IPs|            16|
|Instances|               16|         
|Networks|                  2|
|RAM (GB)|               64|
|Routers|                   2|
|Security Groups|    6|
|Volumes|                 4|
|Volume Storage (GB)| 160|

In addition to the quota mentioned above, for every database instance that is created by a user, the necessary resources to create that instance will be deducted from the admin tenant quota. The users database service quota will also be affected.

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the admin panel in Horizon and select the **Development Platform** panel under Admin. Then click on the **Configure Services** sub-panel.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Database Service

In the **Configure Services** panel locate the Database Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

#### Configuring the Database Service

1. Once the download is complete, click the **Configure Service** button to begin configuration of the service. In the configuration dialog, specify the following configuration options:

	**Key Pair (Required)** - Key Pair to install on all instances created as part of the database service. The public key can be used by an admin to get SSH access to all instances.

	**External Network (Required)** - Network Name for the network that has external network access. For HP Helion OpenStack Commercial Edition this network is named 'ext-net'

	**NTP Server IP** - IP Address to an NTP server to use if instances will not have outbound access to the internet. 

	**Service User Password (Required)** - The password for the Admin user that is currently logged in. This password **MUST** match the password used to login to Horizon.

	**Icinga User Password (Required)** - Specify a password for the Icinga service that is created as part of the install. Keep this password for future use.

	**Volume Type (Required)** - The volume type to use when creating database instances.

	**Enable HA** - Specify if the database service is to be setup in an HA configuration. If selected, each component of the service will have three instances created and active at all times.

	**RabbitMQ IP Address (Required)** - Specify the IP address of the central Helion OpenStack Logstash server.

2. After all configuration options have been provided, select the **Configure** button to complete the configuration step. Wait for the configuration step to complete and the status to change to **Configured**.
3. The following steps will configure the load balancer to take advantage of the highly available database service. Only execute these steps if you have configured Availability Zones and selected the "Enable HA" option when configuring the **Database Service**. To perform the following steps you must be connected to the undercloud node.
	
	1. Identify the API server IPs on the SVC network:

			$ nova list | awk '/trove[0-9]*_api/{ print $12 }' | cut -d "=" -f 2
		You should have as many API servers (and IPs) as you have AZs in your Helion OpenStack install.

	2. Identify the Virtual IP used by the controller nodes to be able to load balance the Helion 	OpenStack services:
			
			$ keystone endpoint-list | awk '/8779/{ print $6}' | egrep -o "[0-9]+.[0-9]+.[0-9]+.[0-9]+"

	3. Update configuration on each of the Helion OpenStack controller nodes by connecting to the controller and doing the following:

		a. Edit the /etc/haproxy/manual/paas.cfg and add the following lines. The last line should be repeated once for each API server identified in step 1. 
	
				listen trove_api
				bind <Virtual IP from step 2>:8779
				server trove-trove<n>_api-<uniqueid> <API server n's IP Address> check inter 2000 rise 2 fall 5

		b. Edit the /etc/iptables/iptables file and add to the end of it:

				-I INPUT -p tcp --dport 8779 -j ACCEPT

		c. Run the following command as root:

				$ sudo iptables -I INPUT -p tcp --dport 8779 -j ACCEPT
				
		d. Reload the haproxy service configuration
		
				$ sudo service haproxy reload

3. Log out from the Horizon dashboard. Log back into the Horizon dashboard as a non-admin user and click on the **Database** panel under the current Project to being using Database Service.

## Install the Marketplace Service<a name="install-marketplace"></a>
This section provides details on installing the Marketplace service from the Development Platform.

### Prerequisites

The **Marketplace Service** will be installed into the admin tenant of the Helion OpenStack overcloud and the admin tenant must have sufficient quota available and unused for the resources the service uses. To check existing quota availability, log-in to Horizon as the **admin** user and open the **Overview** panel under the **Compute** tab.

|Resource | Usage      | 
|--------------|-------------:|
|Floating IPs|           16|
|Instances|                4|         
|Networks|                1|
|RAM (GB)|               8|
|Routers|                   2|
|Security Groups|   4|

### Connect to the Download Service

1. Open Horizon and login as the "admin" user. Then click on the admin panel in Horizon and select the **Development Platform** Panel under Admin. Then click on the **Configure Services** sub-panel.

2. Click the **Connect** button on the **Configure Services** panel and enter your username and password for the HP Cloud OS Content Delivery Network. Select the Sign-up button if you do not have an account.

### Download and Configure the Marketplace Service

In the **Configure Services** panel locate the Application Lifecycle Service item in the Configure Services table and select **Download Service** and wait for the download to complete.

#### Configuring the Marketplace Service

1. Once the download is complete, click the **Configure Service** button to begin configuration of the service. In the configuration dialog, specify the following configuration options:

	**Key Pair (Required)** - Key Pair to install on all instances created as part of the marketplace service. The public key can be used by an admin to get SSH access to all instances.

	**External Network (Required)** - Network Name for the network that has external network access. For HP Helion OpenStack Commercial Edition this network is named 'ext-net'

	**NTP Server IP** - IP Address to an NTP server to use if instances will not have outbound access to the internet. 

	**Service User Password (Required)** - The password for the Admin user that is currently logged in. This password **MUST** match the password used to login to Horizon.

	**Subnet Range** - The subnet to use for Marketplace
	
## Troubleshooting<a name="troubleshooting"></a>

### Service is stuck in download

There are several situations in which a download will not complete.  One cause which is documented, is because the `tmp` directory ran out of space. There is a prerequisite to mount the `tmp` directory to a larger partition.  If you have completed this and it is still failing to download then we will need to reset the download. In the current release, this requires a manual process.

As the "admin" user, in the "admin" tenant, click on **Project**, then **Object Store**. Open the "sherpa-cache" folder and delete the wscatalog.<id> folder which contains the cached download. The service should now be available to download again.


---
layout: default-devplatform
permalink: /als/v1/admin/best-practices/
product: devplatform
---
<!--PUBLISHED-->

Best Practices[](#index-0 "Permalink to this headline")
========================================================

Applying Updates {#applying-updates}
-------------------------------------------------------------------
[Applying Updates](#applying-updates)
    -   [Backup & Migration](#backup-migration)
        -   [Limitations](#limitations)
            -   [Custom Services](#custom-services)
            -   [Hard-coded Database Connection
                Info](#hard-coded-database-connection-info)
            -   [DEAs](#deas)
        -   [Exporting the server data](#exporting-the-server-data)
        -   [Scheduled backups](#scheduled-backups)
        -   [Importing the server data](#importing-the-server-data)
    -   [Upgrading (v1.0 and later)](#upgrade)
    -   [Server Monitoring with New
        Relic](#server-monitoring-with-new-relic)
    -   [System Monitoring with Nagios](#system-monitoring-with-nagios)
    -   [Persistent Storage](#storage)
        -   [Relocating Services, Droplets, and
            Containers](#relocating-services-droplets-and-containers)
        -   [Enabling Filesystem Quotas](#enabling-filesystem-quotas)


Major version upgrades of Application Lifecycle Service can be done using [*kato node
upgrade*](/als/v1/admin/server/upgrade/#upgrade) or a [*migration to a new VM
or cluster*](#bestpractices-migration), but patch releases (normally
minor fixes to particular components) can be applied in place using the
[*kato patch*](/als/v1/admin/reference/kato-ref/#kato-command-ref-patch)
command.

To see a list of patches available from HP, run the following
command on any Application Lifecycle Service VM:

    $ kato patch status

The command will list the updates available. For example:

    2 updates available to be installed.

    Known updates:
      dea-memory-usage-reporting: Fix the reporting of helion stats usage on the DEA end.
        severity: required
        roles affected: dea

      vsphere-autoscaling-fix: Fix VSphere autoscaling behavior.
        severity: required
        roles affected: controller, primary

To apply all patches to all relevant cluster nodes:

    $ kato patch install

To apply a particular patch, specify it by name:

    $ kato patch install dea-memory-usage-reporting

Applying patches will automatically restart all patched roles. To
prevent this, use the `--no-restart` option.

To apply a patch only to the local Application Lifecycle Service VM (not the whole cluster),
use the `--only-this-node` option.

Backup & Migration {#backup-migration}
---------------------------------------------------------------------

This section describes backing up Application Lifecycle Service data and importing it into a
new Application Lifecycle Service system. The export/import cycle is required for:

-   backups of system data
-   moving an Application Lifecycle Service cluster to a new location

### Limitations[](#limitations "Permalink to this headline")

Before deciding on a backup, upgrade or migration strategy, it's
important to understand what data the Application Lifecycle Service system can save, and what
may have to be reset, redeployed, or reconfigured. This is especially
important when migrating to a new cluster.

#### Custom Services[](#custom-services "Permalink to this headline")

Application Lifecycle Service can export and import data from built-in data services running
on Application Lifecycle Service nodes, but it has no mechanism to handle data in [*external
databases*](/als/v1/admin/cluster/external-db/#external-db) (unless
`kato export|import` has also been modified to
recognize the custom service).

Backing up or moving such databases should be handled separately, and
user applications should be reconfigured and/or redeployed to connect
properly to the new database host if the database is not implemented as
an Application Lifecycle Service data service.

#### Hard-coded Database Connection Info[](#hard-coded-database-connection-info "Permalink to this headline")

Applications which write database connection details during staging
rather than taking them from environment variables at run time, must be
re-staged (e.g. redeployed or updated) to pick up the new service
location and credentials. Restarting the application will not
automatically force restaging.

#### DEAs[](#deas "Permalink to this headline")

Droplet Execution Agent (DEA) nodes are not migrated directly from old
nodes to new nodes. Instead, the application droplets (zip files
containing staged applications) are re-deployed to new DEA nodes from
the Controller.

### Exporting the server data[](#exporting-the-server-data "Permalink to this headline")

Data export is done with the [*kato data
export*](/als/v1/admin/reference/kato-ref/#kato-command-ref-data-export)
command. The command can export:

-   internal Application Lifecycle Service data (users, groups, quotas, settings, etc.)
-   application droplets
-   data services

Start by logging into the VM via `ssh`:

    $ ssh helion@helion-xxxx.local

A single-node micro cloud VM can be backed up with a single command:

    $ kato data export --only-this-node

A clustered setup can be backed up with a single command:

    $ kato data export --cluster

Once the export completes, you can use
[scp](http://manpages.ubuntu.com/manpages/lucid/man1/scp.1) or
another utility (e.g. sftp, rsync) to move the .tgz file to another
system, or save the file directly to a mounted external filesystem by
specifying the full path and filename during export (see backup example
below).

**Note**

Exporting data can take several minutes. For clusters with constant
usage or large numbers of users, apps, and databases, put the exporting
system in [*Maintenance Mode*](/als/v1/admin/console/customize/#console-settings)
(e.g. during a scheduled maintenance window) before exporting.

### Scheduled backups[](#scheduled-backups "Permalink to this headline")

Regular backup of controller data, apps, droplets, and service data is
recommended for any production system. Implementation of a regular
backup routine is left to the discretion of the Application Lifecycle Service administrator,
but using
[cron/crontab](http://manpages.ubuntu.com/manpages/oneiric/man1/crontab.1)
is one simple way is to automate this. For example, you could create an
entry like the following in the root user's crontab on the filesystem
node:

    0 3 * * * su - helion /bin/bash -c '/home/helion/bin/kato data export --cluster /mnt/nas/helion-backup.tgz'

This runs `kato data export --cluster` every morning
at 3AM as `root` using the `helion` user's login environment (required) and saves a .tgz file to a
mounted external filesystem.

Scheduled (non-interactive) backups using the `kato export` command will need to be run by `root` as
some shell operations performed in the export require `sudo` when run interactively. For clusters, passwordless [SSH key
authentication](https://help.ubuntu.com/community/SSH/OpenSSH/Configuring#disable-password-authentication)
between the Core node and all other nodes will also need to be set up.
The command should be run on the node hosting the 'filesystem' role, as
some shell commands need to be run locally for that service.

### Importing the server data[](#importing-the-server-data "Permalink to this headline")

To import Application Lifecycle Service data, transfer the exported .tgz file to the target
VM or note the hostname of the old VM / Core node.

**Note**

Before importing data to a new microcloud or cluster, make sure you have
completed first-user (admin) setup in the Application Lifecycle Service Web UI and accepted
the terms and conditions.

**Note**

All roles in the new cluster should be started prior to proceeding with
import. If you would like all services to be imported, their
corresponding roles must be enabled (see also [*Importing Apps using
RabbitMQ
2.4*](/als/v1/admin/reference/known-issues/#known-issues-rabbit-import)).

Login to the Application Lifecycle Service VM (or Core node) and run
`kato data import` with the relevant options. For
example, to import all data into a new cluster from a .tgz file:

    $ kato data import --cluster helion-export-xxxxxxxxxx.tgz

To import data from a running Application Lifecycle Service system instead, specify the
hostname of the old Core node:

    $ kato data import --cluster helion-host.example.com

##Upgrading (v1.0 and later) {#upgrade}


The `kato node upgrade` command was added in
Application Lifecycle Service 1.0 to allow upgrading Application Lifecycle Service systems in place. See
[*Upgrading Application Lifecycle Service*](/als/v1/admin/server/upgrade/#upgrade) for full
instructions.

Server Monitoring with New Relic[](#server-monitoring-with-new-relic "Permalink to this headline")
---------------------------------------------------------------------------------------------------

To use New Relic for server monitoring, you'll need a [New Relic
account](http://newrelic.com/) and a License Key. Install the
`newrelic-sysmond` package and start the monitoring
daemon on each Application Lifecycle Service VM as per the [New Relic Server Monitor
installation
(Ubuntu)](http://docs.newrelic.com/docs/server/server-monitor-installation-ubuntu-and-debian)
instructions.

System Monitoring with Nagios[](#system-monitoring-with-nagios "Permalink to this headline")
---------------------------------------------------------------------------------------------

Though Application Lifecycle Service has an internal mechanism for supervising processes on a
server or cluster ([Supervisor](http://supervisord.org/)), it is
advisable to add some external monitoring for production systems.
[Nagios](http://www.nagios.org/) is a free, open source system
monitoring tool that can provide this external monitoring.

Detailed instructions on installing and configuring Nagios can be found
in the [Nagios Core
Documentation](http://nagios.sourceforge.net/docs/3_0/toc)

##Persistent Storage {#storage}

Cloud hosting providers have different default partition sizes and
configurations. The default root volumes on some cloud hosted VM
instances are often fairly small and are usually ephemeral. Data service
and filesystem nodes should always be backed by some kind of persistent
storage, with enough free filesystem space to accommodate the projected
use of the services.

### Relocating Services, Droplets, and Containers[](#relocating-services-droplets-and-containers "Permalink to this headline")

To move database services, application droplets, and application
containers to larger partitions:

-   mount the filesystem and/or block storage service on the instance
    (with [*quotas enabled*](#bestpractices-filesystem-quotas)),
-   create directories for the items you wish to move,
-   run the [*kato
    relocate*](/als/v1/admin/reference/kato-ref/#kato-command-ref-relocate)
    command(s).

For example:

    $ kato stop
    ...
    $ kato relocate services /mnt/ebs/services
    ...
    $ kato relocate droplets /mnt/ebs/droplets
    ...
    $ kato relocate containers /mnt/containers
    ...

**Note**

For performance reasons, Application Lifecycle Service containers should not be relocated to
block volumes.

### Enabling Filesystem Quotas[](#enabling-filesystem-quotas "Permalink to this headline")

The Application Lifecycle Service filesystem quotas cannot be enforced by the system unless
they are mounted on partitions which support Linux quotas. This may need
to be specified explicitly when running the `mount`
command. The [*kato
relocate*](/als/v1/admin/reference/kato-ref/#kato-command-ref-relocate) command
will warn if this is necessary.

For the example above, the `mount` step might look
like this:

    $ sudo mount -o remount,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0 /mnt/containers
    $ sudo quotacheck -vgumb /mnt/containers
    $ sudo quotaon -v /mnt/containers

To ensure the quotas are preserved after reboot, edit
*/etc/init.d/setup\_helion\_lxc* to include mount commands for each
partition. The example above would require a block such as this:

    # enable quotas for Application Lifecycle Service containers
    if [[ -f "/mnt/containers/aquota.user" ]]; then
      mount -o remount,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0 /mnt/containers
      quotaon -v /mnt/containers
    fi

---
layout: default-devplatform
permalink: /als/v1/admin/best-practices/logging-examples/
product: devplatform
---
<!--PUBLISHED-->

Log Drain Examples[](#log-drain-examples "Permalink to this headline")
=======================================================================
  [Papertrail](#papertrail)
    -   [Loggly](#loggly)
    -   [Splunk](#splunk)
    -   [Hello World Custom Drain](#hello-world-custom-drain)

Detailed instructions on how to use drains with third party log analysis
software or services:

-   [*Papertrail*](#logging-examples-papertrail)
-   [*Loggly*](#logging-examples-loggly)
-   [*Splunk*](#logging-examples-splunk)

**Note**

Do not forward both application and system logs to the same destination.

Papertrail[](#papertrail "Permalink to this headline")
-------------------------------------------------------

1.  [Create an account for Papertrail](https://papertrailapp.com/plans)
2.  In the Dashboard screen, click *Add Systems*.
	<img src="content/documentation/devplatform/helion/imagesppt1.png" />

3.  In the Setup Systems screen under *Other log methods*, click
    *Alternatives*.
	<img src="/content/documentation/devplatform/helion/images/ppt2.png" />

4.  Choose option C: *My system's hostname changes* and give it a
    suitable name.
	<img src="/content/documentation/devplatform/helion/images/ppt3.png" />
5.  Note down the **port number**. You need this later on.
	<img src="/content/documentation/devplatform/helion/images/ppt4.png" />

6. Enable system logging (via udp) by executing the following kato command:
	
`kato log drain add drain-name udp://logs.papertrailapp.com:port#`

**Note**

Papertrail requires systail log lines to have `<13>l` at the beginnging of each line. Make sure the drain you are
forwarding is formatted this way (see example in [*Saving Custom Log
Formats*](/als/v1/admin/server/logging/#logging-drains-save-format)).

Loggly[](#loggly "Permalink to this headline")
-----------------------------------------------

1.  [Create an account for Loggly](https://app.loggly.com/pricing)
2.  Under *Incoming Data* tab, click *Add Input*.
	<img src="/content/documentation/devplatform/helion/images/loggly1.png" />
3.  In the Add Input screen:
	-   Choose *Syslog UDP or TCP*
	-   Choose *Combination Log Type*
	-   [Optional] For JSON Logging, Choose UDP or TCP **with Stripe** and enable **JSON Logging**. (for system logs)
	<img src="/content/documentation/devplatform/helion/images/loggly2.png" />
4.  If we want to accept logs from any Application Lifecycle Service nodes or applications modify Allowed Devices section:
	-   Click *Add device*
	 <img src="/content/documentation/devplatform/helion/images/images/loggly3.png" />
	-   Add IP Address 0.0.0.0/0 when prompted
	 <img src="/content/documentation/devplatform/helion/images/loggly4.png" />
5.  Turn off discovery since we allowed all devices. Also, note down the
    **port number**.
	 <img src="/content/documentation/devplatform/helion/images/loggly5.png" />
6. Enable system logging by executing **one** of the following kato commands:

    	kato log drain add drain-name udp://logs.loggly.com:port#

    	kato log drain add drain-name tcp://logs.loggly.com:port#

Loggly supports JSON format with minor configuration changes shown above. Enable system JSON logging by executing the following kato command:

    kato log drain add --format json drain-name tcp://logs.loggly.com:port#


Splunk[](#splunk "Permalink to this headline")
-----------------------------------------------

1.  [Set up Splunk Server](http://www.splunk.com/download).
2.  In the welcome screen, click *Add data*
	<img src="/content/documentation/devplatform/helion/images/splunk1.png" />
3.  Under *Choose a Data Source*, click **From a TCP port** (or UDP)<br><img src="/content/documentation/devplatform/helion/images/splunk2.png"/>

1. In the **Add New Source** screen:
	-   Select a TCP/UDP port greater than **9999**
	-   Give it a suitable **Source name**.
	-   Set sourcetype to **Manual**
	-   Leave Source Type **empty**
	<img src="/content/documentation/devplatform/helion/images/splunk3.png" />
5. Enable system logging by executing **one** of the following kato commands:

    	kato log drain add drain-name splunk-server-address:port#

    	kato log drain add drain-name tcp://splunk-server-address:port#

Splunk supports JSON format without further configuration. Enable system JSON logging by executing the following kato command:

    kato log drain add --format json drain-name tcp://splunk-server-address:port#

Hello World Custom Drain[](#hello-world-custom-drain "Permalink to this headline")
-----------------------------------------------------------------------------------

The command below starts a drain target server on a node and pipes it to a local file:

    nc -lk 0.0.0.0 10000 > log-output.txt

As long as that nc command runs, this will funnel logs from all drains, targeting it into the file log-output.txt

Enable system logging by executing **one** of the following kato commands:

    kato log drain add drain-name udp://server-address:port#
	kato log drain add drain-name tcp://server-address:port#
---
layout: default-devplatform
permalink: /als/v1/admin/cluster/autoscaling/
product: devplatform
---
<!--PUBLISHED-->

DEA Auto Scaling[](#dea-auto-scaling "Permalink to this headline")
===================================================================
   [DEA Template](#dea-template)
    -   [DEA Scaling configuration](#dea-scaling-configuration)
    -   [Enabling Auto-Scaling](#enabling-auto-scaling)
    -   [Configuration and Tuning
        (Advanced)](#configuration-and-tuning-advanced)
    -   [Writing custom scaling plugins
        (Advanced)](#writing-custom-scaling-plugins-advanced)
    -   [Troubleshooting](#troubleshooting)
    -   [Testing](#testing)


Application Lifecycle Service can automatically add DEA nodes to a cluster to handle
increasing numbers of user application instances.

When auto scaling is enabled, the Application Lifecycle Service will automatically grow the pool
of DEA nodes to accommodate new app deployments. Scaling events are
triggered the available memory in the pool falls below a certain
threshold.

DEA Template[](#dea-template "Permalink to this headline")
-----------------------------------------------------------

Before enabling auto scaling, you will need to create a DEA template
from the standard Application Lifecycle Service VM. Typically you would do this by running
the following commands on a fresh Application Lifecycle Service VM:

    $ kato op defer "node attach -e dea CORE_IP" --run-as-root

This defers the `attach` command and enables the DEA
role on the next boot. Shut down the VM once this is done.


DEA Scaling configuration[](#dea-scaling-configuration "Permalink to this headline")
-------------------------------------------------------------------------------------

The DEA auto scaling configuration file is:

    /s/etc/autoscaling/autoscaling.yaml

This file must be modified on each node running the Controller role.

Comments throughout the file describe in detail what each option does,
and what information is required for each infrastructure platform.

The `enabled_plugins` key must be set to OpenStack.

Each platform has specific tunable settings under the
`platform` key in *autoscaling.yaml* for setting
authorization credentials, DEA template IDs and so forth. Configure the
settings for your platform in this file before proceeding.

Enabling Auto-Scaling[](#enabling-auto-scaling "Permalink to this headline")
-----------------------------------------------------------------------------

Run the following command on the Primary node:

    $ kato config set cloud_controller_ng autoscaling/enabled true
    $ kato config set health_manager autoscaling/enabled true

**Note**

If you are running more than one cloud controller in your cluster,
enable the scaling plugin on **only one** of the cloud controllers,
otherwise each one will provision a separate DEA on every scaling event.

After saving this change, restart the following processes:

    $ kato process restart health_manager cloud_controller_ng

You should then start seeing some scaling information in the Health
Manager's log file:

    $ kato log tail health_manager

Configuration and Tuning (Advanced)[](#configuration-and-tuning-advanced "Permalink to this headline")
-------------------------------------------------------------------------------------------------------

A number of configuration options in the autoscaling file can be
customized to fit your particular requirements.

The options in */s/etc/autoscaling/autoscaling.yaml* are:



- `scale_op_timeout`
	- Specifies how long the scaler will wait for the plugin to complete a scale up operation (Default: 300, Unit: seconds).
- `cooldown_period`
	- After a scaling event, ignore subsequent scaling requests until this period expires. Prevents duplicate scaling events. (Default: 120, Unit: seconds)
- `vm_name_prefix`
	- Gives the new Application Lifecycle Service VM instance a name with this prefix to easily
-     identify autoscaled instances.

Further settings are found in the health\_manager configuration (see `kato config get health_manager autoscaling`)

- `scaleup_threshold`
	- Number of cycles to wait before issuing a scaling request. The health manager monitors the DEA pool continually. If the forward buffer is not maintained during the number of cycles indicated by this value, the scaling event will be sent to the cloud controller. Decrease this value to make autoscaling more aggressive. (Default: 3)
- `forward_buffer`
	- The number of megabytes of free memory to maintain in the DEA pool. Note that app memory usage on each DEA is also accounted for. (Default: 4096, Unit: MB)
- `cooldown_period`
	- After a scaling event, ignore subsequent scaling requests until this period expires (Default: 180, Unit: seconds)
- `dea_staleness`
	- Maximum time to wait for DEAs to report their status via NATS. If a DEA fails to report in during this period (e.g. it becomes unresponsive) it will be removed from the pool, which may lead to a new scaling event being triggered. (Default: 180, Unit: seconds)

Writing custom scaling plugins (Advanced)[](#writing-custom-scaling-plugins-advanced "Permalink to this headline")
-------------------------------------------------------------------------------------------------------------------

Autoscaling plugins are written in Ruby. You can see the built-in
plugins in the */s/etc/autoscaling/plugins/* directory. A simpler
"skeleton" plugin might look like this:

    require 'rubygems'

    class SkeletonPlugin < Plugin

      def platform_name
        "Skeleton"
      end

      def scale_up
        log "Scaling up..."
        log platform_config.inspect
      end

      def handle_command
        log "Handling command: #{cmd}"
      end

    end

The `log` function is available to all plugins and
operates at the cloud controllers global log level.

Once you have written a plugin, install the file in
*/s/etc/autoscaling/plugins/*. Add configuration for the plugin in
*/s/etc/autoscaling/autoscaling.yaml* under the
`platform_config` key in a new section corresponding
to the plugin name (in this case above: `skeleton`).
Enable the plugin by adding it to the `enabled_plugins` list.

Troubleshooting[](#troubleshooting "Permalink to this headline")
-----------------------------------------------------------------

Most of the output from the scaling triggers comes from the health
manager:

    $ kato log tail health_manager

Once scaling has been triggered by the health manager, you can check for
the relevant platform API output in the controller:

    $ kato log tail cloud_controller


Testing[](#testing "Permalink to this headline")
-------------------------------------------------

If you want to emulate a scaling trigger, you can force a scale-up
operation by issuing the following on the cloud controller node:

    $ nats-pub health.scale '{"op": "up"}'---
layout: default-devplatform
permalink: /als/v1/admin/cluster/cloud-init/
product: devplatform
---
<!--PUBLISHED-->

cloud-init[](#cloud-init "Permalink to this headline")
=======================================================

[cloud-init](https://help.ubuntu.com/community/CloudInit) (the Ubuntu
package for handling early initialization of cloud instances) can be
used to provide additional flexibility when configuring Application Lifecycle Service cluster
nodes, and can simplify joining a cluster and assigning roles.

cloud-init can be configured at instance launch time by pasting YAML
directly into the OpenStack Horizon interface.

For example, given a core node at IP 10.2.3.4, the following
cloud-config would add a new DEA node to the cluster:

    #cloud-config

    helion:
      nats:
        ip: 10.2.3.4
      roles: ['dea']
      extname: "paas.example.com" 

-   `nats:ip` will run
    `kato attach <nats ip>` the first time the VM is
    booted.
-   `extname` when supplied with a fully qualified
    domain name will run `kato rename <extname>` on
    the instance first boot.
-   Roles takes a list of roles to configure the node with. For guidance
    on how to work with roles see
    [*Roles*](index.html#server-cluster-roles).

Securing the new node[](#securing-the-new-node "Permalink to this headline")
-----------------------------------------------------------------------------

To lock down and secure this new node, you could use standard cloud-config directives for adding any SSH keys, randomizing passwords, and/or disabling password based authentication entirely. An example that creates a data services node, enables passwordless sudo for the admin group, and disables password based authentication:

    #cloud-config

    helion:
      nats:
        ip: 10.2.3.4
      roles: ['data-services']

    chpasswd:
     list: |
       helion:RANDOM
       root:RANDOM
       ubuntu:RANDOM
     expire: false
    ssh_pwauth: false

    bootcmd:
    - - cloud-init-per
      - once
      - sudo_admin_group_nopasswd
      - sed
      - -ri
      - s|^%admin .*|%admin ALL=\(ALL\) NOPASSWD:ALL|
      - /etc/sudoers

Custom System Configuration[](#custom-system-configuration "Permalink to this headline")
-----------------------------------------------------------------------------------------

In addition to the Application Lifecycle Service node configuration tasks described above,
cloud-init can be used for a variety of system setup tasks:

-   adding custom apt sources
-   setting apt mirrors
-   running arbitrary commands at boot
-   setting up chef, puppet, salt-stack, or MCollective
-   setting the locale and time zone
-   resizing the root filesystem to take up all available space, making
    it easy to grow a snapshot
-   set passwords
-   configure ssh keys

For more information on cloud-init, refer to the [official CloudInit
documentation](https://help.ubuntu.com/community/CloudInit).---
layout: default-devplatform
permalink: /als/v1/admin/cluster/external-db/
product: devplatform
---
<!--PUBLISHED-->

External Data Services[](#external-data-services "Permalink to this headline")
===============================================================================
[General Principles](#general-principles)
    -   [MySQL](#mysql)
    -   [PostgreSQL](#postgresql)
    -   [Troubleshooting](#troubleshooting)

Application Lifecycle Service comes with several data services that can be enabled on an Application Lifecycle Service cluster. However, for implementations where high
availability or high performance databases are required, it's advisable
to configure Application Lifecycle Service to connect to an externally maintained database or
data service.

External data services can be configured at the discretion of the
administrator or service provider, but in many cases they can be set up
so that Application Lifecycle Service can allocate databases in the same way it does for the
built-in databases.

General Principles[](#general-principles "Permalink to this headline")
-----------------------------------------------------------------------

Any application running on Application Lifecycle Service can connect to an external database
directly as long as the instance can route to the IP address and port of
the database server. Database connections can be hard coded in the
application without needing to make any changes to Application Lifecycle Service
configuration.

To automatically provision databases for applications on these external
servers, Application Lifecycle Service must have access to an administrator account on the
database server with permissions to create users and databases. The
credentials for this account, along with the hostname and port of the
database server, are set in the Application Lifecycle Service configuration (via [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config)).

MySQL[](#mysql "Permalink to this headline")
---------------------------------------------

The MySQL server must be set up to allow connections over the network
(rather than just on 'localhost'). Make sure the 'bind-address' is set
to the host's IP address (or '0.0.0.0').

Enter the `mysql` shell and grant the root user
privileges on all tables. For example:

    $ GRANT ALL PRIVILEGES ON *.* TO 'root'@'10.5.120.%' IDENTIFIED BY
    '<PASSWORD>'
    WITH GRANT OPTION;
    $ FLUSH PRIVILEGES;

The `10.5.120.%` portion above should be in relation
to the Application Lifecycle Service `mysql_node` IP address. For
increased security you can create a special 'helion' user with the
same privileges as the 'root' user as an alternative option.

Once the user is configured to accept connections from Application Lifecycle Service and to
create users and databases, change the configuration for 'mysql\_node'
in Application Lifecycle Service. For example:

    $ kato config set mysql_node mysql/host 10.5.120.101
    $ kato config set mysql_node mysql/pass yourpassword
    $ kato config set mysql_node mysql/port 3306
    $ kato config set mysql_node mysql/user root

Once these have been set, restart mysql:

    $ kato restart mysql

PostgreSQL[](#postgresql "Permalink to this headline")
-------------------------------------------------------

Make sure the PostgreSQL database server (version 9.1 or later) will
accept connections over the network. Edit *postgresql.conf* make sure
the 'listen\_addresses' is uncommented and set to the networked
interface IP. For example:

    listen_addresses = 'localhost, 10.5.120.102'

Edit *pg\_hba.conf* and make sure a line exists that allows all Application Lifecycle Service
instances to connect to it. For example:

    host    all   all       10.5.120.0/23   md5

Restart PostgreSQL.

Using the default 'postgres' user (or another account with the same
superuser privileges), change the configuration for 'postgresql\_node'
in Application Lifecycle Service. For example:

    $ kato config set postgresql_node postgresql/host 10.5.120.102
    $ kato config set postgresql_node postgresql/pass yourpassword
    $ kato config set postgresql_node postgresql/port 5432
    $ kato config set postgresql_node postgresql/user postgres

Once these have been set, restart the postgresql\_node process:

    $ kato restart postgresql_node

Troubleshooting[](#troubleshooting "Permalink to this headline")
-----------------------------------------------------------------

The `psql` and `mysql` clients
are available at the command line on the Application Lifecycle Service VM. Log in to the Core
node (i.e. the one running the Cloud Controller) and test the database
connection directly with the appropriate client. For example:

    $ mysql -u helion -p mypassword -h 10.5.120.101
    mysql> show databases;
    ...

If the basic client connection works, test database creation using the
`helion create-service ...` command:

    $ helion create-service mysql
    Creating Service [mysql-24901]: OK

If there are problems, check the corresponding logs on the database
server. These are generally found in */var/log/postgresql* and
*/var/log/mysql*.

Logs from Application Lifecycle Service can be viewed with `kato log tail`:

    $ kato log tail postgresql_node
---
layout: default-devplatform
permalink: /als/v1/admin/cluster/harbor/
product: devplatform
---
<!--PUBLISHED-->

Harbor: TCP/UDP Port Service[](#harbor-tcp-udp-port-service "Permalink to this headline")
==========================================================================================
   [Architecture](#architecture)
    -   [Requirements & Setup](#requirements-setup)
    -   [Troubleshooting](#troubleshooting)

The Harbor service provisions ports to user applications. The standard
router in Application Lifecycle Service is designed for HTTP(S) traffic only, if user
applications require other protocols, consider setting up Harbor.

Information on using the Harbor port service with deployed applications
is in the [*Port Service (Harbor)
documentation*](/als/v1/user/services/port-service/#port-service).

Architecture[](#architecture "Permalink to this headline")
-----------------------------------------------------------

A Harbor node is designed to sit on the edge of the cluster network
(i.e. with a publicly routable network interface) in a similar fashion
to the router component. This allows it to effectively proxy external
and internal traffic from your app to the outside world and vice versa.

Unlike the router component which normally only requires 80/HTTP and
443/HTTPS ports to be externally visible, a Harbor node will
automatically provision ports from a pre-configured range.

The harbor node learns about new routes for each provisioned service
from the DEAs. When an application instance bound to a Harbor service on
a DEA is terminated (stopped, failed, or scaled down), Harbor will also
drop that instance from its list of backends available for the
externally facing port.

Requirements & Setup[](#requirements-setup "Permalink to this headline")
-------------------------------------------------------------------------

An Application Lifecycle Service VM can be configured as a Harbor node in the same way as
other [*data service roles*](index.html#server-cluster-data-services).
For example:


    $ kato node attach -e harbor CORE_IP


The node must be routable both externally by connecting clients, and the
internal DEA nodes must be contactable by the Harbor node. You must also
make allowances for any firewall rules so that the provisioned port
range used by Harbor is open to the external network.

The default range for these ports is '35000 - 40000', however you can
view the current port range on the Harbor node by entering:

    $ kato config get harbor_node port_range

For each new service provisioned, Harbor will chose a random unassigned
port from this range. This range can be set in the Management Console's
[*Settings*](/als/v1/admin/console/customize/#console-settings) section, or by
using the `kato config set ...` command.

A Harbor node can run standalone, or on the same node as your router.
This may be the preferred option if wish to use the same DNS name for
Harbor and Router services. Otherwise, create new DNS entry for the
harbor node, so that consumers of the port do not have to address it by
its external IP.

If you are setting a different IP / DNS name for this port you should
update the node config so that it provides these external connection
details to the users service credentials.

To set the externally routable hostname:

    $ kato config set harbor_node hostname_external ext-services.example.com

To set the externally routable IP:

    $ kato config set harbor_node host_external 192.0.43.10

Troubleshooting[](#troubleshooting "Permalink to this headline")
-----------------------------------------------------------------

If you have problems with the Harbor service, first check the status via
'kato status'.

The Harbor service can be safely restarted; any ports and routes
provisioned are automatically added and the backends are re-validated on
startup:

    $ kato restart harbor

Check the log files for errors and warnings. Four Harbor log files can
be found in the */s/logs/* directory:

    * harbor_gateway.log
    * harbor_node.log
    * harbor_proxy_connector.log
    * harbor_redis.log

No Application Lifecycle Service processes should conflict with the default Harbor port
range. However, in systems with additional custom processes running,
other processes may assume control of a port within Harbor's port range.
This condition which will show up in *harbor\_proxy\_connector.log*.

You can avoid these conflicts by setting the Harbor port range to avoid
conflicting processes. To resolve an accidental conflict, change the
port used by the conflicting application and restart. Any user
application using the port in conflict should be restarted to force
Harbor to re-listen on that port.---
layout: default-devplatform
permalink: /als/v1/admin/cluster/
product: devplatform
---
<!--PUBLISHED-->

Cluster Setup[](#index-0 "Permalink to this headline")
=======================================================
 [Roles](#roles)
    -   [Preparing the Core Node](#preparing-the-core-node)
        -   [CORE\_IP](#core-ip)
        -   [Hostname](#hostname)
        -   [Wildcard DNS](#wildcard-dns)
        -   [Core Node](#core-node)
    -   [Attaching Nodes and Enabling
        Roles](#attaching-nodes-and-enabling-roles)
        -   [Router Nodes](#router-nodes)
        -   [Data Services Nodes](#data-services-nodes)
        -   [DEA Nodes](#dea-nodes)
        -   [Verification](#verification)
        -   [Removing Nodes](#removing-nodes)
        -   [Role Configuration using the Management
            Console](#role-configuration-using-the-management-console)
    -   [Example Clusters](#example-clusters)
        -   [Single-Node](#single-node)
        -   [Three-Node](#three-node)
        -   [Five-Node](#five-node)
        -   [20-Node](#node)
    -   [Roles Requiring Persistent or Shared
        Storage](#roles-requiring-persistent-or-shared-storage)
    -   [Port Configuration](#port-configuration)
    -   [Multiple Controllers](#multiple-controllers)
    -   [Load Balancer and Multiple
        Routers](#load-balancer-and-multiple-routers)
        -   [Rename the Load Balancer](#rename-the-load-balancer)
        -   [Set up the Core Node](#set-up-the-core-node)
        -   [Set up Supplemental Routers](#set-up-supplemental-routers)
        -   [Configure the Application Lifecycle Service Load
            Balancer](#configure-the-helion-load-balancer)
        -   [Load Balancer SSL
            Certificates](#load-balancer-ssl-certificates)

This process begins with an installed [*micro
cloud*](/als/v1/user/reference/glossary/#term-micro-cloud), which must
then be cloned across several
[*node*](/als/v1/user/reference/glossary/#term-node)s. You connect to
each node in turn and tell it which
[*role*](/als/v1/user/reference/glossary/#term-role)s it is to serve,
thereby distributing the processing load for maximum performance.  In Helion, the Horizon Clusters Panel takes care of this for you.

Roles[](#roles "Permalink to this headline")
---------------------------------------------

An Application Lifecycle Service [*node*](/als/v1/user/reference/glossary/#term-node) can
take on one or more of the following roles:

-   [*primary*](/als/v1/admin/reference/architecture/#architecture-primary)
-   [*controller*](/als/v1/admin/reference/architecture/#architecture-controller)
-   [*router*](/als/v1/admin/reference/architecture/#architecture-router)
-   [*dea*](/als/v1/admin/reference/architecture/#architecture-dea)
-   mdns (intended for micro clouds)
-   [*filesystem*](/als/v1/user/services/filesystem/#persistent-file-system)
-   [*mysql*](/als/v1/user/reference/glossary/#term-mysql)
-   [*postgresql*](/als/v1/user/reference/glossary/#term-postgresql)
-   rabbit
-   redis
-   [*memcached*](/als/v1/user/services/memcached/#memcached)
-   [*Harbor*](/als/v1/admin/cluster/harbor/#harbor) (TCP/UDP port service)

The command line tool used to configure Application Lifecycle Service servers is called
[*kato*](/als/v1/admin/reference/kato-ref/#kato-command-ref). You can see a
list of the available roles at the command line by running the [*kato
info*](/als/v1/admin/reference/kato-ref/#kato-command-ref-info) command.

Setup of cluster nodes is done using the [*kato
node*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach) setup,
add, attach, and remove sub-commands.

The [*kato info*](/als/v1/admin/reference/kato-ref/#kato-command-ref-info)
command will show:

-   **assigned roles**: roles currently configured to run on the node
-   **available roles**: roles which can be added with
    `kato role add`

Preparing the Core Node[](#preparing-the-core-node "Permalink to this headline")
---------------------------------------------------------------------------------

In an Application Lifecycle Service cluster, one node is dedicated as the Core node. This node
will have a
[*controller*](/als/v1/admin/reference/architecture/#architecture-controller),
[*primary*](/als/v1/admin/reference/architecture/#architecture-primary),
[*base*](/als/v1/admin/reference/architecture/#architecture-base), and
[*router*](/als/v1/admin/reference/architecture/#architecture-router) role but
can also include additional roles.

Boot an Application Lifecycle Service VM and set up the Core node as described below, then add
the other nodes and assign roles.

### CORE\_IP[](#core-ip "Permalink to this headline")

A [*static IP
address*](/als/v1/admin/server/configuration/#server-config-static-ip) is
necessary to provide a consistent network interface for other nodes to
connect to. If your IaaS or cloud orchestration software provide IP
addresses which persist indefinitely and are not reset on reboot you may
not have to set this explicitly.

Take note of the IP address of the Core node. It will be required when
configuring additional nodes in the following steps, so that they can
attach to the Core node.

Make sure that the IP address of its `eth0`
interface is registering the correct address, which may not be the case
if you have set a static IP and not yet rebooted or restarted
networking. To check the IP address, run:


    $ ifconfig eth0

If necessary, set the [*static IP
address*](/als/v1/admin/server/configuration/#server-config-static-ip):


    $ kato op static_ip

**Note**

If the IP address of the Core node changes, the [*kato node
migrate*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command must be run on all nodes in the cluster (starting with the Core
node) to set the new CORE\_IP.

### Hostname[](#hostname "Permalink to this headline")

Next, set the **fully qualified hostname** of the Core node. This is
required so that Application Lifecycle Service's internal configuration matches the [*DNS
record*](/als/v1/admin/server/configuration/#server-config-dns) created for
this system.

To set the hostname, run:


    $ kato node rename hostname.example.com --no-restart


This hostname will become the basename of the "API endpoint" address
used by clients (e.g. "https://api.hostname.example.com").

**Note**

If you are building a cluster with multiple Routers separate from the
Core node, the load balancer or gateway router must take on the API
endpoint address. Consult the [*Load Balancer and Multiple
Routers*](#cluster-load-balancer) section below.

### Wildcard DNS[](#wildcard-dns "Permalink to this headline")

A wildcard DNS record is necessary to resolve not only the API endpoint,
but all applications which will subsequently be deployed on the PaaS.
[*Create a wildcard DNS
record*](/als/v1/admin/server/configuration/#server-config-dns) for the Core
node (or [*Load Balancer/Router*](#cluster-load-balancer)).

### Core Node[](#core-node "Permalink to this headline")

On the Core node, execute the following command:


    $ kato node setup core api.hostname.example.com

This sets up the Core node with just the implicit **controller**,
**primary**, and **router** roles.

If you intend to set up the rest of the cluster immediately, you would
carry on to enable those roles you ultimately intend to run on the Core
node. For example, to set up a Core node with the **controller**,
**primary** **router**, and **dea** roles:

    $ kato node setup core api.hostname.example.com
    $ kato role add dea


Then proceed to configure the other VMs by attaching them to the Core
node and assigning their particular roles.

Attaching Nodes and Enabling Roles[](#attaching-nodes-and-enabling-roles "Permalink to this headline")
-------------------------------------------------------------------------------------------------------

Adding nodes to the cluster involves attaching the new VMs to the Core
node's IP address using the [*kato node
attach*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command. This command will check that the new node has a version number
compatible with the Core node before attaching it.

Roles can be added (or removed) on the new node after attaching using
the [*kato role*](/als/v1/admin/reference/kato-ref/#kato-command-ref-role-add)
command, but it is generally preferable to enable roles during the
`kato attach` step using the `-e` (enable) option as described below for each of the node types.

### Router Nodes[](#router-nodes "Permalink to this headline")

In smaller clusters, the Router role can be run on the Core Node. To run
its own on a separate node:


    $ kato node attach -e router CORE_IP


**Note** that the public DNS entry for the Application Lifecycle Service cluster's API endpoint
must resolve to the Router if it is separate from the Core Node. For
clusters requiring multiple Routers, see the [*Load Balancer and
Multiple Routers*](#cluster-load-balancer) section below.

### Data Services Nodes[](#data-services-nodes "Permalink to this headline")

Data services can share a single node (small clusters) or run on
separate nodes (recommended for production clusters). To set up all
available data services on a single node and attach it to the Core node,
run the following command on the data services node:


    $ kato node attach -e data-services CORE_IP


**Note**

The [*Harbor*](/als/v1/admin/cluster/harbor/#harbor) port service needs a publicly
routable IP and exposed port range if you want to provide externally
accessible TCP and UDP ports for user applications. See the [*Harbor
Requirements & Setup*](/als/v1/admin/cluster/harbor/#harbor-setup) documentation for
details.

### DEA Nodes[](#dea-nodes "Permalink to this headline")

Nodes which stage application code and run application containers are
called Droplet Execution Agents (DEAs). Once the controller node is
running, you can begin to add some of these nodes with the [*kato node
attach*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command. To turn a generic Application Lifecycle Service VM into a DEA and connect it to the
Core node:


    $ kato node attach -e dea CORE_IP


Continue this process until you have added all the desired DEA nodes.

### Verification[](#verification "Permalink to this headline")

To verify that all the cluster nodes are configured as expected, run the
following command on the Core node:


    $ kato status --all

### Removing Nodes[](#removing-nodes "Permalink to this headline")

Use the [*kato node
remove*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach) to
remove a node from the cluster. Run the following command on the core
node.


    $ kato node remove NODE_IP

### Role Configuration using the Management Console[](#role-configuration-using-the-management-console "Permalink to this headline")

Once cluster nodes are connected to the Core node, roles can be enabled
or disabled using the [*Cluster
Admin*](/als/v1/admin/console/customize/#console-cluster-nodes) interface in the
[*Management
Console*](/als/v1/user/console/#management-console).

Example Clusters[](#example-clusters "Permalink to this headline")
-------------------------------------------------------------------

### Single-Node[](#single-node "Permalink to this headline")

This is a configuration (not actually a cluster) which you would not
generally deploy in production, but it helps to illustrate the role
architecture in Application Lifecycle Service. A node in this configuration will function
much like a micro cloud, but can be used as the starting point for
building a cluster later.

All that is required here is to enable all roles except for **mdns**
(not used in a clustered or cloud-hosted environment):

    $ kato node setup core api.hostname.example.com
    $ kato role add --all-but mdns


### Three-Node[](#three-node "Permalink to this headline")

This is the smallest viable cluster deployment, but it lacks the fault
tolerance of larger configurations:

-   1 Core node consisting of primary, controller, and router (and
    supporting processes)
-   1 data-services node running the database, messaging and filesystem
    services
-   1 DEA (Droplet Execution Agent) node

This configuration can support more users and applications than a single
node, but the failure of any single node will impact hosted
applications.

### Five-Node[](#five-node "Permalink to this headline")

A typical small Application Lifecycle Service cluster deployment might look like this:

-   1 Core node consisting of primary, controller, and router (and
    supporting processes)
-   1 data-services node running the database, messaging and filesystem
    services
-   3 DEA (Droplet Execution Agent) nodes

In this configuration, fault tolerance (and limited scalability) is
introduced in the pool of DEA nodes. If any single DEA node fails,
application instances will be automatically redeployed to the remaining
DEA nodes with little or no application down time.

### 20-Node[](#node "Permalink to this headline")

A larger cluster requires more separation and duplication of roles for
scalability and fault tolerance. For example:

-   1 Core node running the primary and controller roles (with
    supporting processes)
-   1 supplemental Controller node (sharing a filesystem and PostgreSQL
    database with the Core node)
-   1 Load Balancer (Application Lifecycle Service VM or hardware)
-   2 Router nodes
-   1 Filesystem service node
-   1 PostgreSQL + MySQL data service node
-   1 MongoDB, Redis, RabbitMQ + other data service node
-   12 DEA (Droplet Execution Agent) nodes

In this configuration:

-   application instances span a larger group of DEA nodes so
    applications can be easily scaled to meet increasing demand
-   web requests are evenly distributed between two Router nodes, either
    of which can fail without any interruption of service
-   any data service node failure will be localized, not affecting data
    services on other nodes
-   the auxiliary controller balances the load on the Management Console
    and system management tasks

Roles Requiring Persistent or Shared Storage[](#roles-requiring-persistent-or-shared-storage "Permalink to this headline")
---------------------------------------------------------------------------------------------------------------------------

Though all roles can run using the VM's default filesystem, in
production clusters some roles should be backed by a persistent
filesystem (block storage volumes) to provide scalable storage space
and easy snapshotting. Nodes with the following roles should have their
*/var/helion/services* directory on persistent storage:

-   Data Services: MySQL, PostgreSQL, Redis
-   Filesystem Service
-   Memcache
-   RabbitMQ
-   Harbor

**Note**

Though Memcache and Redis are in-memory data stores, system service info
data is stored on disk, so backing them with a persistent filesystem is
recommended.

In clusters with multiple Cloud Controllers, the nodes **must** share a
common */home/helion/helion/data* mount point as described
[*below*](#cluster-multi-controllers) in order to work together
properly.

See the [*Persistent
Storage*](/als/v1/admin/best-practices/#bestpractices-persistent-storage)
documentation for instructions on relocating service data, application
droplets, and containers.

Port Configuration[](#port-configuration "Permalink to this headline")
-----------------------------------------------------------------------

The Application Lifecycle Service [*micro
cloud*](/als/v1/user/reference/glossary/#term-micro-cloud) runs with
the following ports exposed:

<table>
<tr>
<td>Port</td><td>Type</td><td>Service</td></tr>
<tr><td>22</td><td>tcp</td><td>ssh</td></tr>
<tr><td>25</td><td>tcp</td><td>smtp</td></tr>
<tr><td>80</td><td>tcp</td><td>http</td></tr>
</table>

On a production cluster, or a micro-cloud running on a cloud hosting
provider, only ports 22 (SSH), 80 (HTTPS) and 443 (HTTPS) need to be
exposed externally (e.g. for the Router / Core node).

Within the cluster (i.e. behind the firewall), it is advisable to allow
communication between the cluster nodes on all ports. This can be done
safely by using the security group / security policy tools provided by
your hypervisor.

If you wish to restrict ports between some nodes (e.g. if you do not
have the option to use security groups), the following summary describes
which ports are used by which components. **Source** nodes initiate the
communication, **Destination** nodes need to listen on the specified
port.

<table>
<tr>
<td>Port Range<td>Type</td><td>Source</td><td>Destination</td><td>Required By</td></tr>
<tr><td>22</td><td>tcp</td><td>all nodes</td><td>all nodes</td><td>ssh/scp/sshfs</td></tr>
<tr><td>4222</td><td>tcp</td><td>all nodes</td><td>controller</td>controller<td>Nats</td></tr>
<tr><td>3306</td><td>tcp</td><td>dea/controller</td><td>MySQL nodes</td><td>MySQL</td></tr>
<tr><td>5432</td><td>tcp</td><td>dea/controller</td><td>postgresql nodes</td><td>postgreSQL</td></tr>
<tr><td>5454</td><td>tcp</td><td>all nodes</td><td>controller</td><td>redis</td></tr>
</table>
More about [*Nats*](/als/v1/user/reference/glossary/#term-nats) in the Glossary.

Each node can be internally firewalled using
[iptables](http://manpages.ubuntu.com/manpages/man8/iptables.8) to
apply the above rules.

**Comments**:

-   Ports 80 and 443 need only be open to the world on router nodes.
-   Port 4222 should be open on all nodes for
    [*NATS*](/als/v1/user/reference/glossary/#term-nats) communication
    with the MBUS IP (core Cloud Controller)
-   Port 9022 should be open to allow transfer of droplets to and from
    the DEAs, and Cloud Controllers.
-   Port 7845 is required if you plan to stream logs from all nodes in a
    cluster using `kato log tail` command.
-   External access on port 22 can be restricted if necessary to the
    subnet you expect to connect from. If you are providing the
    `helion ssh` feature to your users
    (recommended), define a distinct security group for the
    public-facing Cloud Controller node that is the same as a generic
    Application Lifecycle Service group, but has the additional policy of allowing SSH (Port
    22) from hosts external to the cluster.
-   Within the cluster, port 22 should be open on all hosts to allow
    administrative access over SSH. Port 22 is also used to mount
    Filesystem service partitions in application containers on the DEA
    nodes (via SSHFS).
-   The optional Harbor port service has a configurable port range
    (default 41000 - 61000) which can be exposed externally if required.

**Note**

**Harbor (Port Service) Node Configuration**

The optional [*Harbor*](/als/v1/admin/cluster/harbor/#harbor) TCP/UDP port service must be
set up on a node with a public network interface if you wish to enable
port forwarding for user applications. The security group or firewall
settings for this node should make the configured port range accessible
publicly. See [*Harbor Setup*](/als/v1/admin/cluster/harbor/#harbor-setup) for full
configuration instructions.

Multiple Controllers[](#multiple-controllers "Permalink to this headline")
---------------------------------------------------------------------------

An Application Lifecycle Service cluster can have multiple controller nodes running on
separate VMs to improve redundancy. The key element in designing this
redundancy is to have all controller nodes share a
`/home/helion/helion/data` directory stored on a
high-availability filesystem server. For example:

-   Create a shared filesystem on a Network Attached Storage device.
    [[1]](#id4)

-   Stop the controller process on the Core node before proceeding
    further:

        $ kato stop controller

-   On the Core node *and each additional controller node*:

    -   Create a mount point:

            $ sudo mkdir /mnt/controller

    -   Mount the shared filesystem on the mount point. [[1]](#id4)

    -   Set aside the original `/home/helion/helion/data`:

            $ mv /home/helion/helion/data /home/helion/helion/data.old

    -   Create a symlink from `/home/helion/helion/data` to the mount point:

            $ ln -s /mnt/controller /home/helion/helion/data

-   On the Core node, start the controller process:

        $ kato start controller

-   Run the following command on the additional Controller nodes to
    enable *only* the controller process:

        $ kato node attach -e controller *CORE_IP*

  -----------------------------------------------------------------------------------------------------------------------------------------------------
  [1]
  *([1](#id2), [2](#id3))* The type of filesystem, storage server, and network mount method are left to the discretion of the Application Lifecycle Service administrator.
  -----------------------------------------------------------------------------------------------------------------------------------------------------

Load Balancer and Multiple Routers[](#load-balancer-and-multiple-routers "Permalink to this headline")
-------------------------------------------------------------------------------------------------------

For large scale deployments requiring multiple Router nodes, a load
balancer must be configured to distribute connections between the
Routers. Though most users will prefer to use a hardware load balancer
or elastic load balancing service provided by the cloud hosting
provider, an Application Lifecycle Service VM can be configured to take on this role.

The [*kato node setup
load\_balancer*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command retrieves IP addresses of every router in the cluster and
configures an nginx process to distribute load (via round-robin) among a
pool of Routers and handle SSL termination.

For example, to setup a cluster with an Application Lifecycle Service Load Balancer and
multiple Routers:

### Rename the Load Balancer[](#rename-the-load-balancer "Permalink to this headline")

The Load Balancer is the primary point of entry to the cluster. It must
have a public-facing IP address and take on the primary hostname for the
system as [*configured in
DNS*](/als/v1/admin/server/configuration/#server-config-dns). Run the following
on Load Balancer node:

    $ kato node rename *hostname.example.com*

### Set up the Core Node[](#set-up-the-core-node "Permalink to this headline")

The Core node will need to temporarily take on the API endpoint hostname
of the Application Lifecycle Service system (i.e. the same name as the Load Balancer above).
Run the following on the Core node:

    $ kato node rename *hostname.example.com*

If it is not already configured as the Core node, do so now:

    $ kato node setup core api.\ *hostname.example.com*

The `kato node rename` command above is being used
to set internal Application Lifecycle Service parameters, but all hosts on a network should
ultimately have unique hostnames. After setup, rename the Core node
**manually** by editing */etc/hostname* and */etc/hosts*, then
`sudo service hostname restart`.

### Set up Supplemental Routers[](#set-up-supplemental-routers "Permalink to this headline")

As with the Core node, you will need to run `kato node rename`on each router with the same API endpoint hostname. Run the
following on each Router:

    $ kato node rename *hostname.example.com*

Then enable the 'router' role and attach the node to the cluster:

    $ kato node attach -e router <MBUS_IP>

As above, rename each host manually after configuration to give them
unique hostnames. The MBUS\_IP is the network interface of the Core node
(usually eth0).

### Configure the Application Lifecycle Service Load Balancer[](#configure-the-helion-load-balancer "Permalink to this headline")

**Note**

An Application Lifecycle Service node configured as a Load Balancer cannot have any other
roles enabled.

Attach the Application Lifecycle Service VM to the Core node:

    $ kato node attach <MBUS_IP>

To set up the node as a Load Balancer automatically:

    $ kato node setup load_balancer --force

This command fetches the IP addresses of all configured routers in the
cluster.

To set up the Load Balancer manually, specify the IP addresses of the
Router nodes. For example:

    $ kato node setup load_balancer 10.5.31.140 10.5.31.145

### Load Balancer SSL Certificates[](#load-balancer-ssl-certificates "Permalink to this headline")

The load balancer terminates SSL connections, so SSL certificates must
be set up and maintained on this node.

See the [*Using your own SSL
certificate*](/als/v1/admin/server/configuration/#server-config-ssl-cert-own-use)
and [*CA Certificate
Chaining*](/als/v1/admin/server/configuration/#server-config-ssl-cert-chain)
sections for Application Lifecycle Service Load Balancer instructions.

For other load balancers, consult the documentation for your device or
service on uploading/updating server certificates.
---
layout: default-devplatform
permalink: /als/v1/admin/console/app-store/
product: devplatform
---
<!--PUBLISHED-->

Sample Applications[](#index-0 "Permalink to this headline")
===================================================
 [Sample Applications Definition](#app-store-definition)
            -   [store](#store)
            -   [apps](#apps)
        -   [Hosting the Store Definition
            Files](#hosting-the-store-definition-files)
    -   [Adding the Sample Applications to
        Application Lifecycle Service](#adding-the-app-store-to-helion)

The Sample Applications are a collection of ready-to-run applications which can be
deployed to Application Lifecycle Service with a couple of clicks. This interface uses the
same API as the CLI client, pulling the source code from a Git
repository rather than pushing an archive from the user's local
filesystem.

Users have access to the main Sample Applications interface (see the Application Lifecycle Service User
Guide), but do not have access to add new applications or store
definitions.

Creating Sample Applications[](#creating-an-app-store "Permalink to this headline")
-----------------------------------------------------------------------------

The Sample Applications interface exposes multiple "stores" which specify the
available applications. These stores are sourced from definition files
specified in the main [*Settings*](/als/v1/admin/console/#settings) page of
the Management Console or set using [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config).

### Sample Applications Definition[](#app-store-definition "Permalink to this headline")

Sample Applications definition
[*YAML*](/als/v1/user/reference/glossary/#term-yaml) files describe
each store and its apps, including a link to the source location for
each app. For example:

    store:
      title: Third Party Apps for Application Lifecycle Service Development Platform
      contact: Application Lifecycle Service Development Platform Support 
      icon: http://static.als.hpcloud.com/hp.ico

    apps:
    - name: Bugzilla
      id: bugzilla
      desc: A bug tracking system for individuals or groups of developers
      framework: perl
      runtime: perl514
      services: mysql
      license: MPL
      commit: master
      src: https://github.com/Helion-Apps/bugzilla.git
      info: https://github.com/Helion-Apps/bugzilla.git#readme
      icon: https://get.helion.com/store/icon/bugzilla.png
      mem: 256

    - name: Django CMS
      id: django-cms
      desc: A content management system platform for publishing content on the internet.
      framework: python
      runtime: python27
      services: postgresql
      license: BSD
      commit: helion
      src: https://github.com/Helion-Apps/django-cms.git
      info: https://github.com/Helion-Apps/django-cms.git#readme
      icon: https://get.helion.com/store/icon/django-cms.png
      mem: 128

    - name: Node Chat
      id: node-chat
      desc: A simple chat application in Node.js with no other dependencies. Originally written by Ryan Dahl, the creator of Node.js.
      framework: node
      runtime: node
      commit: master
      icon: https://get.helion.com/store/icon/chat.png
      mem: 64
      license: MIT
      src: https://github.com/Helion-Apps/node-chat.git
      info: https://github.com/Helion-Apps/node-chat.git#readme

The YAML string requires two top-level keys: `store`
and `apps`.

#### store[](#store "Permalink to this headline")
Contains entries that define the store.

**title**:Text used as a display name for the Sample Applications in the Management Console.

**contact**: The name and email address of the store maintainer.

**icon**: An image used for the Sample Applications icon. Specified as a full URL.

#### apps[](#apps "Permalink to this headline")

This is an array of items (see YAML format above), one for each app in the store. Each app is defined by the following fields:

**name**:   The name of the app as displayed in the Sample Applications list.

**desc**:   A short description of the app, displayed below the name.

**id**: A short, lowercase, unique string associated with the app. Apps are sorted alphabetically in the list based on this field.

 **repo**
:   URL of the git repository where the app code resides.

**commit**
:   Branch name, tag name, or exact commit hash to use. If
    unspecified, the HEAD commit of `master`
    branch is used.

**framework**
:   The framework, if the app is deployed using the [*Legacy
    Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy)
    (e.g. `perl`, `python`,
    `node`, `rails3`).

**icon**
:   An image used for the app icon specified either as a full URL, a
    file relative to the `store` key **icon-url**
    URL, `default`, or other variable values.

**info**
:   A URL pointing to documentation for the app.

**license**
:   Optional string indicating the software license of the app (e.g.
     `MIT`, `MPL`,
     `BSD`).

**mem**
:   Memory requirements of the app (integer, in MB).

**runtime**
:   The runtime, if the app is deployed using the [*Legacy
    Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy)
    (e.g. `java`, `python32`,
    `ruby19`, `php`,
    `perl518`).
**services**
:   Data services required by the app.

**Note**

The store definition settings do not override settings in the
application's *manifest.yml* file.

### Hosting the Store Definition Files[](#hosting-the-store-definition-files "Permalink to this headline")

The YAML files defining the stores can be served via HTTP or HTTPS by
any web server at a URL accessible from the Cloud Controller.

Adding the Sample Applications to Application Lifecycle Service[](#adding-the-app-store-to-helion "Permalink to this headline")
---------------------------------------------------------------------------------------------------

1.  Log into the [*Management
    Console*](/als/v1/user/console/#management-console),
2.  Select **Settings \> Cloud Controller** from the menu.
3.  In the **Sample Applications URLs** section, enter a name and content URL for
    your store definition YAML file then click **Add Sample Applications URL**.

To confirm the Sample Applications are loading correctly, select "Sample Applications" in the
menu and view the list of applications displayed. A "CC Catalog Manager"
error appear in the Event Log if a Sample Applications URL fails to load.

Sample Applications URLs can also be viewed, added, deleted, enabled, and disabled
with [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config). For
example:

    $ kato config get cloud_controller_ng app_store
---
layout: default-devplatform
permalink: /als/v1/admin/console/customize/
product: devplatform
---
<!--PUBLISHED-->

Customization[](#customization "Permalink to this headline")
=============================================================

An Application Lifecycle Service PaaS can be extensively customized and themed. PaaS
administrators can add or remove runtimes, frameworks and services from
the system, and change the look and content of the [*Management
Console*](/als/v1/user/console/#management-console) interface.

### [Table Of Contents](/als/v1/index-2/)

-   [Customization](#)
    -   [Console Settings](#console-settings)
        -   [Product](#product)
        -   [Look and Feel](#look-and-feel)
        -   [Welcome Page](#welcome-page)
        -   [Support Page](#support-page)
        -   [Eula Content](#eula-content)
        -   [Custom Stylesheet](#custom-stylesheet)
        -   [Settings Variables](#settings-variables)
        -   [Restoring values](#restoring-values)
    -   [Renaming the Client](#renaming-the-client)

Console Settings[](#console-settings "Permalink to this headline")
-------------------------------------------------------------------

The Management Console is modified mainly through the **Settings \>
Console** pages. Settings are saved as variables which can subsequently
be used in HTML pages via the [Embedded JavaScript
(EJS)](http://embeddedjs.com/) templating engine.

### Product[](#product "Permalink to this headline")

-   **Product Name**: Overrides all occurrences of 'Application Lifecycle Service'
-   **Company Name**: Overrides all occurrences of 'HP
    Software'
-   **Vendor Version**: Overrides all occurrences of the Application Lifecycle Service
    version number.
-   **Default Locale**: Sets the default locale of the console if the
    users current locale isn't recognized. Currently, only the 'en'
    localization is complete.
-   **External Docs URL**: The link that directs users to documentation.
    Defaults to the current documentation published to
    docs.hpcloud.com. Ticking 'Use local docs' will cause this URL to
    be ignored and the docs from the VM will be served instead.

### Look and Feel[](#look-and-feel "Permalink to this headline")

-   **Favicon Logo URL**: The favicon to use. Recommended to be 32x32px
    image/png.
-   **Header Logo URL**: The logo image to use in the header. Size can
    vary although anything bigger than 50px vertically may result in
    some distortion of the header (fixable with a custom style sheet).
-   **Footer Logo URL**: The logo image to use in the footer. Same as
    above but height is about 40px before distortion occurs.
-   **Background Color**: Sets the background color of the console.

### Welcome Page[](#welcome-page "Permalink to this headline")

The HTML/EJS to show on the Welcome page. The [*settings-variables*](#customize-settings-vars) and `username`
variable (current user) are available via EJS, but plain HTML will work
for simple use cases.

### Support Page[](#support-page "Permalink to this headline")

The HTML/EJS to show on the Support page. The [*settings-variables*](#customize-settings-vars) and `support_email` variable (see Settings \> Controller) are available.

### Eula Content[](#eula-content "Permalink to this headline")

The HTML/EJS to show in the EULA overlay. The [*settings-variables*](#customize-settings-vars) are available.

### Custom Stylesheet[](#custom-stylesheet "Permalink to this headline")

CSS defined here will be applied to the page after the default CSS has
been loaded, and override/replace any style. Use this to change the
layout and color of any element in the Management Console. Use web
development tools like Firebug or Chrome DevTools to inspect elements
and find the relevant styles.

### Settings Variables[](#settings-variables "Permalink to this headline")

The following variables (with their default values) are available in the
EJS templates on the settings object (e.g.
`settings.product_name`):

-   product\_name: null,
-   company\_name: 'HP Software',
-   vendor\_version: '3.0',
-   default\_locale: 'en',
-   product\_logo\_favicon\_url: 'img/helion\_logo\_favicon.png',
-   product\_logo\_header\_url: 'img/helion\_logo\_header.png',
-   product\_logo\_footer\_url: 'img/helion\_logo\_footer.png',
-   background\_color: '\#ffffff',
-   style: '',
-   support\_template: SupportTemplate,
-   eula\_template: EulaTemplate,
-   welcome\_template: WelcomeTemplate,
-   external\_docs\_url:
    '[http://docs.helion.com/3.0/](../..)',
-   use\_local\_docs: "false"

### Restoring values[](#restoring-values "Permalink to this headline")

Each setting has an individual **Load Default** button (refresh icon to
the left of the value field) which will replace the customized value
with the default for that setting. Click 'Save' to apply the changes.

The red **Load Defaults** button at the top of the page deletes all
customizations and loads defaults for all settings.

As a failsafe for when style changes have obscured the interface, admins
can also reset specific settings by loading a URL with the following
format:

    https://<helion-url>/#settings/console/reset/setting_name

Replace `setting_name` with one of the variables
above and that value will be reset to the default.

Renaming the Client[](#renaming-the-client "Permalink to this headline")
-------------------------------------------------------------------------

The `helion` client is distributed as a single
file executable for Windows, OS X and Linux (x86 and x86\_64). Zip files
containing executables for each platform can be found in the
`~/helion/static` directory.

After renaming the executable, you can re-package them in .zip files and
modify the
*\~/helion/code/console/js/views/client/templates/client.html*
template to point to the renamed files. 



---
layout: default-devplatform
permalink: /als/v1/admin/console/
product: devplatform
---
<!--PUBLISHED-->

Management Console (Admin View)[](#management-console-admin-view "Permalink to this headline")
===============================================================================================

Application Lifecycle Service's web interface is called the Management Console. The interface
displays more options and settings for Admin users than it does for
regular end users. Some of the features described below are only
available in the Admin view.

### [Table Of Contents](/als/v1/index-2/)

-   [About the Admin Console](#about)
    -   [Welcome](#welcome)
        -   [System Information](#system-information)
    -   [Cluster Nodes](#cluster-nodes)
    -   [Organizations](#organizations)
    -   [Users](#users)
    -   [Applications](#applications)
    -   [Cloud Events](#cloud-events)
    -   [Dashboard](#dashboard)
        -   [Router](#router)
        -   [Primary Node Status Graphs](#primary-node-status-graphs)
    -   [Settings](#settings)
        -   [Console](#console)
        -   [Quota Definitions](#quota-definitions)
        -   [Cloud Controller](#cloud-controller)
        -   [Applications](#console-settings-applications)
        -   [DEA](#dea)
        -   [Logyard](#logyard)
        -   [Harbor](#harbor)
        -   [Data Services](#data-services)
        -   [File System](#file-system)

About the Admin Console[](#about "Permalink to this headline")
-------------------------------------------------


The Application Lifecycle Service Management Console is a web interface that allows the
administration and management of the Application Lifecycle Service Server.

Your hypervisor provides [*tty
console*](/als/v1/user/reference/glossary/#term-tty-console) access to
each of its virtual machines. After startup, an Application Lifecycle Service VM displays:

    Application Lifecycle Service Management Console at

    https://helion-xxxx.local

On a [*micro
cloud*](/als/v1/user/reference/glossary/#term-micro-cloud) VM where
the local network supports [*multicast
DNS*](/als/v1/user/reference/glossary/#term-multicast-dns), the
hostname will be `helion-xxxx.local`. If you have
configured the
[*hostname*](/als/v1/admin/server/configuration/#server-config-hostname) and
[*DNS*](/als/v1/admin/server/configuration/#server-config-dns) of the Application Lifecycle Service
server manually, or are connecting to a server administered by someone
else, supply the assigned hostname instead (e.g.
`api.helion-test.example.com`).

Enter the URL into your web browser, and the Management Console will
load. The Console is supported on the following browsers:

-   Chrome 30+ (WebKit)
-   Firefox 20+
-   IE 10+

Using a browser which fully support WebSockets is recommended.

**Note**

The SSL certificate for the Application Lifecycle Service Management Console is self-signed.
You will need to manually accept this certificate in your browser. See
the [*HTTPS section*](/als/v1/admin/server/configuration/#server-config-https)
for information on using your own certificate.

When you first access the Management Console, you will be prompted to
create a primary administrative user for Application Lifecycle Service. Enter an email
address as the username, set a secure password, then review and accept
the license agreement.

**Note**

**The password you choose here becomes the login password for the**
`helion` **user on the VM** (e.g. for
`ssh` access).

Once you've logged in, you can begin to add other users and admins,
enable and disable services, and generally set up the system to your
requirements.

Basic Application Lifecycle Service administration can be done through the Management
Console, but some maintenance and configuration tasks may need to be
done at the command line using the `kato` command.
See [*Kato Command
Reference*](/als/v1/admin/reference/kato-ref/#kato-command-ref) for a full list
of options.

The Application Lifecycle Service Management Console will periodically send non-identifying pingbacks (Application Lifecycle Service version number and UUID) to HP servers to help improve the web console experience. You can disable this option by setting `theme_settings['pingback_allowed'] = false;` in the *settings.js* file described in the [*Theming and
Customization*](/als/v1/admin/console/customize/#customize) section.

Welcome[](#welcome "Permalink to this headline")
-------------------------------------------------

The top-level page of the Management Console displays quick links to the
most used resources and views. The blue buttons are for features also
available for regular end users (see [*Management Console (User
View)*](/als/v1/user/console/#user-console-welcome)).

Green buttons expose Admin-only functionality:

-   **Configure Available Services**: Opens the [*Cluster
    Nodes*](#console-cluster-nodes) view showing which roles are running
    on which nodes. From this view you can add or remove Service roles
    on the various nodes in the cluster (or on 127.0.0.1 for micro
    clouds).
-   **Manage Organizations**: Opens the
    [*Organizations*](#console-organizations) view.
-   **Manage Users**: Opens the [*Users*](#console-users) view.
-   **View All Deployed Applications**: Opens the :ref: Applications
    \<console-applications\> view.
-   **View Cloud Events**: Opens the Cloud Events
    \<console-cloud-events\> view.
-   **View Dashboard**: Opens the Dashboard \<console-dashboard\>.

### System Information[](#system-information "Permalink to this headline")

-   **Version**: Version (release) number of the system.
-   **MBUS IP**: The IP address that hosts the primary node. Cluster
    nodes (if any) will connect via this IP address. In a micro cloud
    setting, it will be 127.0.0.1.
-   **API Endpoint**: The URL for helion clients to target. Normally
    also the URL for the Management Console.

Cluster Nodes[](#cluster-nodes "Permalink to this headline")
-------------------------------------------------------------

Displays a list of nodes in the current cluster, and what services are
running on each node. In a micro cloud configuration, only the current
local node ('127.0.0.1') is shown.

To enable or disable services on a node, click the **Configure Roles**
button (cog icon) to see the **Node Settings**, showing a list of all
available roles and checkboxes to enable or disable each one. Click
**Save** to apply changes.

See also the [*kato
role*](/als/v1/admin/reference/kato-ref/#kato-command-ref-role-add) and [*kato
info*](/als/v1/admin/reference/kato-ref/#kato-command-ref-info) command
documentation for the CLI equivalents, and the [*Cluster
Setup*](/als/v1/admin/cluster/#cluster-setup) section for information on
adding nodes to the cluster.

Organizations[](#organizations "Permalink to this headline")
-------------------------------------------------------------

The top level Organizations page allows Admins to add and delete
[*Organizations*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces).
Clicking on an organization name opens its details. This view is the
same as a regular [*user's Organizations
view*](/als/v1/user/console/#user-console-organizations), but
admin users can edit quotas, and add/remove domains, spaces, and users.

Users[](#users "Permalink to this headline")
---------------------------------------------

The Users section displays a list of users and admins.

-   Click **+ Add User** to add users.
-   Click on the user name or email address to view account details or
    change the password.

Applications[](#applications "Permalink to this headline")
-----------------------------------------------------------

The Applications section displays a list of all apps on the server.
Click anywhere on the line for an app to view its details. Admins have
the same permissions in the [*Application
View*](/als/v1/user/console/#user-console-app) as a Developer of
the space it was deployed to.

Cloud Events[](#cloud-events "Permalink to this headline")
-----------------------------------------------------------

The Cloud Events section displays a list of events (including errors and
warnings) on the Application Lifecycle Service server. The events can be filtered by Severity
or Type, or by using a substring match in the Search field.

Dashboard[](#dashboard "Permalink to this headline")
-----------------------------------------------------

### Router[](#router "Permalink to this headline")

Shows realtime results for incoming requests (connections per second),
routing errors (errors per second), and an overview of the cumulative
requests to the system.

### Primary Node Status Graphs[](#primary-node-status-graphs "Permalink to this headline")

Displays graphs for server statistics: CPU, Load, Memory, Disk
Operations, Disk Space, Processes, and Swap (primary node or micro cloud
only).

Settings[](#settings "Permalink to this headline")
---------------------------------------------------

The Settings menu gives access to the following Console and system
settings:

### Console[](#console "Permalink to this headline")

Various settings and templates to customize the look and feel of the
Management Console. The settings are divided into the following
categories:

-   **Product**: Options to rename and reversion Application Lifecycle Service for OEM
    deployments, change the default locale (currently only 'en' and 'de'
    available), choose a different URL for documentation, or disable
    console pingbacks.
-   **Look and Feel**: Change the favicon, header, footer, or background
    color.
-   **Welcome Page**: EJS templated HTML to display on the Welcome page
    (see above).
-   **Support Page**: EJS templated HTML to display on the Support page.
    Change this if you are supporting your end users directly.
-   **Eula Content**: End User License Agreement. Change this if you are
    exposing Application Lifecycle Service to end users under specific terms.
-   **Custom Stylesheet**: A single CSS file used to override any
    existing styling in the Management Console. Inspect the Console with
    browser tools such as Firebug or Chrome Developer Tools to see the
    class names and IDs.

### Quota Definitions[](#quota-definitions "Permalink to this headline")

Lists the Quota Definitions available to apply to Organizations on the
system.

-   To edit a definition, click the edit button on the right.
-   To create a new definition use the [*helion quota
    create*](/als/v1/user/reference/client-ref/#command-quota-create)
    command.

### Cloud Controller[](#cloud-controller "Permalink to this headline")

-   **Maintenance Mode**: Shuts down API requests but continues to serve
    web requests, useful when performing system operations such as
    importing and exporting data for upgrades. When the primary node
    enters maintenance mode, the Management Console becomes "read only"
    with the exception of this toggle (to bring it back online).
-   **Logging Level**: Changes the verbosity of Application Lifecycle Service logs from
    'debug2' (most verbose) through 'off' (silent).
-   **Support Email**: The email address displayed to end users when
    errors are encountered. Use an address which is monitored by
    Application Lifecycle Service administrators.
-   **Sample Applications URLs**: URIs for JSON files which populate the [*App
    Store*](app-store.html#app-store). The URIs need not be public, but
    must be accessible from the controller node.
-   **Allowed Repos**: Debian package repositories allowed in
    application containers. End users can install additional packages
    (e.g. with `apt-get` or `aptitude`) only from these repositories.

### Applications[](#console-settings-applications "Permalink to this headline")

-   **Reserved URIs**: URIs which cannot be used for end user
    applications.

### DEA[](#dea "Permalink to this headline")

-   **Max Memory Percentage**: The percentage of physical memory each
    DEA node can use for hosted applications. The 80% default setting
    leaves enough memory for the OS and DEA processes on a node with 4GB
    of RAM. This can be increased on nodes with more memory available
    (e.g. to 90% on a node with 8GB of RAM). Do not exceed 100% unless
    the system correctly supports swap space and has it enabled. Restart
    all DEA roles/nodes to apply the change.
-   **Max Staging Duration**: The maximum time allowed for application
    staging.

### Logyard[](#logyard "Permalink to this headline")

Lists current log
[*Drains*](/als/v1/admin/server/logging/#logging-drains-system) and the log
drain retry limits. Drains and limits cannot be changed in this
interface; use the [*kato log drain
...*](/als/v1/admin/reference/kato-ref/#kato-command-ref-log-drain-add)
commands and [*kato config
...*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config) commands.

### Harbor[](#harbor "Permalink to this headline")

Settings for the [*Harbor*](/als/v1/admin/cluster/harbor/#harbor) TCP/UDP port
service.

-   **External Host**: The public IP (if configured) for the Harbor
    node.
-   **External Hostname**: The public hostname for the Harbor node.
-   **Port Range Minimum**: Sets the minimum for the exposed port range
    (default: 35000).
-   **Port Range Maximum**: Sets the maximum for the exposed port range
    (default: 40000).

See [*Harbor: Requirements &
Setup*](/als/v1/admin/cluster/harbor/#harbor-setup) for more information.

### Data Services[](#data-services "Permalink to this headline")

-   **Allow Over-provisioning**: Ignore the Capacity setting.
-   **Capacity**: Maximum number of service slots to allocate.
-   **Max DB size**: Maximum size on disk for database services.
-   **Max Memory**: Maximum amount of physical memory to allocate the
    service.
-   **Memcached Memory**: Maximum amount of physical memory to allocate
    for memcached instances.
-   **Max FS Size**: Maximum size on disk for filesystem services.

### File System[](#file-system "Permalink to this headline")

-   **Capacity**: Maximum number of service slots to allocate.
-   **Max FS Size**: Maximum size on disk for filesystem services in MB.
-   **Allow Over-provisioning**: Ignore the Capacity setting.


 
---
layout: default-devplatform
permalink: /als/v1/admin/
product: devplatform

---
<!--PUBLISHED-->

#Application Lifecycle Service Admin Guide {#helion-admin-guide}

Application Lifecycle Service is HP's cloud application framework for creating a
multi-language, secure and private Platform-as-a-Service (PaaS). This
guide covers how to set it up and how to configure it for your end
users.

##Wizard-Based Cluster Creation
You can easily create and access Application Lifecycle Service clusters from the Project Dashboard or from the command-line.

- [Creating a Cluster from the Project Dashboard](/helion/devplatform/deploy/)       
- [Creating a Cluster from the Command Line](/als/v1/user/client/)  

##Helion Development Platform Management Console {#management-console}

-   [Management Console](/als/v1/user/console/#management-console)
-   [Sample Applications](console/app-store)

##Advanced/Manual Server Configuration {#server-configuration}
This section covers advanced configuration settings that allow you to modify default cluster component behavior. 

-   [Server Configuration](/als/v1/admin/server/)
    -   [Accessing Server via the Command
        Line](/als/v1/admin/server/#accessing-server-via-the-command-line)
    -   [Common Operations](/als/v1/admin/server/#common-operations)
    -   [Detailed
        Configuration](/als/v1/admin/server/#detailed-configuration)
-   [Router](/als/v1/admin/server/router/)
    -   [Settings](/als/v1/admin/server/router/#settings)
    -   [WebSockets](/als/v1/admin/server/router/#websockets)
    -   [SPDY](/als/v1/admin/server/router/#router-spdy)
-   [Docker & Fence](/als/v1/admin/server/docker/)
    -   [Modifying or Updating the Container
        Image](/als/v1/admin/server/docker/#modifying-or-updating-the-container-image)
    -   [Admin Hooks](/als/v1/admin/server/docker/#admin-hooks)
    -   [Creating a Docker
        Registry](/als/v1/admin/server/docker/#creating-a-docker-registry)
-   [Log Streams](/als/v1/admin/server/logging/)
    -   [Logyard](/als/v1/admin/server/logging/#logyard)
    -   [Drains](/als/v1/admin/server/logging/#drains)
    -   [Configuration](/als/v1/admin/server/logging/#configuration)
    -   [Debugging Logyard](/als/v1/admin/server/logging/#debugging-logyard)
-   [AOK Authentication Server](/als/v1/admin/server/aok/)
    -   [End User Login](/als/v1/admin/server/aok/#end-user-login)
    -   [Strategies](/als/v1/admin/server/aok/#strategies)
    -   [Configuration](/als/v1/admin/server/aok/#configuration)
    -   [User Management](/als/v1/admin/server/aok/#user-management)
    -   [First Admin User Setup](/als/v1/admin/server/aok/#first-admin-user-setup)
    -   [Regular LDAP User
        Setup](/als/v1/admin/server/aok/#regular-ldap-user-setup)
-   [Upgrading Application Lifecycle Service](/als/v1/admin/server/upgrade/)
    -   [Before an upgrade](/als/v1/admin/server/upgrade/#before-an-upgrade)
    -   [Executing the
        upgrade](/als/v1/admin/server/upgrade/#executing-the-upgrade)

##Advanced/Manual Cluster Configuration {#cluster-configuration}

This section provides information on how to set up a standalone cluster and modify default cluster level settings.

-   [Cluster Setup](/als/v1/admin/cluster/)
    -   [Roles](/als/v1/admin/cluster/#roles)
    -   [Preparing the Core
        Node](/als/v1/admin/cluster/#preparing-the-core-node)
    -   [Attaching Nodes and Enabling
        Roles](/als/v1/admin/cluster/#attaching-nodes-and-enabling-roles)
    -   [Example Clusters](/als/v1/admin/cluster/#example-clusters)
    -   [Roles Requiring Persistent or Shared
        Storage](/als/v1/admin/cluster/#roles-requiring-persistent-or-shared-storage)
    -   [Port Configuration](/als/v1/admin/cluster/#port-configuration)
    -   [Multiple Controllers](/als/v1/admin/cluster/#multiple-controllers)
    -   [Load Balancer and Multiple
        Routers](/als/v1/admin/cluster/#load-balancer-and-multiple-routers)
-   [DEA Auto Scaling](/als/v1/admin/cluster/autoscaling/)
    -   [DEA Template](/als/v1/admin/cluster/autoscaling/#dea-template)
    -   [DEA Scaling
        configuration](/als/v1/admin/cluster/autoscaling/#dea-scaling-configuration)
    -   [Enabling
        Auto-Scaling](/als/v1/admin/cluster/autoscaling/#enabling-auto-scaling)
    -   [Configuration and Tuning](/als/v1/admin/cluster/autoscaling/#configuration-and-tuning-advanced)
    -   [Writing custom scaling plugins](/als/v1/admin/cluster/autoscaling/#writing-custom-scaling-plugins-advanced)
    -   [Troubleshooting](/als/v1/admin/cluster/autoscaling/#troubleshooting)
    -   [Testing](/als/v1/admin/cluster/autoscaling/#testing)
-   [cloud-init](/als/v1/admin/cluster/cloud-init/)
    -   [Securing the new
        node](/als/v1/admin/cluster/cloud-init/#securing-the-new-node)
    -   [Custom System
        Configuration](/als/v1/admin/cluster/cloud-init/#custom-system-configuration)
-   [External Data Services](/als/v1/admin/cluster/external-db/)
    -   [General
        Principles](/als/v1/admin/cluster/external-db/#general-principles)
    -   [MySQL](/als/v1/admin/cluster/external-db/#mysql)
    -   [PostgreSQL](/als/v1/admin/cluster/external-db/#postgresql)
    -   [Troubleshooting](/als/v1/admin/cluster/external-db/#troubleshooting)
-   [Harbor: TCP/UDP Port Service](/als/v1/admin/cluster/harbor/)
    -   [Architecture](/als/v1/admin/cluster/harbor/#architecture)
    -   [Requirements & Setup](/als/v1/admin/cluster/harbor/#requirements-setup)
    -   [Troubleshooting](/als/v1/admin/cluster/harbor/#troubleshooting)

##Best Practices {#best-practices}

-   [Best Practices](/als/v1/admin/best-practices/)
    -   [Applying Updates](/als/v1/admin/best-practices/#applying-updates)
    -   [Backup & Migration](/als/v1/admin/best-practices/#backup-migration)
    -   [Upgrading (v1.0 and
        later)](/als/v1/admin/best-practices/#upgrade)
	- [Persistent
        Storage](/als/v1/admin/best-practices/#storage)
- [Hello World Custom Drain Sample](/als/v1/admin/best-practices/logging-examples/#hello-world-custom-drain)

##Reference {#reference}
-   [Kato Command Reference](/als/v1/admin/reference/kato-ref/)
-   [Managing Groups, Users & Limits](/als/v1/user/deploy/orgs-spaces/#orgs-spaces)
-   [Architectural Design](/als/v1/admin/reference/architecture/)
-   [Glossary](reference/glossary)
-   [Troubleshooting](reference/troubleshoot)
-   [Adding System Services](/als/v1/admin/reference/add-service/)

---
layout: default-devplatform
permalink: /als/v1/admin/reference/add-service/
product: devplatform
---
<!--PUBLISHED-->

Adding System Services[](#adding-system-services "Permalink to this headline")
===============================================================================

Application Lifecycle Service has two Service definitions:

-   System Services: Service types (e.g. MySQL, RabbitMQ, Filesystem)
    available for use on the system
-   Provisioned Services: Instances of the System Services created for
    end user applications

The [*helion
services*](/als/v1/user/reference/client-ref/#command-services)
command will show a list of all System Services available on the current
target, as well as a list of Provisioned Services allocated to the
authenticated user.

Administrators can configure external data services to work in the same
way as core Application Lifecycle Service System Services, exposing existing software and
infrastructure for use by Application Lifecycle Service and its users.

---
layout: default-devplatform
permalink: /als/v1/admin/reference/architecture/
product: devplatform
---
<!--PUBLISHED-->

Architectural Design[](#architectural-design "Permalink to this headline")
===========================================================================
 [Roles](#roles)
        -   [Base](#base)
        -   [Primary](#primary)
        -   [Cloud Controller](#cloud-controller)
        -   [Router](#router)
        -   [Droplet Execution Agents](#droplet-execution-agents)
    -   [Service Roles](#service-roles)
        -   [Databases:](#databases)
        -   [Other data services:](#other-data-services)
    -   [Role Groups](#role-groups)

The Application Lifecycle Service VM is a stand-alone [*micro
cloud*](/als/v1/user/reference/glossary/#term-micro-cloud) virtual
machine with all the components necessary for running a test environment
in one instance. For use on a larger scale, the VM can be cloned and
assigned specific roles: Router, Cloud Controller, Droplet Execution
Agents (DEAs, or worker nodes), or specific database services.

<img src="/content/documentation/devplatform/helion/images/helion-architecture-diagram.png" />

Roles[](#roles "Permalink to this headline")
---------------------------------------------

### Base[](#base "Permalink to this headline")

The Base role comprises of several processes that are necessary for any
node to function as part of an Application Lifecycle Service cluster, and is mostly
responsible for communicating with the primary node and forwarding log
information.

This role cannot be disabled on any node.

### Primary[](#primary "Permalink to this headline")

The Primary role is a mandatory part of a Core node (or micro cloud) and
runs a number of critical system processes, including the Health
Manager.

The Health Manager keeps track of the apps on each DEA and provides
feedback on the number currently running. It works in conjunction with
the Cloud Controller and must be run on the same VM.

In a cluster setup, all nodes performing other roles are attached to the
MBUS IP of the Core node. Every cluster must include exactly one Primary
role.

### Cloud Controller[](#cloud-controller "Permalink to this headline")

The Controller manages most of the operations of an Application Lifecycle Service system. It
hosts the Management Console, provides the API endpoint for client
access, manages the cloud\_controller\_ng process, provisions services,
dispatches applications for staging and deployment, and (with the Health
Manager) tracks the availability of DEA nodes.

In a cluster setup, the Controller role must run on the [*Core
node*](/als/v1/admin/cluster/#server-cluster-core-node) that all other
VM's in the cluster connect to.

A single Controller is sufficient for small and mid-sized clusters, but
[*multiple
Controllers*](/als/v1/admin/cluster/#cluster-multi-controllers) can be
configured if necessary for larger implementations.

### Router[](#router "Permalink to this headline")

The router directs incoming network traffic to the appropriate
application.

For smaller configurations, the router can be run on the same Application Lifecycle Service
VM as the other components.

When additional DEAs are in use and traffic increases, additional
routers can be added to handle the load. This will require a [*load
balancer*](/als/v1/admin/cluster/#cluster-load-balancer) to be available
in the cluster.

### Droplet Execution Agents[](#droplet-execution-agents "Permalink to this headline")

The Droplet Execution Agent (DEA) role in Application Lifecycle Service is responsible for
staging applications and running application instances within Linux
containers. In an Application Lifecycle Service cluster, there will typically be a number of
nodes running the DEA role, which in turn each host multiple user
application instances.

The DEA role is comprised of a number of processes:

-   dea\_ng: Master process for staging and starting application instances, reporting on their state via NATS to the Health Manager.
-   dir\_server: Handles requests for directories/files, responding with an HTTP URL.
-   fence: Responsible for the management of application containers using Docker.
-   apptail: Streams application logs via Logyard to various log drains.

The Docker image used for the containers can be customized by admins.

Service Roles[](#service-roles "Permalink to this headline")
-------------------------------------------------------------

Application Lifecycle Service nodes can also be assigned roles for data services. The data
services can be run separately on their own nodes, or grouped together.

### Databases:[](#databases "Permalink to this headline")

-   mysql
-   postgresql
-   redis

### Other data services:[](#other-data-services "Permalink to this headline")

-   filesystem ( Persistent filesystem service )
-   rabbit ( RabbitMQ message queue service )
-   memcached
-   Harbor ( Ports service )

Role Groups[](#role-groups "Permalink to this headline")
---------------------------------------------------------

Role groups represent a set of roles. For example the **data-services**
group provides all databases plus RabbitMQ and the filesystem service:

    $ kato role add data-services

Additional groups can be defined by administrators in
*/s/etc/kato/role\_groups.yml*.
---
layout: default-devplatform
permalink: /als/v1/admin/reference/glossary/
product: devplatform
---
<!--PUBLISHED-->

Glossary[](#index-0 "Permalink to this headline")
==================================================

AMQP
:   Acronym for [Advanced Message Queuing
    Protocol](http://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol).

Apache ANT
:   A software tool for automating software build processes. See
    [Ant](http://ant.apache.org/) for more info.
	
Apache Maven
:   A build automation tool typically used for Java projects. See
    [Maven](http://maven.apache.org/) for more info.

app
:   Any application software intended for instantiation in Application Lifecycle Service. At
    minimum it consists of the application, expressed in a dynamic
    language, plus a configuration file named *manifest.yml*.

Avahi
:   An implementation of [*multicast
    DNS*](/als/v1/user/reference/glossary/#term-multicast-dns) and
    related protocols.

cluster
:   A set of interconnected physical processors or virtual machines,
    managed at least conceptually as a single entity but otherwise
    operating autonomously. Historically the term carried a variety of
    proprietary meanings, but came into general use with the rapid
    development of supercomputing based upon [Beowulf
    Clusters](http://en.wikipedia.org/wiki/Beowulf_cluster). An Application Lifecycle Service
    cluster is one in which
    [*role*](/als/v1/user/reference/glossary/#term-role)s are assigned
    or replicated to multiple cluster
    [*node*](/als/v1/user/reference/glossary/#term-node)s.

component
:   Within Application Lifecycle Service, the term **component** is used when naming a
    discrete part of the Application Lifecycle Service server. For example, a
    [*role*](/als/v1/user/reference/glossary/#term-role) is made up of
    one or more components.

container
:   A lightweight form of virtualization which provides resource
    isolation and secure separation for multiple instances of the same
    base system. According to circumstances it may be used in addition
    to or instead of hypervisor virtualization.

CPAN
:   Acronym for [Comprehensive Perl Archive
    Network](http://www.cpan.org/).

doozerd
:   A consistent distributed data store. Used for cluster management in
    Application Lifecycle Service. (see [Doozer project on
    GitHub](https://github.com/ha/doozerd/#readme))

DHCP
:   [Dynamic Host Configuration
    Protocol](http://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol).
    The DHCP service is used to allocate IP addresses to clients on
    demand and to supply other basic network information they need, such
    as the addresses of a default router and DNS server.

DNS
:   [Domain Name
    System](http://en.wikipedia.org/wiki/Domain_Name_System). Resolves
    domain names to IP addresses. See [*Server Config -
    DNS*](/als/v1/admin/server/configuration/#server-config-dns).

dnsmasq
:   A [lightweight server](http://en.wikipedia.org/wiki/Dnsmasq) for
    locally integrating DNS with DHCP/BOOTP.

dynamic DNS
:   A means of rapidly updating the Domain Name System, possibly making
    use of [**RFC 2136**](http://tools.ietf.org/html/rfc2136)
    Dynamic Updates.

filesystem
:   In Application Lifecycle Service, **filesystem** refers to persistent storage accessed by
    an application :term\`service\` specified in *manifest.yml* through
    a server which has been assigned the filesystem
    [*role*](/als/v1/user/reference/glossary/#term-role).

JSON
:   A notation for structured text data, acronym for [JavaScript Object
    Notation](http://en.wikipedia.org/wiki/JSON).

MBUS
:   Application Lifecycle Service's implementation of an [**RFC
    3259**](http://tools.ietf.org/html/rfc3259) message queue used
    for interprocess communication. *See also:*
    [*NATS*](/als/v1/user/reference/glossary/#term-nats).

memcached
:   Free & open source, high-performance, distributed memory object
    caching system, generic in nature, but intended for use in speeding
    up dynamic web applications by alleviating database load. (see
    [Memcached project page](http://memcached.org/))

micro cloud
:   A preconfigured Application Lifecycle Service virtual machine image consisting of a
    single generic
    [*node*](/als/v1/user/reference/glossary/#term-node) enabled for
    all the [*role*](/als/v1/user/reference/glossary/#term-role)s
    necessary for basic operation, but with no preinstalled
    [*app*](/als/v1/user/reference/glossary/#term-app)s or
    [*service*](/als/v1/user/reference/glossary/#term-service)s.
mongodb
:   A popular [noSQL](http://en.wikipedia.org/wiki/NoSQL) database
    management system.

multicast DNS
:   A distributed means of configuring DNS by [multicast
    discovery](http://en.wikipedia.org/wiki/Multicast_DNS). It is
    supported on Application Lifecycle Service :term\`micro cloud\` servers using
    [*Avahi*](/als/v1/user/reference/glossary/#term-avahi).

mysql
:   A relational database management system.

NAT
:   Acronym for [Network Address
    Translation](http://en.wikipedia.org/wiki/Network_address_translation).

NATS
:   In Application Lifecycle Service, a publish-subscribe message system implemented as a
    process called `nats-server` which listens on a
    network interface, normally on port 4222/tcp. Messages published
    across the network to a particular
    [*MBUS*](/als/v1/user/reference/glossary/#term-mbus) queue managed
    by the nats-server are communicated to clients which are subscribed
    to that queue.

Nginx
:   [Nginx](http://wiki.nginx.org/) is a high-performance, event-driven
    web server.

node
:   An Application Lifecycle Service **node** is a single processing host in a
    [*cluster*](/als/v1/user/reference/glossary/#term-cluster),
    typically a virtual machine running under a hypervisor.

OVF
:   Acronym for [Open Virtualization
    Format](http://dmtf.org/standards/ovf), a specification for virtual
    machine images developed by the DMTF industry consortium.

PaaS
:   Acronym for [Platform as a
    Service](http://en.wikipedia.org/wiki/Platform_as_a_service).

pip
:   A tool for installing and managing Python packages, such as those
    found in the Python Package Index. It's a replacement for
    easy\_install. See
    [pip-installer](http://www.pip-installer.org/en/latest/) for more
    information.

PyPM
:   PyPM is the *binary* package manager for ActivePython. It is usually
    the fastest and most reliable way of installing PyPI packages for
    your Application Lifecycle Service applications. The PyPM repository hosts almost all of
    the Python packages registered in PyPI and includes their latest
    versions. See [PyPM](http://code.activestate.com/pypm) for more
    information.

Polipo
:   A lightweight caching web proxy intended for small applications.

postgresql
:   A relational database management system.

private PaaS
:   A private [*PaaS*](/als/v1/user/reference/glossary/#term-paas) is
    one which is hosted on your private cloud, behind your firewall.

RabbitMQ
:   A [message broker](http://en.wikipedia.org/wiki/Message_broker)
    subsystem which implements
    [*AMQP*](/als/v1/user/reference/glossary/#term-amqp).

Redis
:   An implementation of memory resident key-value store.

resolvconf
:   A system configuration tool typically used by hook scripts at boot
    time. See the [resolvconf man
    page](http://manpages.ubuntu.com/manpages/man8/resolvconf.8)
    for details.

role
:   Each [*node*](/als/v1/user/reference/glossary/#term-node) in a
    Application Lifecycle Service
    [*cluster*](/als/v1/user/reference/glossary/#term-cluster) may be
    assigned certain selectable capabilities within the Application Lifecycle Service
    architecture. These capabilities are called **roles**, and are
    usually denoted in lowercase. Examples of essential roles are
    **router**, **primary**, **controller**, and **dea**. In addition,
    there are **role groups** (for convenience) such as
    **data-services** that represent all data-services. (postgresql
    mysql rabbit mongodb redis filesystem memcached)

service
:   In Application Lifecycle Service, a **service** is a type of
    [*role*](/als/v1/user/reference/glossary/#term-role) that may be
    provisioned on a server and accessed by an application as specified
    in *manifest.yml*.

supervisord
:   A process control system used by Application Lifecycle Service internally. (see
    [Supervisor project page](http://supervisord.org/))

tty console
:   The hypervisor window which provides serial console access to one of
    its virtual machines.

YAML
:   A notation for structured text data, acronym for [YAML Ain't Markup
    Language](http://en.wikipedia.org/wiki/YAML), used in *manifest.yml* configuration files.

 ---
layout: default-devplatform
permalink: /als/v1/admin/reference/groups/
product: devplatform
---
<!--PUBLISHED-->

Managing Groups, Users & Limits (DEPRECATED)[](#managing-groups-users-limits-deprecated "Permalink to this headline")
===================================================================================================================

##* Warning *

Application Lifecycle Service Groups have been **replaced** by [*Organizations and
Spaces*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces).---
layout: default-devplatform
permalink: /als/v1/admin/reference/kato-ref/
product: devplatform
---
<!--PUBLISHED-->

Kato Command Reference[](#kato-command-reference "Permalink to this headline")
===============================================================================
[Commands](#commands)
    -   [Command Usage Details](#command-usage-details)


Application Lifecycle Service administration utility

Usage[](#usage "Permalink to this headline")
---------------------------------------------

**kato** *command* [**-h**] [**--help**] [*arguments*]
[*command-options*]

Commands[](#commands "Permalink to this headline")
---------------------------------------------------

-   [*config*](#kato-command-ref-config) Manipulate configuration values
    of Application Lifecycle Service components.
-   [*data*](#kato-command-ref-data-export) Import or export Application Lifecycle Service
    system data to or from clusters/nodes.
    -   [*data export*](#kato-command-ref-data-export)
    -   [*data import*](#kato-command-ref-data-import)
    -   [*data users*](#kato-command-ref-data-users)
-   [*debug*](#kato-command-ref-debug-configwatch) Commands for
    debugging for Application Lifecycle Service internals.
    -   [*debug configwatch*](#kato-command-ref-debug-configwatch)
    -   [*debug redis*](#kato-command-ref-debug-redis)
-   [*history*](#kato-command-ref-history) Show the kato commands that
    have been run
-   [*info*](#kato-command-ref-info) Show information about this node or
    cluster including assigned and
-   [*inspect*](#kato-command-ref-inspect) Detect common problems with
    your Application Lifecycle Service install using 'kato inspect'
-   [*log*](#kato-command-ref-log-stream) Logging utilities for Application Lifecycle Service
    -   [*log drain*](#kato-command-ref-log-drain-add)
    -   [*log stream*](#kato-command-ref-log-stream)
    -   [*log tail*](#kato-command-ref-log-tail)
-   [*node*](#kato-command-ref-node-attach) Node management
    -   [*node attach*](#kato-command-ref-node-attach)
    -   [*node detach*](#kato-command-ref-node-detach)
    -   [*node list*](#kato-command-ref-node-list)
    -   [*node migrate*](#kato-command-ref-node-migrate)
    -   [*node remove*](#kato-command-ref-node-remove)
    -   [*node rename*](#kato-command-ref-node-rename)
    -   [*node reset*](#kato-command-ref-node-reset)
    -   [*node retire*](#kato-command-ref-node-retire)
    -   [*node setup*](#kato-command-ref-node-setup-core)
    -   [*node upgrade*](#kato-command-ref-node-upgrade)
    -   [*node version*](#kato-command-ref-node-version)
-   [*op*](#kato-command-ref-op) Various operational commands
-   [*patch*](#kato-command-ref-patch) Update an Application Lifecycle Service cluster with
    post-release fixes.
-   [*process*](#kato-command-ref-process-list) Start, stop, or restart
    individual processes. Generally not required;
    -   [*process list*](#kato-command-ref-process-list)
    -   [*process ready*](#kato-command-ref-process-ready)
    -   [*process restart*](#kato-command-ref-process-restart)
    -   [*process start*](#kato-command-ref-process-start)
    -   [*process stop*](#kato-command-ref-process-stop)
-   [*relocate*](#kato-command-ref-relocate) Move containers,
    application droplets, or services to a new mount point
-   [*report*](#kato-command-ref-report) Generate a report that can be
    sent to Application Lifecycle Service support.
-   [*restart*](#kato-command-ref-restart) Restart Application Lifecycle Service or
    individual roles.
-   [*role*](#kato-command-ref-role-add) Management of node roles
    -   [*role add*](#kato-command-ref-role-add)
    -   [*role info*](#kato-command-ref-role-info)
    -   [*role remove*](#kato-command-ref-role-remove)
-   [*shell*](#kato-command-ref-shell) Interactive shell for kato
-   [*start*](#kato-command-ref-start) Start Application Lifecycle Service or individual
    roles.
-   [*status*](#kato-command-ref-status) List configured roles and their
    current status across the cluster.
-   [*stop*](#kato-command-ref-stop) Stop Application Lifecycle Service or individual roles.
-   [*version*](#kato-command-ref-version) Display the version of
    Application Lifecycle Service being run.

Command Usage Details[](#command-usage-details "Permalink to this headline")
-----------------------------------------------------------------------------

**config** **get** [**options**] [*\<component\>*] [*\<key-path\>*]

**config** **set** [**options**] *\<component\>* *\<key-path\>*
[*\<value\>*]

**config** **del** [**options**] *\<component\>* *\<key-path\>*

**config** **push** [**options**] *\<component\>* *\<key-path\>*
*\<value\>*

**config** **pop** [**options**] *\<component\>* *\<key-path\>*
*\<value\>*

Manipulates configuration values of Application Lifecycle Service components.

*\<value\>* If value is not given for "set", then it read from STDIN.

*\<component\>* Can be "cluster", "local" or the name of a process.

**-h** **--help** Show help information

**-j** **--json** For "set", use JSON format when setting config key values.
	For "get", use JSON format for displaying output.

**-y** **--yaml** Use YAML format when retrieving or setting config key values. YAML is the default output format.

**-f** **--flat** Use a flat output format *\<full-config-path\>> \<value\>*

**--force** Force updating value to different type.
<hr>
**data** **export** **--only-this-node** [**options**] [*\<filename\>*]

**data** **export** **--cluster** [**options**] [*\<filename\>*]

**data** **export** **--manual** [**options**] [*\<filename\>*]

Exports Application Lifecycle Service system data to or from clusters/nodes. With no options specified, includes all data except 'resources' and 'aok-config'.

*\<filename\>* The filename the export will be written to

**-h** **--help** Show help information

**--cluster** Operate on the entire cluster

**--only-this-node** Only affect this node

**--manual** Only import/export roles specified on the command line

**--force** Force import/export of specified roles even if they are not enabled. Requires `--manual`. Implies `--only-this-node`

**--remote** Remote import/export (internal use only)

**--base-dir** *\<base-dir\>* Base directory for extracting temporary files

**--droplets** Include droplets (uploaded apps)

**--exclude-droplets** Do not include droplets (uploaded apps)

**--packages** Include app packages

**--exclude-packages** Do not include app packages

**--resources** Include the upload cache

**--exclude-resources** Do not include the upload cache (default)

**--license** Include the Application Lifecycle Service license

**--exclude-license** Do not include the Application Lifecycle Service license

**--exclude-db-encryption-key** Do not include the key

**--main-db** Include the cloud controller's main database

**--exclude-main-db** Do not include the cloud controller's main
database

**--aok-db** Include AOK's database

**--exclude-aok-db** Do not include AOK's database

**--aok-config** Include AOK's configuration

**--exclude-aok-config** Do not include AOK's configuration (default)

**--helion-rest-db** Include Application Lifecycle Service Rest's database

**--exclude-helion-rest-db** Do not include Application Lifecycle Service Rest's database

**--filesystem** Include the filesystem service

**--exclude-filesystem** Do not include the filesystem service

**--exclude-filesystem-data** Do not include the filesystem service's
user data

**--exclude-filesystem-user-creation** Do not include the filesystem
service's user creation/quota

**--harbor** Include the harbor service

**--exclude-harbor** Do not include the harbor service

**--exclude-harbor-data** Do not include the harbor service's user
data

**--exclude-harbor-metadata** Do not include the harbor service's
metadata

**--mysql** Include the MySQL service

**--exclude-mysql** Do not include the MySQL service

 **--exclude-mysql-data** Do not include the MySQL service's data

 **--exclude-mysql-metadata** Do not include the MySQL service's
 metadata

 **--postgresql** Include the PostgreSQL service

 **--exclude-postgresql** Do not include the PostgreSQL service

 **--exclude-postgresql-data** Do not include the PostgreSQL service's
 data

 **--exclude-postgresql-metadata** Do not include the PostgreSQL
 service's metadata

 **--mongodb** Include the MongoDB service

 **--exclude-mongodb** Do not include the MongoDB service

 **--exclude-mongodb-data** Do not include the MongoDB service's data

 **--exclude-mongodb-metadata** Do not include the MongoDB service's
 metadata

 **--memcached** Include the memcached service

 **--exclude-memcached** Do not include the memcached service

 **--exclude-memcached-data** Do not include the memcached service's
 data

 **--exclude-memcached-metadata** Do not include the memcached
 service's metadata

 **--redis** Include the Redis service

 **--exclude-redis** Do not include the Redis service

 **--exclude-redis-data** Do not include the Redis service's data

 **--exclude-redis-metadata** Do not include the Redis service's
 metadata

 **--rabbit** Include the RabbitMQ service

 **--exclude-rabbit** Do not include the RabbitMQ service

 **--exclude-rabbit-data** Do not include the RabbitMQ service's data

 **--exclude-rabbit-metadata** Do not include the RabbitMQ service's
 metadata

 **--rabbit3** Include the RabbitMQ service

 **--exclude-rabbit3** Do not include the RabbitMQ service

 **--exclude-rabbit3-data** Do not include the RabbitMQ service's data

 **--exclude-rabbit3-metadata** Do not include the RabbitMQ service's
 metadata

<hr>

**data** **import** **--only-this-node** [**options**] *\<source\>*

**data** **import** **--cluster** [**options**] *\<source\>*

**data** **import** **--manual** [**options**] *\<source\>*

Imports Application Lifecycle Service system data to or from clusters/nodes. With no options
specified, includes all data except 'resources' and 'aok-config'.

*\<source\>* This can a hostname or a filename to import from

**-h** **--help** Show help information

**--cluster** Operate on the entire cluster

**--only-this-node** Only affect this node

**--manual** Only import/export roles specified on the command line

**--force** Force import/export of specified roles even if they are
not enabled. - Requires `--manual` - Implies `--only-this-node`

**--remote** Remote import/export (internal use only)

**--base-dir** *\<base-dir\>* Base directory for extracting temporary
files

**--legacy** Treat import as a legacy services import (internal use
only)

**--droplets** Include droplets (uploaded apps)

**--exclude-droplets** Do not include droplets (uploaded apps)

**--packages** Include app packages

**--exclude-packages** Do not include app packages

**--resources** Include the upload cache

**--exclude-resources** Do not include the upload cache (default)

**--license** Include the Application Lifecycle Service license

**--exclude-license** Do not include the Application Lifecycle Service license

**--db-encryption-key** Include the key used to encrypt the Application Lifecycle Service
DB (recommended)

**--exclude-db-encryption-key** Do not include the key

**--main-db** Include the cloud controller's main database

**--exclude-main-db** Do not include the cloud controller's main
database

**--aok-db** Include AOK's database

**--exclude-aok-db** Do not include AOK's database

**--aok-config** Include AOK's configuration

**--exclude-aok-config** Do not include AOK's configuration (default)

**--helion-rest-db** Include Application Lifecycle Service Rest's database

**--exclude-helion-rest-db** Do not include Application Lifecycle Service Rest's database

**--filesystem** Include the filesystem service

**--exclude-filesystem** Do not include the filesystem service

**--exclude-filesystem-data** Do not include the filesystem service's
user data

**--exclude-filesystem-user-creation** Do not include the filesystem
service's user creation/quota

**--harbor** Include the harbor service

**--exclude-harbor** Do not include the harbor service

**--exclude-harbor-data** Do not include the harbor service's user
data

**--exclude-harbor-metadata** Do not include the harbor service's
metadata

**--mysql** Include the MySQL service

**--exclude-mysql** Do not include the MySQL service

**--exclude-mysql-data** Do not include the MySQL service's data

**--exclude-mysql-metadata** Do not include the MySQL service's
metadata

**--postgresql** Include the PostgreSQL service

**--exclude-postgresql** Do not include the PostgreSQL service

**--exclude-postgresql-data** Do not include the PostgreSQL service's
data

**--exclude-postgresql-metadata** Do not include the PostgreSQL
service's metadata

**--mongodb** Include the MongoDB service

**--exclude-mongodb** Do not include the MongoDB service

**--exclude-mongodb-data** Do not include the MongoDB service's data

**--exclude-mongodb-metadata** Do not include the MongoDB service's
metadata

**--memcached** Include the memcached service

**--exclude-memcached** Do not include the memcached service

**--exclude-memcached-data** Do not include the memcached service's
data

**--exclude-memcached-metadata** Do not include the memcached
service's metadata

**--redis** Include the Redis service

**--exclude-redis** Do not include the Redis service

**--exclude-redis-data** Do not include the Redis service's data

**--exclude-redis-metadata** Do not include the Redis service's
metadata

**--rabbit** Include the RabbitMQ service

**--exclude-rabbit** Do not include the RabbitMQ service

**--exclude-rabbit-data** Do not include the RabbitMQ service's data

**--exclude-rabbit-metadata** Do not include the RabbitMQ service's
metadata

**--rabbit3** Include the RabbitMQ service

**--exclude-rabbit3** Do not include the RabbitMQ service

**--exclude-rabbit3-data** Do not include the RabbitMQ service's data

**--exclude-rabbit3-metadata** Do not include the RabbitMQ service's
metadata

<hr>

**data** **users** **import** [**options**] *\<filename\>*

**data** **users** **export** [**options**]
[**--exclude-password-hashes**] [*\<filename\>*]

 Import or export a list of Application Lifecycle Service users (CSV format).

 **-h** **--help** Show help information

 **-p** **--exclude-password-hashes** Do not include hashed passwords
 in export

 **-d** **--dry-run** Do not import/export anything, just show what will be done

<hr>

**debug** **configwatch** [**options**] [*\<process-name\>...*]

Watch changes to cluster config

**-d** **--dump-tree** Dump the config tree seen since starting

**-s** **--no-value** Do not print the value of path

<hr>

**debug** **redis**

Connect to the Redis server used for cluster config via redis-cli

<hr>

**history** [**--help**] [**-n** *\<node-IP\>*] [**--json**]

Show the kato commands that have been run

**-h** **--help** Show help information

**-n** **--node** *\<node-IP\>* Get command history from a specific
cluster node

**-j** **--json** Output as JSON

<hr>

**info** [**--help**] [**-n** *\<node-IP\>*] [**--json**] [**--yaml**]

Show information about this node or cluster including assigned and
available roles.

**-h** **--help** Show help information

**-n** **--node** *\<node-IP\>* Show info on a specific cluster node

**-j** **--json** Output as JSON

**-y** **--yaml** Output as YAML

<hr>

**inspect** [**options**]

**inspect** [**options**] [**all**]

**inspect** [**options**] **group** *\<group-name\>*

**inspect** [**options**] **tests** *\<test-name\>...*

Detect common problems with your Application Lifecycle Service install using 'kato inspect'

To run all tests, run:

	kato inspect

To use a specific group of tests, run:

	kato inspect group \<name of group\>

To run specific tests, run:


    kato inspect tests \<test1\> \<test2\> \<test3\>


**-h** **--help** Show help information

**-v** **--verbose** Verbose output

<hr>

**log** **drain** **add** [**options**] *\<name\>* *\<uri\>*
[*\<param\>...*]

Add a new log drain.

Examples:

\# Add a drain to receive system logs

    kato log drain add system\_splunk udp://logs.splunk.com:1234/

\# Add a drain to forward all application and system logs as json

    kato log drain add -f json -p apptail,systail app\_sys\_splunk
    udp://logs.splunk.com:1235/

\# Add a drain with a custom or named format,

    kato log drain add -f "{{.Name}}: {{.Text}}" system\_splunk\_2
    udp://logs.splunk.com:1236/ kato log drain add -f systail-syslog
    system\_splunk\_2 udp://logs.splunk.com:1236/

\# Passing custom parameters to a drain

    kato log drain add mydrain redis://localhost:6379 key=logdata

**-h** **--help** Show help information

**-f** **--format** *\<format\>* Message format

**-p** **--prefix** *\<prefix\>* Message key prefix; possible values:
systail, event, apptail (comma-separated, no spaces)

<hr>

**log** **drain** **delete** [**options**] *\<name\>*

Delete a drain

**-h** **--help** Show help information
<hr>

**log** **drain** **list** [**options**]

List all log drains

**-h** **--help** Show help information

**-y** **--yaml** Output at YAML

**-j** **--json** Output at JSON

<hr>

**log** **drain** **status** [**options**] [*\<drain\>...*]

Show the status of all or specified log drains

**-h** **--help** Show help information

**-n** **--not-running** Show only drains not running

**-y** **--yaml** Output at YAML

**-j** **--json** Output at JSON
<hr>

**log** **stream** [**options**] *\<key\>...*

 Examples:

\# stream cloud events

	kato log stream event
    
\# stream DEA and app log stream

    kato log stream systail.dea systail.stager apptail

\# stream system logs (equivalent to 'kato log tail')

    kato log stream systail

*\<key\>* Logyard stream key prefix (eg: systail.dea)

**-h** **--help** Show help information

**--no-color** Turn off color

**--raw** Show unformatted logs, including logyard INFO records
(skipped by default)

**--json** Show the original JSON

**--time** Show timestamp

**-n** **--node** *\<node-IP\>* Only show logs from a specific cluster
 node

**-l** **--local** Only show logs from the current node

<hr>

**log** **tail** [**options**] [*\<component\>...*]

*\<component\>* Can be a process name, role name or role group name

**-h** **--help** Show help information

**--no-color** Turn off color

**--raw** Show unformatted logs, including logyard INFO records
(skipped by default)

**--time** Show timestamp

**-n** **--node** *\<node-IP\>* Only show logs from a specific cluster
node

**-l** **--local** Only show logs from the current node
<hr>

**node** **attach** [**options**] *\<core-ip\>*

Attach this node to a core node

**-h** **--help** Show help information

**-e** **--enable** *\<roles\>* Enable the specified roles
(comma-separated, no spaces)

**-s** **--no-start** Do not auto start processes

**-v** **--verbose** Show process information when starting/stopping
roles

**-f** **--force** Forces this node to attach to a core node, ignoring
any version mismatches
<hr>

**node** **detach** [**options**]

Detach this node from a core node

**-h** **--help** Show help information

**-s** **--start** Automatically start processes after detaching

**-v** **--verbose** Show process information when starting/stopping
roles
<hr>

**node** **list** [**options**]

List all nodes known to this cluster

**-h** **--help** Show help information

**-j** **--json** Use JSON format for displaying output

**-y** **--yaml** Use YAML format for displaying output

<hr>

**node** **migrate** *\<old-node-IP\>* *\<new-node-IP\>*

Migrate the node configuration from old node to a new node

**-h** **--help** Show help information

**-r** **--no-restart** Do not restart roles after migration

<hr>

**node** **remove** *\<node-IP\>*

Remove the node from the cluster

**-h** **--help** Show help information

<hr>
**node** **rename** [**options**] *\<hostname\>*

**-h** **--help** Show help information.

**-s** **--skip-remap-hosts** Skip the remapping of existing app URLS
to the new domain.

**-l** **--skip-ssl-regeneration** Skip regenerating the SSL keys

**-r** **--no-restart** Do not restart roles.

**-v** **--verbose** Show process information when restarting roles.
<hr>

**node** **reset** **soft**

**node** **reset** **factory**

**node** **reset** **--help**

Reset the Application Lifecycle Service VM to its default configuration.

-   soft: clears all data and resets the VM to its state immediately
    after first boot.
-   factory: returns the VM to its state prior to first boot.

**-h** **--help** Show help information

<hr>

**node** **retire** [**options**]

Gracefully retires a DEA node from the cluster. New instances of the
apps are started on other available DEAs before the retiring DEA is
shut down.

**-h** **--help** Show help information

**-n** **--node** *\<node-id\>* Retire the specified DEA node, local
node is used if not specified

<hr>

**node** **setup** **core** [*\<endpoint\>*]

**node** **setup** **core** **--help**

Configure the core node of your Application Lifecycle Service cluster

**-h** **--help** Show help information

**-v** **--verbose** Show process information

<hr>

**node** **setup** **firstuser** [**options**] *\<email\>* *\<org\>*

First user setup.

*\<email\>* First user's email.

*\<org\>* First user's organization.

**-h** **--help** Show help information

**-p** **--password** *\<password\>* First user's password. If your unix password has not been updated, then
your unix password will be updated to this. Will be prompted for if not given.

**-u** **--username** *\<username\>* First user's username. Will be the provided email if not given.


<hr>

**node** **setup** **load\_balancer** [*\<IP\>...*] [**--force**]

**node** **setup** **load\_balancer** **--help**

Configure this node as a HTTP/S load balancer

**-h** **--help** Show help information

<hr>

**node** **setup** **micro** [**options**] [*\<role\>...*]

**node** **setup** **micro** **--help**

Configure this instance as a micro cloud

**-h** **--help** Show help information

**-d** **--delete** Delete old configuration and re-initialize
everything

**-s** **--no-start** Do not auto start processes

**-v** **--verbose** Show process information

<hr>

**node** **upgrade** [**options**]

Upgrades Application Lifecycle Service

**-h** **--help** Show help information

**-n** **--node** *\<node\>* Targets the provided node.

**-v** **--version** *\<version\>* The version of Application Lifecycle Service to upgrade
to. The latest version is used if this isn't supplied.

**--rollback** Rolls Application Lifecycle Service back to the previous version.

**--skip-confirmation** Skips initial confirmation of upgrade.

**--resume** Resumes an upgrade process, used internally by Kato and
should only be called manually when requested.

**--cluster** Performs an upgrade of all nodes in the cluster.

**--status** Shows the status of upgrades on a node.

**--force** Forces an upgrade to run.

**-j** **--json** Shows the status in json format.

**-u** **--update-kato** Updates kato node upgrade to the latest
codebase.

**--role-order** *\<role-order\>* Comma separated list of roles
defining the order that roles should be upgraded in a cluster.

**--ignore-inspect-failures** Display pre/post upgrade 'kato inspect'
tests as warnings instead of upgrade failures.
<hr>

**node** **version** [**options**] [*\<node-IP\>*]

> **-h** **--help** Show help information.

<hr>

**op** **--help**

**op** **custom\_ssl\_cert** **install** *\<key-path\>* *\<cert-path\>*
*\<domain\>* [**--wildcard-subdomains**] [**--update**]

**op** **custom\_ssl\_cert** **remove** *\<domain\>*

**op** **custom\_ssl\_cert** **list**

**op** **dhcp**

**op** **defer** *\<command\>* [**--run-as-root**] [**--reset**]

**op** **import\_from\_yaml\_files** [**--upgrade**]

**op** **max\_client\_upload** *\<max-size\>*

**op** **regenerate** **ssl\_cert**

**op** **regenerate** **mysql**

**op** **regenerate** **postgresql** [**--no-restart**]

**op** **regenerate** **helion-rest-auth**

**op** **regenerate** **cloud-controller-client-auth**

**op** **regenerate** **token-signing-secret**

**op** **remap\_hosts** *\<old-hostname\>* *\<new-hostname\>*

**op** **run\_deferred**

**op** **set\_timezone** [**--timezone** *\<TZ\>*]

**op** **static\_ip** [**--no-restart**]

**op** **upstream\_proxy** **set** *\<proxy-address\>* [**-u**
*\<user\>*] [**-p** *\<pass\>*]

**op** **upstream\_proxy** **delete**

**op** **update\_hostsfile**

**op** **generate\_service\_tokens**
<hr>
Various operational commands

**custom\_ssl\_cert** Allows admin configuration of custom SSL
certificates to be used in conjunction with router2g and deployed applications.

**dhcp** Configures this node's networking to use DHCP

**defer** Defers a kato command to be run by 'op run\_deferred'

**max\_client\_upload** Set the maximum upload size in MB

**regenerate** Regenerate the configuration for a process

**remap\_hosts** Change the hostname to look for when remapping

**run\_deferred** Runs any previously deferred kato commands

**set\_timezone** Change the default system timezone for the host
machine

**static\_ip** Configures this node to use a static IP

**upstream\_proxy** Configure Application Lifecycle Service to use an external or upstream
proxy server and deployed apps.

**update\_hostsfile** Updates the /etc/hosts file with the endpoint
URI mapped to the CC's internal IP

**generate\_service\_tokens** Generates service auth tokens.

**-h** **--help** Show help information

**-u** **--user** *\<user\>* Proxy username

**-p** **--pass** *\<pass\>* Proxy password

**-r** **--no-restart** Do not restart processes.

<hr>

**patch** **status** [**--all**]

**patch** **install** [**--only-this-node**] [**--no-restart**]
*\<patchname\>*

**patch** **reset**

**patch** **update**

**patch** **reinstall** [**--only-this-node**] [**--no-restart**]
*\<patchname\>*

Updates an Application Lifecycle Service cluster with post-release fixes.

**-h** **--help** Show help information

**-a** **--all** Show status for all patches

**-n** **--only-this-node** Only patch this node (otherwise entire
cluster will be patched)

**-r** **--no-restart** Don't restart any roles during patching

<hr>

**process** **list** [**options**] [*\<process\>...*]

Lists configured processes and their current running status.

**-h** **--help** Show help information

**-n** **--node** *\<node-IP\>* Get status for a specific cluster node
(defaults to local node)

**-c** **--cluster** Includes process status over all cluster nodes

**-j** **--json** Use JSON format for displaying output

**-y** **--yaml** Use YAML format for displaying output

<hr>

**process** **ready** [**options**] *\<process\>*

**-h** **--help** Show help information

**-b** **--block** *\<seconds\>* Block until ready, for max \<seconds\> seconds. If \<seconds\> is 0, then block forever

**-n** **--node** *\<node-IP\>* Check process on a specific cluster node

<hr>

**process** **restart** [**options**] [*\<process\>...*]

**-h** **--help** Show help information

**-n** **--node** *\<node-IP\>* Restart process on a specific cluster
node

**-c** **--cluster** Restarts process on all nodes in the cluster

<hr>

**process** **start** [**options**] [*\<process\>...*]

> **-h** **--help** Show help information
>
> **-n** **--node** *\<node-IP\>* Start process on a specific cluster
> node

<hr>

**process** **stop** [**options**] [*\<process\>...*]

**-h** **--help** Show help information

**-n** **--node** *\<node-IP\>* Stop process on a specific cluster
node
<hr>

**relocate** [**-h**] **containers** *\<new\_location\>*

**relocate** [**-h**] **droplets** *\<new\_location\>*

**relocate** [**-h**] **services** *\<new\_location\>*

Move containers, application droplets, or services to a new mount
point or filesystem location.

**-h** **--help** Show help information
<hr>

**report**

**report** **--node** *\<node-IP\>*

**report** **--cluster**

**report** **--help**

Generate a report that can be sent to Application Lifecycle Service support.

**-h** **--help** Show help information

**-c** **--cluster** Gather reports from entire cluster into one tarball

**-n** **--node** *\<node-IP\>* Gather report from a specific cluster node

<hr>

**restart** [**options**] [*\<role\>...*]

**restart** **--help**

Restart Application Lifecycle Service or individual roles.

**-a** **--all** Also restart core processes

**-n** **--node** *\<node-IP\>* Restart a specific cluster node

**-v** **--verbose** Show process information

<hr>

**role** **add** **--help**

**role** **add** [**-v**] [**--node** *\<node-IP\>*] [**--no-start**]
*\<role\>...*

**role** **add** [**-v**] [**--node** *\<node-IP\>*] [**--no-start**]
**--all**

**role** **add** [**-v**] [**--node** *\<node-IP\>*] [**--no-start**]
**--all-but** *\<role\>...*

**role** **add** [**-v**] [**--node** *\<node-IP\>*] **--only**
*\<role\>...*

Enable roles on a node

**-h** **--help** Show help information

**-a** **--all** Enable all available roles

**-b** **--all-but** Enable all available roles except these

**-o** **--only** Enable only these roles, while disabling others

**-n** **--node** *\<node-IP\>* Add a role on a specific cluster node

**-s** **--no-start** Do not start processes

**-v** **--verbose** Show process information
<hr>

**role** **info** **--help**

**role** **info** [*\<role\>...*]

Display info on roles

**-h** **--help** Show help information
<hr>

**role** **remove** **--help**

**role** **remove** [**-v**] [**--node** *\<node-IP\>*] *\<role\>...*

**role** **remove** [**-v**] [**--node** *\<node-IP\>*] **--all**

**role** **remove** [**-v**] [**--node** *\<node-IP\>*] **--all-but**
*\<role\>...*

Disable roles for a node

**-h** **--help** Show help information

**-a** **--all** Disable all available roles

**-b** **--all-but** Disable all available roles except these

**-n** **--node** *\<node-IP\>* Remove a role on a specific cluster
node

**-v** **--verbose** Show process information

<hr>

**shell** [**--help**]

Interactive shell for kato

**-h** **--help** Show help information

<hr>

**start** [**options**] [*\<role\>...*]

**start** **--help**

Start Application Lifecycle Service or individual roles.

**-n** **--node** *\<node-IP\>* Start a specific cluster node

**-e** **--ephemeral** Try not to regenerate/modify any config items

**-v** **--verbose** Show process information
<hr>

**status** [**options**]

List configured roles and their current status across the cluster.

**-h** **--help** Show help information

**-a** **--all** Show all roles, including roles not configured on
cluster

**-j** **--json** Use JSON format for displaying output.

**-y** **--yaml** Use YAML format for displaying output.

<hr>

**stop** [**options**] [*\<role\>...*]

**stop** **--help**

Stop Application Lifecycle Service or individual roles.

**-n** **--node** *\<node-IP\>* Stop a specific cluster node

**-v** **--verbose** Show process information

<hr>

**version** [**--help**]

Display the version of Application Lifecycle Service being run.

**-h** **--help** Show help information---
layout: default-devplatform
permalink: /als/v1/admin/reference/known-issues/
product: devplatform
---
<!--PUBLISHED-->

Known Issues[](#known-issues "Permalink to this headline")
===========================================================

Buildpack config\_vars Deprecated[](#buildpack-config-vars-deprecated "Permalink to this headline")
----------------------------------------------------------------------------------------------------
 [Buildpack config\_vars Deprecated](#buildpack-config-vars-deprecated)
    -   [Legacy Buildpack and Environment
        Variables](#legacy-buildpack-and-environment-variables)
    -   [Service Gateway Log Errors in Maintenance
        Mode](#service-gateway-log-errors-in-maintenance-mode)
    -   [Nodes with FATAL or perpetually STARTING
        processes](#nodes-with-fatal-or-perpetually-starting-processes)
    -   [Avoiding App Reliance on IP
        Addresses](#avoiding-app-reliance-on-ip-addresses)
    -   [Community Forums](#community-forums)

Buildpacks used to rely on the `config_vars` feature
of *bin/release* to set environment variables, but this has been
deprecated by Heroku.

The replacement mechanism is to [create a shell script in
\$HOME/.profile.d](https://devcenter.heroku.com/articles/profiled) to
set environment variables. This mechanism is fully supported in Application Lifecycle Service
/ Cloud Foundry v2, and is used by all of the built-in buildpacks.

Legacy Buildpack and Environment Variables[](#legacy-buildpack-and-environment-variables "Permalink to this headline")
-----------------------------------------------------------------------------------------------------------------------

When using the [*Legacy
Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks), environment
variable values defined in *manifest.yml* (`env:`
block) cannot be updated without re-pushing the application with new
settings. Changes to variables made in the Management Console will be
overwritten by the original ones defined at push when the application is
restarted.

To modify custom environment variables, re-push the application after
changing the values in *manifest.yml*.

Service Gateway Log Errors in Maintenance Mode[](#service-gateway-log-errors-in-maintenance-mode "Permalink to this headline")
-------------------------------------------------------------------------------------------------------------------------------

With Application Lifecycle Service set in [*Maintenance
Mode*](/als/v1/admin/console/customize/#console-settings), all "\_gateway"
processes will report the following error once per minute:

    Failed registering with cloud controller, status=503

This is normal, and can be safely ignored. The service nodes will
reconnect once the Controller is taken out of Maintenance Mode.

Nodes with FATAL or perpetually STARTING processes[](#nodes-with-fatal-or-perpetually-starting-processes "Permalink to this headline")
---------------------------------------------------------------------------------------------------------------------------------------

If the Core node of an Application Lifecycle Service cluster is offline for more than 90
seconds, `kato status` will show processes on other
nodes (systail, apptail, router and others) in a FATAL or (hung)
STARTING state. These processes will not automatically reconnect to the
Core node.

To correct this, run `kato start` (for FATAL
processes) or `kato restart` (for STARTING
processes) on all affected nodes.

Avoiding App Reliance on IP Addresses[](#avoiding-app-reliance-on-ip-addresses "Permalink to this headline")
-------------------------------------------------------------------------------------------------------------

Cluster configurations make use of private IP addresses for identifying
the various cluster nodes. Best practice is to avoid the literal use of
these addresses wherever possible, as these addresses are subject to
change with cluster configuration.

If the VM instance can locally resolve a hostname rather than an IP
address, it's generally best practice to use the hostname.

If not, Application Lifecycle Service provides various [*environment
variables*](/als/v1/user/reference/environment/#environment-variables)
so that applications do not need to hardcode them at install time. Some
examples are `VCAP_SERVICES` and `DATABASE_URL`. We strongly encourage their use.

A known issue is that some applications have install procedures that
can't be configured to make use of these variables. If the server that's
providing the app's database (mysql\_gateway/node for example) gets
moved to another location, the only way for the app to become aware of
the new credentials is by restaging the app as noted below. A restart
isn't sufficient.

Choose one of the following according to need, either:

    $ helion delete -n
    $ helion push -n

or:

    $ helion delete -n
    $ helion update -n

Another possible workaround in such cases is to write a script that will
pull the credentials from `VCAP_SERVICES` and update
the app's config as needed, then add this script to the pre-running
hooks.

Community Forums[](#community-forums "Permalink to this headline")
-------------------------------------------------------------------

Please keep up to date with the latest Known Issues, FAQs and
announcements in our [online Application Lifecycle Service
forums](https://community.dev.hp.com/t5/Forum/bd-p/cloud_board).


---
layout: default-devplatform
permalink: /als/v1/admin/reference/troubleshoot/
product: devplatform
---
<!--PUBLISHED-->

Troubleshooting[](#troubleshooting "Permalink to this headline")
=================================================================
 [Server Log Files](#server-log-files)
        -   [health\_manager.log](#health-manager-log)
    -   [Inspecting User Apps as an
        Admin](#inspecting-user-apps-as-an-admin)
    -   [System Diagnosis](#system-diagnosis)
    -   [Specific Cases](#specific-cases)

Server Log Files[](#server-log-files "Permalink to this headline")
-------------------------------------------------------------------


If you need to troubleshoot or monitor Application Lifecycle Service logs with a third party,
they can be found in the \~/helion/logs/\* directory on the Application Lifecycle Service
server.

These logs are under daily log rotation with the use of
[logrotate](http://manpages.ubuntu.com/manpages/man8/logrotate.8).
Up to three days worth of compressed logs are kept before deletion of
the oldest archive.

To modify the log rotation, edit the */etc/logrotate.d/helion* file as
needed. To disable Application Lifecycle Service log rotation, delete the file or move it to
another folder.

### health\_manager.log[](#health-manager-log "Permalink to this headline")

The `health_manager` process is responsible for
monitoring containers and making sure they are relaunched if there's a
problem. The *health\_manager.log* file contains information on all
application instances running on the system.

Sometimes you may see "CRASHED" notifications such as this:

    [2013-04-07 22:42:01.329571] hm - pid=2701 tid=5b3b fid=5cbf  DEBUG -- healthmanager.status: {"droplet":119,"state":"CRASHED"}

A CRASHED status means that the app crashed within the container and the
health\_manager is no longer able to find a running process that looks
like that app (e.g. for a Node app, the node process isn't running; for
a Java app, there is no Java process, etc.). Most of the time this is a
problem with the app within the container.

Cross reference the droplet ID in the *dea.log* or *stager.log* files to
find the application name, then check the logs for the application (e.g.
'helion crashlogs'). By far the most common cause of crashing apps is
a lack of memory, allocating more memory to an app is a good first step
to see if this fixes the problem.

Inspecting User Apps as an Admin[](#inspecting-user-apps-as-an-admin "Permalink to this headline")
---------------------------------------------------------------------------------------------------

Application Lifecycle Service Admin accounts have root-like privileges. They can inspect all
user applications and service instances running on the system.

The helion group \<command-users-groups-limits\> command can be used
by admin accounts to inspect applications and service instances for any
group or user. For example:

    $ helion group jane.doe@example.com

This sets the scope of subsequent operations to the specified user. Use
`helion group --reset` to return to the scope of
the logged-in admin user.

System Diagnosis[](#system-diagnosis "Permalink to this headline")
-------------------------------------------------------------------

There may be cases where resolving an issue requires a complete view of
the system metrics. This functionality is provided by the
`helion admin report` command. It generates a
single file (by default named *\<target\>-report.tgz*) that can be
provided to the Application Lifecycle Service support team for analysis:

    $ helion admin report

The file is several megabytes in size and will take a few seconds to
generate. Send it, along with a detailed description of your problem, to
HP at: [als-support@hp.com](mailto:als-support@hp.com)

Specific Cases[](#specific-cases "Permalink to this headline")
---------------------------------------------------------------

**When pushing an app, the Application Lifecycle Service Client reports OK but app isn't
running**

The final output from pushing an app should look like:

    Staging Application: OK
    Starting Application: OK

If the app is being pushed to multiple instances, the client waits
until at least one instance is running, and exits at that point (it
does not wait until all instances are active). If afterwards you run
`helion apps` and find the Health status at 0%,
it is because the app crashed after starting successfully, not because
the Application Lifecycle Service client reported incorrectly.

**DNS queries returning "connection refused"**

This error is reported when the Application Lifecycle Service server does not have an IP
Address. To investigate and resolve, try the following:

-   Verify the ARP tables on the hypervisor host, and on the Application Lifecycle Service
    server through its [*tty
    console*](/als/v1/user/reference/glossary/#term-tty-console):

        $ arp -n

-   Check that the DHCP client is running:

        $ pgrep dhclient
        $ grep dhclient /var/log/syslog

-   Connect to the DHCP server and verify that it is receiving client
    requests from the Application Lifecycle Service server.

-   If your network is statically configured, assign an IP address on
    the Application Lifecycle Service server by editing the
    [interfaces](http://manpages.ubuntu.com/manpages/man5/interfaces.5)
    file:

        /etc/network/interfaces---
layout: default-devplatform
permalink: /als/v1/admin/server/aok/
product: devplatform
---
<!--PUBLISHED-->

AOK Authentication Server[](#aok-authentication-server "Permalink to this headline")
=====================================================================================
[End User Login](#end-user-login)
        -   [Web](#web)
        -   [Client](#client)
    -   [Strategies](#strategies)
    -   [Configuration](#configuration)
    -   [User Management](#user-management)
    -   [First Admin User Setup](#first-admin-user-setup)
    -   [Regular LDAP User Setup](#regular-ldap-user-setup)

AOK is Application Lifecycle Service's authentication management service (replacing Cloud
Foundry's UAA Server). It issues tokens via OAuth2 for client
applications such as the `helion` client and the
Management Console. AOK can connect to other back-end SSO services such
as LDAP by using different [*Strategies*](#aok-strategies).

End User Login[](#end-user-login "Permalink to this headline")
---------------------------------------------------------------

### Web[](#web "Permalink to this headline")

Users log in to the web Management Console as they would with any other
web application. The Management Console checks with the AOK endpoint
(e.g. https://aok.helion.example.com) in the background.

### Client[](#client "Permalink to this headline")

If the strategy has been changed to something other than builtin (see
below), then users connecting with the
[*helion*](/als/v1/user/client/#client) client should be aware
that:

-   The user must enter their identifier in the format expected by the
    [*strategy*](#aok-strategies) used by AOK (e.g. username or email
    address).
-   When using an existing authentication token to log in as a second
    user (e.g. an admin connecting as another user), use the second
    user's helion username, *not the identifier used by AOK's
    strategy*.

These caveats also apply when using other Cloud-Foundry-compatible
clients.

Strategies[](#strategies "Permalink to this headline")
-------------------------------------------------------

The term *strategy* refers to the method used to authenticate users.
There are currently two supported strategies:

-   **builtin**: The default builtin strategy uses a local database of
    users and passwords to authenticate.

-   **ldap**: The ldap strategy authenticates using the LDAP server
    specified in [*kato config*](#aok-configuration). Any user that can
    successfully authenticate with the LDAP server will be allowed to
    use Application Lifecycle Service and will have a (non-admin) user account created for
    them automatically. The LDAP server must return an email address for
    the user to allow them to log in to Application Lifecycle Service. AOK will look for the
    email address under the `mail`,
    `email`, and `userPrincipalName` attributes.

    LDAP groups are not currently supported as a visible construct in
    Application Lifecycle Service.

The use key in the configuration controls the strategy that AOK will
use. This value must correspond exactly to one of the supported strategy
names.

Configuration[](#configuration "Permalink to this headline")
-------------------------------------------------------------

To configure AOK, set the following keys in the AOK config using [*kato
config set*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config):

-   strategy:

    -   use: set to either 'builtin' (default) or 'ldap'. The builtin
        strategy requires no further modification. The ldap strategy
        requires setting options in the corresponding block below.

    -   ldap:

        -   host: hostname or IP of the LDAP server

        -   port: LDAP server port, typically 389

        -   method: plain, ssl, or tls

        -   base: list of domain components (e.g. 'dc=example, dc=com')

        -   uid: LDAP attribute name for the user name that will used in
            the login form. Active Directory (AD) is typically
            'sAMAccountName' or 'UserPrincipalName', while OpenLDAP is
            'uid'.

        -   email: the LDAP attribute containing the user's fully
            qualified email address. An email address attribute is
            necessary for AOK to work properly with the cloud
            controller. This may be a scalar attribute or an array of
            attributes to search. The default is shown. The first
            non-null attribute will be used (AOK will not validate that
            this is an email address). The default attributes are:

            -   mail
            -   email
            -   userPrincipalName

        -   bind\_dn: (optional) credentials for user lookup (e.g.
            'cn=Administrator,cn=Users,dc=example,dc=com'). LDAP servers
            that allow anonymous bind will not require this setting.

        -   password: (optional) default credentials for user lookup

        -   try\_sasl: (optional) when set to true attempts a SASL
            connection to the LDAP server

        -   sasl\_mechanims: (optional) 'DIGEST-MD5' or 'GSS-SPNEGO'

**Note**

An additional 'name\_proc' option in the 'ldap' block allows users to
enter email addresses instead of LDAP user names, matching the user name
entered with the format of the uid attributes. For example, value of
'sAMAccountName' in AD contains only the Windows user name. If your
users prefer using email to login, the following 'name\_proc' value will
trim the email string down to just the Windows login name:

    Proc.new {|name| name.gsub(/@.*$/,'')}

Value must be valid ruby code. Since the provided code will be accepting
arbitrary user input, administrators are urged to use this setting only
when absolutely necessary, and to check the code thoroughly for possible
security implications.

To see the default AOK configuration (default settings) run the
command:

    $ kato config get aok

Settings are nested as per the option list above. To set an option,
specify the full config path to that option. For example:

    $ kato config set aok strategy/ldap/base 'dc=yourdomain, dc=com'

To add an attribute to the 'email' array:

    kato config push aok strategy/ldap/email "ADMailAcct"

To set the entire array in one step, use the `--json` option:

    kato config set --json aok strategy/ldap/email '["mail","ADMailAcct", "email"]'

User Management[](#user-management "Permalink to this headline")
-----------------------------------------------------------------

When using AOK with any strategy other than 'builtin', users in Application Lifecycle Service
will be created automatically for any user who successfully
authenticates.

Administrators can still use the functions as before, but should be
aware of the following caveats:

-   Admins may manually create users if they wish. This may be useful if
    the admin wants to pre-assign users to groups in Application Lifecycle Service before
    those users have logged in for the first time. The admin must create
    the user with the same username that AOK will receive from the
    strategy.
-   Passwords set while creating users or using the password-change
    function will be disregarded - Application Lifecycle Service/AOK does not manage the
    external authentication systems.
-   Admins may delete users, but the user will be recreated if they log
    in again via AOK. If an admin wishes to prevent a user from using
    Application Lifecycle Service, the user's login credentials should be revoked in the
    external authentication system.

First Admin User Setup[](#first-admin-user-setup "Permalink to this headline")
-------------------------------------------------------------------------------

When setting up an Application Lifecycle Service system using AOK, complete the "Set Up First
Admin User" form shown by the web Management Console before configuring
LDAP authentication. This creates an administrative user, and changes
the password of the 'helion' user on the VM to match whatever was
entered in the form.

You may use either a temporary username (e.g. "firstuser") which will be
deleted later, or use the LDAP username you will ultimately use once AOK
is configured.

Once the first user has been created:

-   Log in to the micro cloud VM or Core node as the 'helion' user
    (with the password set previously)

-   [*Configure AOK*](#aok-configuration) to use LDAP

-   Set the `admin_user` key with the desired LDAP
    admin username:

        $ kato config set aok strategy/ldap/admin_user <username>

    This user will be granted admin privileges when logging in for the
    first time.

-   If you created a temporary admin user, delete it at this point.

Regular LDAP User Setup[](#regular-ldap-user-setup "Permalink to this headline")
---------------------------------------------------------------------------------

New users logging in to the Management Console for the first time using
LDAP authentication will not be a member of any organization (and won't
be able to do anything). An admin will have to add each user to an
organization after their initial login.---
layout: default-devplatform
permalink: /als/v1/admin/server/configuration/
product: devplatform
---
<!--PUBLISHED-->

#Detailed Configuration {#detailed-configuration} 

   [Changing the Password](#changing-the-password)

-   [Network Setup](#network-setup)
	-   [Changing the Hostname](#changing-the-hostname)
	-   [Changing IP Addresses](#changing-ip-addresses)
	-   [Setting a Static IP](#setting-a-static-ip)
	-   [Modifying the hosts file](#modifying-etc-hosts)
	-   [DNS](#dns)
	-   [Dynamic DNS](#dynamic-dns)
	-   [Alternate DNS Techniques](#alternate-dns-techniques)
		-   [xip.io](#xip-io)
		-   [dnsmasq](#dnsmasq)
		-   [Adding DNS Nameservers](#adding-dns-nameservers)
		-   [TCP/UDP Port Configuration](#tcp-udp-port-configuration)
		-   [HTTP Proxy](#http-proxy)
		-   [Staging Cache & App HTTP Proxy](#staging-cache-app-http-proxy)
	-   [VM Filesystem Setup](#vm-filesystem-setup)
	-   [Application Lifecycle Service Data Services vs. High Availability Databases](#helion-data-services-vs-high-availability-databases)
	-   [HTTPS & SSL](#https-ssl)
		-   [Using your own SSL certificate](#using-your-own-ssl-certificate)
		-   [Adding Custom SSL Certs (SNI)](#adding-custom-ssl-certs-sni)
		-   [CA Certificate Chaining](#ca-certificate-chaining)
		-   [Generating a self-signed SSL certificate](#generating-a-self-signed-ssl-certificate)
	-   [Quota Definitions](#quota-definitions)
		-   [sudo](#sudo)
		-   [Allowed Repositories](#allowed-repositories)

##General {#general}

**Note**

After booting the VM, run `kato process ready all`
before starting the following configuration steps. This command returns
`READY` when all configured system processes have
started, and is particularly important when using `kato` commands in automated configuration scripts which run
immediately after boot (the
[*--block*](/als/v1/admin/reference/kato-ref/#kato-command-ref-process-ready)
option is useful in this scenario).

### Changing the Password {#changing-the-password}

The default password for the Helion system user
is **helion**.  In clusters created by Helion Orchestration tools (the Horizon Management Console and Installer CLI VM), access after cluster setup is only available by SSH key pair.

This password is changed to match the one set for the first
administrative user created in the Management Console. Once you've set up the primary Application Lifecycle Service admin account, use that account's password when
logging in to the VM at the command line. 

In an Application Lifecycle Service cluster, this change only happens on the node serving the
Management Console pages (which could be one of [*multiple Controller
nodes*](/als/v1/admin/cluster/#cluster-multi-controllers)). In this case,
it's best to log in to each node in the cluster to change the password
manually with the `passwd` command.

##Network Setup {#network-setup}

### Changing the Hostname {#changing-the-hostname}
You may want or need to change the hostname of the Application Lifecycle Service system,
either to match a DNS record you've created or just to make the system
URLs more convenient. This can be done using the [*kato node
rename*](/als/v1/admin/reference/kato-ref/#kato-command-ref) command:

    $ kato node rename mynewname.example.com

This command will change the system hostname in
`/etc/hostname` and `/etc/hosts`, as well as performing some internal configuration for
Application Lifecycle Service such as generating a new server certificate for the
[*Management
Console*](/als/v1/user/console/#management-console).

mDNS is only supported with ".local" hostnames. If you want to give the
VM a canonical hostname on an existing network, [*configure
DNS*](#server-config-dns) and disable the 'mdns' role:

    $ kato role remove mdns

**Note**

Application Lifecycle Service takes a while to configure itself at boot (longer at first
boot). Check `kato status` to see that core services are running before
executing `kato node rename`.

In a [*cluster*](/als/v1/user/reference/glossary/#term-cluster), you
may also need to manually [*modify the /etc/hosts
file*](#server-config-etc-hosts).

### Changing IP Addresses {#changing-ip-addresses}

The Application Lifecycle Service *micro cloud* server is initially set up for
[*DHCP*](/als/v1/user/reference/glossary/#term-dhcp) and [*multicast
DNS*](/als/v1/user/reference/glossary/#term-multicast-dns). This is
often sufficient for local testing, but in this configuration is only a
single node and can only be privately routed.

As you move toward production use of the server, further configuration
of IP addresses and hostnames will therefore be required. A production
Application Lifecycle Service server will most likely be a
[*cluster*](/als/v1/user/reference/glossary/#term-cluster) consisting
of several nodes, some of them requiring IP addresses and corresponding
hostnames.

If your server is to be exposed to the Internet, these addresses must be
routable and the hostnames must appear in the global DNS. Even if your
server is to be part of a [*private
PaaS*](/als/v1/user/reference/glossary/#term-private-paas) for
organizational use only, it must still integrate fully with your network
services, DHCP and DNS in particular. Finally, in the rare case that
such services are not available, the Application Lifecycle Service server can be configured
with static IP addresses and hostnames.

Before we examine these scenarios in detail, let's review the separation
of roles in a [*cluster*](/als/v1/admin/cluster/#cluster-setup):

-   The **core** node which we conventionally call
    `api.helion-xxxx.local` in a micro cloud will
    be given its own hostname and IP address in a cluster so that you
    can reach it from both the [*Management
    Console*](/als/v1/user/console/#management-console) and the
    command line.
-   At the same time, the other nodes in the cluster will also need to
    reach the core node, so whatever address is configured on its
    network interface will have to be known to the network, the primary
    node, and all the other nodes. This can be the same as the primary
    address assigned to the core, or a secondary address used purely
    within the cluster.
-   The **router** nodes, if separate from the primary, will each
    require IP addresses of their own, reachable from any load balancer
    and through any firewall that you put in front of them.

Where you configure these hostnames and IP addresses will depend on how
you operate your data center network. You will want to confer with your
network administrator about this, starting with the MAC address
configured for each VM in the hypervisor. If your site supports a
significant number of VMs, DHCP may be set up to map MAC addresses to IP
addresses in a particular way. For example, a certain range of MAC
addresses may be used for servers in the DMZ, and another range for
internal servers. If you follow this convention, your Application Lifecycle Service server
will obtain an appropriate IP address automatically. DNS at your site
may establish a similar convention, which you will want to follow when
making any name or address changes within the cluster.

Having determined the hostnames of cluster nodes to be managed by
[*DNS*](#server-config-dns), the hostname on the primary node should be
set using [*kato node rename*](#server-config-hostname).

Finally, if you must set a static IP on any cluster node, be sure to
test it before making the change permanent, otherwise you may not be
able to reach the node once it reboots. Assuming that the primary
address is on interface `eth0`, a secondary address
`10.0.0.1/24` could be set up temporarily as
follows:

    $ ipcalc -nb 10.0.0.1/24
    Address:   10.0.0.1
    Netmask:   255.255.255.0 = 24
    Wildcard:  0.0.0.255
    =>
    Network:   10.0.0.0/24
    HostMin:   10.0.0.1
    HostMax:   10.0.0.254
    Broadcast: 10.0.0.255
    Hosts/Net: 254                   Class A, Private Internet
    $ sudo ifconfig eth0:1 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 up

Configure another cluster node using a different address on the same
subnet, and be sure that `ping` works correctly on
the new addresses. You should also use this opportunity to ping the
router and DNS server for this subnet. Check with your network
administrator for their addresses.

### Setting a Static IP {#setting-a-static-ip}

The easiest way to configure an Application Lifecycle Service VM with a static IP address is
to use the [*kato op
static\_ip*](/als/v1/admin/reference/kato-ref/#kato-command-ref-op) command.

This command will prompt for the following inputs:

-   static IP address (e.g. 10.0.0.1)
-   netmask (e.g. 255.255.255.0)
-   network gateway (e.g. 10.0.0.254)
-   (optional) comma-separated list of DNS names servers (e.g.
    10.0.0.252, 10.0.0.253)
-   (optional) comma-separated list of DNS search domains (e.g.
    example.com, example.org)

`kato` will verify the IP addresses given are within legal ranges,
automatically calculate the network / broadcast addresses for you, and
prompt for the *sudo* password to write the changes.

As a precaution, the command does not automatically restart networking
services. To do so, run the following commands:

    $ sudo /etc/init.d/networking restart

You will see a deprecation warning about the `restart` option, which can safely be ignored in this context.

**Note**

If you are setting a new static IP *after* having configured the VM as a
Core node in a cluster, you must run the [*kato node
migrate*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command on each Application Lifecycle Service node to reset the MBUS\_IP for the cluster.

Alternatively, these changes could be made by editing the
*/etc/network/interfaces* file manually. For example:

    auto eth0
    iface eth0 inet static
        address 10.0.0.1
        netmask 255.255.255.0
        network 10.0.0.0
        broadcast 10.0.0.255
        gateway 10.0.0.254
        dns-nameservers 10.0.0.252, 10.0.0.253
        dns-search example.com, example.org

When DHCP is not used, DNS server IP addresses must be set explicitly
using the `dns-nameservers` directive as shown
above. Multiple DNS servers can be specified in a comma separated list.

**Note** that `dnsmasq` does not necessarily
reinitialize on `SIGHUP`. Therefore, perform the
following to reinitialize:

    $ sudo /etc/init.d/dnsmasq restart
    $ sudo /etc/init.d/networking restart

Or use `sudo shutdown -r` to exercise a complete
restart. Then use `ifconfig` to check that the
interface has been configured, and `ping` to check
routing to other hosts on the subnet and out in the world. Finally, use
`dig @<DNS SERVER IP> <HOSTNAME>` to check that DNS
is resolving correctly.

In the event of troubleshooting, you can confirm which DNS servers are
being used by dnsmasq by checking the file
*/var/run/dnsmasq/resolv.conf*.

**Note**

There may be a performance advantage in locally defining a private
secondary IP address ([**RFC
1918**](http://tools.ietf.org/html/rfc1918)) for the controller so
that the other nodes can be assured of routing directly to it. See your
network administrator for advice on which addresses and subnets are
permissible. Once you have this secondary address set up, see the
[*/etc/hosts*](#server-config-etc-hosts) section for final configuration
of the server.
 
### Modifying /etc/hosts {#modifying-etc-hosts}
 
The `/etc/hosts` file is used to resolve certain
essential or local hostnames without calling upon the DNS. Unless you
need to [*change the local hostname*](#server-config-hostname), you will
in general *not* have to edit `/etc/hosts` manually,
but when troubleshooting network issues it never hurts to verify that
the file is configured correctly.

As well, various components in a
[*Cluster*](/als/v1/admin/cluster/#cluster-setup) rely on finding the
cluster nodes in `/etc/hosts`: the Cloud Controller
and the RabbitMQ service in particular.

Application Lifecycle Service will automatically configure `/etc/hosts`
on the virtual machine with one entry for the `localhost` loopback address and another for the [**RFC
1918**](http://tools.ietf.org/html/rfc1918) private IP address of
the cluster's Primary node, for example "10.0.0.1" or "192.168.0.1". All
communication between cluster nodes should be strictly through their
private IP addresses and not on routable addresses provided by the DNS.

Remember that `/etc/hosts` does not support
wildcards. You must use some form of [*DNS*](#server-config-dns) for
that.

Consider an Application Lifecycle Service instance called `helion-test`
in domain `example.com`. The following example is
what you should expect to see on a [*micro
cloud*](/als/v1/user/reference/glossary/#term-micro-cloud)
installation, where all roles are running on the same node:

    $ hostname
    helion-test
    $ ifconfig eth0
    eth0      Link encap:Ethernet  HWaddr 08:00:27:fc:1c:f6
      inet addr:10.0.0.1  Bcast:10.0.0.255  Mask:255.255.255.0
      inet6 addr: fe80::a00:27ff:fefc:1cf6/64 Scope:Link
      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
      RX packets:875142 errors:0 dropped:0 overruns:0 frame:0
      TX packets:106777 errors:0 dropped:0 overruns:0 carrier:0
      collisions:0 txqueuelen:1000
      RX bytes:191340039 (191.3 MB)  TX bytes:23737389 (23.7 MB)
    $ cat /etc/hosts
    127.0.0.1       localhost helion-test
    10.0.0.1        helion-test.example.com api.helion-test.example.com

On a [*cluster*](/als/v1/user/reference/glossary/#term-cluster)
installation, the IP address in /etc/hosts will identify the node
hosting the MBUS, usually the same as the Cloud Controller. On this
node, you will see a correspondence between the network interface
`eth0` address and `/etc/hosts`
as in the above example. On each of the *other nodes* in the cluster,
for example DEA nodes, `eth0` will be configured
with its own address on the same subnet, but `/etc/hosts` will remain the same..

If modifying `/etc/hosts` becomes necessary because
of a hostname change, you can simply edit it as in the following
example:

    $ sudo vi /etc/hosts

### DNS {#dns}

The Application Lifecycle Service micro cloud uses [*multicast
DNS*](/als/v1/user/reference/glossary/#term-multicast-dns). to
broadcast its generated hostname (e.g. `helion-xxxx.local`). This mechanism is intended for VMs running on a local
machine or subnet.

For production use, the server will need:

-   a public DNS record,
-   a wildcard CNAME record, and
-   a fixed IP address.

For example, a DNS zone file for "helion.example.com" might contain:

    helion.example.com        IN    A        10.3.30.200
    *.helion.example.com      IN    CNAME    helion.example.com

The wildcard CNAME record enables routing for the hostnames created for
each application pushed to Application Lifecycle Service. If your networking policy forbids
the use of wildcard records, you will need to add DNS records for each
application pushed to Application Lifecycle Service as well as the following two hostnames:

-   **api.** - API endpoint for clients and the URL of the Management
    Console (e.g. api.helion.example.com)
-   **aok.** - AOK authentication endpoint (e.g.
    aok.helion.example.com)

If you intend to expose your applications at URLs on other domains (e.g.
using [*helion map*](/als/v1/user/reference/client-ref/#command-map) add these names
to the DNS zone file as well. For example:

    app.domain.com              IN    CNAME    helion.example.com

Firewalls and load balancers may require corresponding adjustments.

**Note**

If your site uses DHCP, configure a static binding to the MAC address of
the Application Lifecycle Service VM (and be careful not to change the MAC address
accidentally through the hypervisor). If Application Lifecycle Service is hosted on a cloud
provider, assign a fixed IP address using the platform's tools (e.g.
Floating IP on OpenStack).

With DNS records in place, the multicast DNS broadcast is no longer
necessary. To turn it off on the Application Lifecycle Service server, use the command:

    $ kato role remove mdns

###Dynamic DNS {#dynamic-dns}

If you don't have access to a DNS server, you can use a dynamic DNS
provider, such as [ChangeIP](http://www.changeip.com/freedomains.asp)
and
[others](https://help.ubuntu.com/community/DynamicDNS#Registering_with_a_Dynamic_DNS_provider),
to provide DNS records. You will need one that provides wildcard
subdomain assignment.

Before registering your domain, be sure that your mail server will
accept email from the provider (for example
`support@changeip.com`).

Create an account, choose a subdomain, and ensure that a wildcard
assignment is made on the subdomain to handle `api`
and related application subdomains. Then wait to receive the
authorization email, and verify the zone transfer before proceeding.

### Alternate DNS Techniques {#alternate-dns-techniques)

For situations where mDNS will not work (e.g. running in a cloud hosting
environment or connecting from a Windows system without mDNS support)
but which do not merit the effort of manually configuring a DNS record
(e.g. a test server) alternative methods are available.

####xip.io {#xip-io}

The quickest way to get wildcard DNS resolution is to use the
[xip.io](http://xip.io/) service.  This is the approach taken on clusters created with the Horizon Management Console panel or Application Lifecycle Service Installer CLI, and is done as part of the setup process.

[*Change your hostname*](#server-config-hostname) using [*kato node
rename*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach) to
match the external IP address with the 'xip.io' domain appended. For
example:

    $ kato node rename 10.9.8.7.xip.io

This will change the system hostname and reconfigure some internal
Application Lifecycle Service settings. The xip.io DNS servers will resolve the domain
'10.9.8.7.xip.io' and all sub-domains to '10.9.8.7'. This works for
private subnets as well as public IP addresses.

####dnsmasq {#dnsmasq}

Locally, you can run
[*dnsmasq*](/als/v1/user/reference/glossary/#term-dnsmasq) as a simple
DNS proxy which resolves wildcards for
`*.helion-test.example.com` to
`10.9.8.7` when line such as the following is
present in any of its configuration files:

    address = /.helion-test.example.com/ 10.9.8.7

You must restart the service to pick up the changed configuration:

    $ /etc/init.d/dnsmasq restart

###Adding DNS Nameservers {#adding-dns-nameservers}

You may need to add site-specific DNS nameservers manually if the
Application Lifecycle Service VM or applications running in Application Lifecycle Service containers need to
resolve internal hosts using a particular nameserver.

To explicitly add a DNS nameserver to an Application Lifecycle Service VM running under DHCP,
edit */etc/dhcp/dhclient.conf* and add a line with the DNS server IP.
For example:

    append domain-name-servers 10.8.8.8;

Reboot to apply the changes.

For Application Lifecycle Service VMs with a static IP, add the nameservers when prompted
when running the `kato op static_ip` command (see
[*Setting a Static IP*](#server-config-static-ip) above).

###TCP/UDP Port Configuration {#tcp-udp-port-configuration}

The Application Lifecycle Service [*micro cloud*](/als/v1/user/reference/glossary/#term-micro-cloud) runs with
the following ports exposed:

<table>
<tr><td>Port</td><td>Type</td><td>Service</td></tr>
<tr><td>22</td><td>tcp</td><td>ssh</td></tr>
<tr><td>25</td><td>tcp</td><td>smtp</td></tr>
<tr><td>80</td><td>tcp</td><td>http</td></tr>
</table>

On a production cluster, or a micro cloud running on a cloud hosting
provider, only ports 22 (SSH), 80 (HTTPS) and 443 (HTTPS) need to be
exposed externally (e.g. for the Router / Core node).

Within the cluster (i.e. behind the firewall), it is advisable to allow
communication between the cluster nodes on all ports. This can be done
safely by using the security group / security policy tools provided by
your hypervisor.

If you wish to restrict ports between some nodes (e.g. if you do not
have the option to use security groups), the following summary describes
which ports are used by which components. **Source** nodes initiate the
communication, **Destination** nodes need to listen on the specified
port.

<table>
<tr><td>Port Range</td><td>Type</td><td>Source</td><td>Destination</td><td>Required By</td></tr>
<tr><td>22</td><td>tcp</td><td>all nodes</td><td>all nodes</td><td>ssh/scp/sshfs</td></tr>
<tr><td>4222</td><td>tcp</td><td>all nodes</td><td>all nodes</td><td>dea,controller</td></tr>
<tr><td>3306</td><td>tcp</td><td>dea,controller</td><td>mysql nodes</td><td>MySQL</td></tr>
<tr><td>5432</td><td>tcp</td><td>all nodes</td><td>postgresql nodes</td><td>PostgreSQL</td></tr>
<tr><td>5454</td><td>tcp</td><td>all nodes</td><td>controller</td><td>redis</td></tr>
</table>
   
More on  [*NATS*](/als/v1/user/reference/glossary/#term-nats) communication
    with the MBUS IP (core Cloud Controller)10 is available in the glossary.

Each node can be internally firewalled using
[iptables](http://manpages.ubuntu.com/manpages/man8/iptables.8) to
apply the above rules.

Comments:

-   Ports 80 and 443 need only be open to the world on router nodes.
-   Port 4222 should be open on all nodes for
    [*NATS*](/als/v1/user/reference/glossary/#term-nats) communication
    with the MBUS IP (core Cloud Controller)
-   Port 9022 should be open to allow transfer of droplets to and from
    the DEAs, and Cloud Controllers.
-   Port 7845 is required if you plan to stream logs from all nodes in a
    cluster using `kato log tail` command.
-   External access on port 22 can be restricted if necessary to the
    subnet you expect to connect from. If you are providing the
    `helion ssh` feature to your users
    (recommended), define a distinct security group for the
    public-facing Cloud Controller node that is the same as a generic
    Application Lifecycle Service group, but has the additional policy of allowing SSH (Port
    22) from hosts external to the cluster.
-   Within the cluster, port 22 should be open on all hosts to allow
    administrative access over SSH. Port 22 is also used to mount
    Filesystem service partitions in application containers on the DEA
    nodes (via SSHFS).
-   The optional Harbor port service has a configurable port range
    (default 41000 - 61000) which can be exposed externally if required.

### HTTP Proxy {#http-proxy}

**Note**

If your network has an HTTP proxy, the helion client may attempt to
use this when connecting to api.helion-xxxx.local and fail because the
changes in `/etc/hosts` file are not reflected in
the proxy. To work around this problem in Windows, enable
`\*.local` in the `ProxyOverride` registry key
`HCU/Software/Microsoft/Windows/CurrentVersion/Internet Settings`.

In some cases, it may be a requirement that any HTTP request is first
handled through an upstream or parent proxy (HTTP requests may not be
directly routable otherwise).

In this case it is necessary to tell
[*Polipo*](/als/v1/user/reference/glossary/#term-polipo) about the
proxy so it knows how to handle this correctly.

Open the Polipo config file `/etc/polipo/config` and
add the lines:

    parentProxy = <IP>:<PORT>
    parentAuthCredentials = "myuser:mypassw"

Then restart Polipo:

    $ sudo /etc/init.d/polipo restart

If you are using a SOCKS proxy, edit the file in the same way but with
the lines:

    socksParentProxy=<IP>:<PORT>
    socksProxyType=socks4a | OR | socks5;

Then restart Polipo:

    $ sudo /etc/init.d/polipo restart

For log info, any errors reported by Polipo are available on the
Application Lifecycle Service server in `/var/log/polipo/polipo.log`.

###Staging Cache & App HTTP Proxy {#staging-cache-app-http-proxy}

Application Lifecycle Service caches all application dependencies that are downloaded by
module managers that support the
[*HTTP\_PROXY*](/als/v1/user/reference/environment/#term-http-proxy)
environment variable (e.g. pip, PyPM, PPM, NPM, etc). This is limited to
100MB of in-memory cache.

If you have an upstream HTTP proxy that deployed applications and the
staging system need to traverse to access the internet, use the
`kato op upstream_proxy ...` command on all DEA
nodes:

    $ kato op upstream_proxy set 192.168.0.99:3128

To remove the proxy setting:

    $ kato op upstream_proxy delete <proxy_addr>

To set an HTTP proxy exclusively for apps, add an
`environment/app_http_proxy` setting in the dea\_ng
config using [*kato config
set*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config). For example:

    $ kato config set dea_ng environment/app_http_proxy 10.0.0.47:3000

Adding this configuration sets the 'http\_proxy' environment variable
within all subsequently created application containers.

##VM Filesystem Setup {#vm-filesystem-setup)


The Application Lifecycle Service VM is distributed with a simple default partitioning scheme
(i.e. everything but "/boot" mounted on "/").

Warning

When setting up a production cluster, additional filesystem
configuration is necessary to prevent certain nodes from running out of
disk space.

Some nodes in a production cluster may require additional mount points
on external block storage for:

-   services (data and filesystem service nodes)
-   droplets (controller nodes)
-   containers (DEA and Stager nodes)

Suggestions for mounting block storage and instructions for relocating
data can be found in the [*Persistent
Storage*](/als/v1/admin/best-practices/#bestpractices-persistent-storage)
section.

##Application Lifecycle Service Data Services vs. High Availability Databases {#helion-data-services-vs-high-availability-databases}

Application Lifecycle Service data services do not offer any built-in redundancy. For
business-critical data storage, a high-availability database or cluster
is recommended.

To use an external database instead of the data services provided by
Application Lifecycle Service, specify the database credentials directly in your application
code instead of using the credentials from the
[*VCAP\_SERVICES*](/als/v1/user/reference/environment/#term-vcap-services)
environment variable.

To tie external databases to Application Lifecycle Service as a data service, see the
examples in the [*Adding System
Services*](/als/v1/admin/reference/add-service/#add-service) section.

###HTTPS & SSL {#https-ssl}

HTTPS mode provides access to the provisioned apps using wild card SSL
certificates through the router or
[*Nginx*](/als/v1/user/reference/glossary/#term-nginx) web server.

There are self-signed certificates on the VM to match the default
hostname `helion-xxxx.local`. These certificates
can be found in:

-   `/etc/ssl/certs/helion.crt` (Public
    Certificate)
-   `/etc/ssl/private/helion.key` (Used to
    generate the signed certificates)

If you change the hostname, you will need to regenerate the certificates
or use your own (signed or self-signed) certificate.

### Using your own SSL certificate {#using-your-own-ssl-certificate}

On all router nodes, upload your *.key* file to the */etc/ssl/private/*
directory and your *.crt* file to */etc/ssl/certs/*. Change the
following settings in */s/code/helion-router/config/local.json* to
point to the new files:

    "sslKeyFile": "/etc/ssl/private/example.key",
    "sslCertFile": "/etc/ssl/certs/example.crt",

### Adding Custom SSL Certs (SNI) {#adding-custom-ssl-certs-sni}

The Application Lifecycle Service router supports
[SNI](http://en.wikipedia.org/wiki/Server_Name_Indication), and custom
SSL certificates for domains resolving to the system can be added using
the [*kato op custom\_ssl\_cert
install*](/als/v1/admin/reference/kato-ref/#kato-command-ref-op) command.
Usage:

    kato op custom_ssl_cert install <key-path> <cert-path> <domain> [--wildcard-subdomains]

This must be run on all router nodes in a cluster: the first one as
above, subsequent routers using the `--update` flag.

**Note**

SNI support with multiple Application Lifecycle Service routers works only with TCP load
balancers (e.g. HAProxy, iptables, F5) not HTTP load balancers (e.g.
Nginx, Application Lifecycle Service load balancer).

### CA Certificate Chaining {#ca-certificate-chaining}

When using a signed certificate for Application Lifecycle Service, the certificates in the
chain must be concatenated in a specific order:

-   the domain's crt file
-   intermediate certs
-   the root cert

For example, to create the final certificate for the chain in Nginx
format:

    $ sudo su -c "cat /etc/ssl/certs/site.crt /path/to/intermediate.crt /path/to/rootCA.crt > /etc/ssl/certs/helion.crt"

Once the cert is chained, restart the router processes:

    $ kato restart router

Verify that the full chain is being sent by Nginx using
`openssl`. You should see more than one number in
the list. For example:

    $ openssl s_client -connect api.stacka.to:443
    ---
    Certificate chain
     0 s:/C=CA/ST=British Columbia/L=Vancouver/O=HP Software Inc./OU=Application Lifecycle Service/CN=*.stacka.to
       i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance CA-3
     1 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance CA-3
       i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA
     2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA
       i:/C=US/O=Entrust.net/OU=www.entrust.net/CPS incorp. by ref. (limits liab.)/OU=(c) 1999 Entrust.net Limited/CN=Entrust.net Secure Server Certification Authority

### Generating a self-signed SSL certificate {#generating-a-self-signed-ssl-certificate}

You can re-generate Application Lifecycle Service's self-signed SSL certificate by running
the following command on the VM:

    $ kato op regenerate ssl_cert

To do essentially the same operation manually (substituting
"hostname.mydomain.com" with your own details):

    $ mkdir ~/hostname.mydomain.com
    $ cd ~/hostname.mydomain.com
    $ (umask 077 && touch host.key host.cert host.info)
    $ openssl genrsa 2048 > host.key
    $ openssl req -new -x509 -nodes -sha1 -days 365 -key host.key -multivalue-rdn \
            -subj "/C=CA/emailAddress=email@mydomain.com/O=company_name/CN=*.mydomain.com/CN=mydomain.com" \
            >host.crt

For specific configurations that can be used in the `-subj` option, see <http://www.openssl.org/docs/apps/req.html>.

Following that, run:

    $ openssl x509 -noout -fingerprint -text < host.crt > host.info
    $ chmod 400 host.key host.crt

To get the router to use the new certificate and key files, follow the
steps in the [*Using your own SSL
certificate*](#server-config-ssl-cert-own-use) section above.

With any self-signed SSL certificate, you will get browser warning
messages. The certificate will need to be added to the browser exception
rules, which you will be prompted to do so when visiting one of your
apps via HTTPS for the first time.

##Quota Definitions {#quota-definitions}

Quota definitions define limits for:

-   physical memory (RAM) in MB
-   number of services
-   `sudo` privilege within application containers

Each organization is assigned a quota definition, and all users of an
organization share the defined limits.

Use the `helion quota ...` commands to modify
quota definitions:

-   [*helion quota
    configure*](/als/v1/user/reference/client-ref/#command-quota-configure)
-   [*helion quota
    create*](/als/v1/user/reference/client-ref/#command-quota-create)
-   [*helion quota
    delete*](/als/v1/user/reference/client-ref/#command-quota-delete)
-   [*helion quota
    list*](/als/v1/user/reference/client-ref/#command-quota-list)

Existing quota definitions can also be viewed and edited in the
Management Console [*Quota Definitions
settings*](/als/v1/admin/console/customize/#console-settings-quota-definitions)

### sudo {#sudo}

Quota Definitions can give all users in an Organization the use of the
`sudo` command within application containers. This
option is disabled by default as a security precaution, and should only
be enabled for Organizations where all users are trusted.

### Allowed Repositories {#allowed-repositories}

Even if `sudo` is restricted, special access can be
given to specific repositories for modules and resources needed during
the staging process.

To configure these, modify the `allowed_repos:`
parameter of the `cloud_controller.yml` file:

        allowed_repos:
    - "deb mirror://mirrors.ubuntu.com/mirrors.txt natty main restricted universe multiverse"
    - "deb mirror://mirrors.ubuntu.com/mirrors.txt natty-updates main restricted universe multiverse"
    - "deb http://security.ubuntu.com/ubuntu natty-security main universe"

The file is located on the Application Lifecycle Service server at
`~/helion/vcap/cloud_controller/config/cloud_controller.yml`---
layout: default-devplatform
permalink: /als/v1/admin/server/docker/
product: devplatform
---
<!--PUBLISHED-->

Docker & Fence[](#docker-fence "Permalink to this headline")
=============================================================

Application Lifecycle Service's [*DEA role*](/als/v1/admin/reference/architecture/#architecture-dea)
runs Linux containers to isolate user applications during staging and at
runtime. Management of these application containers is handled by the
`fence` process, which in turn uses
[Docker](http://docs.docker.io/en/latest/) to create and destroy Linux
containers on demand.

Typically, admins will not have to work directly Docker, but it is
available if needed to customize or create new container images.

Modifying or Updating the Container Image[](#modifying-or-updating-the-container-image "Permalink to this headline")
---------------------------------------------------------------------------------------------------------------------

Application containers are created from a base Docker image (a template
used to create Linux containers). Admins can create new images to add
specific software required by applications or update operating system
packages.

To create a new base image for Application Lifecycle Service to use for application
containers, perform the following steps **on all nodes running the DEA
role**:

1.  Start with an empty working directory:

        $ mkdir ~/newimg
        $ cd ~/newimg

2.  Check which image Application Lifecycle Service is currently using as an app container
    template:

        $ kato config get fence docker/image
        helion/stack/alsek

3.  Create a [Dockerfile](http://docs.docker.io/en/latest/use/builder/)
    which inherits the current Docker image, then runs an update or
    installation command. For example:

        FROM helion/stack/alsek
        RUN apt-get -y install libgraphite2-dev

    -   [FROM](http://docs.docker.io/en/latest/use/builder/#from):
        inherits the environment and installed software from Application Lifecycle Service's
        app image.
    -   [RUN](http://docs.docker.io/en/latest/use/builder/#run):
        specifies arbitrary commands to run before saving the image.
    -   [ADD](http://docs.docker.io/en/latest/use/builder/#add): could
        be used to copy files into the image.

4.  Build the image, setting the maintainer's name, and an image name:

        $ sudo docker build -rm -t exampleco/newimg .

5.  Configure Application Lifecycle Service to use the new image:

**Note**

This step only needs to be done once, as the configuration change is
shared with all nodes:

    $ kato config set fence docker/image exampleco/newimg
    WARNING: Assumed type string
    exampleco/newimg

Admin Hooks[](#admin-hooks "Permalink to this headline")
---------------------------------------------------------

If an administrator wants to run arbitrary commands in all application
containers, global admin hooks can be set to run immediately after
corresponding user-specified deployment hooks (pre-staging,
post-staging, pre-running) set in application 
[manifest.yml](/als/v1/user/deploy/manifestyml/) files.

These hooks must be:

-   plain bash scripts with the executable bit set (`chmod +x`)
-   named *pre-staging*, *post-staging*, or *pre-running*
-   installed in */etc/helion/hooks* within the Docker image

For example, a pre-running admin hook might look like this:

    #!/bin/sh
    export PRE_RUN_DATE=`date`
    export EXAMPLECO_KEY="3A0fwPwUftDu0FEzmhN8yJkvM1vS6A"
    if [ -z "$NEW_RELIC_LICENSE_KEY" ]; then
      echo "setting default New Relic key"
      export NEW_RELIC_LICENSE_KEY="bdb9b44e8n4411d8bf39870f1919927d79cr0f1r"
    fi
    export HELION_HOOK_ENV=PRE_RUN_DATE,EXAMPLECO_KEY
    sudo /usr/sbin/nrsysmond-config --set license_key=$NEW_RELIC_LICENSE_KEY
    sudo /etc/init.d/newrelic-sysmond start

**Note**

The `HELION_HOOK_ENV` environment variable is
needed to expose the specified variables in `helion ssh` sessions, the application container's crontab, and PHP
applications using the Legacy buildpack. This requirement may change in
subsequent releases.

The Dockerfile for creating the image (see [*Modifying or Updating the
Container Image*](#docker-modify-container) ) would use the ADD
directive to put a local *hooks* directory in the Docker image's
*/etc/helion/* directory:

    FROM helion/stack/alsek
    ADD hooks /etc/helion/hooks

The pre-running hook example above would require the addition of
`newrelic-sysmond` to the Docker image. A Dockerfile
enabling that might look like this:

    FROM helion/stack/alsek

    RUN echo deb http://apt.newrelic.com/debian/ newrelic non-free >> /etc/apt/sources.list.d/newrelic.list
    RUN wget -O- https://download.newrelic.com/548C16BF.gpg | apt-key add -
    RUN apt-get update
    RUN apt-get install newrelic-sysmond
    # The nrsysmond scripts are run with sudo
    RUN echo "HELION ALL= NOPASSWD: /etc/init.d/newrelic-sysmond" >> /etc/sudoers
    RUN echo "HELION ALL= NOPASSWD: /usr/sbin/nrsysmond-config" >> /etc/sudoers

    ADD hooks /etc/helion/hooks

Creating a Docker Registry[](#creating-a-docker-registry "Permalink to this headline")
---------------------------------------------------------------------------------------

The steps above will work with smaller clusters or micro clouds where
the creation of Docker images on each DEA can be done manually. On
larger clusters, you should set up a [Docker
registry](http://blog.docker.io/2013/07/how-to-use-your-own-registry/)
as a central repository for your container templates.

1.  On the Core node of your cluster, pull the docker-registry
    \<https://index.docker.io/u/samalba/docker-registry/\> image from
    the Docker index:

        $ sudo docker pull helion/docker-registry

2.  Start the server:

        $ sudo docker run -d -p 5000 helion/docker-registry
        f39d1b3f6fedc50e77875526352bd5a0f650a998dc1d7ca4e39c4a1eb8349e42

    This returns the ID of the running registry server image. A shorter
    container ID is also available via `docker ps`.
    You can use either for the subsequent commands.

3.  Use the ID to get the public facing port for the running image. For
    example:

        $ sudo docker port f39d1b3f6fed 5000
        0.0.0.0:49156

    Your registry location is a combination of the API endpoint of your
    cluster (i.e. `kato config get cluster endpoint`) combined with the port number returned by the command
    above. For example:

        api.paas.example.com:49156

    This registry location will be used to pull the images you create to
    your DEA nodes.

4.  Go through steps 1 - 3 [*above*](#docker-modify-container) to create
    a Docker image file. When building the image, substitute the
    registry location for the organization name used in step 4. For
    example:

        $ sudo docker build -rm -t api.paas.example.com:49156/exampleco/newimg .

5.  Push the newly built Docker image to the registry:

        $ sudo docker push api.paas.example.com:49156/exampleco/newimg

> Note
>
> The helion/stack/alsek and helion/base images (approximately
> 1.9GB) are pushed to the registry in addition to the new image. Make
> sure you have sufficient disk space available on the VM.

6.  **On all DEA nodes**, pull the new image from the registry:

        $ sudo docker pull api.paas.example.com:49156/exampleco/newimg

7.  Configure Application Lifecycle Service to use the new image:

        $ kato config set fence docker/image api.paas.example.com:49156/exampleco/newimg
        WARNING: Assumed type string
        api.paas.example.com:49156/exampleco/newimg

    This step only needs to be done once, as the configuration change is
    shared with all nodes

### [Table Of Contents](/als/v1/index-2/)

-   [Docker & Fence](#)
    -   [Modifying or Updating the Container
        Image](#modifying-or-updating-the-container-image)
    -   [Admin Hooks](#admin-hooks)
    -   [Creating a Docker Registry](#creating-a-docker-registry)

---
layout: default-devplatform
permalink: /als/v1/admin/server/
product: devplatform
---
<!--PUBLISHED-->

Server Configuration[](#server-configuration "Permalink to this headline")
===========================================================================

This page covers the initial setup and configuration of the Application Lifecycle Service
Server in a virtual machine under control of a hypervisor running on a
virtualization host.

Accessing Server via the Command Line[](#accessing-server-via-the-command-line "Permalink to this headline")
-------------------------------------------------------------------------------------------------------------

The Application Lifecycle Service server has one user account initially:

	Username: helion
	Password: helion

If the Application Lifecycle Service server is running on a publicly routable network, the
password should be changed as soon as possible.

**Note**

The password of the `helion` account is changed to
match the first user created in the Management Console. If you've
created this "primary admin" user, use that password instead.  If the cluster was created using the Horizon Management Console Panel or Application Lifecycle Service Installer CLI, you must login with your SSH key you selected during cluster creation.

Command access to the Application Lifecycle Service server is available in several ways:

-   Over the hypervisor's [*tty
    console*](/als/v1/user/reference/glossary/#term-tty-console).

-   The [*Application Lifecycle Service
    Client*](/als/v1/user/reference/client-ref/#command-ref-client)
    command, which in addition to specialized functions can provide
    remote shell access to the server:

        $ helion target helion@helion-xxxx.local
        $ helion ssh api

-   The familiar `ssh` command:

        $ ssh helion@helion-xxxx.local

**Note**

For ssh access on Windows, we recommend
[MSYS](http://sourceforge.net/apps/trac/mingw-w64/wiki/MSYS).

On the server, the control command for Application Lifecycle Service is called
`kato`. It is used for configuration and node
management procedures such as start, stop, role specialization, and
status checks. For a complete list of options, see [*Kato Command
Reference*](/als/v1/admin/reference/kato-ref/#kato-command-ref).

Common Operations[](#common-operations "Permalink to this headline")
---------------------------------------------------------------------

Instructions for common operations on the Application Lifecycle Service VM can be found here:

-   [Common Server Operations](/als/v1/admin/server/operations/)
    -   [Server Status](/als/v1/admin/server/operations/#server-status)
        -   [Starting and Stopping
            Roles](/als/v1/admin/server/operations/#starting-and-stopping-roles)
        -   [System Shutdown](/als/v1/admin/server/operations/#system-shutdown)
    -   [Setting the Time Zone](/als/v1/admin/server/operations/#setting-the-time-zone)
    -   [Resetting the VM](/als/v1/admin/server/operations/#resetting-the-vm)
    -   [Monitoring The Application Lifecycle Service
        Server](/als/v1/admin/server/operations/#monitoring-the-helion-server)
        -   [Management Console](/als/v1/admin/server/operations/#management-console)
        -   [New Relic](/als/v1/admin/server/operations/#new-relic)
        -   [Creating an Admin
            User](/als/v1/admin/server/operations/#creating-an-admin-user)
        -   [System Monitoring with
            Nagios](/als/v1/admin/server/operations/#system-monitoring-with-nagios)
    -   [Server Backup, Import, and
        Export](/als/v1/admin/server/operations/#server-backup-import-and-export)
-   [Upgrading Application Lifecycle Service](/als/v1/admin/server/upgrade/)
    -   [Before an upgrade](/als/v1/admin/server/upgrade/#before-an-upgrade)
        -   [Maintenance Mode](/als/v1/admin/server/upgrade/#maintenance-mode)
        -   [Proxy settings](/als/v1/admin/server/upgrade/#proxy-settings)
        -   [RSA keys](/als/v1/admin/server/upgrade/#rsa-keys)
    -   [Executing the upgrade](/als/v1/admin/server/upgrade/#executing-the-upgrade)
        -   [Upgrading an individual
            node](/als/v1/admin/server/upgrade/#upgrading-an-individual-node)
        -   [Upgrading a cluster](/als/v1/admin/server/upgrade/#upgrading-a-cluster)
        -   [Node upgrade ordering](/als/v1/admin/server/upgrade/#node-upgrade-ordering)
        -   [Node Upgrade Process](/als/v1/admin/server/upgrade/#node-upgrade-process)

Detailed Configuration[](#detailed-configuration "Permalink to this headline")
-------------------------------------------------------------------------------

To continue configuring the Application Lifecycle Service server, see:

-   [Detailed Configuration](/als/v1/admin/server/configuration/)
    -   [General](/als/v1/admin/server/configuration/#general)
        -   [Changing the
            Password](/als/v1/admin/server/configuration/#changing-the-password)
    -   [Network Setup](/als/v1/admin/server/configuration/#network-setup)
        -   [Changing the
            Hostname](/als/v1/admin/server/configuration/#changing-the-hostname)
        -   [Changing IP
            Addresses](/als/v1/admin/server/configuration/#changing-ip-addresses)
        -   [Setting a Static
            IP](/als/v1/admin/server/configuration/#setting-a-static-ip)
        -   [Modifying
            /etc/hosts](/als/v1/admin/server/configuration/#modifying-etc-hosts)
        -   [DNS](/als/v1/admin/server/configuration/#dns)
        -   [Dynamic DNS](/als/v1/admin/server/configuration/#dynamic-dns)
        -   [Alternate DNS
            Techniques](/als/v1/admin/server/configuration/#alternate-dns-techniques)
        -   [Adding DNS
            Nameservers](/als/v1/admin/server/configuration/#adding-dns-nameservers)
        -   [TCP/UDP Port
            Configuration](/als/v1/admin/server/configuration/#tcp-udp-port-configuration)
        -   [HTTP Proxy](/als/v1/admin/server/configuration/#http-proxy)
        -   [Staging Cache & App HTTP
            Proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy)
    -   [VM Filesystem Setup](/als/v1/admin/server/configuration/#vm-filesystem-setup)
    -   [Application Lifecycle Service Data Services vs. High Availability
        Databases](/als/v1/admin/server/configuration/#helion-data-services-vs-high-availability-databases)
    -   [HTTPS & SSL](/als/v1/admin/server/configuration/#https-ssl)
        -   [Using your own SSL
            certificate](/als/v1/admin/server/configuration/#using-your-own-ssl-certificate)
        -   [Adding Custom SSL Certs](/als/v1/admin/server/configuration/#adding-custom-ssl-certs-sni)
        -   [CA Certificate
            Chaining](/als/v1/admin/server/configuration/#ca-certificate-chaining)
        -   [Generating a self-signed SSL
            certificate](/als/v1/admin/server/configuration/#generating-a-self-signed-ssl-certificate)
    -   [Quota Definitions](/als/v1/admin/server/configuration/#quota-definitions)
        -   [sudo](/als/v1/admin/server/configuration/#sudo)
        -   [Allowed
            Repositories](/als/v1/admin/server/configuration/#allowed-repositories)
---
layout: default-devplatform
permalink: /als/v1/admin/server/logging/
product: devplatform
---
<!--PUBLISHED-->

Log Streams[](#log-streams "Permalink to this headline")
=========================================================
   [Logyard](#logyard)
    -   [Drains](#drains)
        -   [System Drains](#system-drains)
        -   [Log Format](#log-format)
        -   [Saving Custom Log Formats](#saving-custom-log-formats)
        -   [Custom Drains](#custom-drains)
        -   [Application Drains](#application-drains)
        -   [Drain Status](#drain-status)
        -   [Keys](#keys)
            -   [apptail](#apptail)
            -   [event](#event)
            -   [systail](#systail)
        -   [Managing the systail stream](#managing-the-systail-stream)
    -   [Configuration](#configuration)
        -   [Drain Timeouts](#drain-timeouts)
        -   [User Drain Limit](#user-drain-limit)
        -   [Apptail Limits](#apptail-limits)
    -   [Debugging Logyard](#debugging-logyard)

Application and system logs in Application Lifecycle Service are aggregated into streams
which can be viewed, tailed, filtered, and/or sent via drains to other
log aggregators for archiving or analysis. There are three general types
of streams:

-   **Application log streams**: application logs (plus relevant events)
    from all instances
-   **System log streams**: Application Lifecycle Service and other system logs from all
    nodes (dmesg, dea.log, auth.log, etc.)
-   **Cloud event streams**: cloud events from all nodes (see Cloud
    Events in the Management Console)

A **message** is a single log line or event in a stream.

Each message has a **key** which identifies *which* stream it belongs to
(see [*Keys*](#logging-keys) below).

Logyard[](#logyard "Permalink to this headline")
-------------------------------------------------

Log streams are handled by three processes which run on all Application Lifecycle Service
nodes:

-   **logyard**: listens for incoming log messages and forwarding them
    to a configurable list of drains
-   **systail**: sends system logs (/s/log/\*, etc.) to **logyard** to
    be in turn forwarded to drains
-   **logyard\_sieve**: listens for all system logs and extracts vital
    events back to **logyard**

**apptail** is an additional process which runs only on DEA nodes. It
sends user application logs to **logyard**, injecting relevant
application-specific events from the **logyard\_sieve** stream.

Drains[](#drains "Permalink to this headline")
-----------------------------------------------

A "drain" is a receiver for a log stream. Logyard has three kinds:

-   TCP (e.g. <tcp://10.0.11.101:12345>)
-   UDP (e.g. udp://logs.papertrailapp.com:12345)
-   Redis (e.g. redis://192.168.1.157:5000/)
-   file (e.g. <file:///s/logs/custom-drain-1.log>)

### System Drains[](#system-drains "Permalink to this headline")

Drains for system log and cloud event streams can be added by admins
with the [*kato log
drain*](/als/v1/admin/reference/kato-ref/#kato-command-ref-log-drain-add)
command. For example:

    $ kato log drain add --prefix systail.kato mydrain udp://logs.papertrailapp.com:12345

This creates a UDP drain that receives messages from **kato.log** (on
all nodes in the cluster) and forwards them to
[Papertrail](https://papertrailapp.com/) on port 12345.

The `--prefix` flag takes a [*key*](#logging-keys)
prefix as its argument.

To delete the drain:

    $ kato log drain delete mydrain

The [*kato
history*](/als/v1/admin/reference/kato-ref/#kato-command-ref-history) command
uses a built-in drain which forwards to a Redis server on the Primary
node.

The 'file' drain type will append to a local file. To overwrite the file
instead, add the 'overwrite=1' option:

    $ kato log drain add debug file:///s/logs/debug-1.log overwrite=1

### Log Format[](#log-format "Permalink to this headline")

Log drains can emit entries in a variety of formats:

-   verbatim (default): Log entries as they appear in the source log
    files (plain text).
-   json: Log entries wrapped as JSON objects, with keys identifying
    each part of the entry.
-   custom: Values of the specified JSON keys arranged in an arbitrary
    format.

For example, to add a drain with just the timestamp, application name
and message:

    $ kato log drain add -p apptail -f '{{.human_time}} - {{.app_name}}: {{.text}}' \
    > all-apps file:///s/logs/apptail-short.log

JSON keys are enclosed in double curly braces and prefixed with a
period. The spaces, hyphen, and colon here are functioning as
delimiters. The resulting entry might look like this:

    2013-01-22T16:01:14-08:00 - myenv: Application 'myenv' is now running on DEA 27da51

Different JSON keys are available in different [*log
streams*](#logging-keys):

**apptail.**:

-   text: actual log line
-   unix\_time: timestamp (seconds since 1 January 1970)
-   human\_time: formatted time
-   node\_id: DEA host IP of this app instance
-   filename: log file from which this line originated
-   source: e.g. app, staging, helion.dea, helion.stager, appstore
-   instance\_index: instance number
-   app\_guid: GUID of this app
-   app\_name: application name
-   app\_space: GUID of the space this app belongs to
-   syslog.priority: syslog priority
-   syslog.time: syslog formatted time

**event.**:

-   text: event description
-   unix\_time: timestamp
-   human\_time: formatted time
-   node\_id: Node IP from which this event originated
-   type: type of event (eg: process\_stop)
-   severity: INFO, WARN, ERROR
-   process: the process generating the event
-   info: event-specific information as JSON
-   syslog.priority: syslog priority
-   syslog.time: syslog formatted time

**systail.**:

-   text: actual log line
-   unix\_time: timestamp
-   human\_time: formatted time
-   node\_id: Node IP from which this log line originated
-   name: name of the component (eg: redis\_gateway)
-   syslog.priority: syslog priority
-   syslog.time: syslog formatted time

You can see a list of the default drain formats using [*kato config
get*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config):

    $ kato config get logyard drainformats
    apptail: ! '{{.human_time}} {{.source}}.{{.instance_index}}: {{.text}}'
    event: ! '{{.type}}@{{.node_id}}: {{.desc}} -- via {{.process}}'
    systail: ! '{{.name}}@{{.node_id}}: {{.text}}'
    [...]

These default log formats are used when the corresponding prefix is used
and no format options ("-f") are specified. For example
`kato drain add -p systail.dea ...` would format the
drain using the 'systail' drain format.

### Saving Custom Log Formats[](#saving-custom-log-formats "Permalink to this headline")

Custom formats for drains can be saved as a named type in the Logyard
configuration. To do this, add the formatting string to a new key in
logyard/drainformats. For example, to save the log format used in the
'all-apps' drain example above:

    $ kato config set logyard drainformats/simplefmt "{{.human_time}} - {{.app_name}}: {{.text}}"

You can use this named format when setting up new drains. For example, a
shorter command for creating the 'all-apps' drain would be:

    $ kato log drain add -p apptail -f simplefmt all-apps file:///s/logs/apptail-short.log

A custom "systail" log stream might look like this:

    $ kato config set logyard drainformats/systail-papertrail '<13>1 - {{.human_time}} - {{.name}}@{{.node_id}} -- {{.text}}'

This could be forwarded to the Papertrail log analysis service:

    $ kato log drain add papertrail udp://logs.papertrailapp.com:45678 -f systail-papertrail

You can also change the default apptail, event, and systail drain
formats to modify the output of any drains using these prefixes (e.g.
[*helion
drain*](/als/v1/user/reference/client-ref/#command-drain-add), Cloud
Events in the Management Console, and [*kato log
tail*](/als/v1/admin/reference/kato-ref/#kato-command-ref-log-tail)
respectively).

### Custom Drains[](#custom-drains "Permalink to this headline")

You can add custom drains to Logyard to look for certain events or parse
certain log messages (e.g. tracking application push requests or user
logins). Examples of custom drains and more advanced usage of Logyard
can be found in the [Logyard Developer
Guide](https://github.com/HP/logyard-devguide#readme)

### Application Drains[](#application-drains "Permalink to this headline")

Drains for application log streams can be added by end users with the
[*helion log drain
add*](/als/v1/user/reference/client-ref/#command-drain-add) command.
See the [*Application
Logs*](/als/v1/user/deploy/app-logs/#application-logs) section of the
User Guide for an example.

### Drain Status[](#drain-status "Permalink to this headline")

You can check the status of all drains on Application Lifecycle Service with the
`kato log drain status` subcommand. For example:

    $ kato log drain status
    appdrain.1.mine         192.168.68.5    RUNNING[53]
    appdrain.1.mydrain      192.168.68.5    RETRYING[75]  invalid port 3424252
    builtin.apptail         192.168.68.5    RUNNING[3]
    builtin.cloudevents     192.168.68.5    RUNNING[3]
    builtin.katohistory     192.168.68.5    RUNNING[3]

If the RETRYING drain hits a [*drain
timeout*](#logging-drains-timeouts), its status will change to FATAL.

### Keys[](#keys "Permalink to this headline")

Each message in a log stream is prefixed with a key, identifying what
type of message it is or to which log stream it belongs. The following
keys are available for use in defining drains using the
`--prefix` flag for [*kato log drain
add*](/als/v1/admin/reference/kato-ref/#kato-command-ref-log-drain-add)).

Systail keys are [*configurable*](#logging-systail-manage).

#### apptail[](#apptail "Permalink to this headline")

> apptail.\<app.id\>

#### event[](#event "Permalink to this headline")

-   event.\<eventname\>
    -   process\_stop
    -   process\_exit
    -   kato\_action
    -   timeline
    -   nginx\_error
    -   vcap\_error
    -   vcap\_warning
    -   service\_provision

#### systail[](#systail "Permalink to this headline")

-   systail.\<processname\>
-   systail.\<processname\>.\<nodeip\>
    -   auth
    -   dmesg
    -   dpkg
    -   kato
    -   kernel
    -   nginx\_error
    -   supervisord
    -   cc\_nginx\_error
    -   app\_mdns
    -   app\_store
    -   applog\_redis
    -   apptail
    -   avahi\_publisher
    -   cc\_nginx
    -   cloud\_controller\_ng
    -   logyard\_sieve
    -   dea\_ng
    -   dockerd
    -   aok
    -   filesystem\_gateway
    -   filesystem\_node
    -   harbor\_gateway
    -   harbor\_node
    -   harbor\_proxy\_connector
    -   harbor\_redis
    -   health\_manager
    -   logyard
    -   memcached\_gateway
    -   memcached\_node
    -   mongodb\_gateway
    -   mongodb\_node
    -   mysql
    -   mysql\_gateway
    -   mysql\_node
    -   nats\_server
    -   nginx
    -   postgresql
    -   postgresql\_gateway
    -   postgresql\_node
    -   prealloc
    -   rabbit\_gateway
    -   rabbit\_node
    -   redis\_gateway
    -   redis\_node
    -   redis\_server
    -   router
    -   router2g
    -   stager
    -   systail

### Managing the systail stream[](#managing-the-systail-stream "Permalink to this headline")

The list above shows the default systail keys. These can keys can be
modified with the [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config) command to
add arbitrary system log files to the stream or change the log file
source for an existing key.

-   To retrieve the current list of log files being streamed:

        $ kato config get systail log_files

-   To remove a log file from the stream:

        $ kato config del systail log_files/dpkg

-   To add a new log file to the stream:

        $ kato config set systail log_files/dpkg /var/log/dpkg.log

Restart the `systail` process after adding or
removing log files:

    $ kato process restart systail

**Note**

Do not remove the default Application Lifecycle Service log stream keys (i.e. anything in the
[*systail*](#logging-keys-systail) list above) as this would affect the
output of `kato tail`.

Configuration[](#configuration "Permalink to this headline")
-------------------------------------------------------------

Application Lifecycle Service has a number of configurable limits on application log drains
to help prevent performance problems the logging subsystems. These
settings can all be viewed and set with [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config) commands as
described below:

### Drain Timeouts[](#drain-timeouts "Permalink to this headline")

-   **logyard** **retrylimits**: If a drain gets disconnected (e.g. if
    the log aggregation service goes down), Logyard will retry the
    connection at the following intervals:

    -   once every 5 seconds for 1 to 2 minutes
    -   once every 30 seconds for 5 minutes
    -   once every 1 minute for 10 minutes
    -   once every 5 minutes until connect or destroyed

    This ensures that once connectivity is restored, the drains will
    re-establish their connections within (at most) 5 minutes.

    Application drains will retry for one day. Temporary drains (e.g.
    `kato tail`) will retry for 25 minutes. All
    other drains will retry indefinitely.

    These timeouts can be configured. To see a list of the configured
    timeouts, use [*kato config
    get*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config). For
    example:

        $ kato config get logyard retrylimits
        appdrain.: 24h
        tmp.: 25m

    To set a time-out (minimum 21m), use [*kato config
    set*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config). For
    example, to set the timeout limit to 10 hours on all drains named
    with the prefix "papertrail":

        $ kato config set logyard retrylimits/papertrail 10h

    These limits will take effect on new drains, deleted/re-created
    drains, or for all matching drains after
    `kato process restart logyard` has been run on
    all nodes.

### User Drain Limit[](#user-drain-limit "Permalink to this headline")

-   **cloud\_controller\_ng** **max\_drains\_per\_app** (default 2):
    limits the number of drains an application can have. Once this limit
    is reached, users will see the following notification when trying to
    add a new drain:

        Adding drain [fail] ... Error 123: Per-app drain limit (2) reached.

    To change the limit, set `max_drains_per_app` in
    the cloud\_controller\_ng configuration. For example, to change this
    limit to 5 drains:

        $ kato config set cloud_controller_ng max_drains_per_app 5

### Apptail Limits[](#apptail-limits "Permalink to this headline")

-   **apptail** **read\_limit** (default 16MB): defines the maximum
    number of bytes to read from the end of application log files. This
    is done to prevent performance problems during restart of the
    `apptail` process (or nodes running the process)
    if the log file sources have grown extremely large.

    When this limit is reached, a warning such as the following will
    appear in both the Cloud Events stream and the application's log
    stream:

        WARN -- [exampleapp] Skipping much of a large log file (stderr); size (26122040 bytes) > read_limit (15728640 bytes)

    To change the read\_limit to 100MB:

        $ kato config set apptail read_limit 100

-   **apptail** **rate\_limit** (default 400): limits the number of log
    lines per second that can be read from an application log file. The
    `apptail` process reads (at most) the specified
    number of log lines per second, after which it will wait for one
    second before resuming. A line similar to the `read_limit` warning above is inserted in the stream to explain the
    missing data.

    To change the rate\_limit to 300 lines:

        $ kato config set apptail rate_limit 300

Debugging Logyard[](#debugging-logyard "Permalink to this headline")
---------------------------------------------------------------------

Use `kato log stream debug` to monitor
Logyard-related log activity. The command tails the logyard, apptail,
systail, and logyard\_sieve streams.
---
layout: default-devplatform
permalink: /als/v1/admin/server/operations/
product: devplatform
---
<!--PUBLISHED-->

Common Server Operations[](#common-server-operations "Permalink to this headline")
===================================================================================
[Server Status](#server-status)
        -   [Starting and Stopping Roles](#starting-and-stopping-roles)
        -   [System Shutdown](#system-shutdown)
    -   [Setting the Time Zone](#setting-the-time-zone)
    -   [Resetting the VM](#resetting-the-vm)
    -   [Monitoring The Application Lifecycle Service
        Server](#monitoring-the-helion-server)
        -   [Management Console](#management-console)
        -   [New Relic](#new-relic)
        -   [Creating an Admin User](#creating-an-admin-user)
        -   [System Monitoring with
            Nagios](#system-monitoring-with-nagios)
    -   [Server Backup, Import, and
        Export](#server-backup-import-and-export)

Server Status[](#server-status "Permalink to this headline")
-------------------------------------------------------------

To check the status of Application Lifecycle Service:

    $ kato status

This will list all the roles configured to run on the VM, and whether
they are running, stopped, or starting.

Roles are logical groups of processes (see [*kato role
info*](/als/v1/admin/reference/kato-ref/#kato-command-ref-role-info)) which can
be inspected individually with [*kato process
...*](/als/v1/admin/reference/kato-ref/#kato-command-ref-process-list)
commands.

In particular, the [*kato process
ready*](/als/v1/admin/reference/kato-ref/#kato-command-ref-process-ready)
command is useful for determining if the system is in a state to receive
[*configuration commands*](/als/v1/admin/server/configuration/#server-configuration). For
example, to check that all processes for the configured roles are ready:

    $ kato process ready all

### Starting and Stopping Roles[](#starting-and-stopping-roles "Permalink to this headline")

To control the Application Lifecycle Service roles, use `kato` start,
stop and restart commands:

    $ kato stop

Without any further options the operation applies to all Application Lifecycle Service roles.
To start, stop or restart individual roles, specify them after the
desired command:

    $ kato stop mysql

### System Shutdown[](#system-shutdown "Permalink to this headline")

To safely shutdown the VM, run the `shutdown`
command as root:

    $ sudo shutdown -h now

Setting the Time Zone[](#setting-the-time-zone "Permalink to this headline")
-----------------------------------------------------------------------------

At first boot, the time zone of the Application Lifecycle Service VM is set to UTC. To set
this to your local time zone, use the `kato op set_timezone` command. When run without arguments, the command will prompt
for time zone selection, but the time zone can be set non-interactively
with the `--timezone` option. For example:

    $ kato op set_timezone --timezone America/Chicago

You can also use the `tzselect` command to find the
appropriate time zone string for your location.

Resetting the VM[](#resetting-the-vm "Permalink to this headline")
-------------------------------------------------------------------

If you would like to return an Application Lifecycle Service VM to its original
"out-of-the-box" configuration, use the [*kato node
reset*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
command. This command has two options:

-   `kato node reset factory`: Resets everything.
    The host will behave as it did on first boot (creating a new
    randomized hostname and starting as a micro cloud with no configured
    users). Shutdown the VM after running this command. The primary use
    for this command is to prepare a running VM to be cloned by removing
    stale data/configuration.

-   `kato node reset soft`: Resets only
    configuration and data, but leaves first boot (naming) or other
    state info. You would normally run this together with the [*kato
    node
    setup*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-attach)
    command. For example:

        kato node reset soft
        kato node setup micro

Monitoring The Application Lifecycle Service Server[](#monitoring-the-helion-server "Permalink to this headline")
-----------------------------------------------------------------------------------------------

### Management Console[](#management-console "Permalink to this headline")

The [*Management
Console*](/als/v1/user/console/#management-console) has a
Settings page that allows an administrator to monitor the server
component and services, and restart or stop services as necessary.

### New Relic[](#new-relic "Permalink to this headline")

Please see [*New Relic Server
Monitoring*](/als/v1/admin/best-practices/#bestpractices-nrsysmond). New
Relic can also be used to [*monitor
apps*](/als/v1/user/deploy/newrelic/#newrelic).

### Creating an Admin User[](#creating-an-admin-user "Permalink to this headline")

The easiest way to add admin users to Application Lifecycle Service is via the Management
Console under [*Users*](/als/v1/admin/console/customize/#console-users). The
Management Console will prompt to create the initial admin user the
first time you use it.

If you do not have access to the Management Console, create a user by
logging in to the micro cloud or Core node controller via
`ssh` or through the VM [*tty
console*](/als/v1/user/reference/glossary/#term-tty-console) (as the
`helion` user) and run
`helion register`:

    $ helion target api.helion-xxxx.local
    $ helion register superuser@example.net

Grant administrative privileges using `kato config`:

    $ kato config push cloud_controller_ng admins superuser@example.net

Subsequent new users can be added remotely with the Helion client by an admin user.

### System Monitoring with Nagios[](#system-monitoring-with-nagios "Permalink to this headline")

If Nagios is installed on your server nodes, you can use it to monitor
and report resource utilization. See the [*Best Practices
Guide*](/als/v1/admin/best-practices/#bestpractices-nagios) for details.

Server Backup, Import, and Export[](#server-backup-import-and-export "Permalink to this headline")
---------------------------------------------------------------------------------------------------

The import and export functionality can be used to do regular backups,
or to move the Application Lifecycle Service configuration from one server to another. It is
also a means of upgrading the Application Lifecycle Service VM without having to install
everything from the ground up.

Please see our [*Best
Practices*](/als/v1/admin/best-practices/#bestpractices-controller-migration)
for details on how to
[*export*](/als/v1/admin/best-practices/#bestpractices-migration-export)
and
[*import*](/als/v1/admin/best-practices/#bestpractices-migration-import)
your data.

---
layout: default-devplatform
permalink: /als/v1/admin/server/router/
product: devplatform
---
<!--PUBLISHED-->

Router[](#index-1 "Permalink to this headline")
================================================
[Settings](#settings)
    -   [WebSockets](#websockets)
    -   [SPDY](#router-spdy)

The Application Lifecycle Service Router role manages HTTP and HTTPS traffic between web
clients and application instances. In conjunction with the Cloud
Controller, it maps application URLs to the corresponding application
instances running in Linux containers on DEA nodes, distributing load
between multiple instances (containers) as required.

Application Lifecycle Service's default router ('router2g') supports
[WebSocket](http://www.websocket.org/aboutwebsocket) (including
"wss://" secure web sockets) and [SPDY](http://www.chromium.org/spdy).

Settings[](#settings "Permalink to this headline")
---------------------------------------------------

The Router is configured using [*kato
config*](/als/v1/admin/reference/kato-ref/#kato-command-ref-config). The
following settings are configurable:

**client\_inactivity\_timeout**: time (in seconds) the router waits
for idle clients (default 1200 seconds). To change this:

    $ kato config set router2g client_inactivity_timeout 2400

**backend\_inactivity\_timeout**: time (in seconds) the router waits
for applications to respond (default 1200 seconds). To change this:

    $ kato config set router2g client_inactivity_timeout 2400

**prevent\_x\_spoofing** (true|false): Enable HTTP "X-" header
spoofing prevention (default 'false'). When enabled, the router
discards all X- headers sent by the client (e.g. X-Forwarded-For,
X-Forwarded-proto, X-Real-IP, etc.) and replaces them with values
determined by the router itself. Anti-spoofing features should only
be set at the network gateway, so this option should not be enabled
when routers are configured behind an external load balancer. To
enable:

    $ kato config set router2g prevent_x_spoofing true --json

**session\_affinity** (true|false - disabled/unset by default):
Enable sticky session support on the router. Overrides normal
round-robin load balancing for clients with JSESSIONID, SESSIONID,
or PHPSESSID cookies set (configurable in the router's
*config/local.json* file), routing those clients to specific
application instances. If the backend assigned on the first request
goes down, a new one is automatically assigned. Clients can delete
their sticky session assignment by removing the
HELION\_SESSION\_AFFINITY cookie.

**x\_frame\_options**: Prevent clickjacking on requests with
[X-Frame response
header](https://developer.mozilla.org/en-US/docs/HTTP/X-Frame-Options)
configuration. Disabled if empty (default). Valid values are:

-   DENY
-   SAMEORIGIN
-   ALLOW\_FROM \<uri\>

For example:

       $ kato config set router2g x_frame_options SAMEORIGIN

**Note**

Alternatively, end user applications can employ
[framekiller](http://en.wikipedia.org/wiki/Framekiller) JavaScript
snippets to help prevent frame based clickjacking.

WebSockets[](#websockets "Permalink to this headline")
-------------------------------------------------------

Applications using web sockets must use the VCAP\_APP\_PORT or PORT
[*environment
variables*](/als/v1/user/reference/environment/#environment-variables)
to set the default listener port of the WebSocket server.

SPDY {#router-spdy}
--------------------------------------------------

[SPDY](http://dev.chromium.org/spdy/) is a protocol developed by Google
for reducing web page load time. The router supports SPDY versions 2 and
3. Applications can use SPDY over any HTTPS connection, so long as the
connection consumers (the application server and browser) support it.---
layout: default-devplatform
permalink: /als/v1/admin/server/upgrade/
product: devplatform
---
<!--PUBLISHED-->

Upgrading Application Lifecycle Service[](#upgrading-helion "Permalink to this headline")
=======================================================================
 [Before an upgrade](#before-an-upgrade)
        -   [Maintenance Mode](#maintenance-mode)
        -   [Proxy settings](#proxy-settings)
        -   [RSA keys](#rsa-keys)
    -   [Executing the upgrade](#executing-the-upgrade)
        -   [Upgrading an individual
            node](#upgrading-an-individual-node)
        -   [Upgrading a cluster](#upgrading-a-cluster)
        -   [Node upgrade ordering](#node-upgrade-ordering)
        -   [Node Upgrade Process](#node-upgrade-process)

Application Lifecycle Service 1.0 provides the ability to upgrade a node or cluster in place
via [*kato node
upgrade*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-upgrade)
without the need to rebuild the entire cluster. This section covers how
the upgrade process works.

Before an upgrade[](#before-an-upgrade "Permalink to this headline")
---------------------------------------------------------------------

### Maintenance Mode[](#maintenance-mode "Permalink to this headline")

Before beginning an upgrade, put Application Lifecycle Service in maintenance mode in the
[*Cloud Controller
Settings*](/als/v1/admin/console/customize/#console-settings-maintenance-mode) or
the following `kato` command:

    $ kato config set cloud_controller_ng maintenance_mode true

This shuts down API requests but continues to serve web requests. The Management Console becomes "read only" with the exception of this toggle so that it can be brought back online. Remember to disable maintenance mode once the upgrade has been completed.

### Proxy settings[](#proxy-settings "Permalink to this headline")

The systems being upgraded will need to be able to access the following
public URIs:

-   [https://upgrade.helion.com](https://upgrade.helion.com/)
-   [https://pkg.helion.com](https://pkg.helion.com/)

This may require setting the HTTPS\_PROXY environment variable on each
node if a proxy is in use on your network.

### RSA keys[](#rsa-keys "Permalink to this headline")

For cluster upgrades, you should [set up SSH keys for password-less
authentication](https://help.ubuntu.com/community/SSH/OpenSSH/Configuring#disable-password-authentication)
between the Core node and all other cluster nodes. Without this, you
will be prompted for the 'helion' system user password multiple times
for each node.

Executing the upgrade[](#executing-the-upgrade "Permalink to this headline")
-----------------------------------------------------------------------------

### Upgrading an individual node[](#upgrading-an-individual-node "Permalink to this headline")

To upgrade an individual node, log into the node and run:

    $ kato node upgrade

This will start the **Node Upgrade Process** as described below.

### Upgrading a cluster[](#upgrading-a-cluster "Permalink to this headline")

To upgrade a cluster, log into the Core node in the cluster and run:

    $ kato node upgrade --cluster

This will automatically arrange the nodes in the cluster into a
preferred upgrade order (see below) before upgrading the nodes one at a
time.

### Node upgrade ordering[](#node-upgrade-ordering "Permalink to this headline")

When performing a cluster upgrade, the nodes in the cluster are
automatically arranged into an upgrade order based on the roles they
have enabled. This order is then followed when upgrading nodes.

The default role order is:

-   DEA
-   controller
-   router
-   base
-   primary

Nodes are matched to this ordering by the roles they have enabled. Any
nodes that don't match (e.g. data service nodes) are added to the end to
be upgraded last.

The order can be overridden with the
[*--role-order*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-upgrade)
option.

### Node Upgrade Process[](#node-upgrade-process "Permalink to this headline")

Each node goes through the following process during an upgrade.

1.  Self-update
2.  Application Lifecycle Service version check
3.  Pre-upgrade validation
4.  Retire (DEA nodes only)
5.  Backup state
6.  Upgrade
7.  Post-upgrade validation
8.  Node restart

Before any upgrade actions are performed, `kato node upgrade` performs a self-update check to make sure it is running the
latest code available. After this base check, the version of Application Lifecycle Service
running on the node is checked against the latest version available. If
a newer version of Application Lifecycle Service is available (or if the `--force` option was used) the upgrade process begins.

**Note**

Using the `--force` option is not recommended unless
you have been directed to do so by HP Application Lifecycle Service Support.

A pre-upgrade validation check is performed on the node to check that it
is in working order before any upgrade actions are performed. If this
validation fails then the upgrade process is stopped. These validation
steps can be displayed to the user as errors while still continuing the
upgrade process by using the `--ignore-inspect-failures` option.

**Warning**

Use this option is only if you get failures running
`kato node inspect` that are known to be caused by
systems outside of the control of Application Lifecycle Service, or if directed by
HP Application Lifecycle Service Support.

Next, the upgrade packages are downloaded and a validation check is
performed on the files to make sure everything required for an upgrade
is available. If the node is a DEA it is then
[*retired*](/als/v1/admin/reference/kato-ref/#kato-command-ref-node-retire) to
make sure any applications running on the node are evacuated before the
upgrade takes place.

After the components have been upgraded, the node is restarted and then
post-upgrade validation takes place. If any failures occur, the upgrade
process is stopped and you will be given the option to roll back
the upgrade. As with the pre-upgrade validation, this can be skipped
using the `--ignore-inspect-failures` option (see
warning above).

When `kato node upgrade` completes successfully, the
node is restarted running the latest version of Application Lifecycle Service.

Remember to take the node out of maintenance mode after the upgrade.
---
layout: default-devplatform
permalink: /als/v1/index-2/
product: devplatform

---
<!--PUBLISHED-->

Application Lifecycle Service Documentation[](#helion-documentation "Permalink to this headline")
===============================================================================
 The **Application Lifecycle Service**  is polyglot
Platform-as-a-Service (PaaS) software. Whether you run it in your own data
center using the hypervisor of your choice or on your favorite cloud
hosting provider, it provides the backbone for your private or public PaaS.


**Upgrade and Release Notes**

- All [Release & Support](#release-support) documentation.
 

ALS Admin Guide[](#admin-guide "Permalink to this headline")
---------------------------------------------------------
Documentation intended for system operators in charge of setting up, configuring, and maintaining the PaaS.

-   [Application Lifecycle Service Admin Guide](/als/v1/admin/)
    -   [Management Console](/als/v1/admin/#management-console)
    -   [Server Configuration](/als/v1/admin/#server-configuration)
    -   [Cluster Configuration](/als/v1/admin/#cluster-configuration)
    -   [Best Practices](/als/v1/admin/#best-practices)
    -   [Reference](/als/v1/admin/#reference)

ALS User Guide[](#user-guide "Permalink to this headline")
-------------------------------------------------------
Documentation intended for developers and other end users who will be using a PaaS set up and maintained by others.

-   [Application Lifecycle Service User Guide](/als/v1/user/)
    -   [Quick Start](/als/v1/user/#quick-start)
    -   [Application Lifecycle Service Client](/als/v1/user/#helion-client)
    -   [Deploying Applications](/als/v1/user/#deploying-applications)
    -   [Services](/als/v1/user/#services)
    -   [Logging & Monitoring](/als/v1/user/#logging-monitoring)
    -   [Management Console](/als/v1/user/#management-console)
    -   [Reference](/als/v1/user/#reference)---
layout: default-devplatform
permalink: /als/v1/
product: devplatform

---
<!--PUBLISHED-->

Application Lifecycle Service Documentation[](#helion-documentation "Permalink to this headline")
===============================================================================
 The **Application Lifecycle Service**  is polyglot
Platform-as-a-Service (PaaS) software. Whether you run it in your own data
center using the hypervisor of your choice or on your favorite cloud
hosting provider, it provides the backbone for your private or public PaaS.


**Upgrade and Release Notes**

- All [Release & Support](#release-support) documentation.
 

ALS Admin Guide[](#admin-guide "Permalink to this headline")
---------------------------------------------------------
Documentation intended for system operators in charge of setting up, configuring, and maintaining the PaaS.

-   [Application Lifecycle Service Admin Guide](/als/v1/admin/)
    -   [Management Console](/als/v1/admin/#management-console)
    -   [Server Configuration](/als/v1/admin/#server-configuration)
    -   [Cluster Configuration](/als/v1/admin/#cluster-configuration)
    -   [Best Practices](/als/v1/admin/#best-practices)
    -   [Reference](/als/v1/admin/#reference)

ALS User Guide[](#user-guide "Permalink to this headline")
-------------------------------------------------------
Documentation intended for developers and other end users who will be using a PaaS set up and maintained by others.

-   [Application Lifecycle Service User Guide](/als/v1/user/)
    -   [Quick Start](/als/v1/user/#quick-start)
    -   [Application Lifecycle Service Client](/als/v1/user/#helion-client)
    -   [Deploying Applications](/als/v1/user/#deploying-applications)
    -   [Services](/als/v1/user/#services)
    -   [Logging & Monitoring](/als/v1/user/#logging-monitoring)
    -   [Management Console](/als/v1/user/#management-console)
    -   [Reference](/als/v1/user/#reference)---
layout: default-devplatform
permalink: /als/v1/user/client/
product: devplatform
---
<!--PUBLISHED-->

#Application Lifecycle Service Client[](#helion-client "Permalink to this headline")


The Helion client is the command-line interface
to Application Lifecycle Service. You can use it to push application code up to the server,
start and stop applications, create data services and link them to
applications, and a number of other application management operations.

The [Command Reference](/als/v1/user/reference/client-ref/#command-ref-client) has full
descriptions of all client commands and options. These details are also
available at the command line via the *helion help* command.

##Application Lifecycle Service Client Setup {#helion-client-setup}

**Note**: using the Windows Helion client with
[Cygwin](http://www.cygwin.com/) is not supported.

1.  Download the client for your platform (Windows, OS X, Linux x86,
    Linux x64)
	1. From the ALS cluster management console, find and click ont he "Download the Client" button.
	2. You will taken to a page showing your download options. Select the option for your desired platform.
2.  Unzip the archive in a convenient directory.
3.  Add the executable to your system/shell \$PATH by:
	-   Windows: path = %path%; (where path is the path to the Helion cli)
	-   Linux, OS X: moving it to a directory in your \$PATH,
	-   creating a symlink from a directory in your \$PATH, or
	-   creating a shell alias for the executable.

	For Linux or Mac OS X: Make sure the file is set as executable
	- (`chmod +x helion`) or
	- 	On some systems read access is also necessary    (`chmod 755 helion`).

4.  Confirm that the client is installed correctly by running
    *helion help*.

##Getting Help {#getting-help}


To get a list of available commands or help on a particular command:

    $ helion help [COMMAND]

See also the [Command Reference](/als/v1/user/reference/client-ref/#command-ref-client) for a full
list of commands.

##Targeting the API Endpoint {#targeting-the-api-endpoint}


Before you can use the client, you must set the target URL, which is also known
as the API Endpoint. This tells the client the location where it will push applications to. For example:

    $ helion target api.helion.example.com

For a micro-cloud VM, it might be something like:

    $ helion target api.helion-xxxx.local

##HTTP Proxies {#http-proxies}
**Note**: On the Windows operating system only, this configuration step should not be necessary, as the client queries the Internet Settings
values. 

If there is an HTTP/HTTPS proxy on your network between your client and
the Application Lifecycle Service API endpoint, set the following environment variables in
your shell as appropriate for your proxy. With these set, the client will route
appropriately.

-   https\_proxy (e.g. "*https://yourproxy.example.com*:443/")
-   http\_proxy (e.g. "*http://yourproxy.example.com*:8080/")
-   http\_proxy\_user
-   http\_proxy\_pass

 

##Removing the Client[](#removing-the-client "Permalink to this headline")

To remove or uninstall the client, simply delete the executable and remove any
aliases or `\$PATH` modifications you have made for it.

----
####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
permalink: /als/v1/user/console/
product: devplatform
---
<!--PUBLISHED-->

Management Console[](#index-1 "Permalink to this headline")
============================================================

The Management Console is a web interface for Application Lifecycle Service (ALS). Using the same
API as the `helion` CLI client, it provides access
to a subset of features for deploying, scaling, and configuring
applications as well as monitoring quota usage, and viewing logs.

The interface differs for Admin and non-Admin users. The features described below are available and visible to
to end users. For information on the Management Console view for Admins, see the ALS Admin Guide. 

Welcome[](#welcome "Permalink to this headline")
-------------------------------------------------

The top-level page of the Management Console displays quick links to the
most commonly used resources:

-   **Read the Documentation**: By default,this links to
    [*docs.helion.com*](../../..)
-   **Contact Support**: Link to the [*Support*](#user-console-support)
    page.
-   **Download the Client**: Link to the locally hosted [*CLI
    client*](/als/v1/user/client/#client) download.
-   **Deploy from Sample Applications**: Link to the [Sample Applications](#user-console-app-store).
-   **Organizations Membership**: Link to the end user view of the
    [*Organizations*](#user-console-welcome) page.
-   **Account Details**: Shows the account details of the current user. Also
    accessible from the drop down list at the top left.

Organization View[](#organization-view "Permalink to this headline")
---------------------------------------------------------------------

The Organizations page shows a list of all
[*Organizations*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces) that the
current user is a member of. Depending on how the ALS PaaS has been
set up, it is possible be a member of only a single Organization.

Clicking on the Organization's name opens a view of that organization,
including:

-   **Quota Usage**:
    -   Memory: The amount of RAM (in GB) available to the Organization,
        and how much of it is currently used by applications.
    -   Services: The number of deployed / allotted services.
-   **Domains**: Domains belonging to the Organization that can be used by applications deployed to [*Spaces*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces) in the Organization. Typically, these will be a subdomain of the Application Lifecycle Service system itself. For example, an Organization called `acme` on a PaaS with the address `api.example.org` might have the domain `\*.acme.example.org`.

**Tabs**:

-   **Spaces**: A list of Spaces that belong to the Organization, showing
    the current number of applications and services deployed to that
    space. Clicking on a Space in the list opens a [*view of that
    Space*](#user-console-space).
-   Users: A list of Users who are members of the Organization, showing
    the Email address and Organization
    [*Roles*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces-roles) of each.
    -   Users: can view organization quotas, domains, spaces and users.
    -   Manager: can add domains and spaces to the organization, but not
        users.

**Note**: There is currently no interface in the Management Console for Managers,
Auditors, or Billing Managers to view or adjust billing/payment info and
spending limits.

Spaces View[](#space-view "Permalink to this headline")
-------------------------------------------------------

-   **Apps**: A filterable list of applications in the Space. Clicking an
    app name opens an [*administrative view of that
    application*](#user-console-app).
-   **Services**: A list of services bound to applications in the Space.
    Clicking a service name opens an [*administrative view of that
    service*](#user-console-service).
-   **Domains**: A filterable list of Domains attached to the space. Domains
    can be added and removed by Space or Organization Managers, but must
    first be mapped to the parent Organization (by an Application Lifecycle Service Admin).

**Tabs**:

-   **Timeline**: A real-time stream of events and discussions relevant to
    the Space. The creation, update, and deletion of apps and services
    appear here as notifications which can be commented on by members of
    the Space. Discussions can be started by any member, tagged, and
    assigned to an application (which makes the item visible in the
    Application view).
-   **Managers**: Managers can invite/manage users, enable features for a
    given space.
-   **Developers**: Developers can create, delete, manage applications and
    services, full access to all usage reports and logs.
-   **Auditors**: Auditors have view-only access to all space information,
    settings, reports, and logs.

Application View[](#application-view "Permalink to this headline")
-------------------------------------------------------------------

-   **About**: General information about the app including which buildpack
    it uses, when it was created, and when it was last modified.
-   **Routes**: Essentially, the URLs mapped to the application. These
    [*Routes*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces-routes) are made
    up of the name of the application name (a virtual hostname) followed
    by a dot and a
    [*Domain*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces-domains) (assigned
    to the Org and Space).
-   **Services**: Data (and other) service instances deployed in the Space.
    May be attached to one or more applications in the Space.
-   **Memory** **Usage**: Total RAM consumption (in MB) of all apps in the
    Space.

**Tabs**:

-   **Timeline**: An application-specific subset of the Timeline for the
    Space.
-   **Instances**: List of application instances showing the status and host
    DEA IP address of each.
-   **Logs**: A real time stream of your applications logs.
-   **Files**: A browsable list of directories and files in each application
    instance.
-   **Environment** **Variables**: Environment variables that have been
    explicitly set in the application container (via application config,
    client commands, or this interface). Default variables, those set by
    the application framework, or those added by the system for data
    services are excluded from this view.
-   **Settings**: The number of application instances, disk space, and
    memory allotment used by the application. This usage counts against
    the organizations's quota.

Service Instance View[](#service-instance-view "Permalink to this headline")
-----------------------------------------------------------------------------

Clicking a service instance's name anywhere in the interface brings up a
view of that service instance showing:

-   when it was created
-   when it was last modified
-   which host it is running on
-   which port it is exposed on
-   the service instance name (not the canonical database name)
-   its current state

For more information on a service instance, such as its credentials, use
the [`helion service`](/als/v1/user/reference/client-ref/#command-service)
command.

Sample Apps[](#marketplace "Permalink to this headline")
-----------------------------------------------------

The Sample Apps are collection of ready-to-run applications which can be deployed to Application Lifecycle Service by fetching the source code from the repository.

Click the **Deploy App** button to start it on Application Lifecycle Service. You will be
prompted to choose a Space and Domain for the app if there are multiple
options available.---
layout: default-devplatform
permalink: /als/v1/user/deploy/app-debug/
product: devplatform
---
<!--PUBLISHED-->

Remote Debugging[](#remote-debugging "Permalink to this headline")
===================================================================

Different languages have different tools an protocols for remote
debugging, but most require a connection between the running application
code and the debugging tool or IDE on a port and protocol other than
standard HTTP(S).

Application Lifecycle Service makes this possible through the [*Harbor port
service*](/als/v1/user/services/port-service/#port-service), and the
[*helion push*](/als/v1/user/reference/client-ref/#command-push) command has
a `-d` option to set up port forwarding for a remote
debugging session automatically.

See the [*JPDA Debugging*](/als/v1/user/deploy/languages/java/#java-web-debug) section
of the Java deployment documentation for an example.

HELION\_DEBUG\_COMMAND[](#helion-debug-command "Permalink to this headline")
---------------------------------------------------------------------------------

The helion client can automatically start a local debugger client or
IDE instance with connection information for a newly pushed application.

When the `-d` debugging option is given to
[*helion push*](/als/v1/user/reference/client-ref/#command-push) command,
the client looks for a HELION\_DEBUG\_COMMAND environment variable. If
present, the command specified in that variable is run after the push
completes as child process in the foreground (i.e. blocking the parent
`helion` process) in the local application source
directory.

Special `%HOST%` and `%PORT%` variables can be used in this command, which
are replaced with the hostname or IP address and port number of the new
Harbor debugging service.---
layout: default-devplatform
permalink: /als/v1/user/deploy/app-logs/
product: devplatform
---
<!--PUBLISHED-->

Application Logs[](#application-logs "Permalink to this headline")
===================================================================

Logs for applications running on Application Lifecycle Service are aggregated into streams
so that data from multiple instances can be viewed together and
filtered. Application log streams can be accessed via:

-   the [*Management Console*](/als/v1/admin/console/customize/#management-console)
    using the **View Logs** button on the application Details page, or
-   the [*helion logs*](/als/v1/user/reference/client-ref/#command-logs)
    command
-   application log [*drains*](#application-logs-drain)

Log streams are tailed output from actual log files in each application
container, which are generally found in the */home/helion/logs/* directory.
These files can be accessed with the [*helion
files*](/als/v1/user/reference/client-ref/#command-files) command or from the
Application details page of the [*Management
Console*](/als/v1/admin/console/customize/#management-console).

**Note**

These files are not automatically rotated. For long-running applications
or verbose logs, you should [*rotate them*](#application-logs-rotate) to
avoid filling up the application container's filesystem.

helion logs[](#helion-logs "Permalink to this headline")
-------------------------------------------------------------

To view an application log stream, use the [*helion
logs*](/als/v1/user/reference/client-ref/#command-logs) command:

    $ helion logs myapp

To limit the number of lines displayed, use the `--num` option:

    $ helion logs myapp --num 50

To view log stream as it is updated, use the `--follow` option:

    $ helion logs myapp --follow

Log streams can be filtered on a number of parameters:

-   **--text** does a glob pattern match on the log message
-   **--instance** shows only logs from the specified application
    instances (starting at instance 0).
-   **--filename** filters based on the log filename (e.g. 'stderr.log')
-   **--source** shows only logs from the specified source ('app' or
    'staging'). Without a source specified, the log stream includes
    staging and application logs as well as cloud events relevant to
    app.

The `--json` flag can be used to return each log
line as a JSON object.

**Note**

`helion logs` buffers only 400 lines of the log
stream history (i.e. lines generated prior to it being run). If you need
earlier log lines, use the [*helion
files*](/als/v1/user/reference/client-ref/#command-files) command to fetch the
relevant log file from the *logs/* directory or create a log
[*drain*](#application-logs-drain) preemptively (where possible).

### Adding Files to the Stream[](#adding-files-to-the-stream "Permalink to this headline")

By default, `helion logs` streams log data from
*staging\_tasks.log* (while staging), *stdout.log* and *stderr.log*
(while running).

You can add up to five additional files to the log stream by modifying
the **HELION\_LOG\_FILES** environment variable (in
[*manifest.yml*](/als/v1/user/deploy/manifestyml/#env) or using [*helion
set-env*](/als/v1/user/reference/client-ref/#command-set-env).

The variable should contain a list of named files separated with ":" in
the following format:

    name=/path/to/file.log:name=/path/to/another.log

The *name* used in the value or individual variable name becomes part of
each log line, and can be used for filtering the stream.

For example, to add a specific Tomcat log file to the default
\$HELION\_LOG\_FILES variable, you might set the following in
*manifest.yml*:

    env:
      HELION_LOG_FILES: tomcat=/home/helion/tomcat/logs/catalina.2013-11-04.log:$HELION_LOG_FILES

Paths can be specified fully or specified relative to \$HELION\_APP\_ROOT.

helion drain[](#helion-drain "Permalink to this headline")
---------------------------------------------------------------

The [*helion drain
add*](/als/v1/user/reference/client-ref/#command-drain-add) command is used to
create a log drain which forwards application logs to external log
aggregation services, log analysis tools, or Redis databases. For
example:

    $ helion drain add myapp appdrain udp://logs.loggly.com:12345

This creates a UDP drain called "appdrain" for the application "myapp"
which forwards all log messages and events for that application to
[Loggly](http://loggly.com/) on port 12345.

The log drain URL can contain only:

-   **scheme**: `udp://` or `tcp://`
-   **host**: IP address or hostname
-   **port**: number

Any additional parameters are discarded.

To delete the drain:

    $ helion drain delete appdrain

Use the --json option send the log lines in JSON format:

    $ helion drain add myapp jsondrain --json udp://logs.loggly.com:12346

To check the status of your application drains, use the
`helion drain list` command.

**Note**

If the service at the receiving end of the drain goes offline or becomes
disconnected, Application Lifecycle Service will retry the connection at increasing
intervals.
<!--
Log Drain Examples[](#log-drain-examples "Permalink to this headline")
-----------------------------------------------------------------------

Detailed instructions on how to use drains with third party log analysis
software or services:

-   [*Papertrail*](#app-logging-examples-papertrail)
-   [*Loggly*](#app-logging-examples-loggly)
-   [*Splunk*](#app-logging-examples-splunk)

### Papertrail[](#papertrail "Permalink to this headline")

1.  [Create an account for Papertrail](https://papertrailapp.com/plans)
2.  In the Dashboard screen, click **Add Systems**.
    <img src="/als/v1/images/ppt11.png">
    <img src="/als/v1/images/logo.png">
 
3.  In the Setup Systems screen under *Other log methods*, click
    *Alternatives*.
    <img src="/als/v1/images/ppt21w.png" />
 
4.  Choose option C: *My system's hostname changes* and give it a
    suitable name.
    <img src="/content/documentation/devplatform/stackat0/images/ppt31.png" />

5.  Note the **port number**.
    <img src="/content/documentation/devplatform/stackat0/images/ppt41.png" />

6.  Enable application logging (via udp) by executing the following client command:

    `helion drain add drain-name udp://logs.papertrailapp.com:port#`

### Loggly[](#app-logging-examples-loggly "Permalink to this headline")
Loggly supports JSON format with minor configuration changes as shown below.

1. [Create an account for Loggly](https://app.loggly.com/pricing)
1. Under *Incoming Data* tab, click *Add Input*.
<image src="..\..\images\loggly11.png">
1. In the Add Input screen:
 	- Choose *Syslog UDP or TCP*
 	- Choose *Combination Log Type*
 	- [Optional] For JSON Logging, Choose UDP or TCP **with Stripe** and enable **JSON Logging**. (for system logs)
 	<img src="..\..\images\loggly21.png">
1.  If we want to accept logs from any Application Lifecycle Service nodes or applications, modify the Allowed Devices section:
 	- Click *Add device*
	<img src="..\..\images\loggly31.png">
 	-   Add IP Address 0.0.0.0/0 when prompted
 	<img src="..\..\images\loggly41.png" />
1.  Turn off discovery since we allowed all devices. Also note down the **port number**.
 	<img src="..\..\images\loggly51.png" />
1. Run **one** of the following client commands to create the log drain:


    `helion drain add drain-name udp://logs.loggly.com:port#`

    `helion drain add drain-name tcp://logs.loggly.com:port#`

### Splunk[](#splunk "Permalink to this headline")
Splunk supports JSON format without further configuration.

1.  [Set up Splunk Server](http://www.splunk.com/download).
2.  In the welcome screen, click *Add data*
	<img src="/content/documentation/devplatform/stackat0/images/splunk11.png" />
3.  Under **Choose a Data Source**, click **From a TCP port** (or UDP).
	<img src="/content/documentation/devplatform/stackat0/images/splunk21.png" />
4.  In the Add new Source screen:
	-   Select a TCP/UDP port greater than **9999**
	-   Give it a suitable **Source name**.
	-   Set sourcetype to **Manual**
	-   Leave Source Type **empty**
	<img src="/content/documentation/devplatform/stackat0/images/splunk31.png" />

5.  Run the following client command to create the log drain: 
`helion drain add drain-name udp://splunk-server-address:port#`
OR
helion drain add drain-name tcp://splunk-server-address:port#



### Hello World Custom Drain[](#hello-world-custom-drain "Permalink to this headline")

The command below starts a drain target server on a node, piping to a
local file:

    nc -lk 0.0.0.0 10000 > log-output.txt

As long as that nc command runs, this will funnel logs from all drains
targeting it into the file *log-output.txt*

Run one of the following client commands to create the log drain:


    helion drain add drain-name udp://server-address:port#

OR

    helion drain add drain-name tcp://server-address:port#
-->
Rotating Application Log Files[](#rotating-application-log-files "Permalink to this headline")
-----------------------------------------------------------------------------------------------

Application Lifecycle Service does not automatically rotate application log files in
*/home/helion/logs/*. However, you can add log rotation for these
files yourself using `cron` and
`logrotate`. Programming languages, frameworks, and utilities handle logging
operations in different ways. Check for incompatibilities with
`logrotate` before implementing log rotation scheme using it.

1.  Add a cron key in *manifest.yml* to run `logrotate`. Set HELION\_CRON\_INSTANCES to "all" to specify that
    the job should be run in all application instances. For example:

        env:
          HELION_CRON_INSTANCES: all
        cron:
          - 0 1 * * * /usr/sbin/logrotate --state /home/helion/app/logrotate-state /home/helion/app/app-logrotate.conf

    The `--state` option must be set because the
    `helion` user does not have permission to
    update the default state file.

2.  Add an *app-logrotate.conf* file to the base directory of your application to specify which log files to rotate, and which `logrotate` options to use. For example:

        /home/helion/logs/\*.log {
          daily
          compress
          copytruncate
          dateext
          missingok
          notifempty
          rotate 3
          maxage 7
          size 3M
        }

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default-devplatform
permalink: /als/v1/user/deploy/buildpack/
product: devplatform
---
<!--PUBLISHED-->

Buildpacks[](#buildpacks "Permalink to this headline")
=======================================================

[Buildpacks](https://devcenter.heroku.com/articles/buildpacks) are
bundles of detection and configuration scripts which set up containers
to run applications. For a short introduction to writing buildpacks, see
[this presentation](http://talks.codegram.com/heroku-buildpacks).

Buildpacks are the recommended method for deploying applications to
Application Lifecycle Service. Buildpacks replace the built-in frameworks used in previous versions.

### Built-In Buildpacks[](#built-in-buildpacks "Permalink to this headline")

Application Lifecycle Service will cycle through the `detect` scripts of the built-in buildpacks prior to staging to match the code you are pushing.

### Legacy Buildpack[](#legacy-buildpack "Permalink to this headline")

The legacy buildpack is a special meta-buildpack for deploying applications configured for Cloud Foundry v1 without the need for extensive reconfiguration.

To use the Legacy buildpack: specify the `framework` type for your application (e.g. php,
play, rails3, sinatra, java\_web, java\_ee, etc.). You can optionally
set a specific `runtime:` as well. For example:

    name: bottle-py3
    framework:
      type: python
      runtime: python32

**Note**

When using the Legacy Buildpack, config-defined environment variable
values can only be updated by re-pushing the application with new
settings (see [*Legacy Buildpack and Environment
Variables*](/als/v1/admin/reference/known-issues/#known-issues-legacy-env)).

### Custom Buildpacks[](#custom-buildpacks "Permalink to this headline")

To specify the exact buildpack to use for deploying your application,
set a top-level `buildpack:` key in *manifest.yml*
to the URL of the buildpack's Git repository. For example:

    name: myrubyapp
    mem: 256MB
    buildpack: https://github.com/ActiveState/stackato-buildpack-ruby.git

**Note**

Not all Heroku buildpacks work with Application Lifecycle Service due to environmental
differences (e.g. relying on certain executables or libraries in
Heroku-specific locations). Test any buildpack before using it in
production deployments.

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
permalink: /als/v1/user/deploy/
product: devplatform
---
<!--PUBLISHED-->

General Deployment[](#general-deployment "Permalink to this headline")
=======================================================================

Applications are typically deployed to Application Lifecycle Service by pushing source code
and configuration to the system's API endpoint using the [*helion client*](/als/v1/user/client/#client) or other clients that use the
Application Lifecycle Service or Cloud Foundry API.

The steps for deploying applications will be slightly different
depending on the application and its requirements. 

**Note**

In Application Lifecycle Service 1.0 and later (Cloud Foundry v2 API), application deployment
is done primarily using [Buildpacks](/als/v1/user/deploy/buildpack/). A
special built-in 'Legacy' buildpack handles Cloud Foundry V1 frameworks for
existing application configurations.

Targeting & Authenticating[](#targeting-authenticating "Permalink to this headline")
-------------------------------------------------------------------------------------

Before deploying an app, the client must first target Application Lifecycle Service's API
endpoint URL. This will generally be the same URL that exposes the
Management Console. For example:

    $ helion target api.example.com
    Successfully targeted to [https://api.example.hphelion.com]
    ...

Use the `helion login` command to authenticate
with your username and password:

    $ helion login <username>
    Attempting login to [https://api.example.hphelion.com]
    Password: ******
    Successfully logged into [https://api.example.hphelion.com]

Selecting Org & Space[](#selecting-org-space "Permalink to this headline")
---------------------------------------------------------------------------

If your account is a member of multiple
[*organizations*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces), choose which one you
want to operate under:

    $ helion switch-org exampleco

Likewise, if you are a member of more than one space, choose a default
space:

    $ helion switch-space devel-example

Pushing Application Code[](#pushing-application-code "Permalink to this headline")
-----------------------------------------------------------------------------------

Change to the root directory of your source code project, and use the
`helion push` command to deploy your application.
If you have a [*manifest.yml*](/als/v1/user/deploy/manifestyml/) config file in this
directory, you can use just:

    $ helion push -n

The "-n" option is an alias for "--no-prompt", which takes options from
the config YAML file instead of prompting for them.

The output of the push command will be something like:

    $ helion push -n
    Using manifest file "manifest.yml"
    Application Url: env.example.hphelion.com
    Creating Application [env] as [https://api.example.hphelion.com -> exampleco -> devel-example -> env] ... OK
      Map env.stacka.to ... OK
    Uploading Application [env] ...
      Checking for bad links ... 80 OK
      Copying to temp space ... 79 OK
      Checking for available resources ...  OK
      Processing resources ... OK
      Packing application ... OK
      Uploading (223K) ... 100% OK
    Push Status: OK
    ...
    helion.dea_ng: [STAGED_APP] Completed staging application
    helion.dea_ng.0: [SPAWNING_APP] Spawning app web process: node server.js
    app.0: Server running at
    app.0:   => http://0.0.0.0:50932/
    app.0: CTRL + C to shutdown
    OK
    http://env.heli.on/ deployed

The Helion client will show staging and running
logs for the deployment process. To inspect these logs after deployment
has finished, use the [*helion
logs*](/als/v1/user/reference/client-ref/#command-logs) command.

Language Specific Deployment[](#language-specific-deployment "Permalink to this headline")
-------------------------------------------------------------------------------------------

See each of these sections for language specific deployment details and
examples:

-   [Java](/als/v1/user/deploy/languages/java/)
-   [Node](/als/v1/user/deploy/languages/node/)
-   [PHP](/als/v1/user/deploy/languages/php/)
<!---   [Clojure](/als/v1/user/deploy/languages/clojure/)
-   [Go](/als/v1/user/deploy/languages/go/)
-   [Perl](/als/v1/user/deploy/languages/perl/)
-   [Python](/als/v1/user/deploy/languages/python/)
-   [Ruby](/als/v1/user/deploy/languages/ruby/)
-->
Configuring Your Application For Application Lifecycle Service[](#configuring-your-application-for-helion "Permalink to this headline")
---------------------------------------------------------------------------------------------------------------------

Most applications should be able to run under Application Lifecycle Service with only a few
changes.

**manifest.yml**
:   A manifest.yml file should be added to the root of
    your application to hold installation details as well as setup
    configuration instructions for your app.


    [*manifest.yml*](/als/v1/user/deploy/manifestyml/#manifest-yml)

**Data Services**
:   If you want to use Application Lifecycle Service's data services, your code will need to
    use the connection details provided by special environment variables
    (e.g. DATABASE\_URL). The code should generally check for the
    existence of these environment variables, use them if they exist,
    and otherwise fall back to some default setting.

    See the [*Data
    Services*](/als/v1/user/services/data-services/#data-services) section for
    further details.

**Environment Variables**
:   A number of special environment variables are available during
    staging and runtime. These can be used in
    [*hooks*](/als/v1/user/deploy/manifestyml/#hooks) or application code
    (for setting up databases, filesystem services, web server options,
    and cron jobs) in places where you would normally use hard-coded
    paths, credentials, or host-specific values.

    See the [*Environment
    Variables*](/als/v1/user/reference/environment/#environment-variables)
    section for a complete list.

Application Lifecycle Service push[](#helion-push "Permalink to this headline")
-------------------------------------------------------------

The [*helion push*](/als/v1/user/reference/client-ref/#command-push) command
creates (or updates) applications on Application Lifecycle Service. It negotiates with the
API endpoint to reserve application URLs, allocate application
instances, provision data services, upload application code, and
optionally stage and start the application.

The command will prompt for options or use those specified in a [*manifest.yml*](/als/v1/user/deploy/manifestyml/#manifest-yml) file.

**Note**

The application name must be a valid [hostname
label](http://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_host_names)
(i.e. containing only alphanumeric characters and hyphens).

The `push` command implicitly stages and starts the
application unless the `--no-start` option is used.
With this option, applications are pushed in a pre-staged, stopped state
where variables can be added (e.g. for use in staging hooks). The
application can then be staged and started with the [*helion
start*](/als/v1/user/reference/client-ref/#command-start) command or the Start
button in the [*Management
Console*](/als/v1/admin/console/customize/#user-console-welcome).

The client will display staging logs while pushing the application but
will generally exit before any application logs are visible. To view the
application logs, use the [*helion
logs*](/als/v1/user/reference/client-ref/#command-logs) command.

Allowed File Types[](#allowed-file-types "Permalink to this headline")
-----------------------------------------------------------------------

During the push process, Application Lifecycle Service includes only three file types:

1.  Files
2.  Folders
3.  Links

All other special file types are ignored.

Naming and URLs[](#naming-and-urls "Permalink to this headline")
-----------------------------------------------------------------

To prevent confusion or collisions, Application Lifecycle Service enforces uniqueness for
URLs, application names, and service names:

-   **URLs** (auto-generated or [*manually mapped*](#deploy-map-url))
    must be globally unique, and are allocated on a "first come, first
    serve" basis.
-   **Application names** must be unique within the scope of the
    [*space*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces). Applications deployed in
    different spaces can have the same name, but the full application
    URL must be globally unique URL.
-   **Service names** must be unique within the scope of the
    [*space*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces). The name given to a service
    during creation is a pointer to a globally unique string (i.e. the
    *actual* database name in the system as shown by
    VCAP\_SERVICES), so there is no possibility of naming conflicts
    with services created in other orgs and spaces.

Crontab Support[](#crontab-support "Permalink to this headline")
-----------------------------------------------------------------

**Note**

Cron commands are only executed on instance \#0 of the app.

Cron commands can be provided either in a regular crontab file in the
root directory of the app, or via the `cron:`
section in *manifest.yml* (See [*manifest.yml
Options*](/als/v1/user/deploy/manifestyml/).

The `HOME` and `PATH`
environment variables, as well as all variables that start with
`PERL`, `PYTHON`,
`VCAP`,
`BUNDLE`, `LEIN`,
`GEM`, `RACK`, `RAILS`, `RUBY` or `http`
are exported to the top of the crontab file. When applicable, the
following database related environment variables are also added:
`DATABASE_URL`, `MYSQL_URL`,
`POSTGRESQL_URL`, `REDIS_URL`,
`MONGODB_URL`, and `RABBITMQ_URL`.

This happens after the `pre-running` hook has
executed, so any changes made by those commands will be included in the
crontab file.

After setting up environment variables, we copy the *\$HOME/crontab*
file, and finally the commands from the `cron:`
section in *manifest.yml*. The resulting file is stored at
*\$HELION\_APP\_ROOT/crontab*.

### Whitespace & Newlines in Environment Variables[](#whitespace-newlines-in-environment-variables "Permalink to this headline")

To prevent breakage in cron, embedded newlines ("\\n") in environment
variable values will be replaced with "\\\\n" when generating the
crontab. Any leading and trailing spaces in environment variable values
are also stripped.

Mapping App URLs[](#mapping-app-urls "Permalink to this headline")
-------------------------------------------------------------------

Application Lifecycle Service automatically assigns to each application a URL made up of the
application's name and the base URL for the system. An application named
"myblog" deployed to an Application Lifecycle Service system at "api.example.com" would be given
the URL "myblog.example.com".

In addition to this default URL, additional URLs can be set for an
application using the [*helion
map*](/als/v1/user/reference/client-ref/#command-map) command. The application
will respond to requests on the mapped URL, provided a DNS record has
been set up resolving to Application Lifecycle Service's external IP or hostname.

For example, to map a URL to an existing application on Application Lifecycle Service:

    $ helion apps

    +--------------+---+--------+----------------------------------+------------+
    | Application  | # | Health | URLS                             | Services   |
    +--------------+---+--------+----------------------------------+------------+
    | myapp        | 1 | 100%   | myapp.example.com                  |            |
    +--------------+---+--------+----------------------------------+------------+

    $ helion map myapp example.com

    +--------------+---+--------+----------------------------------+------------+
    | Application  | # | Health | URLS                             | Services   |
    +--------------+---+--------+----------------------------------+------------+
    | myapp        | 1 | 100%   | myapp.example.com                  |            |
    |              |   |        | example.com                     |            |
    +--------------+---+--------+----------------------------------+------------+

If DNS is configured correctly, requests to "example.com" will resolve
transparently to "myapp.example.com".

**Note**

Application URLs are allocated on a "first come, first serve" basis, and
are reserved for the user who created the URL.

URLs can be mapped to multiple applications owned by the same user,
which can be useful for A/B testing. Application Lifecycle Service routes requests to the
mapped URL randomly between all available app instances.

Using the 'myapp.example.com' example above, you could push 'myapp-v2'
(e.g. a more recent revision) then map 'example.com' to that app as
well. You can access the specific versions directly using
'myapp.example.com' and 'myapp-v2.example.com', and use 'example.com' to
round robin between available instances of both versions:

    +-------------+---+---------+--------------------+-------------+
    | Application | # | Health  | URLS               | Services    |
    +-------------+---+---------+--------------------+-------------+
    | myapp       | 5 | RUNNING | myapp.example.com    |             |
    |             |   |         | example.com       |             |
    | myapp-v2    | 1 | RUNNING | myapp-v2.example.com |             |
    |             |   |         | example.com       |             |
    +-------------+---+---------+--------------------+-------------+

As you gain confidence with the new revision, you can increase the
number of instances of 'myapp-v2' (i.e. phasing that version into
production rather than cutting over) and eventually
[*unmap*](/als/v1/user/reference/client-ref/#command-unmap) 'example.com'
from the original 'myapp'.

Best Practices[](#best-practices "Permalink to this headline")
---------------------------------------------------------------

### Reducing downtime during app updates[](#reducing-downtime-during-app-updates "Permalink to this headline")

Updating an app can create downtime while the new code is being staged.
URL mapping can be used to reduce this downtime by switching between two
running versions of an app.

For example, we have an application called "customertracker". The pushed
application name will include a version or build number, but it is
mapped to a "production" URL as well:

    $ helion apps

    +--------------------+---+---------+------------------------------+------------+
    | Application        | # | Health  | URLS                         | Services   |
    +--------------------+---+---------+------------------------------+------------+
    | customertracker-v1 | 1 | RUNNING | customertracker-v1.example.com | customerdb |
    |                    |   |         | customertracker.example.com  |            |
    +--------------------+---+---------+------------------------------+------------+

Push the updated code with a new application name:

    $ helion push --as customertracker-v2

    ...

    $ helion apps

    +--------------------+---+---------+------------------------------+------------+
    | Application        | # | Health  | URLS                         | Services   |
    +--------------------+---+---------+------------------------------+------------+
    | customertracker-v1 | 1 | RUNNING | customertracker-v1.example.com | customerdb |
    |                    |   |         | customertracker.example.com  |            |
    | customertracker-v2 | 1 | RUNNING | customertracker-v2.example.com | customerdb |
    +--------------------+---+---------+------------------------------+------------+

**Note**

In this example, the configured service has the same name, so it is
bound to both versions of the application. This will only work if there
are no database schema changes or differences in the filesystem layout
on a persistent filesystem service. If there are such differences, use
distinct data services for the new version.

Map the "production" URL to the new app:

    $ helion map customertracker-v2 customertracker.example.com

    $ helion apps

    +--------------------+---+---------+------------------------------+------------+
    | Application        | # | Health  | URLS                         | Services   |
    +--------------------+---+---------+------------------------------+------------+
    | customertracker-v1 | 1 | RUNNING | customertracker-v1.stacka.to | customerdb |
    |                    |   |         | customertracker.example.com  |            |
    | customertracker-v2 | 1 | RUNNING | customertracker-v2.stacka.to | customerdb |
    |                    |   |         | customertracker.example.com  |            |
    +--------------------+---+---------+------------------------------+------------+

While both versions of the application are live and mapped to the same
production URL, the router will round-robin web requests to this URL
between both versions.

Next, unmap the production URL from the first app:

    $ helion unmap customertracker-v1 customertracker.example.com

The old version is still available in case it's needed for rollback. If
everything works as expected with the newer code, delete the old app:

    $ helion delete customertracker-v1

    $ helion apps

    +--------------------+---+---------+------------------------------+------------+
    | Application        | # | Health  | URLS                         | Services   |
    +--------------------+---+---------+------------------------------+------------+
    | customertracker-v2 | 1 | RUNNING | customertracker-v2.stacka.to | customerdb |
    |                    |   |         | customertracker.example.com  |            |
    +--------------------+---+---------+------------------------------+------------+

### Managing Multiple Targets[](#managing-multiple-targets "Permalink to this headline")

The Application Lifecycle Service client targets a single location with the command
`helion target`.

If you need to target two or more instances at the same time, use one of
the following methods:

1.  Use the `--target <target>` option. This sets
    the specified target for the current command only, and does not set
    it as the default:

        $ helion apps --target api.helion-xxx1.local

2.  Use two or more terminals to access multiple targets. Within each
    terminal, set the `HELION_TARGET` environment
    variable for the API endpoint URL you want to work with in that
    terminal. The client will use this URL, overriding any target set
    with the `helion target` command:

        $ export HELION_TARGET='api.helion-xxx2.local'

 This target is used until the variable is unset or the terminal is
 closed. To unset it:

	$ unset HELION_TARGET

Persistent Sessions[](#persistent-sessions "Permalink to this headline")
-------------------------------------------------------------------------

With multi-instance applications on Application Lifecycle Service, the Router will distribute
requests among all instances. Without session management, the end user
could access different application instances with each HTTP request
instead of connecting to the same instance that started their session. Application Lifecycle Service's default router does no special handling of
`JSESSIONID` or `SESSIONID`
cookies.

Cloud-enabled applications should use a shared database (e.g. Redis),
cache (e.g. Memcached), or filesystem as a back end for session
management. Some examples of this approach are:

-   Java:
    -   [Tomcat session
        manager](http://tomcat.apache.org/tomcat-6.0-doc/config/manager)
    -   [memcached-session-manager](http://code.google.com/p/memcached-session-manager/)
    -   [tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)
-   Node.js:
    [connect-memcached](https://github.com/balor/connect-memcached#connect-memcached),
    a session store that uses Memcached
-   PHP:
    -   [Persistent Sessions](/als/v1/user/deploy/languages/php/#php-persistent-sessions-filesystem)
    -   [Memcached session support](http://php.net/manual/en/memcached.sessions.php)
-   Python: [Django "How to use
    sessions"](https://docs.djangoproject.com/en/dev/topics/http/sessions/)



---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/clojure/
product: devplatform
---
<!--PUBLISHED-->

Clojure[](#clojure "Permalink to this headline")
=================================================

Application Lifecycle Service supports deploying Clojure applications using
[leiningen](https://github.com/technomancy/leiningen).

To create a new Clojure web application, install leiningen and
[Noir](http://webnoir.org/) (a Clojure web framework):

    $ lein plugin install lein-noir 1.1.0

Create a Noir project:

    $ lein noir new myapp
    ...
    $ cd myapp/

Now deploy to Application Lifecycle Service. Accept the defaults for each prompt:

    $ helion push myapp
    [...]
    Application Deployed URL: 'myapp.helion-xxxx.local'?
    [...]
    Starting Application: OK

Open the application's URL in your browser to see the default Noir welcome
page.

Clojure Database Services Example[](#clojure-database-services-example "Permalink to this headline")
-----------------------------------------------------------------------------------------------------

Taken from the [4clojure sample
app](https://github.com/Stackato-Apps/4clojure/blob/stackato/src/foreclojure/config.clj#L6):

    (defn assoc-cloud-env
      "Import Cloud Foundry / Application Lifecycle Service environment settings"
      [config]
      (let [port (Integer/parseInt (System/getenv "PORT"))
            srv  (parse-string (System/getenv "VCAP_SERVICES"))
            cred ((first (srv "mongodb-1.8")) "credentials")]
        (assoc config
          :jetty-port port
          :db-host    (cred "host")
          :db-port    (cred "port")
          :db-user    (cred "username")
          :db-pwd     (cred "password")
          :db-dbname  (cred "db"))))---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/dotnet/
---
<!--PUBLISHED-->

#Developing In .NET

.NET applications can be built to communicate directly with the <a class="reference external" href="http://docs.hpcloud.com/api">Helion APIs</a> through a REST client
or through the SDK. The SDK simplifies working with the REST services by providing easy to use APIs.</p>
<p>Here is an example of writing and reading from object storage:</p>
<div class="highlight-csharp"><div class="highlight"><pre><span class="c1">//Setup and create a credential to use when connecting to OpenStack</span>
<span class="n">var</span> <span class="n">authUri</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Uri</span><span class="p">(</span><span class="s">&quot;https://region.identity.host.com:12345/v2.0&quot;</span><span class="p">);</span>
<span class="n">var</span> <span class="n">userName</span> <span class="p">=</span> <span class="s">&quot;user name&quot;</span><span class="p">;</span>
<span class="n">var</span> <span class="n">password</span> <span class="p">=</span> <span class="s">&quot;password&quot;</span><span class="p">;</span>
<span class="n">var</span> <span class="n">tenantId</span> <span class="p">=</span> <span class="s">&quot;XXXXXXXXXXXXXX-Project&quot;</span><span class="p">;</span>
<span class="n">var</span> <span class="n">credential</span> <span class="p">=</span> <span class="k">new</span> <span class="n">OpenStackCredential</span><span class="p">(</span><span class="n">authUri</span><span class="p">,</span> <span class="n">userName</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">tenantId</span><span class="p">);</span>

<span class="c1">//Create and connect a new client for working with OpenStack</span>
<span class="n">var</span> <span class="n">client</span> <span class="p">=</span> <span class="n">OpenStackClientFactory</span><span class="p">.</span><span class="n">CreateClient</span><span class="p">(</span><span class="n">credential</span><span class="p">);</span>
<span class="n">await</span> <span class="n">client</span><span class="p">.</span><span class="n">Connect</span><span class="p">();</span>

<span class="c1">//Create a service client for working with the Swift storage service</span>
<span class="n">var</span> <span class="n">storageServiceClient</span> <span class="p">=</span> <span class="n">client</span><span class="p">.</span><span class="n">CreateServiceClient</span><span class="p">&lt;</span><span class="n">IStorageServiceClient</span><span class="p">&gt;();</span>

<span class="c1">//Get the default account, and print out all of its containers</span>
<span class="n">var</span> <span class="n">storageAccount</span> <span class="p">=</span> <span class="n">await</span> <span class="n">storageServiceClient</span><span class="p">.</span><span class="n">GetStorageAccount</span><span class="p">();</span>
<span class="k">foreach</span><span class="p">(</span><span class="n">var</span> <span class="n">container</span> <span class="k">in</span> <span class="n">storageAccount</span><span class="p">.</span><span class="n">Containers</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="n">container</span><span class="p">.</span><span class="n">Name</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>

To learn more about using the SDK:
- 
- [Getting Started With The .NET Library](/als/v1/user/deploy/languages/dotnet/getstarted)
- [Identity Service, Authentication, and the Service Catalog in .NET](/als/v1/user/deploy/languages/dotnet/authentication)
- [Working With Object Storage in .NET](/als/v1/user/deploy/languages/dotnet/objectstore)


##HP Helion PowerShell Environment
The HP Helion PowerShell Environment allows users to manage storage, compute, and block storage services from the [Windows PowerShell Environment](https://docs.hpcloud.com/cli/)


---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/dotnet/authentication/
---
<!--PUBLISHED-->

Identity Service, Authentication, and the Service Catalog in .NET
=================================================================
The [Identity Service API](https://docs.hpcloud.com/identity) is central to using the
APIs for the HP Helion OpenStack&reg; services. The Identity Service not only addresses authentication
but also supplies a catalog of information around the activated and available services.
In other words, the Identity Service API provides the communication API endpoints for services Object Storage, Network, and Compute within the different regions that are available.

The HP Helion .NET SDK provides functionality for basic authentication with the identity service.

Authentication and Tokens
-------------------------
Your first step is to authenticate as a user with the username and password used to log in to the console.

Since services are associated with tenants you need to use a tenantId to
get a valid token for a set of services.

Authenticate as a user by first creating a credential. This example shows how to create a new credential object that can be used by a client to authenticate the user. 

Code-block: csharp

       var authUri = new Uri("https://region.identity.host.com:12345/v2.0");
       var userName = "user name";
       var password = "password";
       var tenantId = "XXXXXXXXXXXXXX-Project";
       var credential = new OpenStackCredential(authUri, userName, password, tenantId);

The next step in the process is to create a client and connect it:

Code-block: csharp

       var client = OpenStackClientFactory.CreateClient(credential);
       await client.Connect();

If authentication failed or there was another error an exception is thrown. There are a
number of exceptions that can be caught depending on the type of error that occurred.

If authentication is successful, the client can be used to access individual service clients for each of the supported services. The client retains all of the authentication details and passes them along to the requested service clients. The actual authentication token is stored in the AccessTokenId property of the client.

## Service Catalog

The service catalog lists the available services. Accessing the catalog, which includes
the API endpoints, is fairly simple through the use of the ServiceCatalog property on the client. The following example demonstrates the use of the ServiceCatalog property in order to list out each of the names of all the available services in a region called "RegionOne". 

Code-block: csharp

       var services = client.Credential.ServiceCatalog.Where(s => s.Endpoints.Any(e => e.Region == "RegionOne"));
       foreach (var service in services)
       {
      Console.WriteLine(service.Name);
       }
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/dotnet/getstarted/
---
<!--PUBLISHED-->

#Getting Started With The .NET SDK

The .NET SDK library is built on top of HP Helion OpenStack® APIs, which removes many of the
complexities of working with the APIs so that developers can focus on writing applications.

The library is designed to be pulled into a .NET application that interacts with HP Helion OpenStack&reg; services through the use of .NET objects, methods, and functions.

The .NET SDK library is available via [Github](https://github.com/stackforge/openstack-sdk-dotnet) and [Nuget](https://www.nuget.org/packages/OpenStack-SDK-DotNet).

Using Nuget, you can include the library by running the following command in the [Package Manager Console](http://docs.nuget.org/docs/start-here/using-the-package-manager-console)

Code-block: yaml

    PM> Install-Package OpenStack-SDK-DotNet

If you aren't using Nuget you can download the library from [Github](https://github.com/stackforge/openstack-sdk-dotnet).

##A Quick Example

For example, we can write a console application that lists all of the storage containers in a user's storage account.

Code-block: csharp

       using System;
       using OpenStack;
       using OpenStack.Identity;
       using OpenStack.Storage;
    
       namespace ConsoleSample
       {
      class Program
      {
     static void Main(string[] args)
     {
    //First we need to create a credential for connecting to the remote services.
    var authUri = new Uri("https://region.identity.host.com:12345/v2.0");
    var userName = "user name";
    var password = "password";
    var tenantId = "XXXXXXXXXXXXXX-Project";
    var credential = new OpenStackCredential(authUri, userName, password, tenantId);
    
    //Next we create a client, and connect it.
    var client = OpenStackClientFactory.CreateClient(credential);
    var connectTask = client.Connect();
    connectTask.Wait();
    
    //Then we create a storage client for working with the object storage service.
    //and get the default storage account.
    var storageServiceClient = client.CreateServiceClient<IStorageServiceClient>();
    var storageAccountTask = storageServiceClient.GetStorageAccount();
    storageAccountTask.Wait();
    
    //Once we have the default storage account, simply loop through the containers.
    //and output them to the console.
    var storageAccount = storageAccountTask.Result;
    foreach (var container in storageAccount.Containers)
    {
       Console.WriteLine(container.Name);
    }
    Console.ReadLine();
    }
    }

Leveraging the .NET SDK library, the code above creates a credential for authentication; creates and connects
a client; uses the client to create a storage service client to get the users account; and enumerates
through all of the containers in the account, printing the name of each one to the console.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/dotnet/objectstore/
---
<!--PUBLISHED-->
#Working with Object Storage in .NET

[Object Storage](http://docs.hpcloud.com/object-storage) is a web scale storage system.
It provides private and public access and is accessible through a simple but robust API. Within
the .NET SDK Library, a service client is used to provide a wrapper around the raw REST API.

Storage Service Client
-----------------------
The easiest method to access object storage is through the storage service client. The following example creates a credential to use for authentication, creates a client, connects, and creates a storage service client:

Code-block: csharp

    var authUri = new Uri("https://region.identity.host.com:12345/v2.0");
    var userName = "user name";
    var password = "password";
    var tenantId = "XXXXXXXXXXXXXX-Project";
    var credential = new OpenStackCredential(authUri, userName, password, tenantId);
            
    var client = OpenStackClientFactory.CreateClient(credential);
    var connectTask = await client.Connect();
            
    var storageServiceClient = client.CreateServiceClient<IStorageServiceClient>();

From here the service client can be used for performing most of the common object storage tasks.

##Listing Containers and Objects
Listing all of the containers or objects that a user has requires the account associated with the user.

Code-block:: csharp

      var storageAccountTask = await storageServiceClient.GetStorageAccount();
    
    The Account object holds a list of containers to which the user has access. The following example iterates through all of the containers in the account, makes a request to the server to get the details of each container, and prints the names of all of the objects inside the container to the console.
    
    .. code-block:: csharp
    
      foreach (var item in storageAccount.Containers)
      {
    Console.WriteLine("Container: " + item.Name);
    var container = await storageServiceClient.GetStorageContainer(item.Name);

    foreach (var obj in container.Objects)
    {
      Console.WriteLine("\t" + obj.Name);
    }
      }

##Creating new Containers and Objects
The storage service client can be used to create new containers and objects. 

The example below creates a new container called **SampleContainer** without any meta data associated with it. The same basic pattern can be used to create new objects as well.

Code-block: csharp

      await storageServiceClient.CreateStorageContainer("SampleContainer", new Dictionary<string, string>());
    
    
This example builds on the last example, adding a new storage object called **SampleObject** with contents from a local file to the newly created **SampleContainer** that was created in the last example.

**Note:** Objects can be overwritten by creating a new object with the same name.

Code-block: csharp
    
      using (var file = new FileStream("--Path to a file--", FileMode.Open))
      {
    await storageServiceClient.CreateStorageObject("SampleContainer", "SampleObject", new Dictionary<string, string>(), file);
      }

##Updating Container and Object Meta-data

The storage service client can also be used to update the meta-data associated with containers and objects. The example below creates a new container called "SampleContainer" without adding any meta-data to it. It then demonstrates how you would retrieve the details of the container, adds some new meta-data to it, then updates the container to include the new meta-data.

Code-block: csharp

    await storageServiceClient.CreateStorageContainer("SampleContainer", new Dictionary<string, string>());
    
    var container = await storageServiceClient.GetStorageContainer("SampleContainer");
    container.Metadata.Add("Title","Sample Container");
    
    await storageServiceClient.UpdateStorageContainer(container);

The following example shows how to use the same pattern for storage objects.

Code-block: csharp

    using (var file = new FileStream("--Path to a file--", FileMode.Open))
    {
      await storageServiceClient.CreateStorageObject("SampleContainer", "SampleObject", new Dictionary<string, string>(), file);
    }
    var obj = await storageServiceClient.GetStorageObject("SampleContainer","SampleObject");
    obj.Metadata.Add("Title","Sample Object");
    
    await storageServiceClient.UpdateStorageObject(obj);

##Deleting Containers and Objects
The following example uses the storage service client to delete the **SampleContainer** container.

Code-block: csharp
    
    await storageServiceClient.DeleteStorageContainer("SampleContainer");

A similar method can be called to delete storage objects as well.

In this example, the storage server client is used to remove the **SampleObject** from the container with the name **SampleContainer**.

Code-block: csharp
    
    await storageServiceClient.DeleteStorageObject("SampleContainer", "SampleObject");

##Downloading Objects
To download the contents of a storage object, use the DowloadStorageObject method. 

This example downloads the contents of the **SampleObject** from the **SampleContainer** and writes it to the given file stream.

Code-block:: csharp
    
      using (var fs = new FileStream("--Path to a file--", FileMode.CreateNew))
      {
    await storageServiceClient.DownloadStorageObject("SampleContainer", "SampleObject", fs);
      }


---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/eclipse/
---
<!--PUBLISHED-->

##Eclipse Plugin for HP Helion Development Platform (APaaS)

##Installation

To install Cloud Foundry Integration for Eclipse, drag and drop into a running [Eclipse Indigo](http://marketplace.eclipse.org/marketplace-client-intro?mpc_install=106257) workspace.

##Connecting to your Helion instance
<img src="/images/Initial_Screen.png">

Expand the "Hewlett Packard" node and select "HP Helion Development Platform"

<img src="/images/New_Server.png">

Click on Next

<img src="/images/Connect-To-Server.png">

Click on the "Manage Cloud Urls" button and enter your server url.

<img src="/images/Manage-Cloud-Url.png">

Select the Helion instance you want to connect to, enter credentials

<img src="/images/Connect-To-Server-2.png">

Once you're connected, select the Organization & Space for this connection, and click "Finish".

<img src="/images//Select-Org-Space.png">


Once you're connected, you should see your Helion server connection in the "Servers" view.

<img src="/images/Server-Connected.png">---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/go/
product: devplatform
---
<!--PUBLISHED-->

Go[](#go "Permalink to this headline")
=======================================

Go applications ([golang](http://golang.org/)) are supported through a
BuildPack framework, and can be pushed to Application Lifecycle Service with a basic setup.

Local Install[](#local-install "Permalink to this headline")
-------------------------------------------------------------

To build Go code, install it locally using one of the [Go
packages](http://code.google.com/p/go/downloads/list).

Deployment[](#deployment "Permalink to this headline")
-------------------------------------------------------

Here is a basic deployment setup based on the ["Hello World" Go sample
application](https://github.com/Stackato-Apps/go-hello-buildpack).

### Files[](#files "Permalink to this headline")

You will need the following files to deploy a Go app on Application Lifecycle Service:

    app.go
    Procfile
    .godir
    manifest.yml

#### app.go[](#app-go "Permalink to this headline")

The Go buildpack recognizes Go apps by the existence of a .go source
file anywhere in the repository:

    package main

    import (
            "fmt"
            "log"
            "net/http"
            "os"
    )

    func main() {
            http.HandleFunc("/", hello)
            err := http.ListenAndServe(":"+os.Getenv("PORT"), nil)
            if err != nil {
                    log.Fatal("ListenAndServe:", err)
            }
    }

    func hello(w http.ResponseWriter, req *http.Request) {
            fmt.Fprintln(w, "hello, world!")
    }

#### Procfile[](#procfile "Permalink to this headline")

To run your web process, you need to declare what command to use. In
this case, we simply need to execute our Go program. Use Procfile to
declare how your web process type is run:

    web: server

#### .godir[](#godir "Permalink to this headline")

The `go` tool uses the directory name of your
project to name executables and determine package import paths. Create
a file called .godir, in your project root, containing the path from
*\$GOPATH/src* to your project root:

    example.com/hello

#### manifest.yml[](#manifest-yml "Permalink to this headline")

This file is optional, as the framework will automatically be detected
by Application Lifecycle Service. However, it can still be used to set the app name,
configure settings, create services, etc. See the [*manifest.yml
docs*](/als/v1/user/deploy/manifestyml/).

> name:
> :   hello-go

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   ["Hello World" Go sample
    application](https://github.com/Stackato-Apps/go-hello-buildpack).
-   [Getting Started with Go on
    Heroku](http://mmcgrana.github.com/2012/09/getting-started-with-go-on-heroku).---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/java/frameworks
---
<!--PUBLISHED-->
#Java Frameworks
Application Lifecycle Service has several Java frameworks to choose from:

-   [Java Web](#java-web)
-   [Spring](#spring)
-   [Java EE (via TomEE or JBoss)](#javaee)
-	[HOME directories](#home-dir)


You can push bytecode built on your local machine with tools like [Maven](http://maven.apache.org/) or build the Java bytecode on Application Lifecycle Service
itself using the [Java Buildpack](/als/v1/user/deploy/buildpack/#buildpacks)


##Java Web Framework<a name="java-web"></a>

The Java Web framework is the default Java framework in Application Lifecycle Service, and
requires little or no modification of application code in most cases.
Application Lifecycle Service simply deploys the WAR file.

The [Hello World Java Sample](/helion/devplatform/workbook/helloworld/java/)
demonstrates a simple Servlet-based Java web app.

### Web Service Configuration

If you have created data services, you can get the service configuration
by using the [environment
variables](/als/v1/user/reference/environment/#environment-variables)
below:

-   DATABASE\_URL
-   VCAP\_SERVICES

If your application uses only one data service, use the DATABASE\_URL
variable. If it uses more than one, use
[*VCAP\_SERVICES*](/als/v1/user/services/data-services/#database-services-vcap-services). <!--[*STACKAT0\_SERVICES*](/als/v1/user/services/data-services/#database-services-helion-services)-->
### JPDA Debugging for the Web Framework

You can debug java\_web applications running on Application Lifecycle Service via
[JPDA](/als/v1/admin/reference/architecture/)
by using the `-d` option with the
`helion push` command:

    $ helion push -d my-java-app

Application Lifecycle Service creates a port service for debugging and shows the external
port number in the command output:

    Debugging now enabled on port 30135

Alternatively, request a Harbor [*port
service*](/als/v1/user/services/port-service/#port-service) in
*manifest.yml* in the format: "*app-name*-debug". For example:

    services:
      ${name}-debug: harbor

The java\_web framework will recognize the service and activate
debugging through the port provided. Connect to this port with the JPDA
debugger of your choice.

To show the port number and external hostname for this service, use the 
[helion service](/als/v1/user/reference/client-ref/#command-services)
command. For the **my-java-app** example above, the command would be:

    $ helion service my-java-app-debug

Use the **hostname** (or **host** for an IP address) and **port** values in the **credentials** section of the output to configure your local
debugging client.

<!--The
[*STACKAT0\_DEBUG\_COMMAND*](/als/v1/user/deploy/app-debug/#app-debug-helion-debug-command)
environment variable can be used to automatically start a debugger or
IDE instance with the appropriate host and port values. -->

**Note**

Though the `helion -d` option is similar to
`vmc -d`, the internal implementation is different.
`vmc -d` cannot be used to activate debugging in
Application Lifecycle Service.


##Spring Framework<a name="spring"></a>

Applications that use the Spring framework are detected and automatically
configured if there is either a *spring-core* jar file or an
*org/springframework* folder.

### Spring Service Configuration

If there is only one service of a given type for example, only one MySQL data service; the application is automatically reconfigured to use that
service.

Define a datasource bean like the following:

    <bean class="org.apache.commons.dbcp.BasicDataSource" id="dataSource">
        <property name="driverClassName" value="com.mysql.jdbc.Driver"/>
        <property name="url" value="jdbc:mysql://localhost:3306/inventory-db"/>
        <property name="username" value="myuser"/>
        <property name="password" value="mypass"/>
    </bean>

The property values are replaced during staging with the values for the
provisioned service.

If you have created more than one service of a given type, you will need
to use VCAP\_SERVICES environment variable to obtain the details for
each one (host, port, username, password).

**Note:** If you are using \<CLOUD\> namespace in your application, make sure the
cloudfoundry-runtime version is 0.8.2.


##JavaEE Framework <a name="javaee"></a>

Application Lifecycle Service's 'java\_ee' framework has two application servers available:

-   TomEE - used for WAR files
-   JBoss - used for EAR files

The Java EE framework is detected if there is a *persistence.xml* file
located in *src/main/resources/META-INF/persistence.xml*.

### JavaEE Service Configuration

For JavaEE applications, you must create a `persistence-unit` in your *persistence.xml* file with the name of your database
service.

For example in *manifest.yml*:

    services:
      service-1:
        type: mysql
      service-2:
        type: mysql

To use `service-1` in your persistence.xml:

    <?xml version="1.0" encoding="UTF-8"?>
    <persistence version="2.0"
      xmlns="http://java.sun.com/xml/ns/persistence"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd">
        <persistence-unit name="persistence-service-1" transaction-type="JTA">
          <jta-datasource>service-1</jta-datasource>
        </persistence-unit>
    </persistence>

And in your JavaEE code:

    @PersistenceContext(unitName = "persistence-service-1")
    private EntityManager em;

##HOME Directories<a name="home-dir"></a>

Java applications will have different HOME directories on Application Lifecycle Service
depending on which Java framework is used:

-   Java Web, Java EE (WAR file), Spring <!--Lift and Grails-->:
    **/home/helion/tomcat/webapps/ROOT**
-   Java EE (EAR file): **/home/helion/jboss/standalone/deployments**
-   Buildpack - Java<!--, Play-->: **/home/helion/app**
<!-- replaced Stackat0 with helion in previous URLs, correct? also removed undocumented pacs/frameworks-->

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/java/
---
<!--PUBLISHED-->

#Developing in Java[](#java "Permalink to this headline")

Whether you're deploying an application to the HP Helion Development Platform, a Cloud Foundry based Platform as a Service (PaaS), or writing applications that take advantage of HP Helion OpenStack® to manage infrastructure or software services, tools to enable successful development are available in Java.

For more information on working with object storage, 
see the [HP Helion OpenStack® Object Storage Service Overview](/helion/openstack/services/object/overview/).

For information about authentication, see [Authenticating with Access Key and Token](/als/v1/user/deploy/languages/java/authentication/).

For more help with building applications, see the Java [Framework](/als/v1/user/deploy/languages/java/frameworks) or [Buildpack](/als/v1/user/deploy/buildpack/#buildpacks) reference.  Supported frameworks include Java Web, Spring, and
Java EE (via TomEE or JBoss)<!--, Grails, and Lift-->.

## Using JDBC[](#using-jdbc "Permalink to this headline")

It is possible to access the database services using the standard JDBC
API:

    String helion_services = System.getenv("VCAP_SERVICES");
    String hostname = NULL_STRING;
    String dbname = NULL_STRING;
    String user = NULL_STRING;
    String password = NULL_STRING;
    String port = NULL_STRING;

    if (helion_services != null && helion_services.length() > 0) {
      try
      {
        JsonRootNode root = new JdomParser().parse(helion_services);

        JsonNode credentials = root.getNode("mysql");

        dbname = credentials.getStringValue("name");
        hostname = credentials.getStringValue("hostname");
        user = credentials.getStringValue("user");
        password = credentials.getStringValue("password");
        port = credentials.getNumberValue("port");

        String dbUrl = "jdbc:mysql://" + hostname + ":" + port + "/" + dbname;

        Class.forName("com.mysql.jdbc.Driver");
        Connection connection = DriverManager.getConnection(dbUrl, user, password);
        return connection;

      }
      catch (Exception e)
      {
        throw new SQLException(e);
      }
    }

### Example[](#example "Permalink to this headline")

The [Java database sample](/helion/devplatform/workbook/messaging/java/) sample
demonstrates a simple Java application using a MySQL service.



CATALINA\_OPTS[](#catalina-opts "Permalink to this headline")
--------------------------------------------------------------

The CATALINA\_OPTS environment variable can be set in the
`env:` block of manifest.yml (or set in the
Management Console) to override Application Lifecycle Service defaults.

**Note**

CATALINA\_OPTS settings cannot be modified without restaging.
Applications must be re-pushed with new settings to apply changes.

Application Lifecycle Service sets the CATALINA\_OPTS environment variable for applications
using Tomcat automatically, based on the `mem:`
value specified for application instances. Application Lifecycle Service will always leave at
least 64MB for the heap, but will otherwise reserves up to 96MB for
overhead, that is for the code of the JVM itself, for additional
libraries loaded via JNI, for additional processes to run in the
background, and for the JVM permanent pool.

This means, for example, a 128MB application will end up with 64MB for
the heap and 64MB for overhead, a 160MB application will still have 64MB
for the heap but 96MB for overhead, and a 512MB application will get a
416MB heap and allow 96MB for overhead.

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/java/authentication/
---
<!--PUBLISHED-->
 
<!--
#Authentication With Apache jclouds and HP Helion

The `Identity Service API <https://docs.hpcloud.com/identity>`_ is central to using the
APIs for the services by HP Helion. Identity Service not only deals with authentication
but also supplies the catalog of information around the activated and available services.
For example, this API is where the API endpoints for services like the different compute regions,
Object Storage, and everything else is available.

Apache jclouds provides functionality to interact with identity service and authentication
to simply authenticate commonly and use it everywhere.
-->
#Authenticating with access key and token

By default, the authentication mechanism for all OpenStack&reg; Keystone based APIs will use your
password as the credential to log in.

The following specifications may serve as a guide if you wish to set API Access Keys:


    properties.setProperty(KeystoneProperties.CREDENTIAL_TYPE, CredentialTypes.API_ACCESS_KEY_CREDENTIALS)

You can provision `Access keys & tokens <https://community.hpcloud.com/article/understanding-hp-cloud-authentication>`_
that are scoped to services on a per-key basis and manage them individually.
To create a client that uses an access key and secret key pair,

    Properties overrides = new Properties();
    properties.setProperty(KeystoneProperties.CREDENTIAL_TYPE, CredentialTypes.API_ACCESS_KEY_CREDENTIALS)

    // Get a context with hpcloud that offers the portable BlobStore API
    BlobStoreContext context = ContextBuilder.newBuilder("hpcloud-objectstorage")
                 .overrides(overrides)
                 .credentials("tenantName:accessKey", "password")
                 .buildView(BlobStoreContext.class);
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/javascript/
---
<!--PUBLISHED-->
Developing in Javascript[](#java "Permalink to this headline")
===========================================

Whether you&#8217;re deploying an application to the HP Helion Development Platform, a
Cloud Foundry based Platform as a Service (PaaS), or writing applications that take
advantage of HP Helion OpenStack® to manage infrastructure or software services, tools
to enable successful development are available in JavaScript.

##Application Lifecycle Services
Application Lifecycle Services (ALS), a cloud foundry based Platform as a Service,
has a built in Node framework with multiple versions of the Node.js runtime.
NPM is used to install Node packages automatically.
Deploying applications to the platform is as simple as adding configuration to
a YAML configuration file and using a console application to push the application to ALS.
Management of the deployed application and its services happens through a web application or
a console application.
To learn more see:

- [Working with applications in Node](/als/v1/user/deploy/languages/node/)
- [The manifest.yml reference](/als/v1/user/deploy/manifestyml/)

##HP Helion SDK
Javascript applications can communicate directly with the [Helion APIs](ref="http://docs.hpcloud.com/api) through a REST client
or use the SDK. The SDK is designed to have a simple, well-documented API set to simplify working with the
services.
To understand how it works, here is an example of uploading and downloading from object storage:

    var pkgcloud = require(&#39;pkgcloud&#39;);
    var hpStorageClient = pkgcloud.storage.createClient({
    provider: &#39;hp&#39;,
    username: &#39;your-user-name&#39;,
    apiKey: &#39;your-api-key&#39;,
    region: &#39;region of identity service&#39;,
    authUrl: &#39;https://your-identity-service&#39; });
    hpStorageClient.upload({
     container: &#39;my-container&#39;,
     remote: &#39;remote-file-name&#39;,
     local: &#39;path/to/local/file&#39;
         },
     function(err, result) {
    if(err) {
      console.dir(err);
      return;
    }
    console.log(<span class="s2">&quot;File uploaded successfully&quot;);
    });
    hpStorageClient.download({
     container: &#39;my-container&#39;,
     remote: &#39;my-file&#39;,
     local: &#39;/path/to/my/file&#39;
       },
       function( err, result) {
    if(err) {
     console.dir(err);
     return;
    }
       console.log(<span class="s2">&quot;File downloaded successfully&quot;);
    });

The example above uploads a local file from the file system into object storage,
and downloads a file onto the local file system.
You can also work with streams for upload and download operations.

    var fs = require(&#39;fs&#39;),
    var pkgcloud = require(&#39;pkgcloud&#39;);
    var hpStorageClient = pkgcloud.storage.createClient({
    provider: &#39;hp&#39;,
    username: &#39;your-user-name&#39;,
    apiKey: &#39;your-api-key&#39;,
    region: &#39;region of identity service&#39;,
    authUrl: &#39;https://your-identity-service&#39; });
    var myFile = fs.createReadStream(&#39;/my/local/file&#39;);
    myFile.pipe(hpStorageClient.upload({
    container: &#39;my-container&#39;,
    remote: &#39;remote-file-name&#39;
    },
    function(err, result) {
    if(err) {
      console.dir(err);
      return;
    }
    ));
    var writableFile = fs.createWriteStream(&#39;/path/to/my/file&#39;);
    hpStorageClient.download({
    container: &#39;my-container&#39;,
    remote: &#39;remote-file-name&#39;
    },
    function(err, result) {
     if(err) {
       console.dir(err);
       return;
    })).pipe(writableFile);

To learn more about using the SDK:
- 
- [Getting Started with the Javascript SDK](/als/v1/user/deploy/languages/javascript/getstarted/)
- [Identity Service, Authentication, and the Service Catalog ](/als/v1/user/deploy/languages/javascript/authentication/)
- [Working With Object Storage in Javascript ](/als/v1/user/deploy/languages/javascript/objectstore/)---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/javascript/authentication/
---
<!--PUBLISHED-->
Authentication
==========================================================
The `Identity Service API <https://docs.hpcloud.com/identity>`_ is central to using the
APIs for the services by HP Helion. Identity Service not only deals with authentication
but also supplies the catalog of information around the activated and available services.
For example, this API is where the API endpoints for services like the different compute regions,
Object Storage, and everything else is available.

The HP Helion Javascript SDK provides functionality to interact with identity service and authentication
to simply authenticate commonly and use it everywhere.

Authenticating with username & password
---------------------------------------
To create a client that authenticates using your HP Public Cloud account,
specify the same login credentials as used to login to the public console.

.. code-block:: javascript

    var pkgcloud = require('pkgcloud');

    var hpClient = pkgcloud.storage.createClient({
       provider: 'hp',
       username: 'your-user-name',
       password: 'your-password',
       region: 'region-a.geo-1',
       authUrl: 'https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/'
    });



Authenticating with access key & token
---------------------------------------
You can provision `Access keys & tokens <https://community.hpcloud.com/article/understanding-hp-cloud-authentication>`_
that are scoped to services on a per-key basis and manage them individually.
To create a client that uses an access key and secret key pair,

.. code-block:: javascript

    var pkgcloud = require('pkgcloud');

    var hpClient = pkgcloud.storage.createClient({
       provider: 'hp',
       username: 'your-user-name',
       apiKey: 'your-api-key',
       region: 'region-a.geo-1',
       authUrl: 'https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/'
    });
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/javascript/getstarted/
---
<!--PUBLISHED-->
.. _get-started-javascript-sdk:

#Getting Started with the Javascript SDK

The HP Cloud Javascript library is built on top of HP Helion APIs; taking away many of the
complexities of working with the APIs to instead focus on writing applications in Nodejs.
The library is designed to be pulled into nodejs applications where, through the use of
PHP objects, methods, and functions, you can interact with HP Cloud services.

Getting The Library
-------------------
The HP Cloud Javascript Library is available on `Github <https://github.com/pkgcloud/pkgcloud>`_
and `npm <https://www.npmjs.org/package/pkgcloud>`_. npm, for those
who don't already know, is the package library for nodejs.

Using npm you can include the library by adding the following to your `package.json <https://www.npmjs.org/doc/json.html>`_ file:

.. code-block:: json

    "dependencies": {
        "pkgcloud": "~0.9.5"
    }

Run 'npm install' or 'npm update' from command line/terminal in your application
directory to download the dependency into your application.

Including The Library
-------------------------------------
To include the library in your application, include this line in your source file.

.. code-block:: javascript

    var pkgcloud = require('pkgcloud');


Debugging
^^^^^^^^^
Debugging is an important part of working with APIs.
Any client you create with createClient can emit logging events.
If you're interested in more detail from the internals of pkgcloud,
you can wire up an event handler for log events.
This will help us see the calls being made to the APIs and the responses we are getting back.

.. code-block:: javascript

  var client = pkgcloud.storage.createClient(options);
  client.on('log::*', function(message, object) {
  if (object) {
   console.log(this.event.split('::')[1] + ' ' + message)
   console.dir(object);
  }
  else {
    console.log(this.event.split('::')[1]  + ' ' + message);
  }});
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/javascript/objectstore/
---
<!--PUBLISHED-->
#Working With Object Storage in Javascript

`Object Storage <http://docs.hpcloud.com/object-storage>`_ is a web scale storage system.
It provides private and public access and is accessible through a simple API. Within
the JavaScript Library a few ways to access this Object Storage are provided.

CRUD
^^^^
Create, Read, Update, and Delete operations happen on storage objects and are fairly straight forward. For example,

.. code-block:: javascript

    var pkgcloud = require('pkgcloud');
    var fs = require('fs');

    // get an object and its content
    var fileStream  = hpStorageClient.download({
    container: 'my-container',
    remote: 'test.json' },
     function(err, result) {
    if(err){
      console.dir(err);
    }});

    var fileContents ='';
    fileStream.on('data', function(chunk){
        fileContents += chunk;
    })
    .on('end', function(){
      console.log(fileContents);
    });

    // Create an object.
    // Create a temporary file to hold the object's content.
    var contentStream = fs.createWriteStream('temp.json', { readable: true});
    contentStream.write(new Buffer ('{ name: \"M5\", type: \"bmw \"}'));
    contentStream.end();
    // create a readable stream to the content.
    contentStream = fs.createReadStream('temp.json');
    contentStream.pipe(client.upload({
        container: 'my-container',
        remote: 'my-file'
        },
        function(err, result) {
         if(err) {
          console.dir(err);
          return;
         }
        console.log("File uploaded successfully");
        // delete the temporary file.
        fs.unlinkSync('temp.json');
    }));
    // Delete an object
    client.removeFile('my-container', 'my-file', function(err, result){
      if(err) {
        console.dir(err);
        return;
      }
      console.log('object deleted successfully');
    });
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/node/
product: devplatform
---
<!--PUBLISHED-->

Developing in Node[](#node-js "Permalink to this headline")
=================================================

Application Lifecycle Service has a built in Node framework with multiple versions of the
[Node.js](http://nodejs.org/) runtime. [NPM](https://npmjs.org/) is used
to install Node packages automatically.

NPM[](#node-npm "Permalink to this headline")
----------------------------------------------

Your application should list dependencies in a standard, top-level
*package.json* file ([specs](http://npmjs.org/doc/json)). Application Lifecycle Service
automatically installs packages listed in the "dependencies" section
before starting the server.

Alternatively, you can call NPM directly using
[*hooks*](/als/v1/user/deploy/manifestyml/#hooks) in the *manifest.yml*
file. 

For NPM packages which include callable scripts or binaries, executable components are automatically added to the container's \$PATH, so a "global install" (`npm install -g`) is not required.

Host and Port Environment Variables[](#host-and-port-environment-variables "Permalink to this headline")
---------------------------------------------------------------------------------------------------------

Deploying Node applications to Application Lifecycle Service requires changing some
application settings to use instance-specific values. These values are
provided to Application Lifecycle Service using environment variables. For example, the
application is not allowed to arbitrarily choose which port it runs on.
It must use the port assigned by Application Lifecycle Service with the `PORT` variable. To access this in a node application:

    process.env.PORT

Likewise, the host IP address is exposed by `VCAP_APP_HOST`:

    process.env.VCAP_APP_HOST

To make the application usable in both local and Application Lifecycle Service deployments,
use structures such as:

    var port = process.env.PORT || 1337;
    var host = process.env.VCAP_APP_HOST || "127.0.0.1";

Using Data Services[](#using-data-services "Permalink to this headline")
-------------------------------------------------------------------------

Data services need to be configured with values from VCAP\_SERVICES, DATABASE\_URL, or a database-specific environment
variable (see also [*Using Configured Database
Services*](/als/v1/user/services/data-services/#database-accessing)).

If the database module you use supports URL-formatted connection
strings, using the
[DATABASE\_URL](/als/v1/user/services/data-services/#database-database-url)
or [*database-specific URL
variable*](/als/v1/user/services/data-services/#database-specific-url)
(REDIS\_URL, MONGODB\_URL, etc.) is often the simplest option.

Use the variable in your code to connect your application to the
database. For example:

    console.log("attempting to connect to mongodb");
    if(process.env.MONGODB_URL){
      mongoose.connect(process.env.MONGODB_URL);
    } else {
      mongoose.connect("127.0.0.1", "myappdb", 27017);
    }

`VCAP_SERVICES` is a JSON object
containing information about all the data service bound to the
application. A typical `VCAP_SERVICES` variable
containing a single MongoDB service might look like this:

    {
      "mongodb": [
        {
          "name": "todos",
          "label": "mongodb-2.4",
          "plan": "free",
          "tags": [
            "mongodb",
            "mongodb-2.4",
            "nosql"
          ],
          "credentials": {
            "hostname": "192.168.66.117",
            "host": "192.168.66.117",
            "port": 25001,
            "username": "4ce459bf-7a15-4c40-ac28-81adbdeba902",
            "password": "00a42612-9751-4d63-a758-186429d4903f",
            "name": "b89e2bc0-cae7-482c-8a47-8c816c67c62e",
            "db": "db"
          }
        }
      ]
    }

To use this information in your application code, use something similar
to this block:

    if(process.env.VCAP_SERVICES){
      var services = JSON.parse(process.env.VCAP_SERVICES);
      var dbcreds = services['mongodb'][0].credentials;
    }

    if(dbcreds){
      console.log(dbcreds);
      mongoose.connect(dbcreds.host, dbcreds.db, dbcreds.port, {user: dbcreds.username, pass: dbcreds.password});
    } else {
      mongoose.connect("127.0.0.1", "myappdb", 27017);
    }

This is the typical pattern used for all databases exposed by
VCAP\_SERVICES.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/catalyst/
---
<!--PUBLISHED-->

Catalyst[](#catalyst "Permalink to this headline")
===================================================

Catalyst is a framework for building web applications, which will run on
Application Lifecycle Service. To learn more about Catalyst, see the [Catalyst
documentation](https://metacpan.org/module/Catalyst). Also, take a look
at the Application Lifecycle Service sample apps listed below to see some working code
examples.

Home Directory[](#home-directory "Permalink to this headline")
---------------------------------------------------------------

Catalyst makes different assumptions on its Home directory depending on
whether or not it is installed in @INC. It makes this distinction based
on the presence of a *Makefile.PL* or *BUILD.PL* file in the app
directory, so it is important to have one even if all prerequisites are
installed via *requirements.txt*.

Alternatively, the Home directory can be [set
explicitly](https://metacpan.org/module/Catalyst#Home) with environment
variables. For example, you could set CATALYST\_HOME in *manifest.yml*:

    env:
      CATALYST_HOME: $HOME

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   [Catalyst Tutorial
    2](https://github.com/Stackato-Apps/catalyst-tut2): Sample
    application from chapter 2 of the Catalyst-Manual.
-   [Catalyst Tutorial
    3](https://github.com/Stackato-Apps/catalyst-tut3): Another Catalyst
    tutorial.
-   [Catalyst Hello
    World](https://github.com/Stackato-Apps/catalyst-welcome): A simple
    Catalyst example.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/cgiapppsgi/
---
<!--PUBLISHED-->

CGI::Application::PSGI[](#cgi-application-psgi "Permalink to this headline")
=============================================================================

An app using the CGI::Application::PSGI framework needs an *app.psgi*
and *requirements.txt* file.

In the *requirements.txt* file, list any module requirements, with at
least:

    CGI::Application::PSGI
    Plack::Builder

In the *app.psgi* file, the basic code will be something like:

    #perl

    use lib "lib";

    use strict;
    use Plack::Builder;
    use CGI::Application::PSGI;
    use AppCore;

    my $handler = sub {
      my $env = shift;
      my $app = AppCore->new({ QUERY => CGI::PSGI->new($env) });
      CGI::Application::PSGI->run($app);
    };

    builder {
      enable 'Plack::Middleware::ContentLength';
      $handler;
    };

In the above example, AppCore.pm is located in the local lib folder and
handles processing of the data and the response as per the
[CGI::Application](http://search.cpan.org/~markstos/CGI-Application-4.50/lib/CGI/Application.pm)
documentation.

**Note**

The `Plack::Middleware::ContentLength` code adds the
Content-Length header which is currently required for Perl apps under
Application Lifecycle Service.

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   [Rubric](https://github.com/Stackato-Apps/rubric): The winning entry from our Application Lifecycle Service contest.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/dancer/
---
<!--PUBLISHED-->

Dancer[](#dancer "Permalink to this headline")
===============================================

An app using the Dancer framework needs an *app.psgi* and
*requirements.txt* file.

In the *requirements.txt* file, list any module requirements, with at
least:

    Dancer
    Plack::Request
    YAML

In the *app.psgi* file, for a simple implementation:

    use Dancer;
    get '/' => sub { "hello world!" };
    dance;

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   [Dancer Hello
    World](https://github.com/Stackato-Apps/dancer-helloworld): Hello
    World sample.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/
---
<!--PUBLISHED-->

Perl {#perl}
===========================================

Perl applications deployed to Application Lifecycle Service using the default 'perl'
framework are run with [PSGI](http://plackperl.org/). Applications are
started from a top-level script which must be called `app.psgi`. For
example, in the
[mojo-helloworld](https://github.com/Stackato-Apps/mojo-helloworld)
sample application:

    $ENV{MOJO_MODE} = 'production';
    require 'app.pl';

**Note**

Both Dancer and Mojolicious scripts automatically use the PSGI protocol,
so there is no need to create a separate app.psgi for them.

The script is a pointer to the actual application,
[app.pl](https://github.com/Stackato-Apps/mojo-helloworld/app.pl). You
could rename `app.pl` to `app.psgi` instead, but using the approach above
allows you to set PSGI-specific configurations in a separate file.

It is possible to [*serve static files with
uWSGI*](#uwsgi-perl-static-files).

The [*perlcgi*](/als/v1/user/deploy/languages/perl/perlcgi/#perlcgi) framework is also available for
running traditional Perl CGI applications without PSGI.

Deploying Applications[](#deploying-applications "Permalink to this headline")
-------------------------------------------------------------------------------

The following is a list of pages with details for deploying various
application types.

-   [CGI::Application::PSGI](/als/v1/user/deploy/languages/perl/cgiapppsgi/)
-   [Perl CGI](/als/v1/user/deploy/languages/perl/perlcgi/)
-   [Catalyst](/als/v1/user/deploy/languages/perl/catalyst/)
-   [Mason](/als/v1/user/deploy/languages/perl/mason/)
-   [Mojolicious](/als/v1/user/deploy/languages/perl/mojo/)
-   [Dancer](/als/v1/user/deploy/languages/perl/dancer/)

Database Services[](#database-services "Permalink to this headline")
---------------------------------------------------------------------

Authentication details for your configured database services can be
found in the `$ENV` variable, under
`DATABASE_URL` or `VCAP_SERVICES`. Here is an example of getting the correct credentials.

### MYSQL\_URL[](#mysql-url "Permalink to this headline")

    my($user,$password,$host,$port,$name) = $ENV{MYSQL_URL} =~ m{mysql://(.+?):(.+)\@(.+?):(\d+)/(.*)}
        or die "MySQL service not configured";
    print $host;
    print $name;
    print $password;
    print $port;
    print $user;

### VCAP\_SERVICES[](#vcap-services "Permalink to this headline")

    use DBI;
    use DBD::mysql;
    use JSON "decode_json";

    if ($ENV{VCAP_SERVICES}) {
        # Extract and convert the JSON string in the VCAP_SERVICES environment variable
        my $vcap_services = decode_json ($ENV{VCAP_SERVICES});

        # Get the database credentials
        my $cred = $vcap_services->{mysql}[0]{credentials};

        # Use the credentials to form whatever connection string your database interface requires
        my $dbh = DBI->connect("DBI:mysql:database=$cred->{name};hostname=$cred->{hostname};port=$cred->{port};",
                               $cred->{user}, $cred->{password})
            or die "Unable to connect: $DBI::errstr\n";
    }
    else {
        # No VCAP_SERVICES environment variable.  Use other connection.
        my $dbh = DBI->connect("DBI:mysql:database=mydb;hostname=127.0.0.1;port=3306;",
                               "username", "password")
            or die "Unable to connect: $DBI::errstr\n";
    }

Worker Applications[](#worker-applications "Permalink to this headline")
-------------------------------------------------------------------------

Non-HTTP apps that run as an Application Lifecycle Service application under the control of
the Health Manager.

To deploy worker applications, you need to use the
[*command*](/als/v1/user/deploy/manifestyml/#command) key and set the
[*processes:
web*](/als/v1/user/deploy/manifestyml/#web) key to
Null ("\~").

### Example[](#example "Permalink to this headline")

    name: perl-app
    framework: perl
    command: perl worker.pl
    processes:
      web: ~

Installing module dependencies[](#installing-module-dependencies "Permalink to this headline")
-----------------------------------------------------------------------------------------------

If the modules your app needs are available via PPM or CPAN, let
Application Lifecycle Service install them and their dependencies using one of the following
methods rather than including them in the source tree of your
application code.

### CPAN Modules via PPM[](#cpan-modules-via-ppm "Permalink to this headline")

[PPM](http://code.activestate.com/ppm) is the binary package manager for
ActivePerl. It is usually the fastest and most reliable way of
installing CPAN modules in the Application Lifecycle Service application droplet. Current
versions of most CPAN modules and frameworks are available.

Modules required by your app can be specified by adding a
`requirements:` section to the
[*manifest.yml*](/als/v1/user/deploy/manifestyml/) file. For example:

    requirements:
      ppm:
        - CGI::Application::PSGI
        - Plack::Builder
        - Data::Dumper
        - JSON
        - JSON::Parse
        - DBI
        - DBD::mysql

**Note**

If you want to use cpan to download the modules, change `ppm:` to `cpan:`.

Alternatively, include a top-level *requirements.txt* file. The
requirements.txt for a minimal Mojolicious app would be just:

    Mojolicious

Prerequisite modules for the framework are installed automatically.

For a simple Dancer application:

    Dancer
    YAML
    Plack::Request

Custom modules that are included within the project can be used in the
normal method:

    use lib "lib";
    use MyCustomPM;

Any non-core dependencies required by these custom modules should be
specified explicitly in *requirements.txt*, *manifest.yml* or
*Makefile.PL* (see below) otherwise those dependencies will not be
packed in the application droplet.

### CPAN Modules via cpanm[](#cpan-modules-via-cpanm "Permalink to this headline")

If the module you require is not available in the HP PPM
repositories, or if you need a
specific version (PPM provides only the current release), you can use
[cpanm](http://search.cpan.org/dist/App-cpanminus/bin/cpanm) to install
them. Any dependencies included in ActivePerl or installed by PPM will
be reused rather than being rebuilt.

You can specify modules for installation via `cpanm`
by including them in one of the following files:

#### manifest.yml {#manifest-yml}

Add a `cpan:` section to *manifest.yml* that
specifies version conditions, requests a module via HTTP URL, or fetches
a branch from a git repo. For example:

    requirements:
      cpan:
        - Mojolicious~">=3.0, <3.50"
        - git://github.com/doy/try-tiny.git@Try-Tiny-0.09
        - http://www.cpan.org/authors/id/G/GA/GAAS/Data-Dump-1.20.tar.gz

This example installs a version of Mojolicious equal or later than 3.0,
but prior to 3.50. Since no such version exists on CPAN, it is fetched
from the BackPAN archive. It then installs the Try-Tiny-0.09 tag from
the try-tiny.git repository (could also be a branch or commit name), and
finally installs Data-Dump-1.20.tar.gz from an absolute download URL.

#### Makefile.PL[](#makefile-pl "Permalink to this headline")

[Makefile.PL](https://metacpan.org/module/ExtUtils::MakeMaker::Tutorial)
is a standard format for specifying dependencies in Perl modules.
Application Lifecycle Service will use this if there is no *cpanfile* or *carton.lock* file.

#### cpanfile[](#cpanfile "Permalink to this headline")

The
[cpanfile](https://metacpan.org/module/MIYAGAWA/Module-CPANfile-0.9031/lib/cpanfile.pod)
format is preferable for Perl web applications, as *Makefile.PL* is
generally intended for Perl modules. It allows for more elaborate
specification of module dependencies (see the [cpanfile
SYNOPSIS](https://metacpan.org/module/MIYAGAWA/Module-CPANfile-0.9031/lib/cpanfile.pod#SYNOPSIS)
for more information).

#### carton.lock[](#carton-lock "Permalink to this headline")

The [carton](https://metacpan.org/module/Carton) module dependency
manager is similar in concept to Ruby's Bundler.

To use it, first install carton locally using `ppm`
or `cpanm`.

Run the `carton install` command in the base
directory of an application with a *cpanfile*. This installs the modules
locally and creates a *carton.lock* file.

If you want to include modules which are not in a public CPAN
repository, run `carton bundle` to add the source
packages in a *local/cache* sub-directory of the application. Application Lifecycle Service
will install those modules from the cached files.

#### Disable Testing[](#disable-testing "Permalink to this headline")

Disabling tests in cpanm can decrease staging times for applications
with numerous module dependencies, especially if those dependencies have
large test suites.

To disable testing for cpanm in staging, set
[PERL\_CPANM\_OPT](http://search.cpan.org/dist/App-cpanminus/bin/cpanm#OPTIONS)
to '--notest' in [*manifest.yml*](/als/v1/user/deploy/manifestyml/):

    name: myapp
    env:
      PERL_CPANM_OPT: --notest

#### Custom CPAN Mirror[](#custom-cpan-mirror "Permalink to this headline")

To make cpanminus use a specific CPAN repository (e.g. a local mirror or
private repo), instead of the default public ones, set the
`--mirror` and `--mirror-only`
options in PERL\_CPANM\_OPT:

    env:
      PERL_CPANM_OPT: --mirror http://cpan.example.com --mirror-only

Serving Static Files with uWSGI[](#serving-static-files-with-uwsgi "Permalink to this headline")
-------------------------------------------------------------------------------------------------

It is possible to serve static files with uWSGI using
`processes: web:` in the
[*manifest.yml*](/als/v1/user/deploy/manifestyml/) file to specify
folders that will be served statically and not by the app.

To make a single folder serve statically, use `--check-static`:

    processes:
        web: $HELION_UWSGI --check-static $HOME/<folder>

To specify multiple folders with static files that do not share a common
root, use `--static-map`:

    processes:
        web: $HELION_UWSGI --static-map /foo=$HOME/static --static-map /bar=$HOME/sub

In this case */foo/index.html* would serve *\$HOME/static/index.html*,
and */bar/index.html* would serve *\$HOME/sub/index.html*. If the file
doesn't exist, then uWSGI will forward the request to the app.

**Note**

Serving static files via uWSGI is only available for Perl and Python
frameworks.

Runtime[](#runtime "Permalink to this headline")
-------------------------------------------------

Application Lifecycle Service deploys Perl applications with [ActivePerl
5.14](http://docs.activestate.com/activeperl/5.14/).

Troubleshooting[](#troubleshooting "Permalink to this headline")
-----------------------------------------------------------------

### General[](#general "Permalink to this headline")

If your application fails to stage or launch successfully, use the
helion logs command to check the stdout and stderr logs.

If there are no helpful messages in those files, there are two
additional log files (staging.log and ppm4.log) which can be accessed
with the helion files command:

    $ helion files myapp logs/staging.log
    $ helion files myapp logs/ppm4.log

### Other Issues[](#other-issues "Permalink to this headline")

**Problem**
:   Application installs but the result is an empty window.
**Possible Resolutions**
:   Perl apps require the Content-Length header to be set in order for
    pages to display correctly. Some frameworks handle this already,
    while for others it needs to be done specifically.

    If you are using CGI::Application::PSGI, add the following to your
    app.psgi file:

        use Plack::Builder;

        ...

        builder {
                ...
                enable 'Plack::Middleware::ContentLength';
                ...
        };

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

Several Perl samples are available in
[Application Lifecycle Service-Apps](https://github.com/Stackato-Apps) on GitHub.

-   [Mojo Scaling
    Demo](https://github.com/Stackato-Apps/mojo-scalingdemo)
-   [Retester](https://github.com/Stackato-Apps/retester)
-   [PhotoBooth](https://github.com/Stackato-Apps/photobooth)
-   [Perl Critic](https://github.com/Stackato-Apps/perlcritic.com)
-   [Bugzilla](https://github.com/Stackato-Apps/bugzilla)

---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/mason/
---
<!--PUBLISHED-->

Mason[](#mason "Permalink to this headline")
=============================================

Mason is a templating system that can handle web requests directly via
PSGI, or act as the view layer for web frameworks such as Catalyst or
Dancer. In the example below, it is used on its own to create a simple
application.

A basic files needed to create an app using Mason are:

1.  *app.psgi*
2.  *requirements.txt*
3.  *manifest.yml*

Template files are also needed, which you can read about in the Mason
documentation, or in our [Hello World sample
app](https://github.com/Stackato-Apps/mason-helloworld).

In the *requirements.txt* file, list any module requirements, with at
least:

    Mason
    Plack::Builder
    Mason::Plugin::PSGIHandler
    Plack::Middleware::ReverseProxy

In the *app.psgi* file:

    #!/usr/bin/perl
    use Cwd qw(realpath);
    use File::Basename;
    use Mason;
    use Plack::Builder;
    use warnings;
    use strict;

    # Include Mason plugins here
    my @plugins = ('PSGIHandler');

    # Create Mason object
    my $cwd = dirname( realpath(__FILE__) );
    my $interp = Mason->new(
            comp_root => "$cwd/comps",
            data_dir  => "$cwd/data",
            plugins   => \@plugins,
    );

    # PSGI app
    my $app = sub {
            my $env = shift;
            $interp->handle_psgi($env);
    };

    builder {
            # Include PSGI middleware required for Application Lifecycle Service
            enable "Plack::Middleware::ContentLength";
            enable "Plack::Middleware::ReverseProxy";
            $app;
    };

The *manifest.yml* file contains deployment instructions for Application Lifecycle Service. See complete details for this file in the [*Configuration With manifest.yml*](/als/v1/user/deploy/manifestyml/) section.

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   [Mason Hello
    World](https://github.com/Stackato-Apps/mason-helloworld): Hello
    World sample.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/mojo/
---
<!--PUBLISHED-->

Mojolicious[](#mojolicious "Permalink to this headline")
=========================================================

Mojolicious is a web framework with a native PSGI interface which is
easy to build and run on Application Lifecycle Service.

A simple app using the Mojolicious framework needs four files:

1.  *app.psgi*
2.  *app.pl*
3.  *requirements.txt*
4.  *manifest.yml*

In the *requirements.txt* file, list any module requirements, with at
least:

    Mojolicious

In the *app.psgi* file, for a simple implementation:

    $ENV{MOJO_MODE} = 'production';
    require 'app.pl';

The *app.pl* file contains the core functionality:

    use Mojolicious::Lite;

    # Simple response to display Environment Variables.
    get '/' => sub {
            my $self = shift;
            $self->render_text(join("<br>", map "$_=$ENV{$_}", sort keys %ENV));
    };

    app->start;

The *manifest.yml* file contains deployment instructions for Application Lifecycle Service.
See complete details for this file in the [*Configuration With
manifest.yml*](/als/v1/user/deploy/manifestyml/) section.

Examples[](#examples "Permalink to this headline")
---------------------------------------------------

-   [Mojo Hello
    World](https://github.com/Stackato-Apps/mojo-helloworld): the
    simplest possible Mojolicious demo.
-   [Mojo Photobooth](https://github.com/Stackato-Apps/photobooth):
    Mojolicious webapp to emulate public photobooths.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/perl/perlcgi/
---
<!--PUBLISHED-->

Perl CGI[](#perl-cgi "Permalink to this headline")
===================================================

The 'perlcgi' framework can be used to run *any* CGI script, but (like
the [*perl*](index.html#perl-index) framework) it provides ActivePerl in
the default PATH and supports module installation via
[*PPM*](index.html#perl-ppm) and [*cpanm*](index.html#perl-cpanm).

Unlike the 'perl' framework, setting the
[*start-file*](/als/v1/user/deploy/manifestyml/#start-file) option
has no effect, as there is no permanently running application. A new
instance of a CGI script is started for each request.

Perl scripts deployed with this framework should begin with:

    #!/usr/bin/env perl

Example[](#example "Permalink to this headline")
-------------------------------------------------

-   [perlcgi-env](https://github.com/Stackato-Apps/perlcgi-env): A
    simple Perl CGI script that displays environment variables.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/php/
---
<!--PUBLISHED-->

#Developing In PHP
Whether you're deploying an application to the HP Helion Development Platform, a
Cloud Foundry based Platform as a Service (PaaS), or writing applications that take
advantage of HP Helion OpenStack® to manage infrastructure or software services, tools
to enable successful development are available in PHP.

For more information on working with object storage, 
see the [HP Helion OpenStack® Object Storage Service Overview](/helion/openstack/services/object/overview/).

For more information on authentication, see [Identity Service, Authentication, and the Service Catalog](/als/v1/user/deploy/languages/php/authentication/).

##Application Lifecycle Services
Application Lifecycle Service (ALS) provides a means to execute PHP applications on a managed platform, controlling application lifecycle through a PaaS tier. Deploying
applications to this platform is as easy as adding details to a YAML configuration file and using
a console application to push the application to ALS.
At its simplest form, the configuration file *manifest.yml*, which is located at the root of a project, 
would look like:
<div class="highlight-none"><div class="highlight"><pre>name: php-web-app
framework:
    type: php
</pre></div>
</div>
This will set the ALS framework type for a PHP web application.

To create a worker non-http application set the web process to <strong>null</strong> (~) and specify
the command to <strong>run</strong>. For example:
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">php-app</span>
<span class="l-Scalar-Plain">framework</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">php</span>
<span class="l-Scalar-Plain">command</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">php worker.php</span>
<span class="l-Scalar-Plain">processes</span><span class="p-Indicator">:</span>
    <span class="l-Scalar-Plain">web</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">~</span>
</pre></div>
</div>
Management of the deployed application and its services happens through a web application or
a console application. To learn more see the [manifest.yml](als/v1/user/deploy/manifestyml/) reference</a>.


Deployment[](#deployment "Permalink to this headline")
-------------------------------------------------------

You will need at least two files to deploy a PHP app on Application Lifecycle Service:
*index.php*, and *manifest.yml*.

The *manifest.yml* must specify **php** as the framework type:

    framework:
            type: php

For more information, see the [manifest.yml](als/v1/user/deploy/manifestyml/) reference.

Application URL[](#application-url "Permalink to this headline")
-----------------------------------------------------------------

Some applications require the user to specify the APP\_URL. Below is an
example on how to obtain the correct urls:

    $appinfo = getenv("VCAP_APPLICATION");
    $appinfo_json = json_decode($appinfo,true);
    $admin = $appinfo_json['uris'][0];

Worker Applications[](#worker-applications "Permalink to this headline")
-------------------------------------------------------------------------

Non-HTTP apps that run as an Application Lifecycle Service application under the control of
the Health Manager.

To deploy worker applications, you need to use the
[*command*](/als/v1/user/deploy/manifestyml/#command) key and set the
[*processes: web*](als/v1/user/deploy/manifestyml/#web)
key to Null ("\~").

### Example[](#example "Permalink to this headline")

    name: php-app
    framework: php
    command: php worker.php
    processes:
      web: ~

Database Services[](#database-services "Permalink to this headline")
---------------------------------------------------------------------

### [DATABASE\_URL](/als/v1/user/services/data-services/#database-url/)

Authentication details for your configured database services can be
found in the **$\_SERVER** variable, under 
**DATABASE_URL**. Here is a sample for retrieving the correct credentials:

    <?php
        $url_parts = parse_url($_SERVER['DATABASE_URL']);
        $db_name = substr( $url_parts['path'], 1 );
        $db_connection_string = $url_parts['host'] . ':' . $url_parts['port'];

        // ** MySQL settings from resource descriptor ** //
        echo $db_name;
        echo $url_parts['user'];
        echo $url_parts['pass'];
        echo $url_parts['host'];
        echo $url_parts['port'];
    ?>

### [VCAP\_SERVICES](/als/v1/user/services/data-services/#vcap-services/)

    <?php
        $services = getenv("VCAP_SERVICES");
        $services_json = json_decode($services,true);
        $mysql_config = $services_json["mysql"][0]["credentials"];

        // ** MySQL settings from resource descriptor ** //
        echo $mysql_config["name"];
        echo $mysql_config["user"];
        echo $mysql_config["password"];
        echo $mysql_config["hostname"];
        echo $mysql_config["port"];
        );
    ?>

PHP.ini[](#php-ini "Permalink to this headline")
-------------------------------------------------

Additional PHP ini files will be loaded from the
`$HELION_APP_ROOT/apache/php/` directory. Refer to
the example below for more information.

Document Root Access[](#document-root-access "Permalink to this headline")
---------------------------------------------------------------------------

If your document root (the location of the main *index.php* file) is the
main application directory, the information stored in 
*manifest.yml* is exposed to the browser.

To prevent exposing this information, you can use an *.htaccess* file in
the document root directory with the following rule:

    <filesmatch "^(manifest)\.yml$">
      order allow,deny
      deny from all
    </filesmatch>

Alternatively, move your application into a subdirectory (e.g. move
*index.php* to *www/index.php*) and explicitly set your document-root in
*manifest.yml*:

    framework:
      document-root: www

Using the *.htaccess* file will generate an "HTTP 403 Forbidden" error
if a user tries to access the denied files. Changing the document-root
will generate an "HTTP 404 Not Found" error instead.

These techniques can be use to hide other files in your application
source tree which you do not want exposed to end users.

SERVER\_NAME & SERVER\_PORT[](#server-name-server-port "Permalink to this headline")
-------------------------------------------------------------------------------------

Application Lifecycle Service serves web applications port 80 and/or 443 at the router, but
within the application container Apache will be running on a different
port. PHP will report this internal IP address and port in the
SERVER\_ADDR and SERVER\_PORT Apache environment variables respectively.

If your application makes use of these variables, you may need to adjust
them by using an [.htaccess
file](http://httpd.apache.org/docs/current/howto/htaccess) to set
one or more
[RewriteRule](http://httpd.apache.org/docs/current/mod/mod_rewrite.html#rewriterule)
directives to correct the server name or port in URLs.

Persistent Sessions (PHP)[](#persistent-sessions-php "Permalink to this headline")
-----------------------------------------------------------------------------------

One of the issues with managing a PHP application running multiple
instances is dealing with user sessions.

If your application uses a [*shared filesystem
service*](/als/v1/user/services/filesystem/#persistent-file-system), you
can store user sessions there. The following *manifest.yml* snippet
creates a persistent filesystem service, creates a directory for
sessions, and writes a PHP config file to set the path to the session
directory:

    services:
      ${name}-fs: filesystem
    hooks:
      post-staging:
      - mkdir -p "$HELION_FILESYSTEM"/sessions
      - echo "session.save_path = $HELION_FILESYSTEM/sessions" > "$HELION_APP_ROOT"/apache/php/sessions.ini

For better performance, use a
[*Memcached*](/als/v1/user/services/memcached/#memcached) service for
session storage instead:

    services:
      ${name}-cache: memcached
    hooks:
      post-staging:
      - echo "session.save_handler = memcached" > "$HELION_APP_ROOT"/apache/php/sessions.ini
      - echo "session.save_path = $MEMCACHE_URL" >> "HELIONO_APP_ROOT"/apache/php/sessions.ini

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/php/authentication/
---
<!--PUBLISHED-->
#Identity Service, Authentication, and the Service Catalog

The [Identity Service API](https://docs.hpcloud.com/identity) is central to using the
APIs for the services by HP Helion. Identity Service not only deals with authentication
but also supplies the catalog of information around the activated and available services.
For example, this API is where the API endpoints for services like the different compute regions,
Object Storage, and everything else is available.

The HP Helion PHP SDK provides functionality to interact with identity service and authentication
at a low level or, through the use of helpers, simply authenticate commonly and use it everywhere.

Authentication and Tokens
-------------------------
The first step is authenticating as a user and there are two ways to do this. The first
option is to use the username and password used to log into the console. The second
option is to use an access key id and secret key available on the API Keys page within the console.

Since services are associated with tenants you need to use a tenantId or tenantName to
get a valid token for a set of services.

Before you look at the helper function let's take a quick look at authenticating manually.

    $identity = new \HPCloud\Services\IdentityServices($endpoint);
    try {
        $token = $identity->authenticateAsAccount($account, $secret, $tenantId, $tenantName);
    }
    catch (\Exception $e) {
        // Authentication failed.
    }

This example authenticates as an account with an access key id and secret key. Only
the tenantId or tenantName needs to be supplied as the other is optional. If authentication
passed, the identity object is authenticated and a token is returned.

If authentication failed or there was another error an exception is thrown. There are a
number of exceptions that can be caught depending on the type of error that occurred.

If you want to authenticate as a user with your console username and password it looks
almost the same as authenticating as an account.

    $identity = new \HPCloud\Services\IdentityServices($endpoint);
    try {
        $token = $identity->authenticateAsUser($username, $password, $tenantId, $tenantName);
    }
    catch (\Exception $e) {
        // Authentication failed.
    }

Note that while you **can** authenticate with a username and password, we recommend using the access key id and secret key method.

###A Bootstrap Identity Helper


If the bootstrap mechanism to setup any global options was used there is a helper
function to get an identity object. For example:

    <?php
    require_once 'vendor/autoload.php';
    use \HPCloud\Bootstrap;
    // Provide credentials
    $settings = array(
        'account' => YOUR_ACCESS_KEY_ID,
        'secret' => YOUR_SECRET_KEY,
        'tenantid' => YOUR_TENANT_ID,
        'endpoint' => IDENTITY_SERVICES_URL,
    );
    Bootstrap::setConfiguration($settings);

Using the helper method identity an identity object is available.


    $identity = Bootstrap::identity();


This object will be authenticated with the credentials provided to the bootstrap.

##The Service Catalog
The service catalog lists the available services. Accessing the catalog, which includes
the API endpoints, is fairly simple through the use of the serviceCatalog method. To
get the entire catalog call the method with no arguments.

    $identity = Bootstrap::identity();
    $catalog = $identity->serviceCatalog();

Calling the serviceCatalog method with the name of a service will return the service
catalog for just this service.

    $identity = Bootstrap::identity();
    $catalog = $identity->serviceCatalog('object-store');

####OpenStack trademark attribution
*The OpenStack Word Mark and OpenStack Logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.*---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/php/objectstore/
---
<!--PUBLISHED-->

#Working With Object Storage in PHP

`Object Storage <http://docs.hpcloud.com/object-storage>`_ is a web scale storage system.
It provides private and public access and is accessible through a simple API. Within
the PHP Library a few ways to access this Object Storage are provided.

Stream Wrappers
---------------
The simplest method to access object storage is through stream wrappers and there are
currently provide two of them. To setup the stream wrappers is fairly simple.

.. code-block:: php

    <?php
    require_once 'vendor/autoload.php';
    use \HPCloud\Bootstrap;
    Bootstrap::useStreamWrappers();

    // Provide credentials
    $settings = array(
      'username' => YOUR_USERNAME,
      'password' => YOUR_PASSWORD,
      'tenantid' => YOUR_TENANT_ID,
      'endpoint' => IDENTITY_SERVICES_URL,
    );

    Bootstrap::setConfiguration($settings);

This example includes the bootstrap, sets up the autoloader, enables the stream wrappers,
and provides the credentials to use.

Calling ``Bootstrap::useStreamWrappers()`` sets up the ``swift`` and ``swiftfs`` stream wrappers.
According to the PHP Stream Wrapper documentation a stream should only implement the features
used. This is what the swift stream wrapper provides. Since there are use cases to treat a
container like a file system and, technically speaking, object storage doesn't support all
those features the ``swiftfs`` stream was created to mimic those features.

To access a file with stream wrappers registered the existing file system utilities can be used. For example:

.. code-block:: php

    $newfile = fopen('swift://mycontainer/foo.txt', 'w');
    fwrite($newfile, "Hello World!");
    fclose($newfile);

The new file can then be read:

.. code-block:: php

    print file_get_contents('swift://mycontainer/foo.txt');

In this case the ``swift`` stream wrapper was used. ``mycontainer`` is the name of the container and
``foo.txt`` is the name of the file stored in the container. Just like a local file it can be opened,
read, write to, and deleted.

Using The PHP Library Internals
-------------------------------
The stream wrappers are powered by a lower level API that can be used. It starts with identity services.

.. code-block:: php

    use \HPCloud\Bootstrap;
    use \HPCloud\Storage\ObjectStorage;

    $identity = Bootstrap::identity();
    $storage = ObjectStorage::newFromIdentity($identity);

``ObjectStorage::newFromIdentity`` is a factory for creating ``ObjectStorage`` objects from identities.
There are other factories that can be used as well.

From here a container can be accessed. For example,

.. code-block:: php

    $container = $storage->container('mycontainer');

The following snippet obtains a file (a.k.a object) from within a container:

.. code-block:: php

    try {
        $object = $container->proxyObject('foo.txt');
    }
    catch (\HPCloud\Transport\FileNotFoundException $nf) {
        // React because the requested object was not found.
    }
    catch (\HPCloud\Exception $e) {
        // Uh-oh, we have a problem.
    }

When fetching objects there are two methods to use in proxyObject and object. The object
method returns a full object with all of its contents. For large files this can take some time.
If you don't need the content or don't know if you will we have the proxyObject method that
grabs the meta data around an object without grabbing the content immediately. If a call is
made for the content it will be loaded at that time.

Creating New Objects
^^^^^^^^^^^^^^^^^^^^
When objects are retrieved from storage they are the class ``\HPCloud\Storage\ObjectStorage\RemoteObject``.
When a new local object it created it is done with the class ``\HPCloud\Storage\ObjectStorage\Object``.
Creating a new object looks like:

.. code-block:: php

    use \HPCloud\Storage\ObjectStorage\Object;
    $object = new Object('bar.txt');
    $object->setContent('Hello World!', 'text/plain');

When using ``setContent`` the MIME type can optionally be set as the as the second parameter.
This can be done later using ``setContentType``. The file is saved through the container object. For example,

.. code-block:: php

    $container->save($object);

CRUD
^^^^
Create, Read, Update, and Delete operations happen on container objects and are fairly simple. For example,

.. code-block:: php

    // Get an object and its content
    $object = $container->proxyObject('foo.txt');
    print $object->content();

    // Create/Update an object
    $container->save($object);

    // Delete an object
    $container->delete('bar.txt');
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/powershell/

---
<!--PUBLISHED-->
#HP Helion Public Cloud CLI Software for Windows PowerShell
Welcome to the Quick Start Page for the Helion PowerShell Environment. 

The Helion PowerShell Tool is a set of PowerShell Cmdlets and Providers that enable users to manage their OpenStack&reg; Services from the command line in Windows.

* To Install the PowerShell CLI take a look at the [Installation Guide](http://docs.hpcloud.com/cli/windows/installation)

* Need help with a Cmdlet? Check out the [Command Line Reference](http://docs.hpcloud.com/cli/windows/reference)
* [Release Notes](http://docs.hpcloud.com/cli/windows/release-notes/)---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/python/django/
---
<!--PUBLISHED-->
#Deploying Django applications


Your app needs a top-level *wsgi.py* file with a global variable named
`application` that refers to your Django WSGI
application. The file should already exist in the Django project,
although a copy of it needs to be in the root directory in order for
Application Lifecycle Service to recognize it.

    $ django-admin.py startproject dj14
    $ cd dj14
    $ cp dj14/wsgi.py wsgi.py

Typically, the *wsgi.py* file is just three lines of code:

    import os
    import django.core.handlers.wsgi
    application = django.core.handlers.wsgi.WSGIHandler()

Your project must also have a *requirements.txt* file containing at
least the `django` project:

    $ cat requirements.txt
    django==1.4
    mysql-python

Configuring the Database[](#configuring-database "Permalink to this headline")
---------------------------------------------------------------------------
See [*Using Configured Database Services*](/als/v1/user/services/data-services/#database-accessing) for more information on connecting with database services.

1. You must modify the `DATABASES` variable of your project's *settings.py* as shown below to detect the database service provisioned by helion:

        import urlparse
        DATABASES = {}
        if 'DATABASE_URL' in os.environ:
                url = urlparse.urlparse(os.environ['DATABASE_URL'])
                DATABASES['default'] = {
                        'NAME': url.path[1:],
                        'USER': url.username,
                        'PASSWORD': url.password,
                        'HOST': url.hostname,
                        'PORT': url.port,
                        }
                if url.scheme == 'postgres':
                        DATABASES['default']['ENGINE'] = 'django.db.backends.postgresql_psycopg2'
                elif url.scheme == 'mysql':
                        DATABASES['default']['ENGINE'] = 'django.db.backends.mysql'
        else:
                DATABASES['default'] = {
                        'ENGINE': 'django.db.backends.mysql',
                        'NAME': 'dev.db',
                        'USER': '',
                        'PASSWORD': '',
                        'HOST': '', # Set to empty string for localhost.
                        'PORT': '', # Set to empty string for default.
                        }



    **Note**: In the future, this may be automatically written to *local\_settings.py* (similar to ep.io and others)

2.  Then add a new dependency to *requirements.txt*:

        $ echo 'mysql-python' >> requirements.txt

### Initializing database[](#initializing-database "Permalink to this headline")

Run the `syncdb` command to initialize the database
tables:

    $ helion run <appname> python manage.py syncdb

If you use a data migration library such as
[South](http://south.aeracode.org/), also run:

    $ helion run <appname> python manage.py migrate

Configuring static media[](#configuring-static-media "Permalink to this headline")
-----------------------------------------------------------------------------------

There are various ways to serve static files for a Django application. While Option \#1 is the most recommended for production deployments, option \#3 is the simplest for non-production/development/test/QA deployments.

1.  Directly serve static files with uWSGI. See [*Serving static files with uWSGI*](index.html#uwsgi-python-static-files) for details. or:
2.  Use `django.contrib.staticfiles`, which is
    included by default in Django 1.3. Read the [Django
    documentation](https://docs.djangoproject.com/en/1.3/howto/static-files/#using-django-contrib-staticfiles)
    to understand the steps involved, or take a look at [this
    commit](https://github.com/ActiveState/stackato-samples/commit/59ec0791)
    in the django-gtd sample app. or:
3.  Set `DEBUG=True` in settings.py. This is not
    recommended for production applications.

Configuring project location[](#configuring-project-location "Permalink to this headline")
-------------------------------------------------------------------------------------------

Your project's *settings.py* may not always reside at the root directory. Furthermore, you may want to extend
`sys.path` to point to certain project sub-directories.

To persist such environment changes (across wsgi.py, settings.py, manage.py, etc.), add the following to manifest.yml:

    env:
      DJANGO_SETTINGS_MODULE: myproject.settings
      PYTHONPATH: myproject

This assumes that your Django project lives under the *myproject/* sub-directory.---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/python/
---
<!--PUBLISHED-->

<h1>Developing In Python<a class="headerlink" href="#developing-in-python" title="Permalink to this headline"></a></h1>
<p>Whether you&#8217;re deploying an application to the HP Helion Development Platform, a
Cloud Foundry based Platform as a Service (PaaS), or writing applications that take
advantage of HP Helion OpenStack® to manage infrastructure or software services, tools
to enable successful development are available in Python.</p>
<div class="section" id="application-lifecycle-services">
<h2>Application Lifecycle Services<a class="headerlink" href="#application-lifecycle-services" title="Permalink to this headline"></a></h2>
<p>Application Lifecycle Services (ALS), a CloudFoundry-based Platform as a
Service, provides a means to execute Python applications on a managed platform.
Deploying Python applications to the platform is normally done using a built-in
<a class="reference external" href="https://github.com/ActiveState/stackato-buildpack-python">Python buildpack</a>.
In order to deploy an application user a Python buildpack, you will need the
following at the top level of your application:</p>
<ul class="simple">
<li>A Procfile with the command to run the application.  If the <tt class="docutils literal"><span class="pre">wapiti.py</span></tt>
file was the file that started your application, you might use something
like:</li>
</ul>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">web</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">python$PYTHON_VERSION wapiti.py</span>
</pre></div>
</div>
<ul class="simple">
<li>A <tt class="docutils literal"><span class="pre">manifest.yml</span></tt> file with at least your application name.  You may
also place other configuration information in this file such as module
requirements.  The minimal file would look like:</li>
</ul>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wapiti</span>
</pre></div>
</div>
<ul class="simple">
<li>If your module requirements are not in the <tt class="docutils literal"><span class="pre">manifest.yml</span></tt> file, you
might need a <tt class="docutils literal"><span class="pre">requirements.txt</span></tt> or <tt class="docutils literal"><span class="pre">requiremenbts.pypm</span></tt> (pypm) file.
For example your <tt class="docutils literal"><span class="pre">requirements.txt</span></tt> may contain:</li>
</ul>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">cherrypy</span>
</pre></div>
</div>
<ul class="simple">
<li>Possibly a <tt class="docutils literal"><span class="pre">runtime.txt</span></tt> file if the application is going to run some
other version of Python other than Python 2.7 (the default).  If your
application was to use Python 3.3 for example:</li>
</ul>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">python-3.3</span>
</pre></div>
</div>
<ul class="simple">
<li>Finally, you will need a file to launch your application.  For this
example, we have been talking about a <tt class="docutils literal"><span class="pre">wapiti.py</span></tt> file which would
launch the application.</li>
</ul>
<p>Management of the deployed application and its services happens through a web
user interface or a command line client.  To learn more see:</p>
<ul class="simple">
<li><a class="reference external" href="http://docs.hpcloud.com/als/v1/user/deploy/languages/python/">Working with applications in Python</a></li>
<li>The [manifest.yml](/als/v1/user/deploy/manifestyml/) reference</a></li>
</ul>
</div>
<div class="section" id="controlling-hp-helion-with-your-application">
<h2>Controlling HP Helion with your Application<a class="headerlink" href="#controlling-hp-helion-with-your-application" title="Permalink to this headline"></a></h2>
<p>If your Python application is going to control HP Helion resources, it can
communicate directly with the <a class="reference external" href="http://docs.hpcloud.com/api">Helion REST APIs</a>
with a client or the Python SDK.  Currently, the Python SDK is very
limited in features, so you will probably be forced to use the CLIs.</p>
<p>The unified Python OpenStack Client has pretty good coverage of OpenStack
features except for network (Neutron) and object store (Swift).  To get full
coverage of features you would need to install the following CLIs in your
<tt class="docutils literal"><span class="pre">requirements.txt</span></tt> file (using our earlier cherrypy example):</p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">cherrypy</span>
<span class="l-Scalar-Plain">python-neutronclient</span>
<span class="l-Scalar-Plain">python-openstackclient</span>
<span class="l-Scalar-Plain">python-swiftclient</span>
</pre></div>
</div>
<p>Using the cherrypy example, you could implement a simple web server to show
volumes.  Obviously, this needs to run under HTTPS:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cherrypy</span>
<span class="kn">import</span> <span class="nn">subprocess</span>

<span class="k">class</span> <span class="nc">VolumeShow</span><span class="p">:</span>
    <span class="nd">@cherrypy.expose</span>
    <span class="k">def</span> <span class="nf">index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">&quot;&quot;&quot;</span>
<span class="s">        &lt;html&gt;&lt;body&gt;</span>
<span class="s">        &lt;form method=&#39;post&#39; action=&#39;/posted/&#39;&gt;</span>
<span class="s">        User: &lt;input name=&quot;username&quot;/&gt;&lt;br&gt;</span>
<span class="s">        Password: &lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt;&lt;br&gt;</span>
<span class="s">        Project: &lt;input name=&quot;project&quot;/&gt;&lt;br&gt;</span>
<span class="s">        Auth URL: &lt;input name=&quot;url&quot;/&gt;&lt;br&gt;</span>
<span class="s">        Region: &lt;input name=&quot;region&quot;/&gt;&lt;br&gt;</span>
<span class="s">        Volume: &lt;input name=&quot;name&quot;/&gt;&lt;br&gt;</span>
<span class="s">        &lt;input type=&#39;submit&#39; value=&#39;Submit&#39; /&gt;</span>
<span class="s">        &lt;/form&gt;&lt;/body&gt;</span>
<span class="s">        &lt;/html&gt;</span>
<span class="s">        &quot;&quot;&quot;</span>

    <span class="nd">@cherrypy.expose</span>
    <span class="k">def</span> <span class="nf">posted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">project</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">&#39;OS_USERNAME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">username</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">&#39;OS_PASSWORD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">password</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">&#39;OS_REGION_NAME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">region</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">&#39;OS_PROJECT_NAME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">project</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">&#39;OS_AUTH_URL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">url</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s">&quot;openstack&quot;</span><span class="p">,</span> <span class="s">&quot;volume&quot;</span><span class="p">,</span> <span class="s">&quot;show&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">],</span>
                             <span class="n">env</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">communicate</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="s">&quot;&lt;title&gt;Volume </span><span class="si">%s</span><span class="s">&lt;/title&gt;</span><span class="se">\n</span><span class="s">&lt;pre&gt;</span><span class="si">%s</span><span class="s">&lt;/pre&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>That example used the unified OpenStack CLI.  A similar thing would work for
the network or object store clients.</p>
   
By default, Application Lifecycle Service uses the built-in Python
[*Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks) to deploy Python
applications. To deploy applications using this buildpack, your
application will need the following in the root directory of the
application:

-   a list of module requirements in a
    [*manifest.yml*](/als/v1/user/deploy/manifestyml/),
    [requirements.txt
    (pip)](http://www.pip-installer.org/en/latest/cookbook.html#requirements-files),
    or *requirements.pypm* ([pypm](http://code.activestate.com/pypm/))
    file.

-   a Procfile specifying the command to run the application server. For
    example, the
    [example-python-django](https://github.com/Stackato-Apps/example-python-django)
    Application Lifecycle Service sample has the following simple *Procfile*:

        web: gunicorn helion.wsgi -b 0.0.0.0:$PORT

This buildpack uses Python 2.7 by default. To specify Python 3.3, create
a *runtime.txt* file setting the version (i.e. `python-3.3`) and use the \$PYTHON\_VERSION environment variable in the
Procfile `web:` command. For example:

    web: python$PYTHON_VERSION app.py

See also: <https://github.com/ActiveState/stackato-buildpack-python>

Python with the Legacy Buildpack[](#python-with-the-legacy-buildpack "Permalink to this headline")
---------------------------------------------------------------------------------------------------

If your Python application has configuration for running on Application Lifecycle Service
2.10 or earlier, you can deploy it using the [*Legacy
Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy), which provides an
updated version of the old Python framework.

With the Legacy Buildpack, applications are run with
[uWSGI](http://projects.unbit.it/uwsgi/). Applications are started from
a top-level script called `wsgi.py` defining a
global `application` variable containing the WSGI
application object. For a minimal sample application, see
[wsgi-helloworld](https://github.com/Stackato-Apps/wsgi-helloworld).

You may add additional arguments to uWSGI in your
`manifest.yml`, eg:

    processes:
      web: $HELION_UWSGI --mount foo=app.py --import module

It is possible to [*serve static files with
uWSGI*](#uwsgi-python-static-files).

Django[](#django "Permalink to this headline")
-----------------------------------------------

-   [Deploying Django applications](/als/v1/user/deploy/languages/python/django/)
    -   [Getting started](/als/v1/user/deploy/languages/python/django/#getting-started)
    -   [Configuring database](/als/v1/user/deploy/languages/python/django/#configuring-database)
    -   [Configuring static media](/als/v1/user/deploy/languages/python/django/#configuring-static-media)
    -   [Configuring project
        location](/als/v1/user/deploy/languages/python/django/#configuring-project-location)

Application URL[](#application-url "Permalink to this headline")
-----------------------------------------------------------------

Some applications require the user to specify the APP\_URL. Below is an
example on how to obtain the correct urls:

    import json
    vcap_app = json.loads(os.environ['VCAP_APPLICATION'])
    APP_URL = 'http://' + vcap_app['uris'][0]

Database Services[](#database-services "Permalink to this headline")
---------------------------------------------------------------------

Some minor edits are required to make your application work with a
database. Python database configurations are located inside
`settings.py`.

### DATABASE\_URL[](#database-url "Permalink to this headline")

Authentication details for your configured database services can be
found in the `os.environ` variable, under
`DATABASE_URL`. Here is an example of getting the
correct credentials.

    import urlparse
    DATABASES = {}
    if 'DATABASE_URL' in os.environ:
        url = urlparse.urlparse(os.environ['DATABASE_URL'])
        DATABASES['default'] = {
            'NAME': url.path[1:],
            'USER': url.username,
            'PASSWORD': url.password,
            'HOST': url.hostname,
            'PORT': url.port,
            }
        if url.scheme == 'postgres':
            DATABASES['default']['ENGINE'] = 'django.db.backends.postgresql_psycopg2'
        elif url.scheme == 'mysql':
            DATABASES['default']['ENGINE'] = 'django.db.backends.mysql'
    else:
        DATABASES['default'] = {
            'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.
            'NAME': 'dev.db',                      # Or path to database file if using sqlite3.
            'USER': '',                      # Not used with sqlite3.
            'PASSWORD': '',                  # Not used with sqlite3.
            'HOST': '',                      # Set to empty string for localhost. Not used with sqlite3.
            'PORT': '',                      # Set to empty string for default. Not used with sqlite3.
            }

### VCAP\_SERVICES[](#vcap-services "Permalink to this headline")

    import json
    vcap_services = json.loads(os.environ['VCAP_SERVICES'])
    srv = vcap_services['mysql'][0]
    cred = srv['credentials']
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.mysql',
            'NAME': cred['name'],
            'USER': cred['user'],
            'PASSWORD': cred['password'],
            'HOST': cred['hostname'],
            'PORT': cred['port'],
        }
    }

Worker Applications[](#worker-applications "Permalink to this headline")
-------------------------------------------------------------------------

Non-HTTP apps that run as an Application Lifecycle Service application under the control of
the Health Manager.

To deploy worker applications, you need to use the
[*command*](/als/v1/user/deploy/manifestyml/#command) key and set the
[*processes:
web*](/als/v1/user/deploy/manifestyml/#web) key to
Null ("\~").

### Example[](#example "Permalink to this headline")

    name: python-app
    framework:
      type: python
      runtime: python27
    command: python worker.py
    processes:
      web: ~

Serving Static Files with uWSGI[](#serving-static-files-with-uwsgi "Permalink to this headline")
-------------------------------------------------------------------------------------------------

It is possible to serve static files with uWSGI using
`processes: web:` in the
[*manifest.yml*](/als/v1/user/deploy/manifestyml/) file to specify
folders that will be served statically and not by the app.

To make a single folder serve statically, use `--check-static`:

    processes:
        web: $HELION_UWSGI --check-static $HOME/<folder>

To specify multiple folders with static files that do not share a common
root, use `--static-map`:

    processes:
        web: $HELION_UWSGI --static-map /foo=$HOME/static --static-map /bar=$HOME/sub

In this case */foo/index.html* would serve *\$HOME/static/index.html*,
and */bar/index.html* would serve *\$HOME/sub/index.html*. If the file
doesn't exist, then uWSGI will forward the request to the app.

**Note**

Serving static files via uWSGI is only available for Perl and Python
frameworks.

Using a custom web server[](#using-a-custom-web-server "Permalink to this headline")
-------------------------------------------------------------------------------------

To use a different web server, instead of uWSGI, specify its startup
command in `manifest.yml`. Here's a sample
manifest.yml used to deploy a Django 1.4 application named "dj14" using
gunicorn:

    name: dj14

    framework:
      type: python

    processes:
      web: gunicorn -b 0.0.0.0:$PORT dj14.wsgi

    requirements:
      pypm: [gunicorn]
      pip: ["http://www.djangoproject.com/download/1.4-beta-1/tarball/#egg=django-1.4b1"]

The custom web server must bind to IP address `0.0.0.0` and port `$PORT`. The same trick can be
used to serve non-WSGI applications (such as Tornado). See the
[bottle-py3 example](https://github.com/Stackato-Apps/bottle-py3) sample
for an example.

Installing Python Packages[](#installing-python-packages "Permalink to this headline")
---------------------------------------------------------------------------------------

**Note**

To install packages from custom repository/mirror. Use the
[*PIP\_OPTS*](/als/v1/user/reference/environment/#term-pip-opts) or
[*PYPM\_OPTS*](/als/v1/user/reference/environment/#term-pypm-opts)
[*environment
variables*](/als/v1/user/reference/environment/#environment-variables).

Application dependencies such as web frameworks or modules from PyPI can
be installed using [*PyPM*](/als/v1/admin/reference/glossary/#term-pypm)
and/or [*pip*](/als/v1/admin/reference/glossary/#term-pip).

### PyPM[](#pypm "Permalink to this headline")

Definition [*PyPM*](/als/v1/admin/reference/glossary/#term-pypm)

To install packages during application deployment with PyPM, add the
requirements to manifest.yml:

    requirements:
      pypm:
        - tornado
        - pymongo

See the [manifest.yml of
tornado-chat-mongo](https://github.com/Stackato-Apps/tornado-chat-mongo/blob/master/stackato.yml)
sample app for an example.

Alternatively, you can list the modules in a top-level
`requirements-pypm.txt` file. The format is similar,
if not same, as [pip requirements
files](http://www.pip-installer.org/en/latest/requirements) and
accepts version specification. The name of this file can be overridden by
setting the `PYPM_REQUIREMENTS_FILE` environment
variable.

### pip[](#pip "Permalink to this headline")

Definition [*pip*](/als/v1/admin/reference/glossary/#term-pip)

In addition - or as alternative - to
[*PyPM*](/als/v1/admin/reference/glossary/#term-pypm), your application
can also make use of pip to install certain dependencies. The above
tornado-chat-mongo sample installs "pycurl" using
[*pip*](/als/v1/admin/reference/glossary/#term-pip):

    requirements:
      pypm:
        - tornado
        - pymongo
      pip:
        - pycurl

If your application already contains a `requirements.txt` file, that will be automatically used to install dependencies;
no need to specify them manually in manifest.yml. The name of this file
can be overridden by setting the `PIP_REQUIREMENTS_FILE` environment variable.

**Note**

A [bug in pip](https://github.com/pypa/pip/issues/219) may prevent the
log file from being accessed by `helion logs`.

PyPy Support[](#pypy-support "Permalink to this headline")
-----------------------------------------------------------

Here is an example of pushing an app using PyPy.

First, clone the <https://github.com/Stackato-Apps/werkzeug-debugger>
repository.

Then add the following `BUILDPACK_URL` to the
*manifest.yml* file:

    env:
      BUILDPACK_URL: git://github.com/HP/heroku-buildpack-pypy.git

Finally, push the app to Application Lifecycle Service:

    $ helion push -n

Other Python Frameworks[](#other-python-frameworks "Permalink to this headline")
---------------------------------------------------------------------------------

Examples of deploying other frameworks are included in the [GitHub
samples repo](https://github.com/Stackato-Apps):

-   Bottle framework
    -   [Bottle
        Currency](https://github.com/Stackato-Apps/bottle-currency)
    -   [Python 3](https://github.com/Stackato-Apps/bottle-py3)
-   Django
    -   [django-gtd](https://github.com/Stackato-Apps/django-gtd)
    -   [pinax-social](https://github.com/Stackato-Apps/pinax-social)
-   Pylons Pyramid
    -   [virginia](https://github.com/Stackato-Apps/pyramid-virginia)
    -   [default](https://github.com/Stackato-Apps/pyramid-default)
-   Tornado
    -   [chat](https://github.com/Stackato-Apps/tornado-chat-mongo)
-   Werkzeug
    -   [werkzeug-debugger](https://github.com/Stackato-Apps/werkzeug-debugger)
-   Celery
    -   [celery-demo](https://github.com/Stackato-Apps/celery-demo)
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/

---
<!--PUBLISHED-->

#Developing In Ruby
<p>Whether you're deploying an application to the HP Helion Development Platform, a
Cloud Foundry based Platform as a Service (PaaS), or writing applications that take
advantage of HP Helion OpenStack® to manage infrastructure or software services, tools
to enable successful development are available in Ruby.</p>
<div class="section" id="application-lifecycle-services">
<h2>Application Lifecycle Services<a class="headerlink" href="#application-lifecycle-services" title="Permalink to this headline"></a></h2>
<p>Application Lifecycle Services (ALS), a cloud foundry based Platform as a Service,
provides a means to execute ruby applications on a managed platform. Deploying applications
to the platform is as simple as adding configuration to a YAML configuration file and using
a console application to push the application to ALS.</p>
<p>At its simplest form the configuration file, <tt class="docutils literal"><span class="pre">manifest.yml</span></tt>, at the root of a project would like:</p>
<div class="highlight-none"><div class="highlight"><pre>name: ruby-web-app
framework:
    type: ruby20
</pre></div>
</div>
<p>This will tell ALS to have a ruby web application.</p>
<p>To create a worker non-http application set the web process to null (~) and specify
the command to run. For example,</p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ruby-app</span>
<span class="l-Scalar-Plain">framework</span><span class="p-Indicator">:</span>
  <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">rails3</span>
  <span class="l-Scalar-Plain">runtime</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ruby19</span>
<span class="l-Scalar-Plain">command</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ruby worker.rb</span>
<span class="l-Scalar-Plain">processes</span><span class="p-Indicator">:</span>
    <span class="l-Scalar-Plain">web</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">~</span>
</pre></div>
</div>
<p>Management of the deployed application and its services happens through a web application or
a console application.</p>
<p>To learn more see:</p>
<ul class="simple">
<li><a class="reference external" href="http://docs.hpcloud.com/als/v1/user/deploy/languages/ruby/">Working with applications in ruby</a></li>
<li>The [manifest.yml](/als/v1/user/deploy/manifestyml/) reference</a></li>
</ul>
</div>
<div class="section" id="hp-helion-sdk">
<h2>HP Helion SDK<a class="headerlink" href="#hp-helion-sdk" title="Permalink to this headline"></a></h2>
<p>Ruby applications can communicate directly with the <a class="reference external" href="http://docs.hpcloud.com/api">Helion APIs</a> through a REST client
or use the SDK. The SDK is designed to have a simple well documented API to simplify working with the
services.</p>
<p>To understand how it works, here is an example of writing and reading from object storage:</p>
<div class="highlight-ruby"><div class="highlight"><pre><span class="k">def</span> <span class="nf">credentials_hash</span>
  <span class="p">{</span>
    <span class="ss">:provider</span> <span class="o">=&gt;</span> <span class="ss">:openstack</span><span class="p">,</span>
    <span class="ss">:openstack_auth_url</span> <span class="o">=&gt;</span> <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;OS_AUTH_URL&#39;</span><span class="o">]</span><span class="p">,</span>
    <span class="ss">:openstack_username</span> <span class="o">=&gt;</span> <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;OS_USER&#39;</span><span class="o">]</span><span class="p">,</span>
    <span class="ss">:openstack_api_key</span> <span class="o">=&gt;</span> <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;OS_API_KEY&#39;</span><span class="o">]</span><span class="p">,</span>
    <span class="ss">:openstack_tenant</span> <span class="o">=&gt;</span>  <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;OS_TENANT&#39;</span><span class="o">]</span> <span class="p">,</span>
    <span class="ss">:openstack_region</span> <span class="o">=&gt;</span> <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;OS_REGION&#39;</span><span class="o">]</span>
  <span class="p">}</span>
<span class="k">end</span>

<span class="n">storage</span> <span class="o">=</span> <span class="no">Fog</span><span class="o">::</span><span class="no">Storage</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">credentials_hash</span><span class="p">)</span>

<span class="c1">#list directories</span>
<span class="n">storage</span><span class="o">.</span><span class="n">directories</span>

<span class="c1">#create a directory</span>
<span class="n">storage</span><span class="o">.</span><span class="n">directories</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="ss">:key</span> <span class="o">=&gt;</span> <span class="s2">&quot;Example&quot;</span><span class="p">)</span>

<span class="c1">#create an object</span>
<span class="n">dir</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">directories</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;Example&quot;</span><span class="p">)</span>
<span class="n">dir</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="ss">:key</span> <span class="o">=&gt;</span> <span class="s2">&quot;sample.txt&quot;</span><span class="p">,</span> <span class="ss">:body</span> <span class="o">=&gt;</span> <span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;/path/to/sample.txt&quot;</span><span class="p">))</span>

<span class="c1">#get the same object out</span>
<span class="n">dir</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">directories</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;Example&quot;</span><span class="p">)</span>
<span class="n">file</span> <span class="o">=</span> <span class="n">dir</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sample.txt&quot;</span><span class="p">)</span>
<span class="n">file</span><span class="o">.</span><span class="n">key</span>   <span class="c1"># =&gt; sample.txt</span>
<span class="n">file</span><span class="o">.</span><span class="n">content_type</span> <span class="c1"># =&gt; text/plain</span>
</pre></div>
</div>

To learn more about getting and using the SDK see:


- [Get Started With the Ruby Library](/als/v1/user/deploy/languages/ruby/getstarted)
- [Connecting To The Service](/als/v1/user/deploy/languages/ruby/connect)
- [Object Storage Examples](/als/v1/user/deploy/languages/ruby/objectstore)


**Note**

See [Buildpacks](/als/v1/user/deploy/buildpack/#buildpacks) for an alternative way
to deploy Ruby on Rails applications.

### Using Ruby 2.0[](#using-ruby-2-0 "Permalink to this headline")

The *manifest.yml* file must specify the Ruby runtime version and Rails as the
framework type:

    framework:
      runtime: ruby20

Default Ruby version is Ruby 1.9

### Known Issues[](#known-issues "Permalink to this headline")

-   Rmagick gem currently not supported.

-   PostgreSQL Gem (pg) version must be pinned to 0.12.2 (if used):

        gem 'pg', '0.12.2'

-   Must specify Rake Gem immediately before the line loading rails.
    This happens because when Rails loads, it finds version 0.9.2 of
    Rake, and that becomes the only version of Rake in the process.
    Later code wants version 0.9.2.2, and fails:

        gem 'rake', '0.9.2.2'
        gem 'rails'

-   For Ruby 1.9, Cloud Foundry requires a tweak to the jquery-rails gem.

    > gem 'cloudfoundry-jquery-rails'

### Ruby on Rails 3.1+[](#ruby-on-rails-3-1 "Permalink to this headline")

To get the asset pipeline working on Application Lifecycle Service, precompile your assets in
your development environment, which compiles them into public/assets:

    bundle exec rake assets:precompile

### Gems and Libraries[](#gems-and-libraries "Permalink to this headline")

A *Gemfile* must be included in your app that lists all required gems.
Run:

    $ bundle install
    $ bundle package

any time you modify the *Gemfile* and prior to pushing an app to
Application Lifecycle Service.

If VCAP sees a Gemfile.lock in the application, it will ensure the
needed gems are packaged, and set the BUNDLE\_PATH environment variable
to point at them.

###Unsupported *Gemfile* features###

1.  git urls or branch dependencies
2.  gem :path =\> "some/path"
3.  platform-conditional gems

Database Services[](#database-services "Permalink to this headline")
---------------------------------------------------------------------

Cloud Foundry supports database auto-reconfiguration for Rails
applications.

Worker Applications[](#worker-applications "Permalink to this headline")
-------------------------------------------------------------------------

Non-HTTP apps that run as an Application Lifecycle Service application under the control of
the Health Manager.

To deploy worker applications, you need to use the
[*command*](/als/v1/user/deploy/manifestyml/#command) key and set the
[*processes: web*](/als/v1/user/deploy/manifestyml/#web)
key to Null ("\~").

### Example[](#example "Permalink to this headline")

    name: ruby-app
    framework:
      type: rails3
      runtime: ruby19
    command: ruby worker.rb
    processes:
      web: ~

General Guidelines[](#general-guidelines "Permalink to this headline")
-----------------------------------------------------------------------

### App/Web Servers[](#app-web-servers "Permalink to this headline")

For the best performance, using Thin Ruby web server is recommended.
Include `gem 'thin'` in your *Gemfile*.

-   [Using Thin
    Webserver](https://devcenter.heroku.com/articles/ruby#webserver):
    Heroku Dev Center.

### Bundler[](#bundler "Permalink to this headline")

First, you need bundler and rails installed locally. This can be done
via:

    $ sudo gem install rails bundler --no-ri --no-rdoc

### Running rake commands[](#running-rake-commands "Permalink to this headline")

Generally, `bundle exec` must be used when running
any commands that are installed through Gemfile/bundler.

To run `rake stats`, for instance, use the
`helion run` command:

    $ helion run *appname* bundle exec rake stats

See the [Command
Reference](/als/v1/user/reference/client-ref/#command-ref-client) for
details on the use of `helion run`.

References[](#references "Permalink to this headline")
-------------------------------------------------------

-   [Auto-Reconfiguration Part
    I](http://blog.cloudfoundry.com/2012/03/12/using-cloud-foundry-services-with-ruby-part-1-auto-reconfiguration/):
    Cloud Foundry Blog.
-   [Auto-Reconfiguration Part
    II](http://blog.cloudfoundry.com/2012/03/15/using-cloud-foundry-services-with-ruby-part-2-run-time-support-for-ruby-applications):
    Cloud Foundry Blog.
-   [Working with Ruby, Rails and Sinatra: Things to
    know](http://docs.cloudfoundry.com/frameworks/ruby/ruby-rails-sinatra):
    Cloud Foundry Documentation.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/getstarted/
---
<!--PUBLISHED-->
Ruby Fog Bindings Examples for use with HP Helion
=================================================

This section includes code examples for working with Ruby Fog bindings
and HP Helion.

Ruby Fog Bindings
---------------------------------------------

These examples currently support Compute and Object
Storage. Support for other services will be added as they become available.

*  :ref:`Installation Instructions <sdk-ruby-installation>`
*  :ref:`Connecting to the Service <sdk-ruby-connect>`
*  :ref:`Compute Examples <sdk-ruby-compute>`
*  :ref:`Object Storage Examples <sdk-ruby-object-storage>`---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/objectstore/
---
<!--PUBLISHED-->

#Examples for working with HP Helion Object Storage Service


The HP Helion Extensions to Ruby Fog library provides Object Storage
services support using two abstractions: a model layer and a request
layer. Executing commands in both layers are detailed in this page.

The examples on this page can be executed from within a Ruby console
(IRB):

        irb

This page discusses the following topics:

-  Connecting to the Service <#sdk-ruby-connect>`
-  `Using the Model Abstraction <#using-the-model-abstraction>`__
-  `Using the Request Abstraction <#using-the-request-abstraction>`__

Using the Model Abstraction
---------------------------

1.  List all directories/containers for the given account

    ::

        dirs = conn.directories
        dirs.size   # returns no. of directories

2.  Create a new directory/container

    ::

        conn.directories.create(:key => "fog-rocks")

3.  View a directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        dir.key    # => fog-rocks

4.  Apply ACLs on an existing directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        dir.public = true
        dir.save
        dir.public?               # => true
        dir.public = false        # toggles between "private" and "public-read" acl on a directory
        dir.save
        dir.public?               # => false

5.  Create a new file/object into an existing directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        dir.files.create(:key => "sample.txt", :body => File.open("/path/to/sample.txt"))

6.  View a file/object from an existing directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        file = dir.files.get("sample.txt")
        file.key   # => sample.txt

7.  Copy a file/object into an existing directory/container

    ::

        file = conn.directories.get("fog-rocks").files.get("sample.txt")
        other_file = file.copy("fog-rocks", "another-sample.txt")
        other_file.key   # => another-sample.txt

8.  View the files/objects for a directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        files = dir.files
        files.directory.key      # => fog-rocks
        files.size               # returns no. of files
        files[0].key             # key of the file in collection
        files[0].content_length  # content length of file
        files[0].last_modified   # last modified date in UTC

9.  Generate a temporary URL for a file or object for sharing purposes

    ::

        dir = conn.directories.get("fog-rocks")
        file = dir.files.get("sample.txt")
        # creates a TempUrl to access sample.txt and access expires in 240 secs
        file.temp_signed_url(240, "GET")

10. Delete a file/object from an existing directory/container

    ::

        dir = conn.directories.get("fog-rocks")
        file = dir.files.get("sample.txt")
        file.destroy
        # chaining a series of calls to delete a file
        conn.directories.get("fog-rocks").files.get("another-sample.txt").destroy

11. Delete an existing directory/container

    ::

        # Note: directory needs to be empty before it can be deleted!
        conn.directories.get("fog-rocks").destroy

**Note**: You cannot use the create, update, or delete operations on a
shared container.

About using object ACLs
~~~~~~~~~~~~~~~~~~~~~~~

Object ACLs allow you to share containers and objects with other
registered HP Helion users. The owner of a container or object can
grant read, write, read/write access to other users. The shared
containers and objects can then be accessed based on the permissions
granted by the owner.

Using the object ACLs to grant access
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To grant access to an object or a container:

::

        mydir = conn.directories.get('rgtest2')  # grant uses username
        mydir.grant("rw", ["someuser"])
        mydir.save                               # share the url for access to container
        mydir.public_url
        # => "https://objects.xxxx.hpcloud.net:443/v1/1111111/rgtest2"

        myfile = mydir.files.get("sample.txt")   # share the url for access to object
        myfile.public_url
        # => "https://objects.xxxx.hpcloud.net:443/v1/1111111/rgtest2/sample.txt"

Using the object ACLs to access shared objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

1. Use the shared URLs to get the contents of a shared container:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sd.url
       # => "https://objects.xxxx.hpcloud.net:443/v1/1111111/rgtest2"
       sd.files

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::OpenStack::Errors::Forbidden``.

2. Use the shared URLs to get the metadata for a container:

   ::

       sd = conn.shared_directories.head(mydir.public_url)

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::OpenStack::Errors::Forbidden``.

3. Use the shared URLs to get the contents of a shared object:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sf = sd.files.get('sample.txt')

4. Use the shared URLs to get the metadata for a shared object:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sf = sd.files.head('sample.txt')

5. Use the shared URLs to put a new object or file into a shared
   container:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sf = sd.files.create(:key => 'tiny2.txt', :body => "This is another text file.")

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::OpenStack::Errors::Forbidden``.

6. Use the shared URLs to update an existing object or file in a shared
   container:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sf = sd.files.new(:key => 'sample.txt')
       sf.body = "This is another text file."
       sf.save

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::OpenStack::Errors::Forbidden``.

7. Use the shared URLs to delete an existing object or file from a
   shared container:

   ::

       sd = conn.shared_directories.get(mydir.public_url)
       sd.destroy

Synchronize containers across regions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Synchronizing containers creates a one-way association from containers
to the sync objects. The sync operation is performed by a background
process on the container server. You must perform a one-time setup to
set the metadata on the containers for syncing.

1. One-Way sync of containers (from source to target only):

   ::

       # create source and target containers
       conn.directories.create(:key => 'imp_stuff')
       conn.directories.create(:key => 'sync_archive')
       dir = conn.directories.get('imp_stuff')
       target_dir = conn.directories.get('sync_archive')

       # create some objects in the source container
       dir.files.create(:key => 'imp_1.txt', :body => "This is a small file but it is very important.")
       dir.files.create(:key => 'imp_2.txt', :body => "This is another small file but it is very important as well.")

       # sync the source -> target
       dir.sync(target_dir, "boogieman")       # => true
       dir.save                                # => true

2. Two-Way sync of containers (from source to target and back):

   ::

       # Now, let's do a two way sync between dir and target containers
       dir = conn.directories.get('imp_stuff')
       target_dir = conn.directories.get('sync_archive')

       # sync the target -> source
       target_dir.sync(dir, "boogieman")       # => true
       target_dir.save                         # => true

3. One and two-way sync of containers across regions:

   ::

       # assuming source container exists in region-a
       dir_a = conn.directories.get('imp_stuff')          # Note: conn points to region-a
       # assuming target container exists in region-a
       target_dir_b = conn2.directories.get('arch_imp_stuff')  # Note: conn2 points to region-b

       # sync the source -> target
       dir_a.sync(target_dir_b, "boogieman") # => true
       dir_a.save # => true

       # sync the target -> source
       target_dir_b.sync(dir_a, "boogieman") # => true
       target_dir_b.save #=> true

Using the Request Abstraction
-----------------------------

1.  List all container for the given account:

    ::

        response = conn.get_containers
        response.body               # returns an array of container hash objects
        response.body[0]["name"]    # returns the name of the container
        response.body[0]["count"]   # returns the number of objects in the container
        response.body[0]["bytes"]   # returns the total bytes for the objects in the container

2.  Create a new container:

    ::

        container = conn.put_container("fog-rocks")   # creates the container
        container.headers                             # returns a hash of headers
        container.headers["Content-Length"]           # returns the content-length

3.  View a container:

    ::

        container = conn.get_container("fog-rocks")
        container.body                                # returns an array of objects hash
        container.body[0]['name']                     # returns the name of the object
        container.headers                             # returns a hash of headers
        container.headers["Content-Length"]           # returns the content-length
        container.headers["Content-Type"]             # returns the content-type
        container.headers["X-Container-Object-Count"] # returns the number of objects in the container
        container.headers["X-Container-Bytes-Used"]   # returns the total bytes for the objects in the container
        container.status                              # HTTP status code for the operation

4.  View the container's headers and metadata without getting the
    content:

    ::

        container = conn.head_container("fog-rocks")
        container.body                             # returns an empty body
        container.headers                          # returns a hash of headers
        container.headers["Content-Length"]        # returns the content-length
        container.headers["Content-Type"]          # returns the content-type
        container.status                           # HTTP status code for the operation

5.  Create a new file into an existing container:

    ::

        file = conn.put_object("fog-rocks", "sample.txt", File.open('/path/to/file/sample.txt'))
        file.headers                            # returns a hash of headers
        file.headers["Content-Length"]          # returns the content-length

6.  View a file from an existing container:

    ::

        file = conn.get_object("fog-rocks", "sample.txt")
        file.body                               # returns the contents of the file
        file.headers                            # returns a hash of headers
        file.headers["Content-Length"]          # returns the content-length
        file.headers["Content-Type"]            # returns the content-type
        file.status                             # HTTP status code for the operation

7.  View the file's headers and metadata without getting the content:

    ::

        file = conn.head_object("fog-rocks", "sample.txt")
        file.body                               # returns the empty body
        file.headers                            # returns a hash of headers
        file.headers["Content-Length"]          # returns the content-length
        file.headers["Content-Type"]            # returns the content-type
        file.status                             # HTTP status code for the operation

8.  Copy a file within the same container:

    ::

        # copy an object
        conn.put_object("fog-rocks", "another-sample.txt", nil, {'X-Copy-From' => "/fog-rocks/sample.txt" })
        # get the copied object
        other_file = conn.get_object("fog-rocks", "another-sample.txt")
        other_file.headers                            # returns a hash of headers
        other_file.headers["Content-Length"]          # returns the content-length

9.  Copy a file from one container to another container:

    ::

        # create a new container
        conn.put_container("fog-rocks-2")             # creates the other new container
        # copy the object
        conn.put_object("fog-rocks-2", "sample.txt", nil, {'X-Copy-From' => "/fog-rocks/sample.txt" })
        # get the copied object
        other_file = conn.get_object("fog-rocks-2", "sample.txt")
        other_file.headers                            # returns a hash of headers
        other_file.headers["Content-Length"]          # returns the content-length

10. Generate a temporary URL for a file or object for sharing purposes:

    ::

        # creates a TempUrl to access sample.txt and access expires in 240 secs
        conn.get_object_temp_url("fog-rocks", "sample.txt", 240, "GET")

11. Delete a file from an existing container:

    ::

        conn.delete_object("fog-rocks", "sample.txt")
        conn.delete_object("fog-rocks", "another-sample.txt")

12. Delete an existing container:

    ::

        # Note: a container needs to be empty before it can be deleted!
        conn.delete_container("fog-rocks")

Using Object ACLs
~~~~~~~~~~~~~~~~~

To use object ACLs in the request abstraction layer, you need to have
already been granted permission to access the objects or containers.
(See the section on `Using Object ACLs <#UsingObjectACLsModelLayer>`__
in the Model Layer section above for information on granting access.)

1. Use the shared URLs to get the contents of a shared container:

   ::

       conn.get_shared_container(mydir.public_url)

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::HP::Errors::Forbidden``.

2. Use the shared URLs to get the metadata of a shared container:

   ::

       conn.head_shared_container(mydir.public_url)

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::HP::Errors::Forbidden``.

3. Use the shared URLs to get the contents of a shared object:

   ::

       conn.get_shared_object(myfile.public_url)

4. Use the shared URLs to get the metadata for a shared object

   ::

       conn.head_shared_object(myfile.public_url)

5. Use the shared URLs to put a new object or file into a shared
   container:

   ::

       conn.put_shared_object(mydir.public_url, 'tiny.txt', File.read('tiny.txt'))

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::HP::Errors::Forbidden``.

6. Use the shared URLs to update an existing object or file in a shared
   container:

   ::

       conn.put_shared_object(mydir.public_url, 'sample.txt', "This text needed some update.")

**Note**: If the grantee does not have access, the system generates an
exception of type ``Fog::HP::Errors::Forbidden``.

7. Use the shared URLs to delete an existing object or file from a
   shared container:

   ::

       conn.delete_shared_object(myfile.public_url)

Synchronize containers across regions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Synchronizing containers creates a one-way association from containers
to the sync objects. The sync operation is performed by a background
process on the container server. You must perform a one-time setup to
set the metadata on the containers for syncing.

1. One-Way sync of containers (from source to target only):

   ::

       # create source and target containers
       conn.put_container('imp_stuff')
       conn.put_container('sync_archive')

       # create some objects in the source container
       conn.put_object('imp_stuff', 'imp_1.txt', "This is a small file but it is very important.")
       conn.put_object('imp_stuff', 'imp_2.txt', File.open('/path/to/file/imp_2.txt'))

       # to sync we need to put some metadata on the source and target containers
       conn.put_container('imp_stuff',
                           {'X-Container-Sync-To'  => "/url/to/the/target/sync_archive",
                            'X-Container-Sync-Key' => 'boogieman'})
       conn.put_container('sync_archive',
                           {'X-Container-Sync-Key' => 'boogieman'})

2. Two-Way sync of containers (from source to target and visa-versa):

   ::

       # Now, let's do a two way sync between dir and target containers
       # to sync we need to put some metadata on the source and target containers
       conn.put_container('imp_stuff',
                           {'X-Container-Sync-To'  => "/url/to/the/target/sync_archive",
                            'X-Container-Sync-Key' => 'boogieman'})
       conn.put_container('sync_archive',
                           {'X-Container-Sync-To'  => "/url/to/the/source/imp_stuff",
                            'X-Container-Sync-Key' => 'boogieman'})

3. One and two-way sync of containers across regions:

   ::

       # assuming source container exists in region-a
       conn.get_container('imp_stuff')                         # Note: conn points to region-a
       # create a new container in region-b
       conn2.put_container('arch_imp_stuff')                   # Note: conn2 points to region-b

       # to sync we need to put some metadata on the source and target containers
       conn.put_container('imp_stuff',
                           {'X-Container-Sync-To'  => "/region-b/url/to/the/target/arch_imp_stuff",
                            'X-Container-Sync-Key' => 'boogieman'})
       conn2.put_container('arch_imp_stuff',
                             {'X-Container-Sync-To'  => "/region-a/url/to/the/source/imp_stuff",
                              'X-Container-Sync-Key' => 'boogieman'})
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/compute/
---
<!--PUBLISHED-->
#Examples for working with HP Helion Compute Service
The HP Cloud services provides compute support using two abstractions: [a model layer](#ModelLayer) and [a request layer](#RequestLayer). Both layers are detailed below.  The code samples on this page can be executed from within a Ruby console (IRB):

        irb

This page discusses the following topics:

* [Connecting to the Service](#connecting-to-the-service)

**Model Layer Examples**

* [Model Server Operations](#model-server-operations)
* [Model Server Volume Operations](#model-server-volume-operations)
* [Model Server Metadata Operations](#model-server-metadata-operations)
* [Model Flavor Operations](#model-flavor-operations)
* [Model Image Operations](#model-image-operations)
* [Model Image Metadata Operations](#model-image-metadata-operations)
* [Model Keypair Operations](#model-keypair-operations)
* [Model Address Operations](#model-address-operations)

**Request Layer Examples**

* [Request Server Operations](#request-server-operations)
* [Request Server Metadata Operations](#request-server-metadata-operations)
* [Request Flavor Operations](#request-flavor-operations)
* [Request Image Operations](#request-image-operations)
* [Request Image Metadata Operations](#request-image-metadata-operations)
* [Request Keypair Operations](#request-keypair-operations)
* [Request Address Operations](#request-address-operations)

## Connecting to the Service

To connect to the HP Cloud Compute V2 Service, follow these steps:

1. Enter IRB

.. code-block:: ruby

        irb

2. Require the Fog library

.. code-block:: ruby

        require 'fog'

3. Establish a connection to the HP Cloud Compute V2 service

.. code-block:: ruby

        conn = Fog::Compute.new(
               :provider => "HP",
               :version => :v2,
               :hp_access_key => "<your_ACCESS_KEY>",
               :hp_secret_key => "<your_SECRET_KEY>",
               :hp_auth_uri => "<IDENTITY_ENDPOINT_URL>",
               :hp_tenant_id => "<your_TENANT_ID>",
               :hp_avl_zone => "<your_AVAILABILITY_ZONE>",
               <other optional parameters>
               )

## Model Server Operations

1. List all available servers for an account:

.. code-block:: ruby

        servers = conn.servers
        servers.size   # returns no. of servers
        # display servers in a tabular format
        conn.servers.table([:id, :name, :state, :created_at])

2.  List servers using a filter:

.. code-block:: ruby

        servers = conn.servers.all(:name => 'My Shiny Server')


3. Obtain the details of a particular server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.name                         # returns name of the server
        server.flavor_id                    # returns id of the flavor used to create the server
        server.image_id                     # returns id of the image used to create the server
        server.addresses                    # returns a hash of public and private IP addresses
        server.created_at                   # returns the date the server was created
        server.state                        # returns the state of the server e.g. ACTIVE, BUILD

4. Create a new server:

.. code-block:: ruby

        new_server = conn.servers.create(
              :name => "My Shiny Server",
              :flavor_id => 101,
              :image_id => "<server_id>"
        )
        new_server.id       # returns the id of the server
        new_server.name     # => "My Shiny Server"
        new_server.state    # returns the state of the server e.g. BUILD
        new_server.private_ip_address   # returns the private ip address
        new_server.public_ip_address    # returns the public ip address, if any assigned

5. Create a server by passing in a keypair and security group:

.. code-block:: ruby

        new_server = conn.servers.create(
                :name=> "My Shiny Server",
                :flavor_id => 101,
                :image_id => "<image_id>",
                :key_name => "my_keypair",
                :security_groups => ["My Security Group"]
        )

6. Create a server by passing in a network_id:

.. code-block:: ruby

        new_server = conn.servers.create(
                :name=> "My Shiny Server",
                :flavor_id => 101,
                :image_id => "<image_id>",
                :key_name => "my_keypair",
                :security_groups => ["My Security Group"],
                :networks => ["<network_id>"]
        )

7. Create a Linux-based persistent server by passing in a bootable volume:

.. code-block:: ruby

        new_server = conn.servers.create(
                :name=> "My Sticky Server",
                :flavor_id => 104,
                :block_device_mapping => [{ 'volume_size' => '',
                'volume_id' => "<volume_id>",
                'delete_on_termination' => '0',
                'device_name' => 'vda'
                }]
        )
    **Note**: In *block_device_mapping*, *volume_size* is ignored; it is automatically retrieved from the specified bootable volume. To delete the bootable volume after the server instance is killed you can set  *delete_on_termination* to `1`.  To preserve the bootable volume, set it to `0` as shown above.

8. Create a new Linux-based server with advanced personalization options:

.. code-block:: ruby

        new_server = conn.servers.create(
              :name => "My Personalized Server",
              :flavor_id => 1,
              :image_id => 2,
              :key_name => "hpdefault",
              :security_groups => ["aaa"],
              :config_drive => true,
              :user_data_encoded => ["This is some encoded user data"].pack('m'),
              :personality => [{
                'contents'  => File.read("/path/to/sample.txt"),
                'path'      => "/path/to/sample.txt"
              }]
        )
        new_server.id       # returns the id of the server
        new_server.name     # => "My Personalized Server"

        # Note: that un-encoded user data can also be provided by setting the user_data property
        # although, encoding the data on the client is faster and efficient
        new_server = conn.servers.new(
              :name => "My Personalized Server",
              ...
              ...
        )
        new_server.user_data = "This is some un-encoded user data"
        new_server.save

The personalization options are:

*config_drive*
: Disk accessible to the server that contains a FAT filesystem. If `config_drive` parameter is set to `true` at the time of server creation, the configuration drive is created.

*user_data_encoded* or *user_data*
: Allows additional metadata to be inserted during server creation by supplying a Base64-encoded string in the `user_data_encoded` parameter, or by providing an unencoded string with the `user_data` attribute. Note that encoding the data on the client is faster and more efficient.

*personality*
: Allows files to be injected into the server instance after its creation. The file `contents` are Base64 encoded and injected into the location specified by `path`.



9. Get console output:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.console_output(10)           # returns 10 lines of console output

10. Get VNC console:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.vnc_console_url('novnc')     # URL to access the VNC console of a server from a browser

11. Update a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.update_name("My Shiny Server Updated")

12. Reboot a server:

.. code-block:: ruby

        server = conn.servers.get("server_id>")
        server.reboot          # soft reboot by default

        server.reboot("HARD")  # hard reboot also possible

13. Rebuild a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.rebuild('server_id', 'My Shiny Server Rebuild')

14. Delete a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>").destroy


Model Server Volume Operations
------------------------------

1. Attach a volume to a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.volume_attachments.create(
                :server_id => s.id,
                :volume_id => "<volume id>",
                :device => "/dev/sdf"
        )
        server.reload                    #reload the server
        server.volume_attachments.all    #list the attachments

2. Obtain details for an volume attached to a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.volume_attachements.get("<volume_id>")

3. List attached volumes for a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        server.volume_attachments.all

4. Detach a volume from a server:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")
        att_volume = server.volume_attachments.get("<volume_id>")
        att_volume.destroy     # also aliased to att_volume.detach

**Model Server Metadata Operations**

1. Create a server with some metadata:

.. code-block:: ruby

        server = conn.servers.create(
              :flavor_id => 1,
              :image_id => 2,
              :name => "myserver",
              :metadata => {'Meta1' => 'MetaValue1', 'Meta2' => 'MetaValue2'}
        )

2. Get the metadata item:

.. code-block:: ruby

        server.metadata.get("Meta1")

3. Update the metadata:

.. code-block:: ruby

        s.metadata.update({"Meta2" => "MetaValue2"})

4. Set the metadata:

.. code-block:: ruby

        s.metadata.set({"Meta3" => "MetaValue3"})

5. Set the metadata explicitly:

.. code-block:: ruby

        m = myserver.metadata.new
        m.key = "Meta4"
        m.value = "Value4"
        m.save

6. Update the metadata:

.. code-block:: ruby

        m = s.metadata.get("Meta1")
        m.value = "MetaUpdValue1"
        m.save

7. List metadata:

.. code-block:: ruby

        s.metadata.all

8. Delete metadata:

.. code-block:: ruby

        m = s.metadata.get("Meta3").destroy

## Model Flavor Operations

1. List all available flavors:

.. code-block:: ruby

        flavors = conn.flavors.all
        flavors.size   # returns no. of flavors
        # display flavors in a tabular format
        conn.flavors.table([:id, :name, :ram, :disk])

2. List flavors using a filter:

.. code-block:: ruby

        flavors = conn.flavors.all(:limit => 2)

3. Obtain the details of a particular flavor:

.. code-block:: ruby

        flavor = conn.flavors.get("<flavor_id>")   # get the flavor
        flavor.name    # returns the name of the flavor eg: m1.tiny, m1.small etc.
        flavor.ram     # returns the ram memory in bytes for the flavor, eg: 4096
        flavor.disk    # returns the disk size in GB for the flavor, eg: 80
        flavor.cores   # returns no. of cores for the flavor, eg: 0.25

**Model Image Operations**

1. List all available images:

.. code-block:: ruby

        images = conn.images
        images.size   # returns no. of images
        # display images in a tabular format
        conn.images.table([:id, :name, :status, :created_at])

2. Obtain the details of a particular image:

.. code-block:: ruby

        image = conn.images.get("<image_id>")    # get the image
        image.name          # returns name of the image
        image.created_at    # returns the date the image was created
        image.status        # returns the state of the image e.g. ACTIVE

3. Create a new snapshot image based on an existing server:

.. code-block:: ruby

        # first, get a server
        server = conn.servers.get("<server_id>")
        s.create_image("My Image")

4. Delete an existing snapshot image:

.. code-block:: ruby

        image = conn.images.get("<image_id>").destroy

## Model Image Metadata Operations

1. Create an image snapshot with some metadata:

.. code-block:: ruby

        myserver.create_image("My Image", {"ImgMeta1" => "ImgMeta1Value"})

2. Get the metadata item:

.. code-block:: ruby

        image = conn.images.get("<image_id>")
        image.metadata.set({"Meta3" => "MetaValue3"})

3. Update the metadata:

.. code-block:: ruby

        image.metadata.update({"Meta2" => "MetaValue2"})

4. Set the metadata:

.. code-block:: ruby

        image.metadata.set({"Meta3" => "MetaValue3"})

5. Set the metadata explicitly:

.. code-block:: ruby

        m = image.metadata.set("Meta1")
        m.value = "MetaUpValue1"
        m.save

6. Update the metadata:

.. code-block:: ruby

        m = myimage.metadata.get("ImgMeta3")
        m.value = "ImgUpdValue3"
        m.save

7. List metadata:

.. code-block:: ruby

        myimage.metadata.all

8. Delete metadata:

.. code-block:: ruby

        m = image.metadata.get("ImgMeta3").destroy

## Model Keypair Operations

1. List all available keypairs:

.. code-block:: ruby

        keypairs = conn.key_pairs
        keypairs.size         # returns no. of keypairs
        # display keypairs in a tabular format
        conn.key_pairs.table([:name, :public_key])

2. Obtain the details of a particular keypair:

.. code-block:: ruby

        keypair = conn.key_pairs.get(key_name)    # get the keypair
        keypair.name          # returns name of the keypair
        keypair.public_key    # returns the public key of the keypair
        # NOTE: Due to security considerations, the private key is not available on subsequent gets
        keypair.private_key   # => nil

3. Create a new keypair:

.. code-block:: ruby

        keypair = conn.key_pairs.create(:name => "mykey")
        keypair.name          # returns name of the keypair
        keypair.public_key    # returns the public key of the keypair
        keypair.private_key   # returns the private key of the keypair
    **Note**: Keypairs with a dot (.) are not allowed.

4. Export a keypair to a file:

.. code-block:: ruby

        keypair = conn.key_pairs.create(:name => "mykey2")
        keypair.write         # => "Key file built: /Users/xxxxx/.ssh/mykey2.pem"

        # Alternatively, you can pass in a path to export the key
        keypair.write("/Users/xxxxx/Downloads/mykey2.pem")

5. Import a public key to create a new keypair:

.. code-block:: ruby

        keypair = conn.key_pairs.create(:name => "mykey", :public_key => "public key material")
        keypair.name          # returns name of the keypair

6. Delete an existing keypair:

.. code-block:: ruby

        keypair = conn.key_pairs.get(key_name)
        keypair.destroy

## Model Address Operations

1. List all public and private ip addresses for a server:

.. code-block:: ruby

        address = conn.addresses

2. Obtain the details of a particular address:

.. code-block:: ruby

        address = conn.addresses.get("<address_id>")  # get the address
        address.ip                                  # returns the ip address

3. Create or allocate a new address:

.. code-block:: ruby

        address = conn.addresses.create             # allocates an ip address from the pool
        address.ip                                  # returns the ip address

4. Associate a server to an existing address:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")        # get the server
        address = conn.addresses.get("<address_id>")    # get the address
        address.server = server                     # associate the server
        address.reload

5. Disassociate a server from an existing address:

.. code-block:: ruby

        address = conn.addresses.get("<address_id>")    # get the address
        address.server = nil                        # disassociate the server
        address.instance_id                         # => nil

6. Delete (release) an existing address:

.. code-block:: ruby

        server = conn.servers.get("<server_id>")      # get the server
        address = conn.addresses.get("<address_id>")  # get the address
        address.server = nil       # disassociate the server
        address.reload

7. Release an address back into the IP pool:

.. code-block:: ruby

        address = conn.addresses.get("<address_id>").destroy
        => true

## Request Server Operations

1. List all available servers for an account:

.. code-block:: ruby

        response = conn.list_servers
        response.body['servers']                    # returns an array of server hashes
        response.headers                            # returns the headers
        response.body['servers'][0]['name']         # returns the name of the server

2. List all available servers using a filter:

.. code-block:: ruby

        response = conn.list_servers_detail(:name => 'My Shiny Server')

3. List all available servers with additional details:

.. code-block:: ruby

        response = conn.list_servers_detail
        response.body['servers']                    # returns an array of server hashes
        response.body['servers'][0]['name']         # returns the name of the server

4. Obtain the details of a particular server:

.. code-block:: ruby

        response = conn.get_server_details("<server_id>")
        server = response.body['server']
        server['name']                              # returns the name of the server
        server['flavor']                            # returns the flavor used to create the server
        server['image']                             # returns the image used to create the server
        server['addresses']                         # returns the public and private addresses
        server['status']                            # returns the state of the server e.g. ACTIVE

5. Create a new server:

.. code-block:: ruby

        response = conn.create_server(
            "My Shiny Server",
            flavor_id,
            image_id,
            {
              'availability_zone' => "az2"
            }
            {
              'security_groups' => ["SecGroup1, SecGroup2"],
              'key_name' => "MyKeyPair1"
            }
        )
        server = response.body['server']
        server['id']                                # returns the id of the new server
        server['name']                              # => "My Shiny Server"
        server['status']                            # returns the state of the server e.g. BUILD

6. Create a server by passing in a keypair and security group:

.. code-block:: ruby

        response = conn.create_server(
            "My Shiny Server",
            101,
            image_id,
            {
              'key_name' => "MyKeyPair1",
              'security_groups' => ["SecGroup1, SecGroup2"],
            }
        )
        server = response.body['server']
        server['id']                                # returns the id of the new server
        server['name']                              # => "My Shiny Server"
        server['status']                            # returns the state of the server e.g. BUILD

7. Create a server by passing in a network:

.. code-block:: ruby

        response = conn.create_server(
            "My Shiny Server",
            101,
            image_id,
            {
              'networks' => ["My Network"]
            }
        )



9. Create a new Linux-based persistent server with a bootable volume

.. code-block:: ruby

        conn.create_persistent_server(
              "MyBootableServer",
              103,
              [{ "volume_size"=>"",                 # ignored
                  "volume_id"=>"65904",
                  "delete_on_termination"=>"0",
                  "device_name"=>"vda"
              }],
              {
               'security_groups' => ["mysecgroup"],
               'key_name' => "mykey"
              }
        )
    **Note**: In *block_device_mapping*, *volume_size* is ignored; it is automatically retrieved from the specified bootable volume. To delete the bootable volume after the server instance is killed you can set  *delete_on_termination* to `1`.  To preserve the bootable volume, set it to `0` as shown above.

10. Create a new Linux-based server with advanced personalization options:

.. code-block:: ruby

        response = conn.create_server(
            "My Shiny Server",
            flavor_id,
            image_id,
            {
              'security_groups' => ["SecGroup1, SecGroup2"],
              'key_name' => "MyKeyPair1",
              'config_drive' => true,
              'user_data_encoded' => ["This is some encoded user data"].pack('m'),
              'personality' => [{
                                 'contents'  => File.read("/path/to/sample.txt"),
                                 'path'      => "/path/to/sample.txt"
                               }]
            }
        )
        server = response.body['server']
        server['id']                    # returns the id of the new server

    The personalization options are:

    *config_drive*
    : Disk accessible to the server that contains a FAT filesystem. If `config_drive` parameter is set to `true` at the time of server creation, the configuration drive is created.

    *user_data_encoded*
    : Allows additional metadata to be inserted during server creation by supplying a Base64-encoded string in the `user_data_encoded` parameter.

    *personality*
    : Allows files to be injected into the server instance after its creation. The file `contents` are Base64 encoded and injected into the location specified by `path`.

    **Note**: The above personalization options are not supported on Windows server instances.

11. Update the name for a server:

.. code-block:: ruby

        address = conn.update_server("<server_id>", {'name' => "My Cool Server"})
        response = conn.get_server_details("<server_id>")
        response.body['server']['name']             # => "My Cool Server"

12. Reboot a server (SOFT):

.. code-block:: ruby

        address = conn.reboot_server("<server_id>", "SOFT")

13. Reboot a server (HARD):

.. code-block:: ruby

        address = conn.rebuild_server("<server_id>", "HARD")

14. Rebuild a server:

        address = conn.reboot_server("<server_id>", "MyRebuiltServer")

15. List both public and private addresses of a particular server:

        response = conn.list_server_addresses("<server_id>")

13. Display console output:

        response = conn.get_console_output("<server_id>", 10)
        # => 10 lines of console output are returned

14. Get the VNC console for a server:

        response = conn.get_vnc_console("<server_id>")
        # => Url to access the VNC console of a server from a browser

16. Delete an existing server:

        conn.delete_server("<server_id>")

## Request Server Metadata Operations

1. Create a server and pass it some metadata at creation:

.. code-block:: ruby

        response = conn.create_server(
                        "myserver", 1, 2,
                        {'metadata' =>
                          {'Meta1' => 'MetaValue1', 'Meta2' => 'MetaValue2'}
                        }
                   )
        response.body['server']['metadata']
        # => {"Meta1"=>"MetaValue1", "Meta2"=>"MetaValue2"}

2. List the existing metadata:

.. code-block:: ruby

        response = conn.list_metadata("servers", "<server_id>")
        response.body['metadata']
        # => {"Meta1"=>"MetaValue1", "Meta2"=>"MetaValue2"}

3. Set new values to the existing metadata:

.. code-block:: ruby

        response = conn.set_metadata("servers", "<server_id>", {"MetaNew1" => "MetaNewValue1"})
        response.body['metadata']
        # => {"MetaNew1"=>"MetaNewValue1"}

4. Update the existing metadata:

.. code-block:: ruby

        response = conn.update_metadata("servers", "<server_id>", {"Meta2" => "MetaValue2"})
        response.body['metadata']
        # => {"Meta2"=>"MetaValue2"}

5. Get a metadata item:

.. code-block:: ruby

        response = conn.get_meta("servers", "<server_id>", "Meta1")
        response.body['meta']
        # => {"Meta1"=>"MetaValue1"}

6. Set a new metadata item or update an existing metadata item:

.. code-block:: ruby

        response = conn.update_meta("servers", "<server_id>", "Meta1", "MetaUpdated1")
        response.body['meta']
        # => {"Meta1"=>"MetaUpdated1"}

7. Delete a metadata item:

.. code-block:: ruby

        conn.delete_meta("servers", "<server_id>", "Meta1")

## Request Flavor Operations


1. List all available flavors:

.. code-block:: ruby

        response = conn.list_flavors
        response.body['flavors']                    # returns an array of flavor hashes
        response.headers                            # returns the headers for the flavors
        response.body['flavors'][0]['name']         # returns the name of the flavor

2. List all available flavors with additional details:

.. code-block:: ruby

        response = conn.list_flavors_detail
        response.body['flavors']                    # returns an array of flavor hashes

3. Obtain the details of a particular flavor:

.. code-block:: ruby

        response = conn.get_flavor_details("<flavor_id>")
        flavor = response.body['flavor']
        flavor['name']                              # returns the name of the flavor
        flavor['disk']                              # returns the disk size of the flavor
        flavor['ram']                               # returns the ram size of the flavor

## Request Image Operations

1. List all available images:

.. code-block:: ruby

        response = conn.list_images
        response.body['images']                     # returns an array of image hashes
        response.headers                            # returns the headers for the images
        response.body['images'][0]['name']          # returns the name of the image

2. List all available images with additional details:

.. code-block:: ruby

        response = conn.list_images_detail
        response.body['images']                     # returns an array of image hashes
        response.body['images'][0]['name']          # returns the name of the image

3. Obtain the details of a particular image:

.. code-block:: ruby

        response = conn.get_image_details("<image_id>")
        image = response.body['image']
        image['name']                               # returns name of the image
        image['status']                             # returns the state of the image e.g. ACTIVE
        image['created']                            # returns the creation date of the image
        image['updated']                            # returns the update date of the image

3. Create a new snapshot image based on an existing server:

.. code-block:: ruby

        conn.create_image("<server_id>", "My Image")    # creates an snapshot image from the server referenced by "server_id"

4. Delete an existing snapshot image:

.. code-block:: ruby

        conn.delete_image("<image_id>")

## Request Image Metadata Operations

1. Create an image and pass it some metadata at creation:

        conn.create_image("<server_id>", "myimage", {'Meta1' => 'MetaValue1', 'Meta2' => 'MetaValue2'})

2. List the existing metadata:

        response = conn.list_metadata("images", "<image_id>")
        response.body['metadata']
        #  => {"Meta1"=>"MetaValue1", "Meta2"=>"MetaValue2"}

3. Set new values to the existing metadata:

        response = conn.set_metadata("images", "<image_id>", {"MetaNew1" => "MetaNewValue1"})
        response.body['metadata']
        # => {"MetaNew1"=>"MetaNewValue1"}

4. Update the existing metadata:

        response = conn.update_metadata("images", "<image_id>", {"Meta2" => "MetaValue2"})
        response.body['metadata']
        # => {"Meta2"=>"MetaValue2"}

5. Get a metadata item:

        response = conn.get_meta("images", "<image_id>", "Meta1")
        response.body['meta']
        # => {"Meta1"=>"MetaValue1"}

6. Update a metadata item:

        response = conn.update_meta("images", "<image_id>", "Meta1", "MetaUpdated1")
        response.body['meta']
        # => {"Meta1"=>"MetaUpdated1"}

7. Delete a metadata item:

        conn.delete_meta("images", "<image_id>", "Meta1")

## Request Keypair Operations

1. List all available keypairs:

        response = conn.list_key_pairs
        response.body['keypairs']                   # returns an array of keypair hashes
        response.headers                            # returns the headers
        response.body['keypairs'][0]['keypair']['name']        # returns the name of the keypair

2. Create a new keypair:

        response = conn.create_key_pair("mykey")
        keypair = response.body['keypair']
        keypair['name']                             # returns the name of the keypair
        keypair['public_key']                       # returns the public key of the keypair
        keypair['private_key']                      # returns the private key of the keypair

3. Obtain a keypair:

        response = conn.get_key_pair("mykey")


4. Import a public key to create a new keypair:

        response = conn.create_key_pair("mykey", "public key material")
        keypair = response.body['keypair']
        keypair['name']                             # returns the name of the keypair

4. Delete an existing keypair:

        conn.delete_key_pair("<key_name>")

## Request Address Operations

1. List all available floating IP addresses:

        server = conn.servers.first
        response = conn.list_server_addresses(server.id)
        response.body['addresses']                  # returns an array of address hashes
        response.headers                            # returns the headers


2. List addresses by network for a server:

        server = conn.servers.first
        network = network_conn.networks.first.name
        response = conn.list_server_addresses_by_network(server.id, name)     # get the addresses (assumes server is in network)

3. Obtain the details of a particular address:

        response = conn.get_address("<address_id>")     # get the address
        response.body['address']['ip']              # returns the ip address

3. Create (allocate) a new address:

        response = conn.allocate_address            # allocates an ip address from the pool
        response.body['address']['ip']              # returns the ip address

4. Associate a server to an existing address:

        conn.associate_address("<server_id>", "<ip_address>")

5. Disassociate a server from an existing address:

        conn.disassociate_address("<server_id>", "<ip_address>")

6. Delete (release) an existing address:

        conn.release_address("<address_id>")            # releases the ip address to the pool
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/connect/
---
<!--PUBLISHED-->

#Connecting to HP Helion using Ruby Fog Bindings
The HP Helion uses OpenStack as the platform and you can connect and set
up your HP Helion Cloud using Ruby Fog. To begin, connect using the following
instructions:

-  `Initial Connection <#initial-connection>`__
-  `Optional Parameters <#optional-parameters>`__

Initial Connection
------------------

To connect to the HP Helion, follow these steps:

1. Enter IRB

   ::

       irb

2. Require the Fog library and Rubygems:

   ::

       require 'fog'

3. Establish a connection to the desired HP Helion service

   ::

       def credentials_hash
          {
            :provider => :hp,
            :hp_auth_uri => ENV['OS_AUTH_URL'],
            :hp_access_key => ENV['OS_USER'],
            :hp_secret_key => ENV['OS_API_KEY'],
            :hp_tenant_id =>  ENV['OS_TENANT'],
            :hp_avl_zone => ENV['OS_REGION']
          }
       end

       storage = Fog::<SERVICE-NAME>.new(credentials_hash)

Where ``SERVICE-NAME`` can be
`Compute <https://github.com/fog/fog/blob/master/lib/fog/hp/docs/compute.md>`__,
`Storage <https://github.com/fog/fog/blob/master/lib/fog/hp/docs/object_storage.md>`__


Optional Parameters
-------------------

This section describes the optional parameters that you can use when
connecting to any of the HP Helion services. The examples below show the
Compute service, but these optional parameters work with all of the HP
Helion services.

The ``user_agent`` parameter allows you to specify a string to pass as a
``user_agent`` header for the connection. You can use this to track the
caller of the operations. You can set the ``user_agent`` parameter as
follows:

::

        conn = Fog::Compute.new(
               ...
               ...
               :user_agent => "MyApp/x.x.x")

This inserts a ``user_agent`` string such as
``hphelionfog/x.x.x (MyApp/x.x.x)`` into the header.

In addition to the ``user_agent`` parameter, there are several
additional parameters you can set using the ``connection_options``
parameter. These options are provided by the Excon library and allow you
to modify the underlying connection to a service. These options are
`Instrumentation <#Instrumentation>`__, `Timeouts <#Timeouts>`__,
`Proxy <#Proxy>`__, and `HTTPS/SSL <#HTTPS>`__.

Instrumentation
~~~~~~~~~~~~~~~

Use this parameter for debugging purposes. When you use the default
instrumentor ``Excon::StandardInstrumentor``, all events are output to
``stderr``. You can also designate your own instrumentor. You can set
the default instrumentor as follows:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {:instrumentor => Excon::StandardInstrumentor})

Timeouts
~~~~~~~~

Use this parameter to set different timeout values. You can set the
timeouts parameter as follows:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {
                      :connect_timeout => <time_in_secs>,
                      :read_timeout => <time_in_secs>,
                      :write_timeout => <time_in_secs>})

Proxy
~~~~~

Use this parameter to specify a proxy URL for both HTTP and HTTPS
connections. You can set the proxy parameter as follows:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {:proxy => 'http://myproxyurl:4444'})

HTTPS/SSL
~~~~~~~~~

By default, peer certificates are verified when you use secure socket
layer (SSL) for HTTPS. Sometimes this does not work due to
configurations in different operating systems, causing connection
errors. To help avoid this, you can set HTTPS/SSL parameters. To set the
path to the certificates:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {:ssl_ca_path => "/path/to/certs"})

To set the path to a certificate file:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {:ssl_ca_file => "/path/to/certificate_file"})

To set turn off peer verification:

::

        conn = Fog::Compute.new(
               ...
               ...
               :connection_options => {:ssl_verify_peer => false})

**Note**: This makes your connection less secure.

For further information on these options, please see `the Excon
documentation <http://github.com/geemus/excon>`__.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/languages/ruby/install/
---
<!--PUBLISHED-->

#Installing Ruby Fog Bindings for HP Helion
Before you can begin working with the Ruby Fog bindings, you have to
install them (of course!). This page provides you with the installation
information for the following operating systems:

-  `Ubuntu Installation <#ubuntu-installation>`__
-  `Mac OSX Installation <#mac-osx-installation>`__
-  `CentOS Installation <#centos-installation>`__
-  `Uninstalling <#uninstalling>`__

To install and use HP Helion Ruby bindings for Fog, please install the
`latest release <http://fog.io>`__ of Fog.

Ubuntu Installation
-------------------

If you plan on using the Ruby Fog binding on Ubuntu, we recommend you
use Ubuntu versions 12.04 or 12.10. The Ruby Fog bindings may work on
other versions, but are not supported.

To install the Ruby Fog bindings on the Ubuntu operating system, follow
these steps while logged in as the root user:

1. Install Ruby and Ruby-dev:

   ::

       apt-get install ruby1.9.3 ruby-dev

2. Install RubyGems:

   ::

       apt-get install rubygems

3. Install the dependent libraries:

   ::

       apt-get install libxml2 libxml2-dev libxslt1-dev libxslt1.1 sgml-base xml-core

4. Install the RDoc Ruby source documentation generator package:

   ::

       gem install rdoc

5. Install the Fog gem:

   ::

       gem install fog

See the :ref:`Connecting to the Service <sdk-ruby-connect>`
page for details on how to connect.

MacOS X Installation
--------------------

Some Ruby packages require C/C++ compiler support. On the MacOS, if you
haven't already installed XCode, we recommend that you install it to
provide the needed C/C++ compiler for your system.

To install the Ruby Fog bindings on MacOS X, follow these steps while
logged in as the root user:

1.  Download and install Xcode. You can `download the most recent
    version of XCode through the Mac App
    Store <https://itunes.apple.com/us/app/xcode/id497799835?ls=1&mt=12>`__.
    If you want to install an earlier version of Xcode, go to the `Apple
    Developer <https://developer.apple.com/downloads/index.action>`__
    site and search for "Xcode". In the results list, select the version
    of Xcode that you want and install it. (Note that you need to be
    signed up as an "Apple Developer" to access the download. Sign-up is
    free.)

2.  To make your installation process easier we recommend that you
    install
    `Homebrew <http://wiki.github.com/mxcl/homebrew/installation>`__.
    Follow the instructions on the Homebrew page to install the package.
    After you have downloaded Homebrew, the CLI command to install it
    is:

    ::

        homebrew install - ruby -e "$(curl -fsSkL raw.github.com/mxcl/homebrew/go)"

3.  Add the Homebrew path to your $PATH environment variable. You can
    either do this via the CLI command line:

    ::

        export PATH=:/usr/local/sbin:$PATH

    (The default Homebrew installation location is the
    ``/usr/local/sbin`` directory.) Or you can add the Homebrew path
    (``/usr/local/sbin``) to your $PATH environment variable in your
    local ``.profile`` file.

4.  Install RVM on your system:

    ::

        curl -L get.rvm.io | bash -s stable

    **Note**: You can also install RVM using `Jewelry
    Box <https://unfiniti.com/software/mac/jewelrybox>`__, a RVM
    graphical user interface (GUI) for Mac OSX.

5.  Install the packages required by RVM; the following command lists
    the required packages:

    ::

        source ~/.rvm/scripts/rvm
        rvm requirements # install required packages

6.  Install the required packages listed in Step 5:

    ::

        brew install <packages>

    Where ``<packages>`` are the packages that you need to install.

7.  Install the ``libksba`` library:

    ::

        brew install libksba

8.  Install Ruby:

    ::

        rvm user all
        rvm install ruby-1.9.3 --with-gcc=clang

9.  Use the Ruby version and make it the default:

    ::

        rvm use 1.9.3 --default

10. Install the Fog gem:

    ::

        gem install fog

See the :ref:`Connecting to the Service <sdk-ruby-connect>`
page for details on how to connect.

CentOS Installation
-------------------

If you plan on using the Ruby Fog binding on CentOS, we recommend you
use CentOS versions 6.2 or 6.3. The Ruby Fog bindings may work on other
versions, but are not supported.

To install the Ruby Fog bindings on CentOS, follow these steps while
logged in as the root user:

1. Install Ruby and Ruby Dev:

   ::

       yum install -y ruby ruby-devel

2. Install Rubygems:

   ::

       yum install -y rubygems

3. Install the dependent libraries:

   ::

       yum install -y gcc make libxml2 libxml2-devel libxslt libxslt-devel

4. Install RDoc Ruby source documentation generator package:

   ::

       gem install rdoc

5. Install the Fog gem:

   ::

       gem install fog

See the :ref:`Connecting to the Service <sdk-ruby-connect>`
page for details on how to connect.

Uninstalling
------------

Its recommended that you uninstall a previous version prior to
upgrading. To uninstall, execute the following command while logged in as
the root user:

::

        gem uninstall fog
---
layout: default-devplatform
permalink: /als/v1/user/deploy/manifestyml/
product: devplatform
---
<!--PUBLISHED-->

#Manifest.yml Options {#manifest-yml-options}

Using a *manifest.yml* file is the standard configuration file format for all
Cloud Foundry systems, allowing for portability from those systems to
Application Lifecycle Service without configuration changes.

The client uses the keys to determine values
that are otherwise passed by the user as arguments or as answers to
prompts.

[name:](#name)

- [applications](#applications)
	- [depends-on](#depends-on)
	- [helion](#helion)

- [buildpack:](#buildpack)
    -   [framework:](#framework)
        -   [type:](#type)
        -   [runtime:](#runtime)
        -   [document-root:](#document-root)
        -   [start-file:](#start-file)
    -   [app-dir](#app-dir)
    -   [services:](#services)
    -   [requirements:](#requirements)
        -   [OS Packages](#os-packages)
        -   [Language Modules](#language-modules)
    -   [mem:](#mem)
    -   [disk:](#disk)
    -   [instances:](#instances)
    -   [url (or urls):](#url-or-urls)
    -   [env:](#env)
        -   [env Attributes](#env-attributes)
    -   [processes:](#processes)
        -   [web:](#web)
    -   [command:](#command)
    -   [cron:](#cron)
    -   [ignores:](#ignores)
    -   [inherit:](#inherit)
    -   [hooks:](#hooks)
        -   [pre-push:](#pre-push)
        -   [pre-staging:](#pre-staging)
        -   [post-staging:](#post-staging)
        -   [pre-running:](#pre-running)
    -   [drain:](#drain)
    -   [min\_version:](#min-version)
        -   [client:](#client)
        -   [server:](#server)
    -   [Key Substitution](#key-substitution)


##applications: {#applications}

This key contains a list of options corresponding to individual apps to
be pushed. Each sub-key should match the name of folders where the files
for each app are contained. For example:

    applications:
      web:
        name: springweb
        framework:
          name: spring
        instances: 1
        mem: 512
      worker:
        name: springweb-helper
        framework:
          name: node
        instances: 1
        mem: 64

Here the two keys `web:` and `worker:` match subdirectories (named `web` and
`worker`) of the directory containing the
*manifest.yml* file.

The shortcut "." can be used if the application code is in the top level
directory along with the *manifest.yml* file:

    applications:
      .:
        name: singleapp
        framework:
          name: spring
        instances: 1
        mem: 512

###depends-on: {#depends-on}
When deploying multiple applications from a single *manifest.yml* use
the `depends-on:` key to set the order in which the
apps are started and stopped. An app with the `depends-on:` option will be pushed only after the listed apps have been
pushed and are running on the server.

In the previous example, if you wanted to ensure that `web` was started before `worker`, you would add
`depends-on: worker` in the `web:` section:

    applications:
      web:
        depends-on: worker
        name: springweb
        framework:
          name: spring
        instances: 1
        mem: 512
      worker:
        name: springweb-helper
        framework:
          name: node
        instances: 1
        mem: 64

If an app is stopped or restarted, the process happens in the reverse
order.

###helion: {#helion}
The following Application Lifecycle Service-specific options need to be placed in a
`helion:` block within the application block.

-   processes:
-   min\_version:
-   env:
-   ignores:
-   hooks:
-   cron:
-   requirements

For example:

    applications:
      .:
        name: celery-demo
        framework:
          name: python
          runtime: python27
        mem: 128
        helion:
          env:
            CELERY_ENV:
              default: crisper
          processes:
            web: celeryd
          requirements:
            pypm: [celery]
          hooks:
            pre-running:
              - sudo cp $HOME/fstab /etc/fstab
              - sudo mount /dev/shm
          min_version:
            server: 0.9.0.143
            client: 1.0

Configuration options for Application Lifecycle Service applications can be stored in a
*manifest.yml* file in the top-level application directory.

The *manifest.yml* file defines **keys** and associated **values** which
the `helion` client uses to set options that are
otherwise passed by the user as command arguments or answers to prompts.
Other values are used by the server to install needed packages, or run
setup scripts during the staging, post-staging, or pre-running steps in
deployment.

[*Key substitution*](#key-substitution) can be used to
insert values from one key into another.

The following sections describe the available keys and the values that
can be assigned to them:

##name: {#name}
This is the name of the application being pushed. If not specified, the
user will be prompted during `helion push` to
provide a name. The name can also be specified on the command line (eg.
`helion push currency-converter`).

Example:

    name: currency-converter

**Note**

The application name must be a valid [hostname
label](http://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_host_names)
(i.e. containing only alphanumeric characters and hyphens).

buildpack:[](#buildpack "Permalink to this headline")
------------------------------------------------------

The Git repository URL for the specific
[*buildpack*](/als/v1/user/deploy/buildpack/#buildpacks) used to deploy the application.
For example:

    name: java-app
    mem: 512M
    buildpack: https://github.com/heroku/heroku-buildpack-java.git

If unset, Application Lifecycle Service will check to see if the application triggers the
`detect` scripts in any of its [*built-in
buildpacks*](/als/v1/user/deploy/buildpack/#buildpacks-built-in).

framework:[](#framework "Permalink to this headline")
------------------------------------------------------

Allows the app to specify a framework and runtime to be used. Specifying
a value for the `framework` key triggers the use of
the [*Legacy Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy).

**Note**

The keys in the `framework` section are used with
the [*Legacy Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy) only.
Applications using language or framework-specific buildpacks do not
require these values, and should instead specify the
[*buildpack*](#yml-buildpack) or rely on the detection scripts
of the [*built-in buildpacks*](/als/v1/user/deploy/buildpack/#buildpacks-built-in).

### type:[](#type "Permalink to this headline")

The framework to use. Check `helion frameworks`
for a complete list of available frameworks. If not specified, user may
be prompted during `helion push`. Can also be
input with the command line option --framework, -f (eg.
`helion push --framework python`).

### runtime:[](#runtime "Permalink to this headline")

The runtime to use. Check `helion runtimes` for a
complete list of available runtimes. If not specified, server will
select the best option based on available data. Can also be input with
the command line option --runtime, -f (eg.
`helion push --runtime python32`).

Example:

    framework:
      type: python
      runtime: python32

### document-root:[](#document-root "Permalink to this headline")

Overrides the default document-root setting (\$HOME) for the web server.

**Note**

Node.js, Perl, PHP, and Python frameworks only.

Setting a deeper document root directory avoids the problem of exposing
supporting files (e.g. *manifest.yml*) over HTTP.

Example:

    framework:
      type: php
      document-root: web

The document-root must always be specified relative to \$HOME
(/home/helion/app).

### start-file:[](#start-file "Permalink to this headline")

Set the main application filename.

**Note**

Perl and Python frameworks only.

If your application does not use a conventional filename (e.g. app.psgi
for Perl, wsgi.py for Python) using this option, possibly in conjunction
with **document-root**, avoids the need to refactor the application for
Application Lifecycle Service. For example:

    framework:
      start-file: temp.psgi

Or:

    framework:
      start-file: temp.py

This value will be used by the
[*PROCESSES\_WEB*](/als/v1/user/reference/environment/#term-processes-web) and
HELION\_START\_FILE environment variables. Any changes to
HELION\_START\_FILE at runtime will not change the value of
[*PROCESSES\_WEB*](/als/v1/user/reference/environment/#term-processes-web) as
the macro is expanded before the pre-running hooks are run.

app-dir[](#app-dir "Permalink to this headline")
-------------------------------------------------

The directory containing the application code to be pushed to Application Lifecycle Service
(if it's not in the top-level directory). This directory becomes the
\$HOME directory of the application when the application is pushed to
Application Lifecycle Service. For example, Java applications will often have a 'target'
sub-directory containing the output of ant or mvn builds:

    name: sample
    framework:
      type: java_web
      runtime: java7
    app-dir: target

If required, you can also set
[*document-root*](#yml-document-root) in the
[*framework*](#yml-framework) section to specify a
sub-directory of the application \$HOME to be used as the document root.

To launch multiple applications from multiple sub-directories use a
[*manifest.yml*](/als/v1/user/deploy/manifestyml/#manifest-yml) file.

###services: {#services}
A list of services to create and bind to the application. Each sub key
is the name of the service to create / bind, and the associated value is
the type of the new service. If multiple services of the same type are
needed, list them on separate lines as in the example below.

Use `helion services` for a complete list of
available services. If not specified, the user may be prompted during
`helion push`.

Example:

    services:
      customerdb: mysql
      paymentsdb: mysql

The Application Lifecycle Service client supports [*key
substitution*](#yml-key-substitution) for service names,
allowing you to create service names based on the specified application
name. For example:

    services:
      ${name}-db: mysql

The application name can be set as an option to the [*helion
push*](/als/v1/user/reference/client-ref/#command-push) command, overriding
the **name** value defined in *manifest.yml*. Use this technique when
pushing multiple versions of the same application (using different
names) if you want them to use separate databases. For example:

    name: sample

    framework:
      type: node

    services:
      ${name}-db: mysql

Using the name specified in *manifest.yml*, a data service is created to
match that name:

    $ helion push -n
    Pushing application 'sample'...
    Framework:       node
    Runtime:         <framework-specific default>
    Application Url: sample.helion-pjw3.local
    Creating Application [sample]: OK
    Binding service [sample-db]: OK
    ...
    Starting Application [sample]: ...OK

If you specify a new name for the application as an argument to
`helion push`, a new service with a matching name
is created rather than binding to the existing 'sample-db' service:

    $ helion push sample-2 -n
    Pushing application 'sample-2'...
    Framework:       node
    Runtime:         <framework-specific default>
    Application Url: sample-2.helion-pjw3.local
    Creating Application [sample-2]: OK
    Binding service [sample-2-db]: OK
    ...
    Starting Application [sample-2]: ..OK

    $ helion apps

    +-------------+---+---------+------------------------------+-------------+
    | Application | # | Health  | URLS                         | Services    |
    +-------------+---+---------+------------------------------+-------------+
    | sample      | 1 | RUNNING | sample.helion-pjw3.local   | sample-db   |
    | sample-2    | 1 | RUNNING | sample-2.helion-pjw3.local | sample-2-db |
    +-------------+---+---------+------------------------------+-------------+

requirements:[](#requirements "Permalink to this headline")
------------------------------------------------------------

Specifies required modules, and allows the installation of additional OS
packages.

### OS Packages[](#os-packages "Permalink to this headline")

OS packages can be added in an `ubuntu:` block
within a `staging:` and/or `running:` block. Plain strings are treated as package names:

    requirements:
      staging:
        ubuntu:
          - libfoo-dev
      running:
        ubuntu:
          - libfoo
          - some-app

To add the OS requirements to both the staging and running phases add
the `ubuntu:` block directly beneath the
`requirements:` key:

    requirements:
      ubuntu:
        - libfoo-dev

If your account has been given sudo privileges in application
containers, you can use arrays to add additional repositories,
overriding repository restrictions set by admins.

Example:

    requirements:
      staging:
        ubuntu:
          - ["ppa:gophers/go"]
          - golang-stable
      running:
        ubuntu:
          - libfoo

### Language Modules[](#language-modules "Permalink to this headline")

For the installation of language modules, replacing the
*requirements.txt* file. For
[*Python*](/als/v1/user/deploy/languages/python/#python-index), `pypm:` and `pip:` can be specified:

    requirements:
      pypm:
        - tornado
        - pymongo
      pip:
        - pycurl

For [*Perl*](/als/v1/user/deploy/languages/perl/#perl-index), `ppm:` or `cpan:` can be specified:

    requirements:
      ppm:
        - CGI::Application::PSGI
        - Plack::Builder

    requirements:
      cpan:
        - CGI::Application::PSGI
        - Plack::Builder

mem:[](#mem "Permalink to this headline")
------------------------------------------

The amount of memory to allocate for the application.

Syntax: \<int\> or \<int\>M - Memory in megabytes. eg. 256M

Syntax: \<int\>G or \<float\>G - Memory in gigabytes. eg. 1.5G or 2G

If not specified, user may be prompted during `helion push`. Can also be specified on the command line (eg.
`helion push --mem 256M`).

Example:

    mem: 64M

disk:[](#disk "Permalink to this headline")
--------------------------------------------

The amount of disk space to allocate for the application (minimum
512MB).

Syntax: \<int\> or \<int\>M - Disk in megabytes. eg. 768M

Syntax: \<int\>G or \<float\>G - Disk in gigabytes. eg. 1.5G or 2G

If not specified, 2GB of disk space is allocated. Can also be specified
on the command line (eg. `helion push --disk 768M`).

Example:

    mem: 3.5GB

instances:[](#instances "Permalink to this headline")
------------------------------------------------------

The number of instances to allocate for the application. If not
specified, defaults to 1. Can be specified on the command line (eg.
`helion push --instances 2`).

Example:

    instances: 2

url (or urls):[](#url-or-urls "Permalink to this headline")
------------------------------------------------------------

List of URLs mapped to the application. For example:

    name: cms-platform

    url:
      - blog.example.org
      - exampleblog.com

With this key specified, Application Lifecycle Service will not assign a default
"appname.paasname.com" URL to the application. If you would like this
URL assigned as well, add `${name}.${target-base}`
to the list of URLs.

See [*Mapping App URLs*](index.html#deploy-map-url) for more
information.

env:[](#env "Permalink to this headline")
------------------------------------------

A map of environment variables to initialize for the application. Each
subkey is the name of the variable, with an associated value.

Example:

    env:
      HOME_IP_ADDRESS: 127.0.0.1

Avoid using this for values which should not be stored in plain text,
such as API keys and passwords.

### env Attributes[](#env-attributes "Permalink to this headline")

Each environment variable can have attributes which modify the
interactive behavior of the [*helion
client*](/als/v1/user/reference/client-ref/#command-ref-client) when using the
[*push*](/als/v1/user/reference/client-ref/#command-push) command. These
attributes are set with the following keys:

-   **default** (string): The value to use if nothing is entered by the
    user interactively (no default).
-   **required** ([boolean](http://yaml.org/type/bool)): If set,
    the variable must have a value (defaults to "false" == "not
    required").
-   **inherit** (boolean): If set, the client looks in the local
    environment for a variable of the same name and takes its value
    (defaults to "false" == "no inheritance").
-   **prompt** (string): The prompt to show when the client asks for the
    variable value (Defaults to "Enter \<varname\>:").
-   **choices** (list of strings): If specified, a list of legal values
    for the variable, to be presented to the user as a menu rather than
    prompting for a string (no default).

For example:

    env:
      MY_SPECIAL_VAR:
        default: "development"
        required: y
        inherit: y
        prompt: "What type of deployment?: "
        choices:
          - "development"
          - "testing"
          - "staging"
          - "production"

Pushing with the `--no-prompt` option will fail with
the error message "Required variable *VAR\_NAME* not set" if "required"
is set but no value is given (via "default", "inherit" or the
`--env` option).

**Note**

These attributes are only recognized by the [*Helion
client*](/als/v1/user/reference/client-ref/#command-ref-client).

##processes: {#processes}

### web: {#web}

**Note**

Used with the [*Legacy buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy)
only. When using other buildpacks, create a
[Procfile](https://devcenter.heroku.com/articles/procfile) in the
application's root directory.

Specify a custom command to launch your web application or to pass
custom arguments to uWSGI. For example:

    processes:
      web: python3.2 app.py

This key is required when using the
[*generic*](/als/v1/user/deploy/other-frameworks/#generic-framework) framework, but is
optionally available for all other frameworks.

**If defined**, this process is expected to launch a HTTP server bound
to `0.0.0.0` host and `$PORT`
port.

**If set to Null ("\~")**, the application is treated as a worker
application and not provisioned with a URL. For example, an application
that just runs a background Perl script might look like this:

    name: perlwork
    framework:
      type: perl
    command: perl worker.pl
    processes:
      web: ~

A 'command:' value must be present for worker applications.

If the application exists solely to run commands via
[*cron*](#yml-cron), a dummy command such as '*sleep 365d*'
should be specified.

The `$PROCESSES_WEB` and `$HELION_UWSGI` variables can also be used with `processes: web:`.

`$PROCESSES_WEB` contains the command that is used
to start the web application, if you want to override the default
command.

`$HELION_UWSGI` is defined for runtimes using
uWSGI (Perl and Python), and it contains the command to start uWSGI with
all relevant options. It can be used if you are appending additional
uWSGI options to the command.

command:[](#command "Permalink to this headline")
--------------------------------------------------

Used for worker applications to start a background process. Below is an
example using the
[*standalone*](/als/v1/user/deploy/other-frameworks/#standalone-framework) framework:

    name: helion-worker
    instances: 1
    framework:
      type: standalone
      runtime: ruby18
    command: ruby worker.rb

cron:[](#cron "Permalink to this headline")
--------------------------------------------

Commands listed here are added to the crontab file. See the section on
[*Crontab Support*](index.html#deploy-crontab) for details.

Example:

    cron:
      - PLUGH=xyzzy
      - "*/1 * * * * env > $HOME/env"

ignores:[](#ignores "Permalink to this headline")
--------------------------------------------------

A list of .gitignore-style patterns. Files and directories in the
application directory matching at least one pattern are ignored during
"push" and "update".

Example:

    ignores: ["tmp", ".git"]

To include all hidden files or folders simply use an empty list.

Example:

    ignores: []

If not specified, a default list is used to exclude files and folders
not typically required in a deployed application (e.g. the dot files and
folders of various source code control systems).

The default list contains the following: \~\*/, .git/, \*.svn/, \*.hg/,
\*CVS/, \_FOSSIL\_.fos, \*.bzr, \*.cdv, \*.pc, \*RCS, \*SCCS,\*\_MTN,
\*\_build, \*\_darcs, \*\_sgbak, \*autom4te.cache, \*blib, \*cover\_db,
\*\~.dep, \*\~.dot, \*\~.nib, \*\~.plst

inherit:[](#inherit "Permalink to this headline")
--------------------------------------------------

This special key has the effect of treating its value as the name of a
file to be included into *manifest.yml*.

Example:

*parent.yml*:

    env:
      COMPANY: The ABC Company

*manifest.yml*:

    name: example-app
    inherit: parent.yml
    mem: 64M

effect from processing:

    name: example-app
    env:
      COMPANY: The ABC Company
    mem: 64M

##hooks: {#hooks}
Hooks are commands that are run at various point of the staging and
running process of an app.

### pre-push:[](#pre-push "Permalink to this headline")

Commands run **on the local system** before pushing the code to
Application Lifecycle Service. This can be useful for building source files (e.g. with
`make`) or performing configuration steps that need
to be done on the local system before the application code can be
pushed. Commands are executed between application creation (when the URL
and application resources are reserved) and the actual upload of the
local code.

The client will set the HELION\_HOOK\_ACTION variable to "create" if
the application is new, or "update" if it detects the application
already exists. You can use this variable to run hooks differently in
either context.

### pre-staging:[](#pre-staging "Permalink to this headline")

A list of commands to be run in the root of the app's directory before
the staging process is started. The commands are only run a single time
on push or update.

### post-staging:[](#post-staging "Permalink to this headline")

A list of commands to be run in the root of the app's directory after
the staging process is complete. The commands are only run a single time
on push or update.

### pre-running:[](#pre-running "Permalink to this headline")

A list of commands to be run in the root of the app's directory after
staging is complete and before the app is started. The commands are run
sequentially, in the order listed, each time an app is started or
restarted.

Example:

    hooks:
      pre-staging:
        - python prestagingsetup.py
      post-staging:
        - python manage.py syncdb --noinput
        - python manage.py migrate --noinput
      pre-running:
      - python prerunsetup.py

Hook processing ends and staging aborts if a command returns a nonzero
exit status (i.e. if the command fails). You can suppress this behavior
by prefacing the command with "-" to force staging to proceed despite
failures. The "-" must be included in a quoted command string. For
example:

    hooks:
      post-staging:
        - "-python manage.py syncdb --noinput"

Commands used in the `hooks:` keys may not include
shell metacharacters, such as "&&" for combining commands, "\#" for
comments, "\<", "\>" or "|" for I/O redirection.

If you need shell functionality such as metacharacters, signal trapping,
or forcing zero exit status, wrap your command in a *script.sh* file and
use `sh +x script.sh` as your hook command.

Also note that if only a single command needs to be run, the list format
is not needed and can be included on the same line:

    hooks:
      post-staging: python staging.py
      pre-running:  python running.py

drain:[](#drain "Permalink to this headline")
----------------------------------------------

[*Application log drains*](/als/v1/user/deploy/app-logs/#application-logs-drain) can be
added to an application when it is deployed by describing them in a
`drain:` block with a drain name and URL:

    drain:
      drain_name: protocol://host.domain.tld:port/

To enable JSON logging, specify the URL separately along with a
`json: true` line:

    drain:
      drain_name:
        url: protocol://host.domain.tld:port/
        json: true

For example:

    drain:
      mytestdrain: udp://logs.loggly.com:12346/
      otherdrain:
        url: tcp://logs.papertrailapp.com:12345/
        json: true

min\_version:[](#min-version "Permalink to this headline")
-----------------------------------------------------------

Sets requirements for the minimum version of the client and server under
which the app will run.

### client:[](#client "Permalink to this headline")

The minimum version of the Application Lifecycle Service client needed to manage the app.

To determine the client version, use:

    $ helion version

    helion 0.3.13.0.18

Example:

    min_version:
      client: 0.3.13.0.18

### server:[](#server "Permalink to this headline")

The minimum version of the Application Lifecycle Service server needed to run the app.

##Key Substitution {#key-substitution}
The value of any key in *manifest.yml* can be inserted in other keys
using the \${*key*} syntax. For example:

    name: example-app
    env:
      MY_NAME: ${name}

This defines a "MY\_NAME" environment variable with the value
"example-app".

A small number of keys are predefined for your use within
*manifest.yml*:

	  ------------------------------------------------------------------------
	  key
	  substitution
	  value
	  -------------- ---------------------------------------------------------
	  \${random-word \${target-base}
	  }              The hostname of the targeted Application Lifecycle Service system, for
	  A short        example **helion-xxxx.local**
	  alphanumeric   
	  string of      
	  random         
	  characters     
	  ------------------------------------------------------------------------

**Note**

See the [*services*](#services) section for an example of
variable key substitution for yaml key names.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/newrelic/
product: devplatform
---
<!--PUBLISHED-->
<!-- file deliberately orphaned, functionality not implemented 
New Relic Monitoring {#new-relic-monitoring}-->
===========================================================================
   [New Relic for Ruby](#new-relic-for-ruby)
        -   [The Ruby Gem](#the-ruby-gem)
        -   [Installing the Ruby agent with the Bundler
            Gem](#installing-the-ruby-agent-with-the-bundler-gem)
        -   [Configuration File](#configuration-file)
    -   [New Relic for Python](#new-relic-for-python)
        -   [Bottle Currency Example](#bottle-currency-example)
    -   [New Relic for Java](#new-relic-for-java)
        -   [Pet Catalog Example](#pet-catalog-example)
    -   [New Relic for PHP](#new-relic-for-php)
        -   [WordPress Example](#wordpress-example)
    -   [Results](#results)
 
**Note**

These instructions are for use with Application Lifecycle Service. For further details,
please see the [New Relic
site](http://newrelic.com/docs/python/new-relic-for-python).

New Relic can be used to track your application analytics running in
Application Lifecycle Service as well as for server monitoring. The languages it can
currently be used with are:

1.  [*Ruby*](#newrelic-ruby)
2.  [*Python*](#newrelic-python)
3.  [*Java*](#newrelic-java)
4.  [*PHP*](#newrelic-php)

In order to use New Relic, you need a [New Relic
account](http://newrelic.com/).

**Note**

For security reasons, avoid committing your license key to source
control.

New Relic for Ruby[](#new-relic-for-ruby "Permalink to this headline")
-----------------------------------------------------------------------

### The Ruby Gem[](#the-ruby-gem "Permalink to this headline")

New Relic recommends installing the New Relic Ruby gem available on
gemcutter as `newrelic_rpm`:

    $ sudo gem install newrelic_rpm

Update the Ruby Gem at any time by running:

    $ sudo gem update newrelic_rpm

Once the Ruby Gem is installed, add this line to your *Gemfile*:

    $ gem 'newrelic_rpm'

### Installing the Ruby agent with the Bundler Gem[](#installing-the-ruby-agent-with-the-bundler-gem "Permalink to this headline")

Add the gem specification to your *Gemfile*. It's best to place the New
Relic gem as low in the list as possible, allowing the frameworks above
it to be instrumented when the gem initializes:

    $ gem 'newrelic_rpm'

In the same folder as the *Gemfile*, run:

    $ bundle install

### Configuration File[](#configuration-file "Permalink to this headline")

After installing the agent, copy the newrelic.yml file into the config
subdirectory of your application. You can download a fresh newrelic.yml
that includes your license key from the Account Settings link when
logged in to [rpm.newrelic.com](http://rpm.newrelic.com/).

Whenever you update the agent, double-check that your Agent
configuration file (*config/newrelic.yml*) is up to date. To do this,
you'll need to do a visual inspection of the default *newrelic.yml* file
that lives in the Agent plugin folder
(*vendor/plugins/newrelic\_rpm/newrelic.yml*). Look for new
configuration options that aren't in your *config/newrelic.yml* file.

New Relic for Python[](#new-relic-for-python "Permalink to this headline")
---------------------------------------------------------------------------

The New Relic Python agent is pre-installed on Application Lifecycle Service.

The minimal steps required to integrate New Relic to your Python WSGI
application:

1.  At the top of *wsgi.py*, add:

        import newrelic.agent
        newrelic.agent.initialize()

2.  In *wsgi.py*, wrap your `application` WSGI entry
    point, eg:

        application = newrelic.agent.wsgi_application()(application)

3.  Add required newrelic environment variables to *manifest.yml*:

        env:
              NEW_RELIC_LOG: stderr
              NEW_RELIC_LOG_LEVEL: DEBUG  # <- this is optional
              NEW_RELIC_APP_NAME: <your application name>
              NEW_RELIC_LICENSE_KEY: <your license key>

An alternative to modifying your python is to wrap
`$PROCESSES_WEB` in *manifest.yml* with
[newrelic-admin](https://newrelic.com/docs/python/python-agent-admin-script).

### Bottle Currency Example[](#bottle-currency-example "Permalink to this headline")

[Bottle Currency with New Relic on
GitHub](https://github.com/Stackato-Apps/bottle-currency/tree/newrelic).

New Relic for Java[](#new-relic-for-java "Permalink to this headline")
-----------------------------------------------------------------------

The New Relic Java agent is **not** pre-installed on the Application Lifecycle Service VM. To
add monitoring, you must include the agent with your application.

-   Download a fresh newrelic\_agent\<version number\>.zip that includes
    your license key from the Account Settings link when logged in to
    [rpm.newrelic.com](http://rpm.newrelic.com/).

-   Unpack the zip file in a convenient directory to edit the
    newrelic.yml file inside.

-   Set the app\_name in newrelic.yml to the actual name of your
    application as you would like it to appear in your New Relic
    dashboard.

-   Save your changes and place the newrelic folder in the root
    directory of your application along with WEB-INF folder.

-   Add the following section to a "hooks" section in *
-   .yml*:

        hooks:
            pre-running:
            - mv newrelic $HELION_APP_ROOT/tomcat/
            - cd $HELION_APP_ROOT/tomcat/newrelic
            - java -jar newrelic.jar install

### Pet Catalog Example[](#pet-catalog-example "Permalink to this headline")

[Pet Catalog (Java EE) with New Relic on
GitHub](https://github.com/Stackato-Apps/pet-catalog/tree/newrelic).

New Relic for PHP[](#new-relic-for-php "Permalink to this headline")
---------------------------------------------------------------------

The New Relic agent PHP libraries are pre-installed on Application Lifecycle Service. To add
monitoring, you need to add an agent configuration file to the root
directory of the application and make some modifications to
*manifest.yml*.

-   Add a `newrelic.ini` file in
    [*HOME*](/als/v1/user/reference/environment/#term-home) directory
    containing the following:

        extension=newrelic.so

        newrelic.daemon.logfile="/home/helion/logs/newrelic-daemon.log"
        newrelic.daemon.loglevel="warning"

        newrelic.logfile="/home/helion/logs/php_agent.log"
        newrelic.loglevel="warning"

        newrelic.license="XXXXXXX-your-new-relic-key-XXXXXXXXXXX"
        newrelic.appname="YourAppName"

    The `license_key` can be found in your 'Account
    settings' page on New Relic.

    Set `newrelic.appname` to the actual name of
    your application as you would like it to appear in your New Relic
    dashboard.

    The above settings are described in detail in the [New Relic PHP
    Agent Settings
    documentation](http://newrelic.com/docs/php/php-agent-phpini-settings).

-   Add the following section to a "hooks" section in *manifest.yml*:

        hooks:
            pre-running:
            - mv -f newrelic.ini $HELION_APP_ROOT/apache/php/newrelic.ini

### WordPress Example[](#wordpress-example "Permalink to this headline")

[WordPress with New Relic on
GitHub](https://github.com/Stackato-Apps/wordpress/tree/newrelic).

Results[](#results "Permalink to this headline")
-------------------------------------------------

Push the app to the Application Lifecycle Service server, and make a few requests to it in a
browser. After a few minutes, check the New Relic dashboard to confirm
the information is being logged correctly.
---
layout: default-devplatform
permalink: /als/v1/user/deploy/orgs-spaces/
product: devplatform
---
<!--PUBLISHED-->

Organizations & Spaces[](#organizations-spaces "Permalink to this headline")
=============================================================================

Organizations and Spaces are the main organizational units in Application Lifecycle Service.

-   Organizations have Users, Spaces, and Domains
-   Spaces have Users, Applications, and Service Instances
-   Applications have Routes (which are derived from Domains)

Organizations[](#organizations "Permalink to this headline")
-------------------------------------------------------------

An organization is a top-level group of users, spaces, and domains. Only
Application Lifecycle Service admins (accounts with global superuser privileges) can manage
Organizations.

Each organization is assigned a [*Quota
Definition*](/als/v1/admin/server/configuration/#server-config-quota-definitions),
a set of limits on memory, applications, and service instances which is
share between all members of the organization.

Spaces[](#spaces "Permalink to this headline")
-----------------------------------------------

An organization can contain multiple spaces (e.g. **development**,
**test**, and **production**). A domain can be mapped to multiple spaces
but a route can be mapped to only one space.

Domains[](#domains "Permalink to this headline")
-------------------------------------------------

A domain in Application Lifecycle Service is a fully-qualified, second-level or lower domain
name (e.g. "example.com" or "helion.example.com").

Organizations and spaces can have custom domains, but are often able to
use a system domain by default as well (e.g. "myorg.net" and
"helion.example.com"). Domains belong to an organization. They are
associated with one or more spaces within that organization, but are not
directly bound to apps. Apps are assigned a "hostname + domain"
combination called a Route.

Routes[](#routes "Permalink to this headline")
-----------------------------------------------

A route is a virtual hostname followed by a domain name or
fully-qualified sub-domain (e.g. "myapp.myorg.example.com").

Management[](#management "Permalink to this headline")
-------------------------------------------------------

You can manage spaces and organizations with the [*helion
client*](/als/v1/user/client/#client) or the [*Management
Console*](/als/v1/admin/console/customize/#user-console-organizations).

Users & Roles[](#users-roles "Permalink to this headline")
-----------------------------------------------------------

Application Lifecycle Service users can take on different roles within Orgs and Spaces. These
roles can be assigned by a Manager of the relevant scope or an Application Lifecycle Service
Admin:

### Org Roles[](#org-roles "Permalink to this headline")

-   Manager: Can invite/manage users, select/change the plan, establish
    spending limits
-   Billing Manager: Can edit/change the billing account info, payment
    info
-   Auditor: View only access to all org and space info, settings,
    reports

### Space Roles[](#space-roles "Permalink to this headline")

-   Space Manager: Can invite/manage users, enable features for a given
    space
-   Space Developer: Can create, delete, manage applications and
    services, full access to all usage reports and logs
-   Space Auditor: View only access to all space information, settings,
    reports, logs---
layout: default-devplatform
permalink: /als/v1/user/deploy/other-frameworks/
product: devplatform
---
<!--PUBLISHED-->

Generic & Standalone Frameworks[](#generic-standalone-frameworks "Permalink to this headline")
===============================================================================================

The Generic and Standalone frameworks are for applications that might
not fit any of the other frameworks available in Application Lifecycle Service.

-   **Generic** is for web applications.
-   **Standalone** is for background applications without an HTTP
    interface.

These two frameworks make no assumptions about the application type and
can be customized to run a wide variety of non-standard applications.

Any language [*runtime*](/als/v1/user/deploy/manifestyml/#runtime)
available on the server can be specified in the config file. If a
runtime is not specified, Python 2.7 is made available by default.

Generic[](#generic "Permalink to this headline")
-------------------------------------------------

The Generic framework requires a custom [*processes:
web:*](/als/v1/user/deploy/manifestyml/#processes) setting in
*manifest.yml* specifying a command to start the web process (e.g. a
custom web server).

The example below shows a web process that serves static files from the
application directory using Python's
[SimpleHTTPServer](/als/v1/admin/server/):

    framework:
        type: generic
    processes:
        web: python -m SimpleHTTPServer $PORT

If you wish to run an application *without* a web interface (i.e. a
background "worker" process), [*set 'processes: web:' to
Null*](/als/v1/user/deploy/manifestyml/#processes-web-null) or use the
Standalone framework instead.

Standalone[](#standalone "Permalink to this headline")
-------------------------------------------------------

The Standalone framework uses a custom command specified in the
[*command:*](/als/v1/user/deploy/manifestyml/#command) key to start a
background worker process.

The example below shows *manifest.yml* configuration for an application
running a simple Python worker script.

    name: worker
    framework:
      type: standalone
      runtime: python27
    command: python main.py

The `command` must start a long-running child
process. If this process exits for any reason, the Health Manager will
restart the application instance.

Application Lifecycle Service will not assign URLs to apps deployed with the standalone
framework, as it is intended for background worker processes. The
`helion` client includes a heuristic that will
automatically suppress URL mapping for applications using this
framework.

**Note**

If the application does not serve web requests, it may appear in the
Management Console or `helion apps` command as not
running. To verify a non-web application is actually running, use
`helion logs` or `helion ssh`.

See the
[helion-worker](https://github.com/helion-apps/helion-worker/tree/master)
sample for a simple working example.---
layout: default-devplatform
permalink: /als/v1/user/deploy/stackatoyml/
product: devplatform
---
<!--PUBLISHED-->
<!--note that all this content has been merged into the manifest.yml file and is retained here in this orphaned article for reference only-->

HP Options[](#yml-options "Permalink to this headline")
===========================================================================
[name:](#name)
    -   [buildpack:](#buildpack)
    -   [framework:](#framework)
        -   [type:](#type)
        -   [runtime:](#runtime)
        -   [document-root:](#document-root)
        -   [start-file:](#start-file)
    -   [app-dir](#app-dir)
    -   [services:](#services)
    -   [requirements:](#requirements)
        -   [OS Packages](#os-packages)
        -   [Language Modules](#language-modules)
    -   [mem:](#mem)
    -   [disk:](#disk)
    -   [instances:](#instances)
    -   [url (or urls):](#url-or-urls)
    -   [env:](#env)
        -   [env Attributes](#env-attributes)
    -   [processes:](#processes)
        -   [web:](#web)
    -   [command:](#command)
    -   [cron:](#cron)
    -   [ignores:](#ignores)
    -   [inherit:](#inherit)
    -   [hooks:](#hooks)
        -   [pre-push:](#pre-push)
        -   [pre-staging:](#pre-staging)
        -   [post-staging:](#post-staging)
        -   [pre-running:](#pre-running)
    -   [drain:](#drain)
    -   [min\_version:](#min-version)
        -   [client:](#client)
        -   [server:](#server)
    -   [Key Substitution](#key-substitution)



Configuration options for Application Lifecycle Service applications can be stored in a
*manifest.yml* file in the top-level application directory.

The *manifest.yml* file defines **keys** and associated **values** which
the `helion` client uses to set options that are
otherwise passed by the user as command arguments or answers to prompts.
Other values are used by the server to install needed packages, or run
setup scripts during the staging, post-staging, or pre-running steps in
deployment.

[*Key substitution*](#yml-key-substitution) can be used to
insert values from one key into another.

The following sections describe the available keys and the values that
can be assigned to them:

name:[](#name "Permalink to this headline")
--------------------------------------------

This is the name of the application being pushed. If not specified, the
user will be prompted during `helion push` to
provide a name. The name can also be specified on the command line (eg.
`helion push currency-converter`).

Example:

    name: currency-converter

**Note**

The application name must be a valid [hostname
label](http://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_host_names)
(i.e. containing only alphanumeric characters and hyphens).

buildpack:[](#buildpack "Permalink to this headline")
------------------------------------------------------

The Git repository URL for the specific
[*buildpack*](/als/v1/user/deploy/buildpack/#buildpacks) used to deploy the application.
For example:

    name: java-app
    mem: 512M
    buildpack: https://github.com/heroku/heroku-buildpack-java.git

If unset, Application Lifecycle Service will check to see if the application triggers the
`detect` scripts in any of its [*built-in
buildpacks*](/als/v1/user/deploy/buildpack/#buildpacks-built-in).

framework:[](#framework "Permalink to this headline")
------------------------------------------------------

Allows the app to specify a framework and runtime to be used. Specifying
a value for the `framework` key triggers the use of
the [*Legacy Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy).

**Note**

The keys in the `framework` section are used with
the [*Legacy Buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy) only.
Applications using language or framework-specific buildpacks do not
require these values, and should instead specify the
[*buildpack*](#yml-buildpack) or rely on the detection scripts
of the [*built-in buildpacks*](/als/v1/user/deploy/buildpack/#buildpacks-built-in).

### type:[](#type "Permalink to this headline")

The framework to use. Check `helion frameworks`
for a complete list of available frameworks. If not specified, user may
be prompted during `helion push`. Can also be
input with the command line option --framework, -f (eg.
`helion push --framework python`).

### runtime:[](#runtime "Permalink to this headline")

The runtime to use. Check `helion runtimes` for a
complete list of available runtimes. If not specified, server will
select the best option based on available data. Can also be input with
the command line option --runtime, -f (eg.
`helion push --runtime python32`).

Example:

    framework:
      type: python
      runtime: python32

### document-root:[](#document-root "Permalink to this headline")

Overrides the default document-root setting (\$HOME) for the web server.

**Note**

Node.js, Perl, PHP, and Python frameworks only.

Setting a deeper document root directory avoids the problem of exposing
supporting files (e.g. *manifest.yml*) over HTTP.

Example:

    framework:
      type: php
      document-root: web

The document-root must always be specified relative to \$HOME
(/home/helion/app).

### start-file:[](#start-file "Permalink to this headline")

Set the main application filename.

**Note**

Perl and Python frameworks only.

If your application does not use a conventional filename (e.g. app.psgi
for Perl, wsgi.py for Python) using this option, possibly in conjunction
with **document-root**, avoids the need to refactor the application for
Application Lifecycle Service. For example:

    framework:
      start-file: temp.psgi

Or:

    framework:
      start-file: temp.py

This value will be used by the
[*PROCESSES\_WEB*](/als/v1/user/reference/environment/#term-processes-web) and
HELION\_START\_FILE environment variables. Any changes to
HELION\_START\_FILE at runtime will not change the value of
[*PROCESSES\_WEB*](/als/v1/user/reference/environment/#term-processes-web) as
the macro is expanded before the pre-running hooks are run.

app-dir[](#app-dir "Permalink to this headline")
-------------------------------------------------

The directory containing the application code to be pushed to Application Lifecycle Service
(if it's not in the top-level directory). This directory becomes the
\$HOME directory of the application when the application is pushed to
Application Lifecycle Service. For example, Java applications will often have a 'target'
sub-directory containing the output of ant or mvn builds:

    name: sample
    framework:
      type: java_web
      runtime: java7
    app-dir: target

If required, you can also set
[*document-root*](#yml-document-root) in the
[*framework*](#yml-framework) section to specify a
sub-directory of the application \$HOME to be used as the document root.

To launch multiple applications from multiple sub-directories use a
[*manifest.yml*](/als/v1/user/deploy/manifestyml/#manifest-yml) file.

services:[](#services "Permalink to this headline")
----------------------------------------------------

A list of services to create and bind to the application. Each sub key
is the name of the service to create / bind, and the associated value is
the type of the new service. If multiple services of the same type are
needed, list them on separate lines as in the example below.

Use `helion services` for a complete list of
available services. If not specified, the user may be prompted during
`helion push`.

Example:

    services:
      customerdb: mysql
      paymentsdb: mysql

The Application Lifecycle Service client supports [*key
substitution*](#yml-key-substitution) for service names,
allowing you to create service names based on the specified application
name. For example:

    services:
      ${name}-db: mysql

The application name can be set as an option to the [*helion
push*](/als/v1/user/reference/client-ref/#command-push) command, overriding
the **name** value defined in *manifest.yml*. Use this technique when
pushing multiple versions of the same application (using different
names) if you want them to use separate databases. For example:

    name: sample

    framework:
      type: node

    services:
      ${name}-db: mysql

Using the name specified in *manifest.yml*, a data service is created to
match that name:

    $ helion push -n
    Pushing application 'sample'...
    Framework:       node
    Runtime:         <framework-specific default>
    Application Url: sample.helion-pjw3.local
    Creating Application [sample]: OK
    Binding service [sample-db]: OK
    ...
    Starting Application [sample]: ...OK

If you specify a new name for the application as an argument to
`helion push`, a new service with a matching name
is created rather than binding to the existing 'sample-db' service:

    $ helion push sample-2 -n
    Pushing application 'sample-2'...
    Framework:       node
    Runtime:         <framework-specific default>
    Application Url: sample-2.helion-pjw3.local
    Creating Application [sample-2]: OK
    Binding service [sample-2-db]: OK
    ...
    Starting Application [sample-2]: ..OK

    $ helion apps

    +-------------+---+---------+------------------------------+-------------+
    | Application | # | Health  | URLS                         | Services    |
    +-------------+---+---------+------------------------------+-------------+
    | sample      | 1 | RUNNING | sample.helion-pjw3.local   | sample-db   |
    | sample-2    | 1 | RUNNING | sample-2.helion-pjw3.local | sample-2-db |
    +-------------+---+---------+------------------------------+-------------+

requirements:[](#requirements "Permalink to this headline")
------------------------------------------------------------

Specifies required modules, and allows the installation of additional OS
packages.

### OS Packages[](#os-packages "Permalink to this headline")

OS packages can be added in an `ubuntu:` block
within a `staging:` and/or `running:` block. Plain strings are treated as package names:

    requirements:
      staging:
        ubuntu:
          - libfoo-dev
      running:
        ubuntu:
          - libfoo
          - some-app

To add the OS requirements to both the staging and running phases add
the `ubuntu:` block directly beneath the
`requirements:` key:

    requirements:
      ubuntu:
        - libfoo-dev

If your account has been given sudo privileges in application
containers, you can use arrays to add additional repositories,
overriding repository restrictions set by admins.

Example:

    requirements:
      staging:
        ubuntu:
          - ["ppa:gophers/go"]
          - golang-stable
      running:
        ubuntu:
          - libfoo

### Language Modules[](#language-modules "Permalink to this headline")

For the installation of language modules, replacing the
*requirements.txt* file. For
[*Python*](/als/v1/user/deploy/languages/python/#python-index), `pypm:` and `pip:` can be specified:

    requirements:
      pypm:
        - tornado
        - pymongo
      pip:
        - pycurl

For [*Perl*](/als/v1/user/deploy/languages/perl/#perl-index), `ppm:` or `cpan:` can be specified:

    requirements:
      ppm:
        - CGI::Application::PSGI
        - Plack::Builder

    requirements:
      cpan:
        - CGI::Application::PSGI
        - Plack::Builder

mem:[](#mem "Permalink to this headline")
------------------------------------------

The amount of memory to allocate for the application.

Syntax: \<int\> or \<int\>M - Memory in megabytes. eg. 256M

Syntax: \<int\>G or \<float\>G - Memory in gigabytes. eg. 1.5G or 2G

If not specified, user may be prompted during `helion push`. Can also be specified on the command line (eg.
`helion push --mem 256M`).

Example:

    mem: 64M

disk:[](#disk "Permalink to this headline")
--------------------------------------------

The amount of disk space to allocate for the application (minimum
512MB).

Syntax: \<int\> or \<int\>M - Disk in megabytes. eg. 768M

Syntax: \<int\>G or \<float\>G - Disk in gigabytes. eg. 1.5G or 2G

If not specified, 2GB of disk space is allocated. Can also be specified
on the command line (eg. `helion push --disk 768M`).

Example:

    mem: 3.5GB

instances:[](#instances "Permalink to this headline")
------------------------------------------------------

The number of instances to allocate for the application. If not
specified, defaults to 1. Can be specified on the command line (eg.
`helion push --instances 2`).

Example:

    instances: 2

url (or urls):[](#url-or-urls "Permalink to this headline")
------------------------------------------------------------

List of URLs mapped to the application. For example:

    name: cms-platform

    url:
      - blog.example.org
      - exampleblog.com

With this key specified, Application Lifecycle Service will not assign a default
"appname.paasname.com" URL to the application. If you would like this
URL assigned as well, add `${name}.${target-base}`
to the list of URLs.

See [*Mapping App URLs*](index.html#deploy-map-url) for more
information.

env:[](#env "Permalink to this headline")
------------------------------------------

A map of environment variables to initialize for the application. Each
subkey is the name of the variable, with an associated value.

Example:

    env:
      HOME_IP_ADDRESS: 127.0.0.1

Avoid using this for values which should not be stored in plain text,
such as API keys and passwords.

### env Attributes[](#env-attributes "Permalink to this headline")

Each environment variable can have attributes which modify the
interactive behavior of the [*helion
client*](/als/v1/user/reference/client-ref/#command-ref-client) when using the
[*push*](/als/v1/user/reference/client-ref/#command-push) command. These
attributes are set with the following keys:

-   **default** (string): The value to use if nothing is entered by the
    user interactively (no default).
-   **required** ([boolean](http://yaml.org/type/bool)): If set,
    the variable must have a value (defaults to "false" == "not
    required").
-   **inherit** (boolean): If set, the client looks in the local
    environment for a variable of the same name and takes its value
    (defaults to "false" == "no inheritance").
-   **prompt** (string): The prompt to show when the client asks for the
    variable value (Defaults to "Enter \<varname\>:").
-   **choices** (list of strings): If specified, a list of legal values
    for the variable, to be presented to the user as a menu rather than
    prompting for a string (no default).

For example:

    env:
      MY_SPECIAL_VAR:
        default: "development"
        required: y
        inherit: y
        prompt: "What type of deployment?: "
        choices:
          - "development"
          - "testing"
          - "staging"
          - "production"

Pushing with the `--no-prompt` option will fail with
the error message "Required variable *VAR\_NAME* not set" if "required"
is set but no value is given (via "default", "inherit" or the
`--env` option).

**Note**

These attributes are only recognized by the [*helion
client*](/als/v1/user/reference/client-ref/#command-ref-client).

processes:[](#processes "Permalink to this headline")
------------------------------------------------------

### web:[](#web "Permalink to this headline")

**Note**

Used with the [*Legacy buildpack*](/als/v1/user/deploy/buildpack/#buildpacks-legacy)
only. When using other buildpacks, create a
[Procfile](https://devcenter.heroku.com/articles/procfile) in the
application's root directory.

Specify a custom command to launch your web application or to pass
custom arguments to uWSGI. For example:

    processes:
      web: python3.2 app.py

This key is required when using the
[*generic*](/als/v1/user/deploy/other-frameworks/#generic-framework) framework, but is
optionally available for all other frameworks.

**If defined**, this process is expected to launch a HTTP server bound
to `0.0.0.0` host and `$PORT`
port.

**If set to Null ("\~")**, the application is treated as a worker
application and not provisioned with a URL. For example, an application
that just runs a background Perl script might look like this:

    name: perlwork
    framework:
      type: perl
    command: perl worker.pl
    processes:
      web: ~

A 'command:' value must be present for worker applications.

If the application exists solely to run commands via
[*cron*](#yml-cron), a dummy command such as '*sleep 365d*'
should be specified.

The `$PROCESSES_WEB` and `$HELION_UWSGI` variables can also be used with `processes: web:`.

`$PROCESSES_WEB` contains the command that is used
to start the web application, if you want to override the default
command.

`$HELION_UWSGI` is defined for runtimes using
uWSGI (Perl and Python), and it contains the command to start uWSGI with
all relevant options. It can be used if you are appending additional
uWSGI options to the command.

command:[](#command "Permalink to this headline")
--------------------------------------------------

Used for worker applications to start a background process. Below is an
example using the
[*standalone*](/als/v1/user/deploy/other-frameworks/#standalone-framework) framework:

    name: helion-worker
    instances: 1
    framework:
      type: standalone
      runtime: ruby18
    command: ruby worker.rb

cron:[](#cron "Permalink to this headline")
--------------------------------------------

Commands listed here are added to the crontab file. See the section on
[*Crontab Support*](index.html#deploy-crontab) for details.

Example:

    cron:
      - PLUGH=xyzzy
      - "*/1 * * * * env > $HOME/env"

ignores:[](#ignores "Permalink to this headline")
--------------------------------------------------

A list of .gitignore-style patterns. Files and directories in the
application directory matching at least one pattern are ignored during
"push" and "update".

Example:

    ignores: ["tmp", ".git"]

To include all hidden files or folders simply use an empty list.

Example:

    ignores: []

If not specified, a default list is used to exclude files and folders
not typically required in a deployed application (e.g. the dot files and
folders of various source code control systems).

The default list contains the following: \~\*/, .git/, \*.svn/, \*.hg/,
\*CVS/, \_FOSSIL\_.fos, \*.bzr, \*.cdv, \*.pc, \*RCS, \*SCCS,\*\_MTN,
\*\_build, \*\_darcs, \*\_sgbak, \*autom4te.cache, \*blib, \*cover\_db,
\*\~.dep, \*\~.dot, \*\~.nib, \*\~.plst

inherit:[](#inherit "Permalink to this headline")
--------------------------------------------------

This special key has the effect of treating its value as the name of a
file to be included into *manifest.yml*.

Example:

*parent.yml*:

    env:
      COMPANY: The ABC Company

*manifest.yml*:

    name: example-app
    inherit: parent.yml
    mem: 64M

effect from processing:

    name: example-app
    env:
      COMPANY: The ABC Company
    mem: 64M

hooks:[](#hooks "Permalink to this headline")
----------------------------------------------

Hooks are commands that are run at various point of the staging and
running process of an app.

### pre-push:[](#pre-push "Permalink to this headline")

Commands run **on the local system** before pushing the code to
Application Lifecycle Service. This can be useful for building source files (e.g. with
`make`) or performing configuration steps that need
to be done on the local system before the application code can be
pushed. Commands are executed between application creation (when the URL
and application resources are reserved) and the actual upload of the
local code.

The client will set the HELION\_HOOK\_ACTION variable to "create" if
the application is new, or "update" if it detects the application
already exists. You can use this variable to run hooks differently in
either context.

### pre-staging:[](#pre-staging "Permalink to this headline")

A list of commands to be run in the root of the app's directory before
the staging process is started. The commands are only run a single time
on push or update.

### post-staging:[](#post-staging "Permalink to this headline")

A list of commands to be run in the root of the app's directory after
the staging process is complete. The commands are only run a single time
on push or update.

### pre-running:[](#pre-running "Permalink to this headline")

A list of commands to be run in the root of the app's directory after
staging is complete and before the app is started. The commands are run
sequentially, in the order listed, each time an app is started or
restarted.

Example:

    hooks:
      pre-staging:
        - python prestagingsetup.py
      post-staging:
        - python manage.py syncdb --noinput
        - python manage.py migrate --noinput
      pre-running:
      - python prerunsetup.py

Hook processing ends and staging aborts if a command returns a nonzero
exit status (i.e. if the command fails). You can suppress this behavior
by prefacing the command with "-" to force staging to proceed despite
failures. The "-" must be included in a quoted command string. For
example:

    hooks:
      post-staging:
        - "-python manage.py syncdb --noinput"

Commands used in the `hooks:` keys may not include
shell metacharacters, such as "&&" for combining commands, "\#" for
comments, "\<", "\>" or "|" for I/O redirection.

If you need shell functionality such as metacharacters, signal trapping,
or forcing zero exit status, wrap your command in a *script.sh* file and
use `sh +x script.sh` as your hook command.

Also note that if only a single command needs to be run, the list format
is not needed and can be included on the same line:

    hooks:
      post-staging: python staging.py
      pre-running:  python running.py

drain:[](#drain "Permalink to this headline")
----------------------------------------------

[*Application log drains*](/als/v1/user/deploy/app-logs/#application-logs-drain) can be
added to an application when it is deployed by describing them in a
`drain:` block with a drain name and URL:

    drain:
      drain_name: protocol://host.domain.tld:port/

To enable JSON logging, specify the URL separately along with a
`json: true` line:

    drain:
      drain_name:
        url: protocol://host.domain.tld:port/
        json: true

For example:

    drain:
      mytestdrain: udp://logs.loggly.com:12346/
      otherdrain:
        url: tcp://logs.papertrailapp.com:12345/
        json: true

min\_version:[](#min-version "Permalink to this headline")
-----------------------------------------------------------

Sets requirements for the minimum version of the client and server under
which the app will run.

### client:[](#client "Permalink to this headline")

The minimum version of the Application Lifecycle Service client needed to manage the app.

To determine the client version, use:

    $ helion version

    helion 0.3.13.0.18

Example:

    min_version:
      client: 0.3.13.0.18

### server:[](#server "Permalink to this headline")

The minimum version of the Application Lifecycle Service server needed to run the app.

Key Substitution[](#key-substitution "Permalink to this headline")
-------------------------------------------------------------------

The value of any key in *manifest.yml* can be inserted in other keys
using the \${*key*} syntax. For example:

    name: example-app
    env:
      MY_NAME: ${name}

This defines a "MY\_NAME" environment variable with the value
"example-app".

A small number of keys are predefined for your use within
*manifest.yml*:

  ------------------------------------------------------------------------
  key
  substitution
  value
  -------------- ---------------------------------------------------------
  \${random-word \${target-base}
  }              The hostname of the targeted Application Lifecycle Service system, for
  A short        example **helion-xxxx.local**
  alphanumeric   
  string of      
  random         
  characters     
  ------------------------------------------------------------------------

**Note**

See the [*services*](#yml-services) section for an example of
variable key substitution for yaml key names.
---
layout: default-devplatform
permalink: /als/v1/user/
product: devplatform
---
<!--PUBLISHED-->

Application Lifecycle Service User Guide[](#helion-user-guide "Permalink to this headline")
=========================================================================

Application Lifecycle Service is a polyglot Platform-as-a-Service (PaaS). You can easily
deploy applications written in a wide range of languages and web
frameworks using a variety of data services simply by pushing your
source code to the system.

Application Lifecycle Service handles the automatic configuration of the language runtime,
web server, application dependencies, databases, and other services.

Quick Start[](#quick-start "Permalink to this headline")
---------------------------------------------------------

-   [Quick Start](/als/v1/user/quick-start/)
    -   [Management Console](/als/v1/user/quick-start/#management-console)
    -   [Application Lifecycle Service Client](/als/v1/user/quick-start/#helion-client)
    -   [Setting Organization and
        Space](/als/v1/user/quick-start/#setting-organization-and-space)
    -   [Deploying Apps](/als/v1/user/quick-start/#deploying-apps)

Application Lifecycle Service Client[](#helion-client "Permalink to this headline")
-----------------------------------------------------------------
-   [Application Lifecycle Service Client Command Reference](/als/v1/user/reference/client-ref/)
-   [Application Lifecycle Service Client](/als/v1/user/client/)
    -   [Application Lifecycle Service Client Setup](/als/v1/user/client/#helion-client-setup)
    -   [Getting Help](/als/v1/user/client/#getting-help)
    -   [Targeting the API
        Endpoint](/als/v1/user/client/#targeting-the-api-endpoint)
    -   [HTTP Proxies](/als/v1/user/client/#http-proxies)
    -   [Removing the Client](/als/v1/user/client/#removing-the-client)



Deploying Applications[](#deploying-applications "Permalink to this headline")
-------------------------------------------------------------------------------

-   [General Deployment](/als/v1/user/deploy/)
-   [Manifest.yml Options](/als/v1/user/deploy/manifestyml/)
-   [Remote Debugging](/als/v1/user/deploy/app-debug/)
-   [**Frameworks & Languages**](/als/v1/user/deploy/#language-specific-deploy)
	-   Frameworks
	    -   [Organizations & Spaces](/als/v1/user/deploy/orgs-spaces/)
	    -   [Buildpacks](/als/v1/user/deploy/buildpack/)
	    -   [Generic & Standalone Frameworks](/als/v1/user/deploy/other-frameworks/)    
    -   Languages
	    -   [Clojure](/als/v1/user/deploy/languages/clojure/)
	    -   [Go](/als/v1/user/deploy/languages/go/)
	    -   [Java](/als/v1/user/deploy/languages/java/)
	    -   [Node.js](/als/v1/user/deploy/languages/node/)
	    -   [Perl](/als/v1/user/deploy/languages/perl/)
	    -   [PHP](/als/v1/user/deploy/languages/php/)
	    -   [Python](/als/v1/user/deploy/languages/python/)
	    -   [Ruby](/als/v1/user/deploy/languages/ruby/)

Services[](#services "Permalink to this headline")
---------------------------------------------------

-   [Data Services](/als/v1/user/services/data-services/)
-   [Persistent File System](/als/v1/user/services/filesystem/)
-   [Memcached Service](/als/v1/user/services/memcached/)
-   [Port Service](/als/v1/user/services/port-service/)
-   [User-Provided Services](/als/v1/user/services/user-provided/)

Logging & Monitoring[](#logging-monitoring "Permalink to this headline")
-------------------------------------------------------------------------

-   [Application Logs](/als/v1/user/deploy/app-logs/)
-   [New Relic Monitoring](/als/v1/user/deploy/newrelic/)

Management Console[](#management-console "Permalink to this headline")
-----------------------------------------------------------------------

-   [Management Console](/als/v1/admin/console/customize/)
    -   [Welcome](/als/v1/admin/console/customize/#welcome)
    -   [Organization View](/als/v1/admin/console/customize/#organization-view)
    -   [Space View](/als/v1/admin/console/customize/#space-view)
    -   [Application View](/als/v1/admin/console/customize/#application-view)
    -   [Service Instance
        View](/als/v1/admin/console/customize/#service-instance-view)
    -   [Sample Applications](/als/v1/admin/console/customize/#app-store)
    -   [Support](/als/v1/admin/console/customize/#support)

Reference[](#reference "Permalink to this headline")
-----------------------------------------------------

-   [Environment Variables](/als/v1/user/reference/environment/)
-   [Glossary](reference/glossary)
-   [Troubleshooting](reference/troubleshoot)
-   [Application Lifecycle Service Client API](/als/v1/user/reference/api/)

---
layout: default-devplatform
permalink: /als/v1/user/quick-start/
product: devplatform

---
<!--PUBLISHED-->

Prerequisites[](#index-0 "Permalink to this headline")
=====================================================

This guide covers the basics of using an Application Lifecycle Service (ALS) PaaS.

To follow along,
you will need:

-   a user account
-   a copy of the Helion CLI client
-   a web browser


Management Console[](#management-console "Permalink to this headline")
-----------------------------------------------------------------------

The web interface for Application Lifecycle Service is called the [*Management
Console*](/als/v1/admin/console/customize/#management-console). You can use it to:

-   see your current usage and quota
-   monitor and manage applications you have deployed
-   see which runtimes, frameworks, and services are available
-   deploy applications from the Marketplace

To use it, open the API Endpoint URL (e.g. *https://api.10.0.0.1.xip.io*) in
your favorite browser. Log in with the username and password that have
been set up for you on the system.

The interface should be mostly self-explanatory. It exposes most of the
functionality you have access to as an end user, but to deploy your own
applications from source code on your local machine you will need to install and use
the Helion [Application Lifestyle Service client](/als/v1/user/client/#helion-client-setup).

Application Lifecycle Service Client[](#helion-client "Permalink to this headline")
-----------------------------------------------------------------

The Helion client is used for pushing
applications to Application Lifecycle Service and interacting with the system from the
command line.

1.  Download the client for your platform (Windows, OS X, Linux x86,
    Linux x64)
2.  Unzip the archive in a convenient directory.
3.  Add the executable to your system/shell \$PATH by:
	- moving it to a directory in your \$PATH,
	-   creating a symlink from a directory in your \$PATH, or
	-   creating a shell alias for the executable.
4.  Confirm that the client is installed correctly by running
    `helion help`.

The [*Application Lifecycle Service Client Command
Reference*](/als/v1/user/reference/client-ref/#command-ref-client) has a full
list of commands and options.

### Target and Login[](#target-and-login "Permalink to this headline")

To connect the helion client to the PaaS, use
the `target` command to specify the API Endpoint
URL. This is normally the hostname prepended with "api." for example:

	$ helion target api.example.hphelion.com
	Target:       https://api.example.hphelion.com
	Organization: <none>
	Space:        <none>
	Successfully targeted to [https://api.example.hphelion.com]

Once you have successfully targeted Application Lifecycle Service, you must authenticate
using `helion login` with the credentials that
have been created for you:

	$ helion login user@example.com
	Attempting login to [https://api.example.hphelion.com]
	Password: ********
	Successfully logged into [https://api.example.hphelion.com]


Setting Organization and Space[](#setting-organization-and-space "Permalink to this headline")
-----------------------------------------------------------------------------------------------

If you are logging in for the first time, your user account will not
automatically choose an [*Organization and
Space*](/als/v1/user/deploy/orgs-spaces/#orgs-spaces) for deployment. You will need to set these manually.

To set the Organization you belong to:

    $ helion switch-org *org-name*
    Switching to organization *org-name* ... OK
    Unsetting current space ... OK
    Target:       https://api.stacka.to
    Organization: *org-name*
    Space:        <none>

To set the Space you want to deploy applications to:

    $ helion switch-space dev
    Switching to organization *org-name* ... OK
    Switching to space dev ... OK
    Target:       https://api.stacka.to
    Organization: test-org
    Space:        dev

**Note**:If your account is not a member of a Space, you will need an
Organization Manager to add you as a Developer. If you are an
Organization Manager or Admin, you can create new Spaces in the
[*Management Console*](/als/v1/admin/console/customize/#user-console-space) or with
the [*helion
create-space*](/als/v1/user/reference/client-ref/#command-create-space)
command.

Deploying Apps[](#deploying-apps "Permalink to this headline")
---------------------------------------------------------------

The steps for deploying applications will vary slightly depending on the
language or framework used, but the basic command is:

	$ helion push --as [appname]

By default, the client will take application code from your current
working directory and push it to Application Lifecycle Service for further staging and
configuration, prompting for additional configuration information as
necessary.

### Sample Applications[](#sample-applications "Permalink to this headline")

Numerous sample applications are available from
[Application Lifecycle Service-Apps](https://github.com/Stackato-Apps) on Github, each with a
README.md file showing how to deploy it on Application Lifecycle Service.

Many of these have a [*manifest.yml*](/als/v1/user/deploy/manifestyml/) configuration
file, so you can skip the interactive prompts by using the
`-n` option.

	$ helion push -n [appname]

### Test the Application[](#test-the-application "Permalink to this headline")

The output of `helion push` will show the URL of
the running application. Paste this URL into a web browser to try the
application or run:

	$ helion open [appname]

Documentation on configuring applications in specific languages and
frameworks is available in the [*Deploying Apps*](/als/v1/user/deploy/#deploying-apps) section.

---
layout: default-devplatform
permalink: /als/v1/user/reference/api/
product: devplatform
---
<!--PUBLISHED-->

Application Lifecycle Service Client API[](#helion-client-api "Permalink to this headline")
=========================================================================

Application Lifecycle Service is fully compatible with the [Cloud Foundry v2
API](http://docs.cloudfoundry.org/services/api.html).

---
layout: default
title: "Application Lifecycle Service Client Command Reference"
permalink: /als/v1/user/reference/client-ref/
product: devplatform

---
<!--PUBLISHED-->

Application Lifecycle Service Client Command Reference[](#helion-client-command-reference "Permalink to this headline")
=====================================================================================================

- [Usage](#usage)   
- [Getting Started](#getting-started)
- [Applications](#applications)
- [Services](#services)
- [Organizations](#organizations)
- [Spaces](#spaces)
- [Routes](#routes)
- [Domains](#domains)
- [Administration](#administration)
- [Convenience](#convenience)
- [Miscellaneous](#miscellaneous)


Usage[](#usage "Permalink to this headline")
---------------------------------------------

**helion** [*options*] *command* [*arguments*] [*command-options*]

For more information., use the `helion help`,
`helion help [command]`, and
`helion options` commands.

Many of the informational commands take a `--json`
option if you wish to generate machine-parseable output. In some cases
the `--json` option reveals additional details.

Note that Administrative user privileges are required for some commands.

## Getting Started[](#getting-started "Permalink to this headline")

### helion login ###

Logs in to the current or specified target with the named user.

<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--credentials</td>
    <td>The credentials to use. Each use of the option declares a single element, using the form "key: value" for the argument. This is an ALS 3-specific option</td>
    </tr><tr>
    <td>--group</td>
    <td>The group to use for the login. This is an ALS 2-specific option.</td>
    </tr><tr>
    <td>--ignore-missing</td>
    <td>Disable errors generated for missing organization and/or space.</td>
    </tr>
    <tr>
    <td>--no-prompt, --noprompt,<br> 
		--n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr><tr>
    <td>--non-interactive</td>
    <td>Same as no-prompt.</td>
    </tr><tr>
    <td>--organization,<br> --o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--password, --passwd</td>
    <td>The password to use. For ALS 3, this is a shorthand for <i>--credentials 'password:</i></td>
    </tr><tr>
    <td>--space</td>
    <td>The space (in the organization) to use. This is an ALS 3-specific option. If not specified the user is prompted to choose among the possible s in the organization if specified. If the organization is not specified, the user is prompted to choose from all spaces in all organizations the user belongs to.</td>
    </tr><tr>
    <td>--target</td>
    <td>The one-off target to use for the current operation only.</td>
    </tr><tr>
    <td>--token</td>
    <td>The one-off authentication token to use for the current operation only.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, --t</td>
    <td>Originally used to activate tracing of the issued REST requests and responses; tracing is always active now. See the <i>trace</i> command to print the saved trace to <i>stdout</i>.</td>
    </tr>
</table>


###helion logout *\<target\>*###
Logs out of the current, specified, or all targets.

<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--all</td>
    <td>log out of all targets we know. Cannot be used together with a target.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, --n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, --t</td>
    <td>Originally used to activate tracing of the issued REST requests and responses; tracing is always active now. See the <i>trace</i> command to print the saved trace to <i>stdout</i>.</td>
    </tr>
</table>

### helion target *\<url\>*###
Set the target API endpoint for the client or report the current target.

<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td width=200>--allow-http</td>
    <td>Required to prevent the client from rejecting http URLs.</td>
    </tr>
    <tr>
    <td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, -n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--organization, -o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--space, -s</td>
    <td>The space (in the organization) to use. This is an ALS 3-specific option. If not specified the user is prompted to choose among the possible spaces in the organization if specified. If the organization is not specified, the user is prompted to choose from all spaces in all organizations the user belongs to.</td>
    </tr><tr>
    <td>--trace, -t</td>
    <td>Originally used to activate tracing of the issued REST requests and responses; tracing is always active now. See the <i>trace</i> command to print the saved trace to <i>stdout</i>.</td></tr>
    <tr><td>--verbose</td>
    <td>More verbose operation.</td>
    </tr>
</table>

## Applications[](#applications "Permalink to this headline")##
###helion apps###
Lists the applications deployed to the target.
<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--all</td>
    <td>Show all applications instead of just those associated with the current space.</td>
    </tr>
    <tr>
    <td>--group</td>
    <td>The once-off group to use for the current operation. This is an ALS 2-specific option.</td>
    </tr>
    <tr>
    <td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, -n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--organization, -o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--space, -s</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--space-guid</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--target</td>
    <td>The one-off target to use for the current operation only.</td>
    </tr><tr>
    <td>--token</td>
    <td>The one-off authentication token to use for the current operation only.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, -t</td>
    <td>The once-off space to use for the current operation, specified by guid. This is an ALS 3-specific option. Cannot be used together with `--space`.</td>
    </tr><tr>
    <td>--verbose</td>
    <td>More verbose operation.</td>
    </tr>
</table>

###helion app *\<application\>*###
Shows the information of the specified application.

<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--group</td>
    <td>The once-off group to use for the current operation. This is an ALS 2-specific option.</td>
    </tr>
    <tr>
    <td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>
    <tr>
    <td>--manifest</td>
    <td>Path of the manifest file to use. If not specified, a search is performed.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, -n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--organization, -o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--path</td>
    <td>Path of the directory holding the application files to push. Defaults to the current working directory.</td>
    </tr><tr>
    <td>--space, -s</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--space-guid</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--target</td>
    <td>The one-off target to use for the current operation only.</td>
    </tr><tr>
    <td>--token</td>
    <td>The one-off authentication token to use for the current operation only.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, -t</td>
    <td>The once-off space to use for the current operation, specified by guid. This is an ALS 3-specific option. Cannot be used together with `--space`.</td>
    </tr><tr>
    <td>--verbose</td>
    <td>More verbose operation.</td>
    </tr>
</table>

### helion list###
List the applications deployed to the target.
<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--all</td>
    <td>Show all applications instead of just those associated with the current space.</td>
    </tr>
    <tr>
    <td>--group</td>
    <td>The once-off group to use for the current operation. This is an ALS 2-specific option.</td>
    </tr>
    <tr>
    <td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, -n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--organization, -o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--space, -s</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--space-guid</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--target</td>
    <td>The one-off target to use for the current operation only.</td>
    </tr><tr>
    <td>--token</td>
    <td>The one-off authentication token to use for the current operation only.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, -t</td>
    <td>The once-off space to use for the current operation, specified by guid. This is an ALS 3-specific option. Cannot be used together with `--space`.</td>
    </tr>
</table>

##Information##
###helion crashes *\<application\>*###
List recent application crashes.
<table>
    <tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr>
    <tr>
    <td>--group</td>
    <td>The once-off group to use for the current operation. This is an ALS 2-specific option.</td>
    </tr>
    <tr>
    <td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>
    <tr>
    <td>--manifest</td>
    <td>Path of the manifest file to use. If not specified, a search is performed.</td>
    </tr>
    <tr>
    <td>--no-prompt, --non-interactive, --noprompt, -n</td>
    <td>Disable all prompts (interactive queries) that would normally be seen by the user.</td>
    </tr><tr>
    <td>--no-tail</td>
    <td>Complementary alias of <i>--tail</i>.</td>
    </tr><td>--no-trace</td>
    <td>Complementary alias of <i>--trace</i>.</td>
    </tr><tr>
    <td>--organization, -o</td>
    <td>The organization to use. This is an ALS 3-specific option. If not specified programmatically, the user is prompted to choose an organization.</td>
    </tr><tr>
    <td>--path</td>
    <td>Path of the directory holding the application files to push. Defaults to the current working directory.</td>
    </tr><tr>
    <td>--space, -s</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--space-guid</td>
    <td>The one-off space to use for the current operation, specified by name. This is an ALS 3-specific option. Cannot be used together with `--space-guid`.</td>
    </tr><tr>
    <td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr><tr>
    <td>--target</td>
    <td>The one-off target to use for the current operation only.</td>
    </tr><tr>
    <td>--token</td>
    <td>The one-off authentication token to use for the current operation only.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </tr><tr>
    <td>--trace, -t</td>
    <td>The once-off space to use for the current operation, specified by guid. This is an ALS 3-specific option. Cannot be used together with `--space`.</td>
    </tr>
</table>

### helion crashlogs *\<application\>*###
Display log information for the application. An alias of 'logs'.
<table><tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr><tr>
    <td>--all</td>
    <td>Retrieve the logs from all instances. Before 2.3 only.</td>
    </tr><tr>
    <td>--filename</td>
    <td>Filter the log stream by origin file (glob pattern). Target version 2.4+ only.</td>
    </tr><tr>
    <td>--follow</td>
    <td>Tail -f the log stream. Target version 2.4+ only.</td>
    </tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is an ALS 2-specific option.</td>
    </tr>
    <tr>
    <td>
    </td>

    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option. </td></tr>
    <td>--instance</td>

    <td> The id of the instance to filter the log stream for, or (before
            2.3), to retrieve the logs of. </td></tr>
    <tr><td>--json</td>

    <td>  Print the raw json log stream, not human-formatted data.
    </td></tr>
    <tr><td> --manifest</td>

    <td>Path of the manifest file to use. If not specified a search is
    done. </td></tr>

    <tr><td> --no-prompt </td>

    <td>Disable interactive queries.</td></tr>

    <tr><td>  --no-tail</td>

    <td> Complementary alias of --tail.</td></tr>

    <tr><td> --no-trace</td>

    <td> Complementary alias of --trace.</td></tr>

    <tr><td> --non-interactive</td>

    <td> Alias of --no-prompt.</td></tr>

    <tr><td> --noprompt </td>

    <td> Alias of --no-prompt. </td></tr>

    <tr><td>     --num </td>
    <td>  Show the last num entries of the log stream. Target version 2.4+
    only. </td></tr>
    <tr><td>--organization</td>

    <td> The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td></tr>
    <tr><td>    --path </td>
    <td>    Path of the directory holding the application files to push.
    Defaults to the current working directory.</td></tr>
    <tr><td>  --prefix </td>
    <td> Put instance information before each line of a shown log file.
    Before 2.3 only.</td></tr>
    <tr><td>   --prefix-logs </td>
    <td>    Alias of --prefix.</td></tr>
    <tr><td>  --prefixlogs </td>
    <td>     Alias of --prefix.</td></tr>
    <tr><td>  --source </td>
    <td> Filter the log stream by origin stage (glob pattern). Target
    version 2.4+ only.</td></tr>
    <tr><td>  --space </td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td></tr>
    <tr><td>--space-guid </td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td></tr>

    <tr><td>--tail</td>

    <td>Request target to stream the log.</td></tr>

    <tr><td>--target</td>

    <td>The once-off target to use for the current operation.</td></tr>

    <tr><td>--text</td>

    <td> Filter the log stream by log entry text (glob pattern).</td></tr> Target
    version 2.</td></tr>4+ only.</td></tr>

    <tr><td>--token</td>

    <td>The once-off authentication token to use for the current
    operation.</td></tr>

    <tr><td>--token-file</td>

    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td></tr>

    <tr><td>--trace</td>

    <td>Activate tracing of the issued REST requests and responses.</td></tr> This
    option is a no-op now.</td></tr> Tracing is always active.</td></tr> See the 'trace'
    command to print the saved trace to stdout.</td></tr>

    <tr><td> -n</td>
    <td>  Alias of --no-prompt.</td></tr>
    <tr><td>  -o</td>
    <td>  Alias of --organization.</td></tr>
    <tr><td>-t</td>
    <td> Alias of --trace.</td></tr>
</table>

### helion disk *\<application\>*###
Show the disk reservation for a deployed application.


<table><tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr><tr> <td> --group</td>
    <td>  The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td></tr>

    <tr> <td> --manifest </td>
    <td>Path of the manifest file to use. If not specified a search is done.</td>
    </tr>
    <tr><td>  --no-prompt</td>
    <td> Disable interactive queries.</td></tr>
    <tr><td>  --no-tail</td>
    <td> Complementary alias of --tail.</td></tr>
    <tr><td>  --no-trace</td>
    <td>  Complementary alias of --trace.

    <tr><td> --non-interactive</td>
    <td>  Alias of --no-prompt.</td></tr>

    <tr><td>--noprompt</td>
    <td>  Alias of --no-prompt.</td></tr>

    <tr><td> --organization</td>

    <td> The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td></tr>

    <tr><td> --path</td>
    <td> Path of the directory holding the application files to push.
    Defaults to the current working directory.</td></tr>

    <tr><td> --space</td>
    <td>  The once-off space to use for the current operation, specified by name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td></tr>

    <tr><td> --space-guid</td>
    <td> The once-off space to use for the current operation, specified by guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td></tr>

    <tr><td> --tail</td>
    <td>   Request target to stream the log.</td></tr>

    <tr><td> --target</td>
    <td>The once-off target to use for the current operation.</td></tr>
    <tr><td>    --token</td>
    <td>The once-off authentication token to use for the current operation.</td></tr>
    <tr><td> --token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td></tr>
    <tr><td>   --trace</td>
    <td>Activate tracing of the issued REST requests and responses. This option is a no-op now. Tracing is always active. See the 'trace' command to print the saved trace to stdout.</td></tr>
    <tr><td>    -n</td>
    <td> Alias of --no-prompt.</td></tr>
    <tr><td>   -o</td>
    <td> Alias of --organization.</td></tr>
    <tr><td>    -t</td>
    <td> Alias of --trace.</td>
    </tr>
</table>


### helion drain list *\<application\>*###
Show the list of drains attached to the application.
    
<table><tr>
    <td><b>Option</b></td>
    <td><b>Description</b></td>
    </tr><tr> <td> --group
    <td> The once-off group to use for the current operation. This is an Application Lifecycle Service 2 option.
    </td>
    </tr>    <tr><td>
    </td>
    </tr>    <tr><td>--json </td>
    <td>Print raw json as output, not human-formatted data.</td>
    </td>
    </tr>    <tr><td> --manifest</td>
    <td>    Path of the manifest file to use. If not specified a search is done.</td>
    </td>
    </tr>    <tr><td> --no-prompt</td>
    <td> Disable interactive queries.</td>
    </td>
    </tr>    <tr><td>--no-tail</td>
    <td> Complementary alias of --tail.</td>
    </td>
    </tr>    <tr><td> --no-trace</td>
    <td> Complementary alias of --trace.</td>
    </td>
    </tr>    <tr><td>--non-interactive</td>
    <td> Alias of --no-prompt.</td>
    </td>
    </tr>    <tr><td> --noprompt</td>
    <td>Alias of --no-prompt.</td>
    </td>
    </tr>    <tr><td> --organization</td>
    <td> The once-off organization to use for the current operation. This is an Application Lifecycle Service 3 option.</td>
    </td>
    </tr>    <tr><td> --path</td>
    <td> Path of the directory holding the application files to push. Defaults to the current working directory.</td>
    </td>
    </tr>    <tr><td> --space</td>
    <td> The once-off space to use for the current operation, specified by name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </td>
    </tr>    <tr><td> --space-guid</td>
    <td>The once-off space to use for the current operation, specified by guid. This is an Application Lifecycle Service 3 option. Cannot be used together with 
    --space.</td>
    </td>
    </tr>    <tr><td> --tail</td>
    <td>Request target to stream the log.</td>
    </td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </td>
    </tr>    <tr><td> --token</td>
    <td> The once-off authentication token to use for the current operation.</td>
    </td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and authorization tokens.</td>
    </td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This option is a no-op now. Tracing is always active. See the 'trace' command to print the saved trace to stdout.</td>
    </td>
    </tr>    <tr><td>     -n</td>
    <td>Alias of --no-prompt.</td>
    </td>
    </tr>    <tr><td>   -o</td>
    <td> Alias of --organization.</td>
    </td>
    </tr>    <tr><td>    -t</td>
    <td> Alias of --trace.</td>
    </tr>
</table>
### helion drains *\<application\*###
Show the list of drains attached to the application.</td>
    
   
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is an
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    </tr>    <tr><td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>


### helion env *\<application\* ###
List the application's environment variables.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr></table>
### helion events *\<application\*###
Show recorded application events, for application or space.
    Without an application given the current or specified space is
    used, otherwise that application. This is an Application Lifecycle Service 3 specific
    command.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr>
    <td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr></tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr></table>

### helion files *\<application\* *\<apath\* ###
Display directory listing or file.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr>
    <td>--all</td>
    <td>When present, access all instances for the file or directory.
    Cannot be used together with --instance.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>When present the instance to query. Cannot be used together with
    --all. Defaults to 0 (except when --all is present).</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--prefix</td>
    <td>Put instance information before each line of a shown file or
    directory listing. Effective only for --all.</td>
    </tr>    <tr><td>--prefix-logs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--prefixlogs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with
    --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with
    --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr></table>
### helion file *\<application\* *\<apath\*  ###
Display directory listing or file.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>When present, access all instances for the file or directory.
    Cannot be used together with --instance.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>When present the instance to query. Cannot be used together with --all. Defaults to 0 (except when --all is present).</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--prefix</td>
    <td>Put instance information before each line of a shown file or
    directory listing. Effective only for --all.</td>
    </tr>    <tr><td>--prefix-logs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--prefixlogs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr></table>
### helion health *\<application\* ###
Report the health of the specified application(s).</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Report on all applications in the current space. Cannot be used
    together with application names.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr> </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>
### helion instances *\<application\*###
List application instances for a deployed application.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr> </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>
###helion logs *\<application\*###
Display the application log stream.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Retrieve the logs from all instances. Before 2.3 only.</td>
    </tr>    <tr><td>--filename</td>
    <td>Filter the log stream by origin file (glob pattern). Target
    version 2.4+ only.</td>
    </tr>    <tr><td>--follow</td>
    <td>Tail -f the log stream. Target version 2.4+ only.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>The id of the instance to filter the log stream for, or (before
            2.3), to retrieve the logs of.</td>
    </tr>    <tr><td>--json</td>
    <td>Print the raw json log stream, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--num</td>
    <td>Show the last num entries of the log stream. Target version 2.4+
    only.</td>
    </tr>    <tr><td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--prefix</td>
    <td>Put instance information before each line of a shown log file.
    Before 2.3 only.</td>
    </tr>    <tr><td>--prefix-logs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--prefixlogs</td>
    <td>Alias of --prefix.</td>
    </tr>    <tr><td>--source</td>
    <td>Filter the log stream by origin stage (glob pattern). Target
    version 2.4+ only.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--text</td>
    <td>Filter the log stream by log entry text (glob pattern). Target
    version 2.4+ only.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr> </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>

### helion mem *\<application\*###
Show the memory reservation for a deployed application.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr> </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>
### helion stats *\<application\*###
Display the resource usage for a deployed application.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>

    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>

### helion tail *\<application\* *\<apath\*###
Monitor file for changes and stream them.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>When present the instance to query. Cannot be used together with --all. Defaults to 0 (except when --all is present).</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr> </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>
##**Management**##
### helion create-app *\<application\*###
Create an empty application with the specified configuration.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--buildpack</td>
    <td>Url of a custom buildpack. This is an Application Lifecycle Service 3 specific option.</td>
    </tr>    <tr><td>--command</td>
    <td>The application's start command. Defaults to a framework-specific
    value if required and not specified by manifest.yml.</td>
    </tr>    <tr><td>--disk</td>
    <td>The application's per-instance disk allocation. Defaults to a
    framework-specific value if not specified by manifest.yml.</td>
    </tr>    <tr><td>--env</td>
    <td>Environment variable overrides. These are always applied
    regardless of --env-mode. The mode is restricted to the variable
    declarations found in the manifest.</td>
    </tr>    <tr><td>--env-mode</td>
    <td>Environment replacement mode. One of preserve, or replace. The
    default is "preserve". Using mode "replace" implies --reset as
    well, for push. Note that new variables are always set. Preserve
    only prevents update of existing variables. This setting applies
    only to the variable declarations found in the manifest. Overrides
    made with --env are always applied.</td>
    </tr>    <tr><td>--framework</td>
    <td>Specify the framework to use. Cannot be used together with --no-framework. Defaults to a heuristically chosen value if not
    specified, and none for --no-framework. This is an Application Lifecycle Service 2
    specific option.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instances</td>
    <td>The number of application instances to create. Defaults to 1, if
    not specified by a manifest.yml.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--mem</td>
    <td>The application's per-instance memory allocation. Defaults to a
    framework-specific value if not specified by manifest.yml.</td>
    </tr>    <tr><td>--no-framework</td>
    <td>Create application without any framework. Cannot be used together
    with --framework. This is an Application Lifecycle Service 2 specific option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--reset</td>
    <td>Analogue of --env-mode, for the regular settings.</td>
    </tr>    <tr><td>--runtime</td>
    <td>The name of the runtime to use. Default is framework specific, if
    not specified by a manifest.yml. This is an Application Lifecycle Service 2 specific
    option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--stack</td>
    <td>The OS foundation the application will run on. This is an Application Lifecycle Service
    3 specific option.</td>
    </tr>    <tr><td>--helion-debug</td>

    <td>host:port of the Komodo debugger listener to inject into the
    application as environment variables.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--url</td>
    <td>The urls to map the application to. I.e. can be specified multiple
    times.</td>
    </tr><tr>
    <td>-d</td>
<td>Set up debugging through an application-specific harbor (port)
    service. Target version 2.8+ only.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr></tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>

### helion dbshell *\<application\* *\<service\*###
Invoke interactive db shell for a bound service.</td>
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--dry</td>
    <td>Print the low-level ssh command to stdout instead of executing it.</td>
    </tr>    <tr><td>--dry-run</td>
    <td>Alias of --dry.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td> </tr></table>
### helion delete *\<application\*###
Delete the specified application(s).
    
<table>
    <tr><td>--all</td>
    <td>Delete all applications. Cannot be used together with application
    names.</td>
    </tr>    <tr><td>--force</td>
    <td>Force deletion.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion drain add *\<application\* *\<drain\* *\<uri\*###
Attach a new named drain to the application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>The drain target takes raw json log entries.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td></tr>
</table>
###helion drain delete *\<application\* *\<drain\*###
Remove the named drain from the application.</td>

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td> </tr></table>
### helion env-add *\<application\* *\<varname\* *\<value\*###
Add the specified environment variable to the named application.</td>

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion env-del *\<application\* *\<varname\*###
Remove the specified environment variable from the named
application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion map *\<application\* *\<url\*###
Make the application accessible through the specified URL (a route
consisting of host and domain)

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion open *\<application\*###
Open the url of the specified application in the default web browser. If 'api' is specified as the app name, the Management Console is opened. With no arguments, the 'name' value from the manifest.yml in the current directory is used (if            present). 

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion push *\<application\*###
Configure, create, push, map, and start a new application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--as</td>
    <td>The name of the application to push/update the selected
    application as. Possible only if a single application is pushed or
    updated.</td>
    </tr>    <tr><td>--buildpack</td>
    <td>Url of a custom buildpack. This is an Application Lifecycle Service 3 specific option.</td>
    </tr>    <tr><td>--command</td>
    <td>The application's start command. Defaults to a framework-specific
    value if required and not specified by manifest.yml.</td>
    </tr>    <tr><td>--copy-unsafe-links</td>

    <td>Links pointing outside of the application directory are copied
    into the application.</td>
    </tr>    <tr><td>--disk</td>
    <td>The application's per-instance disk allocation. Defaults to a
    framework-specific value if not specified by manifest.yml.</td>
    </tr>    <tr><td>--env</td>
    <td>Environment variable overrides. These are always applied
    regardless of --env-mode. The mode is restricted to the variable
    declarations found in the manifest.</td>
    </tr>    <tr><td>--env-mode</td>
    <td>Environment replacement mode. One of preserve, or replace. The
    default is "preserve". Using mode "replace" implies --reset as
    well, for push. Note that new variables are always set. Preserve
    only prevents update of existing variables. This setting applies
    only to the variable declarations found in the manifest. Overrides
    made with --env are always applied.</td>
    </tr>    <tr><td>--force-start</td>
    <td>Push, and start the application, even when stopped.</td>
    </tr>    <tr><td>--framework</td>
    <td>Specify the framework to use. Cannot be used together with --no-framework. Defaults to a heuristically chosen value if not
    specified, and none for --no-framework. This is an Application Lifecycle Service 2
    specific option.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instances</td>
    <td>The number of application instances to create. Defaults to 1, if
    not specified by a manifest.yml.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--mem</td>
    <td>The application's per-instance memory allocation. Defaults to a
    framework-specific value if not specified by manifest.yml.</td>
    </tr>    <tr><td>--no-framework</td>
    <td>Create application without any framework. Cannot be used together
    with --framework. This is an Application Lifecycle Service 2 specific option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-resources</td>
    <td>Do not optimize upload by checking for existing file resources.</td>
    </tr>    <tr><td>--no-start</td>
    <td>Push, but do not start the application.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noresources</td>
    <td>Alias of --no-resources.</td>
    </tr>    <tr><td>--nostart</td>
    <td>Alias of --no-start.</td>
    </tr>    <tr><td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--reset</td>
    <td>Analogue of --env-mode, for the regular settings.</td>
    </tr>    <tr><td>--runtime</td>
    <td>The name of the runtime to use. Default is framework specific, if
    not specified by a manifest.yml. This is an Application Lifecycle Service 2 specific
    option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--stack</td>
    <td>The OS foundation the application will run on. This is an Application Lifecycle Service
    3 specific option.</td>
    </tr>    <tr><td>--helion-debug</td>

    <td>host:port of the Komodo debugger listener to inject into the
    application as environment variables.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--url</td>
    <td>The urls to map the application to. I.e. can be specified multiple
    times.</td>
    </tr><tr>
    <td>-d</td>
    <td>Set up debugging through an application-specific harbor (port)
    service. Target version 2.8+ only.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>

### helion rename *\<application\* *\<name\*###
Rename the specified application. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion restart *\<application\*###
Stop and restart a deployed application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion run *\<command\*###
Run an arbitrary command on a running instance.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Run the command on all instances. Cannot be used together with --instance.</td>
    </tr>    <tr><td>--application</td>
    <td>Name of the application to operate on.</td>
    </tr>    <tr><td>--banner</td>
    <td>Show the leading and trailing banner to separate instance data.
    Applies only when --all is used. Defaults to on.</td>
    </tr>    <tr><td>--dry</td>
    <td>Print the low-level ssh command to stdout instead of executing it.</td>
    </tr>    <tr><td>--dry-run</td>
    <td>Alias of --dry.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>The instance to access with the command. Defaults to 0. Cannot be
    used together with --all.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-banner</td>
    <td>Complementary alias of --banner.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-a</td>
    <td>Alias of --application.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion scale *\<application\*###
Update the number of instances, memory and/or disk reservation for a deployed application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--disk</td>
    <td>The new disk reservation to use.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instances</td>
    <td>Absolute number of instances to scale to, or relative change.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--mem</td>
    <td>The new memory reservation to use.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-d</td>
    <td>Alias of --disk.</td> </tr><tr>
    <td>-i</td>
    <td>Alias of --instances.</td>
    </tr><tr>
    <td>-m</td>
    <td>Alias of --mem.</td>
    </tr><tr>
    <td>-n</td>
    
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion scp *\<paths\*###
Copy source files and directories to the destination.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--application</td>
    <td>Name of the application to operate on.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>The instance to access with the command. Defaults to 0.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-a</td>
    <td>Alias of --application.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion set-env *\<application\* *\<varname\* *\<value\*###
Add the specified environment variable to the named application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion ssh *\<command\*###
SSH to a running instance (or target), or run an arbitrary command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Run the command on all instances. Cannot be used together with --instance.</td>
    </tr>    <tr><td>--application</td>
    <td>Name of the application to operate on, or "api" to talk to the
    cloud controller node.</td>
    </tr>    <tr><td>--banner</td>
    <td>Show the leading and trailing banner to separate instance data.
    Applies only when --all is used. Defaults to on.</td>
    </tr>    <tr><td>--dry</td>
    <td>Print the low-level ssh command to stdout instead of executing it.</td>
    </tr>    <tr><td>--dry-run</td>
    <td>Alias of --dry.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--instance</td>
    <td>The instance to access with the command. Defaults to 0. Cannot be
    used together with --all.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-banner</td>
    <td>Complementary alias of --banner.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-a</td>
    <td>Alias of --application.</td> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion start *\<application\*###
Start a deployed application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion stop *\<application\*###
Stop a deployed application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unmap *\<application\* *\<url\*###
Unregister the application from a URL.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unset-env *\<application\* *\<varname\*###
Remove the specified environment variable from the named application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    <Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
## Services[](#services "Permalink to this headline")##
###helion service-plans###
List all available plans of the supported services. This is an
Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion services###
List the supported and provisioned services of the target.

<table>     <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion service *\<name\*###
Show the information about the named service.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>

**Authentication Tokens**
### helion create-service-auth-token *\<label\* *\<provider\*###
Create a new service authentication token. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auth-token</td>
    <td>Value of the new token.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion delete-service-auth-token *\<label\*###
Delete the specified service authentication token. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion service-auth-tokens###
Show all service authentication tokens knowns to the target. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr> <td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion update-service-auth-token *\<label\*###
Update the specified service authentication token. This is a
    Application Lifecycle Service 3 specific command.
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auth-token</td>
    <td>New value of the specified token.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
##**Brokers**##
### helion add-service-broker *\<name\*###
Make the named service broker known. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--broker-token</td>
    <td>Value of the broker's token.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--url</td>
    <td>Location of the broker.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion delete-service-broker *\<name\*###
Remove the named service broker from the target. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion remove-service-broker *\<name\*###
Remove the named service broker from the target. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion service-brokers###
Show the list of known service brokers. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion update-service-broker *\<name\* *\<newname\*###
Update the target's knowledge of the named service broker. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--broker-token</td>
    <td>New value of the broker's token.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--url</td>
    <td>New location of the broker.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
##**Management**##
### helion bind-service *\<service\* *\<application\*###
Bind the named service to the specified application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes. 
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion clone-services *\<source\* *\<application\*###
Copy the service bindings of the source application to the destination application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion create-service *\<vendor\* *\<name\* *\<application\*###
Create a new provisioned service, and optionally bind it to an application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--credentials</td>
    <td>The credentials to use. Each use of the option declares a single
    element, using the form "key: value" for the argument. This is a
    Application Lifecycle Service 3 specific option. This is restricted to user-provided
    services.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--plan</td>
    <td>The service plan to use. This is an Application Lifecycle Service 3 specific option.</td>
    </tr>    <tr><td>--provider</td>
    <td>The service provider. Use this to disambiguate between multiple
    providers of the same vendor/type. This is an Application Lifecycle Service 3 specific
    option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--version</td>
    <td>The service version. Use this to disambiguate between multiple
    versions of the same vendor/type. This is an Application Lifecycle Service 3 specific
    option.</td> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion delete-service *\<service\*###
Delete the named provisioned service.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td>
    </tr>    <tr><td>--all</td>
    <td>Delete all services. Cannot be used together with named service
    instances.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--unbind</td>
    <td>Unbind service from applications before deleting. By default bound
    services are skipped and not deleted. This is an Application Lifecycle Service 3
    specific option.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion rename-service *\<service\* *\<name\*###
Rename the specified service instance. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion tunnel *\<service\* *\<tunnelclient\*###
Create a local tunnel to a service, optionally start a local client as well.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--allow-http</td>
    <td>Required to prevent the client from rejecting http urls.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--port</td>
    <td>Port used for the tunnel.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--url</td>
    <td>Url the tunnel helper application is mapped to and listens on.
    Relevant if and only if the helper has to be pushed,i.e. on first
    use of the tunnel command.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unbind-service *\<service\* *\<application\*###
Disconnect the named service from the specified application.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--manifest</td>
    <td>Path of the manifest file to use. If not specified a search is
    done.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-tail</td>
    <td>Complementary alias of --tail.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--path</td>
    <td>Path of the directory holding the application files to push.
    Defaults to the current working directory.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--tail</td>
    <td>Request target to stream the log.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--timeout</td>
    <td>The time the client waits for an application to start before
    giving up and returning, in seconds. Note that this is measured
    from the last entry seen in the log stream. While there is
    activity in the log the timeout is reset.
    The default is 2 minutes.
    Use the suffixes 'm', 'h', and 'd' for the convenient
    specification of minutes, hours, and days. The optional suffix 's'
    stands for seconds.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
## Organizations<a name="organizations"></a>
### helion create-org *\<name\*###
Create a new organization. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--activate</td>
    <td>Switch the current organization to the newly created one. Done by
    default.</td>
    </tr>    <tr><td>--add-self</td>
    <td>Add yourself to the new organization, as developer. Done by
    default.</td>
    </tr>    <tr><td>--no-activate</td>
    <td>Complementary alias of --activate.</td>
    </tr>    <tr><td>--no-add-self</td>
    <td>Complementary alias of --add-self.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--quota</td>
    <td>The named quota of the new organization. Default is the target's
    choice.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion delete-org *\<name\*###
Delete the named organization. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--recursive</td>
    <td>Remove all sub-ordinate parts, and relations.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-r</td>
    <td>Alias of --recursive.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion link-user-org *\<user\* *\<org\*###
Add the specified user to the named organization, in various roles. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auditor</td>
    <td>Affect the auditor role</td>
    </tr>    <tr><td>--billing</td>
    <td>Affect the billing manager role</td>
    </tr>    <tr><td>--manager</td>
    <td>Affect the manager role</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion orgs###
List the available organizations. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td>
    </tr>    <tr><td>--full</td>
    <td>Show more details.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion org *\<name\*###
Show the named organization's information. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--full</td>
    <td>Show more details.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota-org *\<name\* *\<quota\*###
Set the quotas for the current or named organization. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion rename-org *\<name\* *\<newname\*###
Rename the named organization. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion switch-org *\<name\*###
Switch the current organization to the named organization. This invalidates the current space. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unlink-user-org *\<user\* *\<org\*###
Remove the specified user from the named organization, in various roles. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auditor</td>
    <td>Affect the auditor role</td>
    </tr>    <tr><td>--billing</td>
    <td>Affect the billing manager role</td>
    </tr>    <tr><td>--manager</td>
    <td>Affect the manager role</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr></table>
## Spaces<a name="spaces"></a>
### helion create-space *\<name\*###
Create a new space. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--activate</td>
    <td>Switch the current space to the newly created one. Done by
    default.</td>
    </tr>    <tr><td>--auditor</td>
    <td>Add yourself to the new space, as auditor. By request.</td>
    </tr>    <tr><td>--developer</td>
    <td>Add yourself to the new space, as developer. Done by default.</td>
    </tr>    <tr><td>--manager</td>
    <td>Add yourself to the new space, as manager. Done by default.</td>
    </tr>    <tr><td>--no-activate</td>
    <td>Complementary alias of --activate.</td>
    </tr>    <tr><td>--no-auditor</td>
    <td>Complementary alias of --auditor.</td>
    </tr>    <tr><td>--no-developer</td>
    <td>Complementary alias of --developer.</td>
    </tr>    <tr><td>--no-manager</td>
    <td>Complementary alias of --manager.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion delete-space *\<name\*###
Delete the named space. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--recursive</td>
    <td>Remove all sub-ordinate parts, and relations.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-r</td>
    <td>Alias of --recursive.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion link-user-space *\<user\* *\<space\*###
Add the specified user to the named space, in various roles. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auditor</td>
    <td>Affect the auditor role</td>
    </tr>    <tr><td>--developer</td>
    <td>Affect the developer role</td>
    </tr>    <tr><td>--manager</td>
    <td>Affect the manager role</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion rename-space *\<name\* *\<newname\*###
Rename the named space. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion spaces###
List the available spaces in the specified organization. See --organization for details This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--full</td>
    <td>Show more details.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion space *\<name\*###
Show the named space's information. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--full</td>
    <td>Show more details.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion switch-space *\<name\*###
Switch from the current space to the named space. This may switch the organization as well. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unlink-user-space *\<user\* *\<space\*###
Remove the specified user from the named space, in various roles. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--auditor</td>
    <td>Affect the auditor role</td>
    </tr>    <tr><td>--developer</td>
    <td>Affect the developer role</td>
    </tr>    <tr><td>--manager</td>
    <td>Affect the manager role</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>

### Routes[](#routes "Permalink to this headline")###
### helion delete-route *\<name\*###
Delete the named route. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--space</td>
    <td>The name of the space to use as context.
    Defaults to the current space.
    A current space is automatically set if there is none, either by
    taking the one space the user has, or asking the user to choose
    among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion routes###
List all available routes. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>

### Domains[](#domains "Permalink to this headline")###
### helion domains###
List the available domains in the specified space, or all. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Query information about all domains. Cannot be used together with
    a space.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--space</td>
    <td>The name of the space to use as context.
    Defaults to the current space.
    A current space is automatically set if there is none, either by
    taking the one space the user has, or asking the user to choose
    among the possibilities. Cannot be used together with --all.</td> 

    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion map-domain *\<name\*###
Add the named domain to an organization or space. This is a Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--space</td>
    <td>The name of the space to use as context.
    Defaults to the current space.
    A current space is automatically set if there is none, either by
    taking the one space the user has, or asking the user to choose
    among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion unmap-domain *\<name\*###
Remove the named domain from an organization or space. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The name of the parent organization to use as context.
    Defaults to the current organization.
    A current organization is automatically set if there is none,
    either by taking the one organization the user belongs to, or
    asking the user to choose among the possibilities.</td>
    </tr>    <tr><td>--space</td>
    <td>The name of the space to use as context.
    Defaults to the current space. 
    A current space is automatically set if there is none, either by
    taking the one space the user has, or asking the user to choose
    among the possibilities.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>

### Administration[](#administration "Permalink to this headline")
### helion admin grant *\<email\*
Grant the named user administrator privileges for the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion admin list###
Show a list of the administrators for the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion admin patch *\<patch\*###
Apply a patch to the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--dry</td>
    <td>Print the low-level ssh command to stdout instead of executing it.</td>
    </tr>    <tr><td>--dry-run</td>
    <td>Alias of --dry.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion admin report *\<destination\*###
Retrieve a report containing the logs of the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion admin revoke *\<email\*###
Revoke administrator privileges for the named user at the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion frameworks###
List the supported frameworks of the target. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups add-user *\<group\* *\<user\*###
Add the named user to the specified group. This is an Application Lifecycle Service 2
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion groups create *\<name\*###
Create a new group with the specified name. This is an Application Lifecycle Service 2
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups delete-user *\<group\* *\<user\*###
Remove the named user from the specified group. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups delete *\<name\*###
Delete the named group. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups limits *\<group\*###
Show and/or modify the limits applying to applications in the named group. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--apps</td>
    <td>Limit for the number of applications in the group.</td>
    </tr>    <tr><td>--appuris</td>
    <td>Limit for the number of mapped uris per application.</td>
    </tr>    <tr><td>--drains</td>
    <td>Limit for the number of drains in the group.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-sudo</td>
    <td>Complementary alias of --sudo.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--services</td>
    <td>Limit for the number of services in the group.</td>
    </tr>    <tr><td>--sudo</td>
    <td>Applications can use sudo (or not).</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups show###
Show the list of groups known to the target. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion groups users *\<group\*###
Show the list of users in the named group. This is an Application Lifecycle Service 2
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion group *\<name\*###
Report the current group, or (un)set it. This is an Application Lifecycle Service 2
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--reset</td>
    <td>Reset the current group to nothing. Cannot be used together with
    name.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion info###
Show the basic system and account information.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion limits *\<group\*###
Show and/or modify the limits applying to applications in the named group. This is an Application Lifecycle Service 2 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--apps</td>
    <td>Limit for the number of applications in the group.</td>
    </tr>    <tr><td>--appuris</td>
    <td>Limit for the number of mapped uris per application.</td>
    </tr>    <tr><td>--drains</td>
    <td>Limit for the number of drains in the group.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-sudo</td>
    <td>Complementary alias of --sudo.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--services</td>
    <td>Limit for the number of services in the group.</td>
    </tr>    <tr><td>--sudo</td>
    <td>Applications can use sudo (or not).</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota configure *\<name\*###
Reconfigure the named quota definition. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--allow-sudo</td>
    <td>Applications can use sudo in their container.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-allow-sudo</td>

    <td>Complementary alias of --allow-sudo.</td>
    </tr>    <tr><td>--no-paid-services-allowed</td>

    <td>Complementary alias of --paid-services-allowed.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--no-trial-db-allowed</td>

    <td>Complementary alias of --trial-db-allowed.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--paid-services-allowed</td>

    <td>Applications can use non-free services.</td>
    </tr>    <tr><td>--services</td>
    <td>Limit for the number of services in the quota.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--trial-db-allowed</td>

    <td>Applications can use trial databases.</td> </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota create *\<name\*###
Create a new quota definition. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--allow-sudo</td>
    <td>Applications can use sudo in their container.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-allow-sudo</td>

    <td>Complementary alias of --allow-sudo.</td>
    </tr>    <tr><td>--no-paid-services-allowed</td>

    <td>Complementary alias of --paid-services-allowed.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--no-trial-db-allowed</td>

    <td>Complementary alias of --trial-db-allowed.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--paid-services-allowed</td>

    <td>Applications can use non-free services.</td>
    </tr>    <tr><td>--services</td>
    <td>Limit for the number of services in the quota.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    </tr>    <tr><td>--trial-db-allowed</td>

    <td>Applications can use trial databases.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota delete *\<name\*###
Delete the named quota definition. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota list###
List the available quota definitions. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota rename *\<name\* *\<newname\*###
Rename the named quota definition. This is an Application Lifecycle Service 3 specific
command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quota show *\<name\*###
Show the details of the named quota definition. If not specified it will be asked for interactively (menu). This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion quotas###
List the available quota definitions. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion runtimes###
List the supported runtimes of the target. This is an Application Lifecycle Service 2
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion stacks###
List the supported stacks of the target. This is an Application Lifecycle Service 3
specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion targets###
List the available targets, and their authorization tokens, if any.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
###helion tokens###
List the available targets, and their authorization tokens, if any.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion usage *\<userOrGroup\*###
Show the current memory allocation and usage of the active or specified user/group (Application Lifecycle Service 2), or the specified or current space (Application Lifecycle Service 3).

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--all</td>
    <td>Query information about everything. Cannot be used together with
    userOrGroup.</td>
    </tr>    <tr><td>--group</td>
    <td>The once-off group to use for the current operation. This is a
    Application Lifecycle Service 2 option.</td>
    </tr>    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The once-off organization to use for the current operation. This
    is an Application Lifecycle Service 3 option.</td>
    </tr>    <tr><td>--space</td>
    <td>The once-off space to use for the current operation, specified by
    name. This is an Application Lifecycle Service 3 option. Cannot be used together with --space-guid.</td>
    </tr>    <tr><td>--space-guid</td>
    <td>The once-off space to use for the current operation, specified by
    guid. This is an Application Lifecycle Service 3 option. Cannot be used together with --space.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion user-info *\<name\*###
Shows the information of a user in the current or specified target. Defaults to the current user. Naming a specific user requires an Application Lifecycle Service 3 target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion user###
Show the name of the current user in the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion version###
Print the version number of the client.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>

**User Management**
### helion add-user *\<name\*
Register a new user in the current or specified target. This operation requires administrator privileges, except if "allow\_registration" is set server-side.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--admin</td>
    <td>Give the newly created user administrator privileges.</td>
    </tr>    <tr><td>--apps</td>
    <td>Limit for the number of applications in the group.</td>
    </tr>    <tr><td>--appuris</td>
    <td>Limit for the number of mapped uris per application.</td>
    </tr>    <tr><td>--drains</td>
    <td>Limit for the number of drains in the group.</td>
    </tr>    <tr><td>--email</td>
    <td>The email of the user to create. This is an Application Lifecycle Service 3 specific
    option.</td>
    </tr>    <tr><td>--group</td>
    <td>The group to put the new user into. This is an Application Lifecycle Service 2 specific
    option.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-sudo</td>
    <td>Complementary alias of --sudo.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The organization to place the new user into. Defaults to the
    current organization. This is an Application Lifecycle Service 3 specific option.</td>
    </tr>    <tr><td>--passwd</td>
    <td>Alias of --password.</td>
    </tr>    <tr><td>--password</td>
    <td>The password to use.</td>
    </tr>    <tr><td>--services</td>
    <td>Limit for the number of services in the group.</td>
    </tr>    <tr><td>--sudo</td>
    <td>Applications can use sudo (or not).</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion delete-user *\<email\*###
Delete the named user, and the user's applications and services from the current or specified target. This operation requires administrator privileges.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
###helion login-fields###
Show the names of the credential fields needed for a login. This is an Application Lifecycle Service 3 specific command.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion passwd###
Change the password of the current user in the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--passwd</td>
    <td>Alias of --password.</td>
    </tr>    <tr><td>--password</td>
    <td>The new password. If not present it will be interactively asked
    for.</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion register *\<name\*###
Register a new user in the current or specified target. This operation requires administrator privileges, except if "allow\_registration" is set server-side.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--admin</td>
    <td>Give the newly created user administrator privileges.</td>
    </tr>    <tr><td>--apps</td>
    <td>Limit for the number of applications in the group.</td>
    </tr>    <tr><td>--appuris</td>
    <td>Limit for the number of mapped uris per application.</td>
    </tr>    <tr><td>--drains</td>
    <td>Limit for the number of drains in the group.</td>
    </tr>    <tr><td>--email</td>
    <td>The email of the user to create. This is an Application Lifecycle Service 3 specific
    option.</td>
    </tr>    <tr><td>--group</td>
    <td>The group to put the new user into. This is an Application Lifecycle Service 2 specific
    option.</td>
    </tr>    <tr><td>--mem</td>
    <td>Amount of memory applications can use.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-sudo</td>
    <td>Complementary alias of --sudo.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--organization</td>
    <td>The organization to place the new user into. Defaults to the
    current organization. This is an Application Lifecycle Service 3 specific option.</td>
    </tr>    <tr><td>--passwd</td>
    <td>Alias of --password.</td>
    </tr>    <tr><td>--password</td>
    <td>The password to use.</td>
    </tr>    <tr><td>--services</td>
    <td>Limit for the number of services in the group.</td>
    </tr>    <tr><td>--sudo</td>
    <td>Applications can use sudo (or not).</td>
    </tr>    <tr><td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-o</td>
    <td>Alias of --organization.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion token###
Interactively set authentication token.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion unregister *\<email\*###
Delete the named user, and the user's applications and services from the current or specified target. This operation requires administrator privileges.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion users###
Show the list of users known to the current or specified target.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### Convenience[](#convenience "Permalink to this headline")###
### helion aliases###
List the known aliases (shortcuts).

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion alias *\<name\* *\<command\*###
Create a shortcut for a command (prefix).

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion unalias *\<name\*###
Remove a shortcut by name.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>

### Miscellaneous[](#miscellaneous "Permalink to this headline")###
### helion admin exit###
Exit the shell. No-op if not in a shell.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
###helion admin help *\<cmdname\*###
Retrieve help for a command or command set. Without arguments help for all commands is given. The default format is --full.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--by-category</td>
    <td>Activate by-category form of the help.</td>
    </tr>    <tr><td>--full</td>
    <td>Activate full form of the help.</td>
    </tr>    <tr><td>--json</td>
    <td>Activate json form of the help.</td>
    </tr>    <tr><td>--list</td>
    <td>Activate list form of the help.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--short</td>
    <td>Activate short form of the help.</td>
    </tr>    <tr><td>--width</td>
    <td>The line width to format the help for. Defaults to the terminal
    width, or 80 when no terminal is available.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-w</td>
    <td>Alias of --width.</td>
    </tr>
</table>
###helion curl *\<operation\* *\<path\* *\<header\*###
Run a raw rest request against the chosen target

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--no-trace</td>
    <td>Complementary alias of --trace.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--target</td>
    <td>The once-off target to use for the current operation.</td>
    </tr>    <tr><td>--token</td>
    <td>The once-off authentication token to use for the current
    operation.</td>
    </tr>    <tr><td>--token-file</td>
    <td>Path to an existing and readable file containing the targets and
    authorization tokens.</td>
    </tr>    <tr><td>--trace</td>
    <td>Activate tracing of the issued REST requests and responses. This
    option is a no-op now. Tracing is always active. See the 'trace'
    command to print the saved trace to stdout.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-t</td>
    <td>Alias of --trace.</td>
    </tr>
</table>
### helion debug-packages###
Show the packages used the client, and their versions.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion drain exit###
Exit the shell. No-op if not in a shell.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion drain help *\<cmdname\*###
Retrieve help for a command or command set. Without arguments help for all commands is given. The default format is --full.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--by-category</td>
    <td>Activate by-category form of the help.</td>
    </tr>    <tr><td>--full</td>
    <td>Activate full form of the help.</td>
    </tr>    <tr><td>--json</td>
    <td>Activate json form of the help.</td>
    </tr>    <tr><td>--list</td>
    <td>Activate list form of the help.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--short</td>
    <td>Activate short form of the help.</td>
    </tr>    <tr><td>--width</td>
    <td>The line width to format the help for. Defaults to the terminal
    width, or 80 when no terminal is available.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-w</td>
    <td>Alias of --width.</td>
    </tr>
</table>
### helion exit###
Exit the shell. No-op if not in a shell.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion groups exit###
Exit the shell. No-op if not in a shell.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion groups help *\<cmdname\*###
Retrieve help for a command or command set. Without arguments help for all commands is given. The default format is --full.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--by-category</td>
    <td>Activate by-category form of the help.</td>
    </tr>    <tr><td>--full</td>
    <td>Activate full form of the help.</td>
    </tr>    <tr><td>--json</td>
    <td>Activate json form of the help.</td>
    </tr>    <tr><td>--list</td>
    <td>Activate list form of the help.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--short</td>
    <td>Activate short form of the help.</td>
    </tr>    <tr><td>--width</td>
    <td>The line width to format the help for. Defaults to the terminal
    width, or 80 when no terminal is available.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-w</td>
    <td>Alias of --width.</td>
    </tr>
</table>
###helion guid *\<type\* *\<name\*###
Map the specified name into a uuid, given the type. This is an Application Lifecycle Service 3 specific command.
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion help *\<cmdname\*###
Retrieve help for a command or command set. Without arguments help for all commands is given. The default format is --full.

<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--by-category</td>
    <td>Activate by-category form of the help.</td>
    </tr>    <tr><td>--full</td>
    <td>Activate full form of the help.</td>
    </tr>    <tr><td>--json</td>
    <td>Activate json form of the help.</td>
    </tr>    <tr><td>--list</td>
    <td>Activate list form of the help.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--short</td>
    <td>Activate short form of the help.</td>
    </tr>    <tr><td>--width</td>
    <td>The line width to format the help for. Defaults to the terminal
    width, or 80 when no terminal is available. </tr><tr>td></tr><tr>
    <td>-w</td>
    <td>Alias of --width.</td>
    </tr>
</table>
### helion named-entities###
List the entity types usable for 'guid'. I.e. the types of the
    named entities known to the client.
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--json</td>
    <td>Print raw json as output, not human-formatted data.</td>
    </tr>    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion quota exit###
Exit the shell. No-op if not in a shell.
    
<table>
    <tr><td><b>Option</b></td><td><b>Description</b></td></tr>
    <tr><td>--no-prompt</td>
    <td>Disable interactive queries.</td>
    </tr>    <tr><td>--non-interactive</td>

    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>--noprompt</td>
    <td>Alias of --no-prompt.</td>
    </tr><tr>
    <td>-n</td>
    <td>Alias of --no-prompt.</td>
    </tr>
</table>
### helion quota help *\<cmdname\>*###
Retrieve help for a command or command set. Without arguments, help for all commands is given. The default format is --full.
    
<table>
<tr><td><b>Option</b></td><td><b>Description</b></td></tr>
<tr><td>--by-category</td>
<td>Activate by-category form of the help.</td>
</tr>    <tr><td>--full</td>
<td>Activate full form of the help.</td>
</tr>    <tr><td>--json</td>
<td>Activate json form of the help.</td>
</tr>    <tr><td>--list</td>
<td>Activate list form of the help.</td>
</tr>    <tr><td>--no-prompt</td>
<td>Disable interactive queries.</td>
</tr>    <tr><td>--non-interactive</td>
<td>Alias of --no-prompt.</td>
</tr><tr>
<td>--noprompt</td>
<td>Alias of --no-prompt.</td>
</tr><tr>
<td>--short</td>
<td>Activate short form of the help.</td>
</tr>    <tr><td>--width</td>
<td>The line width to format the help for. Defaults to the terminal
width, or 80 when no terminal is available.</td> </tr><tr>
<td>-n</td>
<td>Alias of --no-prompt.</td>
</tr><tr>
<td>-w</td>
<td>Alias of --width.</td>
</tr>
</table>
### helion trace###
Print the saved REST trace for the last client command to stdout.
    
<table>
<tr><td><b>Option</b></td><td><b>Description</b></td></tr>
<tr><td>--no-prompt</td>
<td>Disable interactive queries.</td>
</tr>    <tr><td>--non-interactive</td>
<td>Alias of --no-prompt.</td>
</tr><tr>
<td>--noprompt</td>
<td>Alias of --no-prompt.</td>
</tr><tr>
<td>-n</td>
<td>Alias of --no-prompt.</td>
</tr></table>
---
layout: default-devplatform
permalink: /als/v1/user/reference/environment/
product: devplatform
---
<!--PUBLISHED-->

Environment Variables[](#environment-variables "Permalink to this headline")
=============================================================================

Application Lifecycle Service exposes a number of predefined [environment
variables](http://manpages.ubuntu.com/manpages/man7/environ.7)
during runtime (including hook processing, cron jobs and ssh commands).

You can set your own environment variables:

-   in an `env:` block in
    [*manifest.yml*](/als/v1/user/deploy/manifestyml/#env),
-   via the application's Details page in the [*Management
    Console*](/als/v1/admin/console/customize/#management-console), or
-   using the [*helion env-add*](/als/v1/user/reference/client-ref/#command-env-add)
    command.

**Note**

To see a complete list of environment variables in an Application Lifecycle Service
application container, deploy the
[node-env](https://github.com/Stackato-Apps/node-env) sample.

DATABASE\_URL
:   Contains an access URL for a database service. If more than one type
    of database is present, `DATABASE_URL` will not
    be available. Instead, use the [*Database Specific URL
    variables*](/als/v1/user/services/data-services/#database-specific-url)
    below.

    Example:

        mysql://u93Mm8XmGXQ9R:p8LwNeQXMrNzi@192.168.0.112:3306/d0a60c0be931f4982bbef153f993237bc

MEMCACHE\_URL: Location of and credentials for the bound **Memcached** service, if there is (only) one.

MYSQL\_URL: Location of and credentials for the bound **MySQL** service, if there is (only) one.

POSTGRESQL\_URL: Location of and credentials for the bound **PostgreSQL** service, if there is (only) one.

REDIS\_URL: Location of and credentials for the bound **Redis** service, if there is (only) one.

RABBITMQ\_URL: Location of and credentials for the bound **RabbitMQ** service, if there is (only) one.

HOME: Identifies the working directory assigned to a particular user on login. In an Application Lifecycle Service application container, this is generally set to */home/helion/app/* by default.

HTTP\_PROXY:   A variable recognized by many web applications to direct them to a proxy HTTP server.

PATH: A list of directories, separated by ":", which are to be searched for the names of executable files to be interpreted as commands.

PIP\_OPTS: Custom/alternate [*PIP*](/als/v1/user/reference/glossary/#term-pip) repo location. See [running your own package index](http://guide.python-distribute.org/pip.html#running-your-own-package-index) for more info.

    Example:

        env:
          PIP_OPTS: "--extra-index-url=http://company.com/inhouse-pypi-mirror"

PORT: Application Lifecycle Service alternative for VCAP\_APP\_PORT.

PROCESSES\_WEB: This variable contains the default start command that would be used
    when [*manifest.yml*](/als/v1/user/deploy/manifestyml/)
    doesn't override it. It is provided so that users can specify a
    wrapper around the default command, e.g.

    > processes:
    > :   web: newrelic\_wrapper \$PROCESSES\_WEB

    Note that `PROCESSES_WEB` may be undefined when
    Application Lifecycle Service can't determine the default command (e.g. because the app
    uses a non-standard main application file).

PYPM\_OPTS: Custom/alternate [*PyPM*](/als/v1/user/reference/glossary/#term-pypm) repo location.
    Repo mirroring is sort of undocumented feature. Example:

        env:
            PYPM_OPTS: "-R http://pypm-free.activestate.com/2.7/linux-x86_64/"

HELION\_APP\_ENV: Note

    Internal use, subject to change.

    Contains a list of all environment variables set with [*helion
    env-add*](/als/v1/user/reference/client-ref/#command-ref-client) or
    [*manifest.yml*](/als/v1/user/deploy/manifestyml/#env).

HELION\_APP\_NAME: Contains the application name as specified during application push
    (or in *manifest.yml*). Available during staging
    as well as in the application instance.
HELION\_APP\_NAME\_UPCASE: Contains the same value as HELION\_APP\_NAME transformed to uppercase, with dashes replaced by underscores. For example if HELION\_APP\_NAME is "php-info", then HELION\_APP\_NAME\_UPCASE will be "PHP\_INFO".

This makes it possible to access the environment variables for [*harbor*](/als/v1/user/services/port-service/#port-service-env-vars) and [*filesystem*](/als/v1/user/services/filesystem/#file-system-usage) services.

HELION\_APP\_ROOT: This is the "root" directory from the Application Lifecycle Service point of view. It contains app specific HOME directory (app/), the log file directory (logs/) and various scripts.

The [*HOME*](#term-home) environment variable will actually point to the app directory, which looks mostly like the directory uploaded by the client. This is where *manifest.yml* and all the application files live.

HELION\_DOCUMENT\_ROOT: This contains the root directory where the user can access. The document-root must always be specified relative to \$HOME (/home/helion/app).

HELION\_FILESYSTEM: If the app uses a single `filesystem` service, then the local mount point is stored in this variable. If there is more than one `filesystem` service, `HELION_FILESYSTEM` is not available. Instead, a custom environment variable `HELION_FILESYSTEM_*` will be created based on the name of each filesystem service (with hyphens replaced by underscores).

    For example, if your *manifest.yml* file configures the following
    services:

        services:
          my-data: filesystem
          plugins: filesystem

    Two environment variables would be created:
    `HELION_FILESYSTEM_MY_DATA` and
    `HELION_FILESYSTEM_PLUGINS`.

HELION\_TARGET: Can be set in the local shell to specify the API endpoint target for the `helion` client. When set, the `helion target` command is ignored until the variable is explicitly unset. Can be overridden with the `--target` option.

HELION\_UWSGI: Set by the Perl and Python frameworks only. It contains the default uswgi start command to run the application via uwsgi. It is provided in case the user wants to add additional uwsgi options in [*manifest.yml*](/als/v1/user/deploy/manifestyml/):

        processes:
          web: $HELION_UWSGI --another-uwsgi-option

VCAP\_APP\_HOST: This variable contains the IP address of the host that the application is running on.

VCAP\_APP\_PORT: This variable contains the port that the application will be exposed on.

VCAP\_APPLICATION: This variable contains all relevant application details for the Application Lifecycle Service Application. (Instance ID, App Name, App Uris, Users/Groups etc.)

VCAP\_SERVICES: Contains connection details, credentials, and meta data for services bound to the application. See [*VCAP\_SERVICES*](/als/v1/user/services/data-services/#database-services-vcap-services).---
layout: default-devplatform
permalink: /als/v1/user/reference/glossary/
---
<!--PUBLISHED-->

Glossary[](#index-0 "Permalink to this headline")
==================================================

AMQP
:   Acronym for [Advanced Message Queuing
    Protocol](http://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol).

Apache ANT
:   A software tool for automating software build processes. See
    [Ant](http://ant.apache.org/) for more info.

Apache Maven
:   A build automation tool typically used for Java projects. See
    [Maven](http://maven.apache.org/) for more info.

app
:   Any application software intended for instantiation in Application Lifecycle Service. At
    minimum it consists of the application, expressed in a dynamic
    language, plus a configuration file named 
    *manifest.yml*.

Avahi
:   An implementation of [*multicast DNS*](#term-multicast-dns) and
    related protocols.

cluster
:   A set of interconnected physical processors or virtual machines,
    managed at least conceptually as a single entity but otherwise
    operating autonomously. Historically the term carried a variety of
    proprietary meanings, but came into general use with the rapid
    development of supercomputing based upon [Beowulf
    Clusters](http://en.wikipedia.org/wiki/Beowulf_cluster). An Application Lifecycle Service
    cluster is one in which [*role*](#term-role)s are assigned or
    replicated to multiple cluster [*node*](#term-node)s.

component
:   Within Application Lifecycle Service, the term **component** is used when naming a
    discrete part of the Application Lifecycle Service server. For example, a
    [*role*](#term-role) is made up of one or more components.

container
:   A lightweight form of virtualization which provides resource
    isolation and secure separation for multiple instances of the same
    base system. According to circumstances it may be used in addition
    to or instead of hypervisor virtualization.

CPAN
:   Acronym for [Comprehensive Perl Archive
    Network](http://www.cpan.org/).

doozerd
:   A consistent distributed data store. Used for cluster management in
    Application Lifecycle Service. (see [Doozer project on
    GitHub](https://github.com/ha/doozerd/#readme))

DHCP
:   [Dynamic Host Configuration
    Protocol](http://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol).
    The DHCP service is used to allocate IP addresses to clients on
    demand and to supply other basic network information they need, such
    as the addresses of a default router and DNS server.

DNS
:   [Domain Name
    System](http://en.wikipedia.org/wiki/Domain_Name_System). Resolves
    domain names to IP addresses.

dnsmasq
:   A [lightweight server](http://en.wikipedia.org/wiki/Dnsmasq) for
    locally integrating DNS with DHCP/BOOTP.

dynamic DNS
:   A means of rapidly updating the Domain Name System, possibly making
    use of [**RFC 2136**](http://tools.ietf.org/html/rfc2136)
    Dynamic Updates.

filesystem
:   In Application Lifecycle Service, **filesystem** refers to persistent storage accessed by
    an application :term\`service\` specified in *manifest.yml* through
    a server which has been assigned the filesystem
    [*role*](#term-role).

JSON
:   A notation for structured text data, acronym for [JavaScript Object
    Notation](http://en.wikipedia.org/wiki/JSON).

MBUS
:   Application Lifecycle Service's implementation of an [**RFC
    3259**](http://tools.ietf.org/html/rfc3259) message queue used
    for interprocess communication. *See also:* [*NATS*](#term-nats).

memcached
:   Free & open source, high-performance, distributed memory object
    caching system, generic in nature, but intended for use in speeding
    up dynamic web applications by alleviating database load. (see
    [Memcached project page](http://memcached.org/))

micro cloud
:   A preconfigured Application Lifecycle Service virtual machine image consisting of a
    single generic [*node*](#term-node) enabled for all the
    [*role*](#term-role)s necessary for basic operation, but with no
    preinstalled [*app*](#term-app)s or [*service*](#term-service)s.

mongodb
:   A popular [noSQL](http://en.wikipedia.org/wiki/NoSQL) database
    management system.

multicast DNS
:   A distributed means of configuring DNS by [multicast
    discovery](http://en.wikipedia.org/wiki/Multicast_DNS). It is
    supported on Application Lifecycle Service :term\`micro cloud\` servers using
    [*Avahi*](#term-avahi).

mysql
:   A relational database management system.

NAT
:   Acronym for [Network Address
    Translation](http://en.wikipedia.org/wiki/Network_address_translation).

NATS
:   In Application Lifecycle Service, a publish-subscribe message system implemented as a
    process called `nats-server` which listens on a
    network interface, normally on port 4222/tcp. Messages published
    across the network to a particular [*MBUS*](#term-mbus) queue
    managed by the nats-server are communicated to clients which are
    subscribed to that queue.

Nginx
:   [Nginx](http://wiki.nginx.org/) is a high-performance, event-driven
    web server.

node
:   An Application Lifecycle Service **node** is a single processing host in a
    [*cluster*](#term-cluster), typically a virtual machine running
    under a hypervisor.

OVF
:   Acronym for [Open Virtualization
    Format](http://dmtf.org/standards/ovf), a specification for virtual
    machine images developed by the DMTF industry consortium.

PaaS
:   Acronym for [Platform as a
    Service](http://en.wikipedia.org/wiki/Platform_as_a_service).

pip
:   A tool for installing and managing Python packages, such as those
    found in the Python Package Index. It's a replacement for
    easy\_install. See
    [pip-installer](http://www.pip-installer.org/en/latest/) for more
    information.

PyPM
:   PyPM is the *binary* package manager for ActivePython. It is usually
    the fastest and most reliable way of installing PyPI packages for
    your Application Lifecycle Service applications. The PyPM repository hosts almost all of
    the Python packages registered in PyPI and includes their latest
    versions. See [PyPM](http://code.activestate.com/pypm) for more
    information.

Polipo
:   A lightweight caching web proxy intended for small applications.

postgresql
:   A relational database management system.

private PaaS
:   A private [*PaaS*](#term-paas) is one which is hosted on your
    private cloud, behind your firewall.

RabbitMQ
:   A [message broker](http://en.wikipedia.org/wiki/Message_broker)
    subsystem which implements [*AMQP*](#term-amqp).

Redis
:   An implementation of memory resident key-value store.

resolvconf
:   A system configuration tool typically used by hook scripts at boot
    time. See the [resolvconf man
    page](http://manpages.ubuntu.com/manpages/man8/resolvconf.8)
    for details.

role
:   Each [*node*](#term-node) in an Application Lifecycle Service [*cluster*](#term-cluster)
    may be assigned certain selectable capabilities within the Application Lifecycle Service
    architecture. These capabilities are called **roles**, and are
    usually denoted in lowercase. Examples of essential roles are
    **router**, **primary**, **controller**, and **dea**. In addition,
    there are **role groups** (for convenience) such as
    **data-services** that represent all data-services. (postgresql
    mysql rabbit mongodb redis filesystem memcached)

service
:   In Application Lifecycle Service, a **service** is a type of [*role*](#term-role) that
    may be provisioned on a server and accessed by an application as
    specified in *manifest.yml*.

supervisord
:   A process control system used by Application Lifecycle Service internally. (see
    [Supervisor project page](http://supervisord.org/))

tty console
:   The hypervisor window which provides serial console access to one of
    its virtual machines.

YAML
:   A notation for structured text data, acronym for [YAML Ain't Markup
    Language](http://en.wikipedia.org/wiki/YAML), used in*manifest.yml* configuration files.

---
layout: default-devplatform
permalink: /als/v1/user/reference/troubleshoot/
product: devplatform
---
<!--PUBLISHED-->

Troubleshooting[](#troubleshooting "Permalink to this headline")
=================================================================

SSH to Failed Containers[](#ssh-to-failed-containers "Permalink to this headline")
-----------------------------------------------------------------------------------

For troubleshooting and diagnostic purposes, it is possible to use helion ssh to access a [*container*](/als/v1/user/reference/glossary/#term-container) that has recently failed or did not start correctly. Containers are kept for one hour before being reclaimed. See the [*Command Reference*](/als/v1/user/reference/client-ref/#command-ref-client) for details on the `helion ssh` command.

Checking the Logs[](#checking-the-logs "Permalink to this headline")
---------------------------------------------------------------------

Most Application Lifecycle Service users will not have administrative access to the server. If you need to troubleshoot an application deployment or runtime failure, you can use the helion client to view the `stderr` and `stdout` log files. For example, if an application called `myapp` did not deploy correctly, run the command:

    $ helion logs myapp --all

This will generally show all errors encountered during deployment.

If you need to view another log file (e.g. one specific to your
application), use the files command to explore the remote filesystem and
return the contents of the files:

    $ helion files myapp logs
    stderr.log                                 44B
    stdout.log                                101B
    myapp-err.log                             189B

    $ helion files myapp logs/myapp-err.log

If that command should fail, try using the run command in combination
with ls or cat:

    $ helion run myapp cat ../logs/myapp-err.log

Specific Cases[](#specific-cases "Permalink to this headline")
---------------------------------------------------------------
**When pushing an app, the Application Lifecycle Service Client reports OK but app isn't
running**

The final output from pushing an app should look like:

    Staging Application: OK
    Starting Application: OK

If the app is being pushed to multiple instances, the client waits until at least one instance is running, and exits at that point (it does not wait until all instances are active). If afterwards you run `helion apps` and find the Health status at 0%, it is because the app crashed after starting successfully, not because the Application Lifecycle Service client reported incorrectly.

**DNS queries returning "connection refused"**

This error is reported when the Application Lifecycle Service server does not have an IP Address. To investigate and resolve, try the following:



- Verify the ARP tables on the hypervisor host, and on the Application Lifecycle Service server through its [*tty console*](/als/v1/user/reference/glossary/#term-tty-console):

         $ arp -n



- Check that the DHCP client is running:

        $ pgrep dhclient
        $ grep dhclient /var/log/syslog



- Connect to the DHCP server and verify that it is receiving client requests from the Application Lifecycle Service server.

- If your network is statically configured, assign an IP address on the Application Lifecycle Service server by editing the [interfaces](http://manpages.ubuntu.com/manpages/man5/interfaces.5) file:

        /etc/network/interfaces---
layout: default-devplatform
permalink: /als/v1/user/services/data-services/
product: devplatform
---
<!--PUBLISHED-->

Data Services[](#index-0 "Permalink to this headline")
=======================================================

Intro[](#intro "Permalink to this headline")
---------------------------------------------

Application Lifecycle Service includes a number of data services which can be bound to the
applications you deploy. These include several databases (PostgreSQL,
MySQL, Redis), the RabbitMQ messaging service, a [*persistent
file system*](/als/v1/user/services/filesystem/#persistent-file-system) service and
[*Memcached*](/als/v1/user/services/memcached/#memcached).

Configuring Application Lifecycle Service Data Services[](#configuring-helion-data-services "Permalink to this headline")
-------------------------------------------------------------------------------------------------------

The data services your application requires need to be specified at the
time your app is pushed to the Application Lifecycle Service server. This can be done in a
number of ways:

1.  Specifying the required services in the *manifest.yml* file.
2.  Configuring services during the `push` process.
3.  Configuring services manually.

If you would like to use an external database system, see [*Using
External Database Services*](#database-external).

###Using manifest.yml {#using-manifest-yml}

The manifest.yml file can hold a lot of application specific details
that tell the Application Lifecycle Service Client what to do without having to enter them
when you run `helion push`. For complete details
for the manifest.yml file, please see [*Configuration With
manifest.yml*](/als/v1/user/deploy/manifestyml/).

A simple example:

    name: cirrus
    mem: 256M
    instances: 2
    services:
        cirrusdb: mysql

This tells the Application Lifecycle Service Client to request a MySQL database called
`cirrusdb`. Possible service types are:

-   [*filesystem*](/als/v1/user/reference/glossary/#term-filesystem)
-   [*memcached*](/als/v1/user/reference/glossary/#term-memcached)
-   [*mysql*](/als/v1/user/reference/glossary/#term-mysql)
-   [*postgresql*](/als/v1/user/reference/glossary/#term-postgresql)
-   [*rabbitmq*](/als/v1/user/reference/glossary/#term-rabbitmq)
-   [*redis*](/als/v1/user/reference/glossary/#term-redis)

To access the data services once they've been created, see [*Accessing
Configured Database Services*](#database-accessing).

### Using helion push[](#using-helion-push "Permalink to this headline")

If you do not specify services in the manifest.yml file, you will be
prompted to create one during the push process. Should you want to set
up a database service, enter "y" when asked, and follow the prompts:

    $ helion push

    ...
    Would you like to bind any services to 'cirrus' ?  [yN]: y
    The following system services are available
    1. mongodb
    2. mysql
    3. postgresql
    4. redis
    5. <None of the above>
    Please select one you wish to provision: 2
    Specify the name of the service [mysql-18cab]: cirrusdb
    Creating Service: OK
    Binding Service: OK
    ...

In order to ensure the correct services are configured each time the app
is pushed, your services should be listed in the manifest.yml file.

### Creating and Binding Services[](#creating-and-binding-services "Permalink to this headline")

It is possible to create services and bind them to an app after they are
pushed to the Application Lifecycle Service server. There are two ways to do this:

**helion create-service \<service\> \<name\> \<app\>**
:   This combines all parameters into a single command.
    `service` is the type of service you want to
    create (mysql, redis, postgresql). `name` is the name you want to assign to the service.
    `app` is the name of the application the service
    is to be bound to.

        $ helion create-service mysql ordersdb myapp
        Creating Service: OK
        Binding Service: OK
        Stopping Application [myapp]: OK
        Staging Application [myapp]: OK
        Starting Application [myapp]: OK

        $ helion apps

        +-------------+---+-------------+---------------------------+----------------+
        | Application | # | Health      | URLS                      | Services       |
        +-------------+---+-------------+---------------------------+----------------+
        | myapp       | 1 | RUNNING     | myapp.helion-xxxx.local | ordersdb       |
        +-------------+---+-------------+---------------------------+----------------+

**create-service \<service\> \<name\>**

**bind-service \<servicename\> \<app\>**
These two commands do the same thing as if all three parameters were passed using `create-service`, but it allows the flexibility of creating and perhaps configuring the service before binding it.



- `service` is the type of service you want to create (mysql, redis, postgresql, mongodb).
- `name` is the name you want to assign to the service.
- `servicename` is the name assigned during the `create-service` command. 
- `app` is the name of the application the service is to be bound to.

        $ helion create-service mysql customerdb
        Creating Service: OK

        $ helion bind-service customerdb myapp
        Binding Service: OK
        Stopping Application [myapp]: OK
        Staging Application [myapp]: OK
        Starting Application [myapp]: OK

        $ helion apps

        +-------------+---+---------+---------------------------+-----------------------+
        | Application | # | Health  | URLS                      | Services              |
        +-------------+---+---------+---------------------------+-----------------------+
        | myapp       | 1 | RUNNING | myapp.helion-xxxx.local | ordersdb, customerdb  |
        +-------------+---+---------+---------------------------+-----------------------+

For further information on the commands for managing services, please see
the [*helion services*](/als/v1/user/reference/client-ref/#command-services)
command reference.

**Note**

To remotely check the settings and credentials of any Application Lifecycle Service service,
use the [*helion
service*](/als/v1/user/reference/client-ref/#command-services) command.

Using Database Services[](#using-database-services "Permalink to this headline")
---------------------------------------------------------------------------------

When you bind a database service to an application running in Application Lifecycle Service,
[*environment
variables*](/als/v1/user/reference/environment/#environment-variables)
containing that service's host, port, and credentials are added to the
application container. You can use these environment variables in your
code to connect to the service, rather than hard coding the details.

Examples of how to parse and use these variables can be found in the
[*Language Specific
Deployment*](/als/v1/user/deploy/#language-specific-deploy) section.

### DATABASE\_URL<a name="database-url"></a>

**If only one relational database service** is bound to an application,
use the DATABASE\_URL environment variable. It contains the connection
string for the bound database in the following format:

    protocol://username:password@host:port/database_name

For example, a DATABASE\_URL for a PostgreSQL service would look like
this:

    postgres://u65b0afbc8f8f4a1192b73e8d0eb38a24:p9eb83c11c59c4bcabfa475a4871e9242@192.168.69.117:5432/da17e48ddc82848499cb387bc65f5d4f9

The "protocol" portion specifies the type of database. For example:

-   mysql://
-   postgresql://

**Note**

The "database name" portion of the URL is the *actual* database name
(e.g. "da17e48ddc82848499cb387bc65f5d4f9"), not the user-specific
service name set during deployment/service creation (e.g. "myapp-db").

### Database-Specific URLs[](#database-specific-urls "Permalink to this headline")

**If a non-relational data service type** is bound to the application,
use the corresponding named environment variable:

-   REDIS\_URL
-   RABBITMQ\_URL

**If more than one relational database service type** is bound to the
application (e.g. MySQL and PostgreSQL), the DATABASE\_URL variable will
not be set but the following database-specific variables will:

-   MYSQL\_URL
-   POSTGRESQL\_URL
-   ORACLE\_URL (with Oracle Database add-on)

These have the same format as DATABASE\_URL.

**If more than one database of the same type** is bound to the
application (e.g. two MongoDB services), none of the URL formatted
environment variables will be available. Use
VCAP\_SERVICES instead.

### VCAP\_SERVICES <a name="vcap-services"></a>

Contains a JSON string listing the credentials for all bound services,
grouped by service type. For example:

    {
            "mysql": [
                    {
                            "name": "mydb",
                            "label": "mysql-5.5",
                            "plan": "free",
                            "tags": [
                                    "mysql",
                                    "mysql-5.5",
                                    "relational"
                            ],
                            "credentials": {
                                    "name": "d0a60c0be931f4982bbef153f993237bc",
                                    "hostname": "192.168.0.112",
                                    "host": "192.168.0.112",
                                    "port": 3306,
                                    "user": "u93Mm8XmGXQ9R",
                                    "username": "u93Mm8XmGXQ9R",
                                    "password": "p8LwNeQXMrNzi"
                            }
                    }
            ]
    }

This variable contains some additional meta-information, and can be used
for compatibility with Cloud Foundry.

**Note**

VCAP\_SERVICES variables use non-versioned
service names The version number remains in 'label' key.

Using External Databases[](#using-external-databases "Permalink to this headline")
-----------------------------------------------------------------------------------

Applications running in Application Lifecycle Service can use external databases by
hard-coding the host and credentials, or by specifying the them in a
custom environment variable.

Hard-coded Database Connections[](#hard-coded-database-connections "Permalink to this headline")
-------------------------------------------------------------------------------------------------

Applications which write database connection details during staging
rather than taking them from environment variables at run time, must be
re-staged (e.g. redeployed or updated) to pick up the new service
location and credentials. Restarting the application will not
automatically force restaging.

Accessing Database Services[](#accessing-database-services "Permalink to this headline")
-----------------------------------------------------------------------------------------

You may need to connect to a database service directly for purposes of
initial database setup, modifying fields, running queries, or doing
backups. These operations can be done using the `dbshell` (preferred) or `tunnel` commands.

### Using dbshell[](#using-dbshell "Permalink to this headline")

The `helion dbshell` command creates an SSH tunnel
to database services. To open an interactive shell to a service:

    $ helion dbshell <application_name> <service_name>

The command will automatically open the appropriate database client for
the database you're connecting to, provided that client is installed on
the local system.

It is also available inside application containers, providing a quick
way to import data from dump files, or setting up schemas. For example,
to import data from file in an application directory, you could use a
hook in *manifest.yml* such as:

    hooks:
      post-staging:
        - dbshell < setup/sample-data.sql

### Using Tunnel[](#using-tunnel "Permalink to this headline")

The `helion tunnel` command is an alternative
method for accessing database services. The command creates a small Ruby
application which proxies database requests over HTTP. This is the
standard method for database access in Cloud Foundry, but tends to be
slower than using `dbshell`:

To create or use a tunnel:

    $ helion tunnel <servicename>

Depending on the service you are connecting to, a list of options will
be provided. Here is an example of connecting to a MySQL service:

    $ helion tunnel mydb

    Getting tunnel url: OK, at https://tunnel-xxxxx.helion-xxxx.local
    Getting tunnel connection info: OK

    Service connection info:
    +----------+-----------------------------------+
    | Key      | Value                             |
    +----------+-----------------------------------+
    | username | uT9efVVFCk                        |
    | password | pHFitpIU1z                        |
    | name     | d5eb2468f70ef4997b1514da1972      |
    +----------+-----------------------------------+

    1. none
    2. mysql
    3. mysqldump
    Which client would you like to start?

For simple command line access, select option **2. mysql**.

To get a dump of the entire database, select option **3. mysqldump**.
You will be prompted to enter a path to where the dump will be saved to.

If you want to connect with a database viewer, or run multiple commands
from the command line, passing in SQL files, select option **1. none**.
This will set up a port for you to connect with locally:

    1. none
    2. mysql
    3. mysqldump

    Which client would you like to start? **none**

    Starting tunnel to remarks on port 10000.
    Open another shell to run command-line clients or
    use a UI tool to connect using the displayed information.
    Press Ctrl-C to exit...

You how have all the information you need to access the data. Notice the
"Service connection info" box above that tells you your username,
password, and the database name.

Open a new command line window. You can connect to the MySQL database
directly with:

    $ mysql --protocol=TCP --host=localhost --port=10000 --user=<user> --password=<password> <name>

    example:

    $ mysql --protocol=TCP --host=localhost --port=10000 --user=uT9efVVFCk --password=pHFitpIU1z d5eb2468f70ef4997b1514da1972

To import an SQL file, call the same command, and pipe in the file:

    $ mysql --protocol=TCP --host=localhost --port=10000 --user=<user> --password=<pass> <name> < mydatabase.sql

To pull a dump of all databases:

    $ mysqldump -A --protocol=TCP --port=10000 --host=localhost --user=<user> --password=<pass>

### Pre-populating a database while pushing an app[](#pre-populating-a-database-while-pushing-an-app "Permalink to this headline")

When a database needs to be populated with data the first time it is
run, it can be done by the use of a hook during the staging process.
This can be accomplished in two steps.

First, create a script file in the app's root directory that uses the
same data source variables from VCAP\_SERVICES as the ones being
used in the app. This file will open a connection to the database,
create tables, and insert records as necessary, as in this Perl example:

    use strict;
    use warnings;

    use DBI;
    use DBD::mysql;
    use JSON "decode_json";

    my $services = decode_json($ENV{VCAP_SERVICES});
    my $credentials = $services->{mydb};

    my $dbh = DBI->connect("DBI:mysql:database=$credentials->{name};hostname=$credentials->{hostname};port=$credentials->{port};",
                           $credentials->{'user'}, $credentials->{'password'})
        or die "Unable to connect: $DBI::errstr\n";

    my $sql_init =
        'CREATE TABLE customers (
                        id INT(11) AUTO_INCREMENT PRIMARY KEY,
                        customername TEXT,
                        created DATETIME
                );
        ';
    $dbh->do($sql_init);

    $sql_init =
                'INSERT INTO customers
                        (customername, created)
                VALUES
                        ("John Doe", now()),
                        ("Sarah Smith", now());
        ';
    $dbh->do($sql_init);

    $dbh->disconnect;

Next, modify your *manifest.yml* file to make use of the
`post-staging` hook which will execute a command to
run the script:

    name: customertracker
    services:
      mysql: customerdb
    hooks:
      post-staging: perl preload.pl

With those changes, the data from your script will be executed after the
staging process is complete but before the app starts to run.

### Backing up a MySQL database[](#backing-up-a-mysql-database "Permalink to this headline")

#### Using helion run[](#using-helion-run "Permalink to this headline")

To export a MySQL database, use the `helion run`
command to remotely execute the dbexport tool:

	$ helion run [application-name] dbexport service-name > dumpfile.sql

This will run a `dbexport` of the named data service
remotely and direct the output to a local file. If run from a directory
containing the manifest.yml file, the application name may be omitted.

#### Using helion tunnel[](#using-helion-tunnel "Permalink to this headline")

**Note**

This method of database backup is available for compatibility with Cloud
Foundry. It tends to be slower than using `helion run ...`.

To back up a MySQL database, use the [*tunnel*](#database-tunnel)
command to make a connection to the server and export the data using
`mysqldump`.

Use the `tunnel` command to access the service (in
this example a MySQL database named `customerdb`):

    $ helion tunnel customerdb

    Password: ********
    Getting tunnel url: OK, at https://tunnel-xxxxx.helion-xxxx.local
    Getting tunnel connection info: OK

    Service connection info:
    +----------+-----------------------------------+
    | Key      | Value                             |
    +----------+-----------------------------------+
    | username | uT9efVVFCk                        |
    | password | pHFitpIU1z                        |
    | name     | d5eb2468f70ef4997b1514da1972      |
    +----------+-----------------------------------+

    1. none
    2. mysql
    3. mysqldump
    Which client would you like to start?

Select option **3. mysqldump**. You will be prompted to enter a path to
where the dump will be saved.

See the [*tunnel*](#database-tunnel) command documentation for other
ways of accessing a MySQL database. See [*Importing a MySQL
database*](#bestpractices-importing-mysql) for details on importing a
file created by mysqldump into an existing MySQL database service.

### Importing a MySQL database[](#importing-a-mysql-database "Permalink to this headline")

#### Using helion run[](#id2 "Permalink to this headline")

To import a MySQL database, use the `helion dbshell` command:

    $ helion dbshell [application name] [service name] < dumpfile.sql

This command redirects the contents of a local database dump file to the
appropriate database client running in the application instance (i.e.
equivalent to `helion run dbshell ...`). If run
from a directory containing the *manifest.yml* file, the application and
service names may be omitted.

#### Using helion tunnel[](#id3 "Permalink to this headline")

**Note**

This method of database import is available for compatibility with Cloud
Foundry. It tends to be slower than using `helion run ...`.

To import data from a `mysqldump` into an existing
MySQL database service, use the `tunnel` command:

    $ helion tunnel <servicename>

    Password: ********
    Getting tunnel url: OK, at https://tunnel-xxxxx.helion-xxxx.local
    Getting tunnel connection info: OK

    Service connection info:
    +----------+-----------------------------------+
    | Key      | Value                             |
    +----------+-----------------------------------+
    | username | uT9efVVFCk                        |
    | password | pHFitpIU1z                        |
    | name     | d5eb2468f70ef4997b1514da1972      |
    +----------+-----------------------------------+

    1. none
    2. mysql
    3. mysqldump
    Which client would you like to start?

Choose option **1. none** which will allow for command line access to
the database. A MySQL service is configured on Port 10000, so open a new
Terminal window to enter commands with.

Then, import an SQL file with the following command:

    $ mysql --protocol=TCP --host=localhost --port=10000 --user=<user> --password=<pass> <name> < mydatabase.sql

See the [*tunnel*](#database-tunnel) command documentation for other
ways of accessing a MySQL database. See [*Backing up a MySQL
database*](#bestpractices-backing-up-mysql) for details on how to create
a `mysqldump` backup that can then be imported into
another database service.

### Database Version Changes[](#database-version-changes "Permalink to this headline")

The VCAP\_SERVICES environment variable in Application Lifecycle Service does not include
version numbers in the service name string. This can cause problems when
migrating applications from Cloud Foundry v1 systems which reference
versioned database names in VCAP\_SERVICES.

There are two application level fixes for this issue:

#### Method 1[](#method-1 "Permalink to this headline")

Update references to VCAP\_SERVICES in the application code to exclude
version numbers. For example:

    MySQL:         'mysql-5.x' -> 'mysql'
    PostgreSQL:    'postgresql-x.x' -> 'postgresql'
    Redis:         'redis-2.x' -> 'redis'

#### Method 2[](#method-2 "Permalink to this headline")

Update the application code to use the DATABASE\_URL environment
variable. See [*Using Database Services*](#database-accessing) for
general information and the following language-specific documentation:

-   [*Perl Data
    Services*](/als/v1/user/deploy/languages/perl/#perl-data-services)
-   [*PHP Data
    Services*](/als/v1/user/deploy/languages/php/#php-data-services)
-   [*Python Data
    Services*](/als/v1/user/deploy/languages/python/#python-data-services)

The following changes to sample applications show this modification:

-   PERL:
    <https://github.com/Stackato-Apps/bugzilla/commit/414804f3c02dab5104f048c013b8a3127e5268b2>
-   PYTHON:
    <https://github.com/Stackato-Apps/django-gtd/commit/fdc7361086c5a1f9d2b10ee5e7af918e9f60b999>
-   PHP:
    <https://github.com/Stackato-Apps/owncloud-core/commit/3bd87948f48910f27fa1e059e863bcf312cce5f3>

SQLite[](#sqlite "Permalink to this headline")
-----------------------------------------------

Applications can use an [SQLite database](http://www.sqlite.org/) as an
alternative to Application Lifecycle Service database services. However, as the filesystem of
an application container is ephemeral (i.e. it is destroyed when an
application is stopped, restarted, or updated), you should always store
the SQLite file on a [*Persistent File
System*](/als/v1/user/services/filesystem/#persistent-file-system) mount point to avoid
losing data.
---
layout: default-devplatform
permalink: /als/v1/user/services/filesystem/
product: devplatform
---
<!--PUBLISHED-->

Persistent File System[](#persistent-file-system "Permalink to this headline")
===============================================================================

The file system of application containers are ephemeral. Any application
data or files stored locally within these containers is lost when the
instance is stopped or restarted. To solve this, Application Lifecycle Service provides a filesystem type of service that can be shared between application instances,
and even between applications deployed to the same space.

A persistent file system service allows apps to do the following:

1.  Share files across multiple instances of an app
2.  Store files that persist if an app is removed (providing the service
    is not deleted) or if the server is restarted.
3.  Conserve space on filesystems allocated within the VM instance by referencing the persistent filesystem instead.

Creating A Persistent File System[](#creating-a-persistent-file-system "Permalink to this headline")
-----------------------------------------------------------------------------------------------------

A filesystem service can be configured in your *manifest.yml* file:

    services:
        mydata: filesystem

You can also use the `helion create-service`
command:

    $ helion create-service filesystem mydata
        Creating Service: OK

        $ helion services

        =========== Provisioned Services ============

        +----------------+------------+
        | Name           | Service    |
        +----------------+------------+
        | mydata         | filesystem |
        +----------------+------------+

Using A Persistent File System[](#using-a-persistent-file-system "Permalink to this headline")
-----------------------------------------------------------------------------------------------

**Note**

File system service is available during pre-staging and shouldn't need
to be reconfigured when the application starts.

The filesystem service creates a path which your app can use to store
and read files.

If there is only one filesystem service, the
`HELION_FILESYSTEM` environment variable can be
used to get the path.

If there is more than one filesystem service,
`HELION_FILESYSTEM` is not available. Instead, a
custom environment variable `HELION_FILESYSTEM_*`
will be created based on the name of each filesystem service (with
hyphens replaced by underscores).

For example, if your *manifest.yml* file configures the following
services:

    services:
        my-data: filesystem
        plugins: filesystem

Two environment variables would be created:
`HELION_FILESYSTEM_MY_DATA` and
`HELION_FILESYSTEM_PLUGINS`.

This naming scheme can be used in conjunction with the
`HELION_APP_NAME_UPCASE` environment variable. For
example, in an app with the following filesystem service defined:

    services:
      ${name}-foo: filesystem
      ${name}-bar: filesystem

The filesystem mount point for the "foo" filesystem service can be
accessed within the container using constructs such as:

    FOO=HELION_FILESYSTEM_${HELION_APP_NAME_UPCASE}_FOO
    mkdir ${!FOO}/myapp

**Note**

To use declarations like these in
[*hooks*](/als/v1/user/deploy/manifestyml/#hooks), put them in a
separate bash script. Brace expansion and grouping cannot be used
directly in YAML files.

<!-- Does this also apply for VCAP services? if so should be rewritten perhaps. 
Alternatively, `STACKAT0_SERVICES` contains
information for all services:

    {
        "plugins": {
            "dir": "/home/helion/fs/plugins"
                },
                "my-data": {
                        "dir": "/home/helion/fs/my-data"
                },
                "mydb": {
                        "name": "db76e25bc8fc142858653a6cb8c643204",
                        "hostname": "192.168.0.112",
                        "host": "192.168.0.112",
                        "port": 3306,
                        "user": "u7Fjl8hdb4iNu",
                        "username": "u7Fjl8hdb4iNu",
                        "password": "p4XQAhZr8xfHg"
                }
        }
-->
Since the [*environment
variables*](/als/v1/user/reference/environment/#environment-variables) are
available during the staging process, it is possible to make use of them
in the [*manifest.yml*](/als/v1/user/deploy/manifestyml/) file to
configure a filesystem service and create a symlink to it for use by the
app. (see example below)

Example of Using A Persistent File System[](#example-of-using-a-persistent-file-system "Permalink to this headline")
---------------------------------------------------------------------------------------------------------------------

**Note**

When linking the file system service to the application, using symlinks
is strongly recommended.

We will go through how we customized our WordPress installation to use
the persistent file system. Before you begin, find out where all the
user generated contents are saved. You may have to make modifications to
this general approach if your application stores user generated content
in more than one location. In WordPress, they are stored in wp-content
folder.

We need to add the following to our manifest.yml:

    services:
        fs-wp: filesystem
    hooks:
        post-staging:
        # create wp-content in the shared filesystem
        - mkdir -p "$HELION_FILESYSTEM"/wp-content

        # migrate existing wp-content data into the shared filesystem
        - mv wp-content/* "$HELION_FILESYSTEM"/wp-content

        # remove unused wp-content directories
        - rm -rf wp-content

        # link to wp-content folder in the shared filesystem
        - ln -s "$HELION_FILESYSTEM"/wp-content wp-content

**Note**

When moving files onto the mounted filesystem with a `mv` hook, you may see an error message similar to:

    mv: failed to preserve ownership for... Permission denied

This is a misleading warning, as the files **will** actually be moved with
the correct permissions and ownership.---
layout: default-devplatform
permalink: /als/v1/user/services/memcached/
product: devplatform
---
<!--PUBLISHED-->

Memcached Service[](#memcached-service "Permalink to this headline")
=====================================================================

Memcached is an in-memory key-value store used for caching by many web
applications and frameworks. It is available in Application Lifecycle Service as a service
which can be shared by application instances.

Using the Service[](#using-the-service "Permalink to this headline")
---------------------------------------------------------------------

As with other [*data services*](/als/v1/user/services/data-services/#data-services), the
location and port of the memcached service is exposed to the application
via environment variables: MEMCACHE\_URL or VCAP\_SERVICES.

The easiest way to connect an application to a Memcached service is to
use the MEMCACHE\_URL environment variable. It contains the location and
port of the service created for the application. For example:

    MEMCACHE_URL=10.13.0.6:11000

Using MEMCACHE\_URL will only work if `sasl_enabled`
is set to `False` in the memcached\_node
configuration (default). To enable SASL for Memcached, an Application Lifecycle Service
administrator can run the following commands on the Cloud Controller:

    $ kato config set memcached_node sasl_enabled true
    $ kato restart memcached_node

With SASL enabled, applications must parse the[*VCAP\_SERVICES*](/als/v1/user/services/data-services/#database-services-vcap-services)
environment variables to extract the `name`, `user`, and `password`
strings from the memcached `credentials` list. Using SASL with Memcached
requires client libraries/modules in the application which support
authentication via SASL.

**Warning:** Running Memcached **without** SASL enabled is insecure and should only be done if all system users are trusted. Any Application Lifecycle Service user can connect to the provisioned service instance if the IP address and port is discovered.

Django Example using Memcached[](#django-example-using-memcached "Permalink to this headline")
-----------------------------------------------------------------------------------------------

The [Django GTD](https://github.com/Stackato-Apps/django-gtd) sample
application uses the simpler VCAP\_SERVICES method for connecting to the
Memcached service without authentication.

The relevant configuration in this example:

1.  specifies the location of memcache using the MEMCACHE\_URL in
    *settings.py*:

        CACHES = {
            'default': {
            'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
            'LOCATION': os.getenv('MEMCACHE_URL'),
            }
        }

2.  adds the cache to middleware classes:

        MIDDLEWARE_CLASSES = (
            'django.middleware.cache.UpdateCacheMiddleware',
            'django.middleware.cache.FetchFromCacheMiddleware',
            ...
        )

3.  adds the python-memcached module and a memcached service in
    *manifest.yml*:

        requirements:
            pip:
            - python-memcached
            ...
        services:
            memcached-gtd: memcached
            ...
---
layout: default-devplatform
permalink: /als/v1/user/services/port-service/
product: devplatform
---
<!--PUBLISHED-->

Port Service (Harbor)[](#port-service-harbor "Permalink to this headline")
===========================================================================

HTTP and HTTPS ports and routing are provided automatically for all web
applications deployed to Application Lifecycle Service (unless [processes:
web:](/als/v1/user/deploy/manifestyml/#web) is set to
"\~").

If your application requires additional TCP or UDP ports, use the Harbor service to allocate them.

Requesting a Port[](#requesting-a-port "Permalink to this headline")
---------------------------------------------------------------------

Additional ports are provisioned like any other data service. To request
a port with the Helion command-line client:

    $ helion create-service harbor debug-port

To request a port from Harbor in the **manifest.yml** file, add it in the
[**services**](/als/v1/user/deploy/manifestyml/#services) block.
For example:

    name: port-test
    mem: 256
    services:
      my-port: harbor

This creates a TCP port tunnel which the application can access on the
host and port specified in the \$HELION\_SERVICES environment
variable.

The example above might create the following "my-port" object in
\$HELION\_SERVICES:

    {
      "my-port": {
        "hostname": "192.168.68.111",
        "host": "192.168.68.111",
        "port": 30134,
        "name": "cf7f868a-8b7b-4ac8-ab4d-9fd87efb7c09",
        "node_id": "harbor_node_1",
        "int_port": 4100,
        "ext_hostname": "ports.example.com",
        "ext_host": "15.185.104.122"
      }
    }

This provides the following information:

-   **hostname**: The internal hostname (if configured) of the node
    providing the service (i.e. the Harbor node). If none is configured
    by the admin, this will show the internal IP address.
-   **host**: The internal IP address of the Harbor node.
-   **port**: The external port number exposed by the service.
    Connections from external clients and other internal applications
    (those not directly bound to the service) will connect with this
    port number.
-   **name**: The service instance ID (Application Lifecycle Service internal refer).
-   **node\_id**: The Harbor node ID (Application Lifecycle Service internal).
-   **int\_port**: The port on the application container which forwards
    to Harbor (see also [Harbor Environment
    Variables](#port-service-env-vars)). Application(s) bound to the
    service should connect to this port.

Access to the port from outside of the Application Lifecycle Service system/cluster may or
may not be exposed, depending on how the Harbor service is configured by
the Admin. If Harbor is set up to allow public port access, the
following two settings will also be shown:

-   **ext\_hostname**: The public hostname (if configured) exposing the
    port.
-   **ext\_host**: The public IP address exposing the port.

**Note**

To remotely check the settings and credentials of any Application Lifecycle Service service,
use the [**helion
service**](/als/v1/user/reference/client-ref/#command-services) command.

### Harbor Environment Variables[](#harbor-environment-variables "Permalink to this headline")

If there is only one Harbor service, the **HELION_HARBOR** environment variable can be used to get the internal port
number.

If there is more than one Harbor service, **HELION_HARBOR** is not available. Instead, a custom
**HELION\_HARBOR\_<SERVICE\_NAME>** environment
variable will be created for each harbor service (service name
upper-cased with hyphens replaced by underscores).

For example, if your *manifest.yml* file configures the following
services:

    services:
      udp-port: harbor
      tcp-port: harbor

Two environment variables would be created:
`HELION_HARBOR_UDP_PORT` and
`HELION_HARBOR_TCP_PORT`.

This naming scheme can be used in conjunction with the
**HELION\_APP\_NAME\_UPCASE** environment variable. For
example, in an app with the following harbor services defined:

    services:
      udp-${name}: harbor
      tcp-${name}: harbor

The Harbor port number for the UDP service could be accessed within the
container with a construct such as:

    UDP_SERVICE_NAME=HELION_HARBOR_UDP_${HELION_APP_NAME_UPCASE}
    UDP_SERVICE_PORT=${!UDP_SERVICE_NAME}

**Note**

To use declarations like these in
[*hooks*](/als/v1/user/deploy/manifestyml/#hooks), put them in a
separate bash script. Brace expansion and grouping cannot be used directly in YAML files.

Setting the Port Protocols[](#setting-the-port-protocols "Permalink to this headline")
---------------------------------------------------------------------------------------

Harbor supports both the TCP and UDP protocols. When you provision a service with Harbor it will create a TCP enabled port by default. If you want to have a UDP port provisioned instead, you simply prefix your
service name with udp, for example:

    $ helion create-service harbor udp-debug-port

If you have an application that requires both TCP & UDP, you can prefix
your service name with both, for example:

    $ helion create-service harbor both-debug-port

Harbor will then create UDP and TCP proxies for your application, so
applications like DNS can use both protocols on the same provisioned
port.

Multiple Application Instances[](#multiple-application-instances "Permalink to this headline")
-----------------------------------------------------------------------------------------------

Harbor recognizes when you have multiple instances of your app running,
and will update the available app backends accordingly.

-   For TCP connections it will round-robin between your available
    backends on each new connection, in a similar fashion to the router
    component.
-   For UDP this is not the case, as it is a stateless protocol. For
    multiple UDP backends harbor will use a FIFO queue, that is the
    first app instance available becomes the primary backend, and any
    added later are queued.

HTTPS via Harbor[](#https-via-harbor "Permalink to this headline")
-------------------------------------------------------------------

SSL termination of HTTPS to applications hosted on Application Lifecycle Service normally
happens at the Router.

There is currently no mechanism for users to add SSL certificates for their own applications to the Router, but you can expose an external HTTPS interface via the Harbor port service which uses your SSL certificates.

To do this, upload the SSL certificate(s) and key(s) along with your application, and expose your application server directly on the TCP port provided by Harbor.

For example, an application running through the port service might have a URL such as: *https://harbor-node.helion.com:35048/*

You can set up aliases to this URL using DNS, but the explicit port
specification must always be added.

**Notes:** 


- When using this approach, the hostname / IP address of the app will be the one provided by the Harbor node the client will connect using the Harbor-assigned port number, **not** 443.
- Using Harbor in this way does **not** take advantage of any load balancing set up for regular web traffic through the Routers and Load Balancer.
- If you have multiple instances of your app routing through a Harbor TCP port, connections will be distributed via round-robin.

### HTTPS Container Proxy[](#https-container-proxy "Permalink to this headline")

If you are using a framework such as Python or Perl which sets up uWSGI
(or any other framework that provides its own intermediate web server)
Harbor can provision an HTTPS server in the app container that forwards
HTTPS requests to the framework's HTTP server. To do this, add the
suffix **https** to the name of your Harbor service. For example:

    name: harbor-test-app

    services:
      custom-cert-https: harbor

Put your server certificate and key (named *harbor.crt* and *harbor.key*
respectively) in a folder called *certs* in the application's root
directory. For example:

    app_root
    	certs
        harbor.crt
        harbor.key
    	...

Alternatively, use a standalone or buildpack setup which provisions its
own intermediate web server instead.

### Multiple SSL Certificates[](#multiple-ssl-certificates "Permalink to this headline")

If your application uses multiple SSL certificates, use the following
naming scheme:

-   *harbor service name*.key
-   *harbor service name*.crt

For example:

    app_root
    	certs
        	harbor-https-custom-1.crt
        	harbor-https-custom-2.key
    	...

The proxy will look for these certs before reverting to `harbor.crt` and `harbor.key`.


---
layout: default-devplatform
permalink: /als/v1/user/services/user-provided/
product: devplatform
---
<!--PUBLISHED-->

User-Provided Services[](#user-provided-services "Permalink to this headline")
===============================================================================

User-provided service instances allow you connect applications running
on Application Lifecycle Service to specified external data services, without hard coding the
credentials into the application. The service instance provides the
connection information to the application via the VCAP\_SERVICES environment variables, just like the [*built-in data
services*](/als/v1/user/services/data-services/#data-services).

Think of user-provided services as a credentials database for your
Application Lifecycle Service application space. You provide the connection information,
Application Lifecycle Service stores it in a [*JSON object*](#user-provided-using) which can
be bound any applications in the space.

Creating[](#creating "Permalink to this headline")
---------------------------------------------------

User-provided service instances will typically be used to connect
applications hosted on Application Lifecycle Service to existing external database hosts or
clusters. For example, to connect an app to a PostgreSQL database hosted
outside of Application Lifecycle Service:

    $ helion create-service user-provided prod-db-int
    Which credentials to use for connections [hostname, port, password]: host, port, database, user, pass
    host: dbhost1.example.com
    port: 5432
    database: prod-django-321
    user: ro-web
    pass: vsTLP2gs
    Creating new service ... OK

The parameter names provided in the first step will become the keys in
the JSON object exposed to the application later.

Binding[](#binding "Permalink to this headline")
-------------------------------------------------

Once the service instance has been created it can be bound to
applications, just like any other service:

    $ helion bind-service prod-db-int django-cms
    Binding prod-db-int to scaling-demo ...
    Stopping Application [django-cms] ... OK
    Starting Application [django-cms] ...
    OK
    http://django-cms.helion.example.com/ deployed

Using[](#using "Permalink to this headline")
---------------------------------------------

The `helion service` command will show the
credentials:

    $ helion service prod-db-int

    prod-db-int
    +--------------+------------------------------+
    | What         | Value                        |
    +--------------+------------------------------+
    | Type         | user-provided                |
    | Space        | example::example-dev         |
    |              |                              |
    | Credentials  |                              |
    | - database   | prod-django-321              |
    | - host       | dbhost1.example.com          |
    | - pass       | vsTLP2gs                     |
    | - port       | 5432                         |
    | - user       | ro-web                       |
    |              |                              |
    | Applications | django-cms                   |
    +--------------+------------------------------+

The [*VCAP\_SERVICES*](/als/v1/user/services/data-services/#database-services-vcap-services)
variables will expose the connection information within the application
container. The parameter names you provided when setting up the service
instance become the keys in the `prod-db-int` JSON
object:

    django-cms$ echo VCAP_SERVICES |json
    {
      "prod-db-int": {
        "database": "prod-django-321",
        "host": "dbhost1.example.com",
        "pass": "vsTLP2gs",
        "port": "5432",
        "user": "ro-web"
      }
    }

To have your application use this information, parse the variable in
your application code to extract the credentials at runtime. See the
[*Language Specific
Deployment*](/als/v1/user/deploy/#language-specific-deploy) section for
examples.

Frameworks or buildpacks that autoconfigure bound services will do so
automatically, as they would for system-provided data services.
---
layout: default-devplatform
title: "HP Helion Development Platform Java Database Sample"
permalink: /helion/devplatform/workbook/database/java/
product: devplatform

---
<!--PUBLISHED-->


#Java MySQL Database Sample
This very simple Servlet-based Java webapp displays the text "Executed query "SELECT "Hello World!"".", and then the result of that query: "Hello World". This is a demonstration of the minimum requirements to build an application that can connect to a MySQL database provided by ALS and run queries against it. Use this sample to ensure that you have set up your environment for connecting to and working with MySQL on the Helion Development Platform. 

##Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

###MySQL

If the MySQL service is not enabled on your cluster, or if you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. <br>For example: *https://api.xx.xx.xx.xx.xip.io*, substitute your own cluster's link.
2. On the **Admin** tab, click **Cluster**.
3. Click the **Settings** icon (a gear icon in the upper right corner)
4. The **MySQL** check box should be checked. If it is not, check it.
5. Click **Save**.

**NOTE**: If a more durable or scalable MySQL database service is needed, ensure your ALS cluster is configured to use a database instance or master/slave pair provided by the Database Service. For more information, refer to [Creating a Database Instance in the Database Service](/helion/devplatform/createdatabase/) and [Connecting the Database Service with ALS](/helion/devplatform/connectdatabase/).

###JDK

In order to install other prerequisites like Maven you have to have the Java Development Kit (JDK) installed.  The JDK can be installedwith he following command on a Mac/UNIX environment.

    sudo apt-get install default-jdk

The simplest way to install JDK on a PC environment is to visit the [JDK installation page](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html), select and run the appropriate installer for your chosen platform.


###Maven

[Maven](http://maven.apache.org/ "Maven") must be installed. 
The simplest way to install Maven on a Mac/UNIX environment is:

	sudo apt-get install maven 

The simplest way to install Maven on a PC environment is to [download the latest version of Maven](http://maven.apache.org/download.cgi) and then follow the [installation directions](http://maven.apache.org/guides/getting-started/windows-prerequisites.html).

##Download the Application Files
[Click here to access the download directory](https://github.com/HelionDevPlatform/helion-mysql-java). 


##Build the Application

If you are not already there, *cd* into this app's root directory and execute:

	mvn clean package

This builds the application with Maven. It will create the *mysql-java-1.0.war* file within the target directory.


##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages. 

Use the Helion client to deploy your app to Helion Development Platform.  If you are using Eclipse, you can optionally use the [plugin](/helion/devplatform/eclipse/) to deploy.

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
	
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute
	
		helion push
	
6.	Accept any default values that you may be prompted for.
	<br>	**Note**: By default, ALS clusters are configured with two domains (private and public). In some situations the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets

This first line in this section of the MysqlServlet.java file shows how to retrieve the connection information for the MySQL instance from the application's environment variables. The connection information is represented using JSON. 

The rest of the code shown here parses the JSON string that was retrieved and builds the appropriate JDBC connection string.

	String vcap_services = System.getenv("VCAP_SERVICES");
	
	        Connection dbConnection = null;
	
	        if (vcap_services != null && vcap_services.length() > 0) {
	            try {
	                // Use a JSON parser to get the info we need from  the
	                // VCAP_SERVICES environment variable. This variable contains
	                // credentials for all services bound to the application.
	                // In this case, MySQL is the only bound service.
	                JsonRootNode root = new JdomParser().parse(vcap_services);
	
	                JsonNode mysqlNode = root.getNode("mysql");
	                JsonNode credentials = mysqlNode.getNode(0).getNode("credentials");
	
	                // Grab login info for MySQL from the credentials node
	                String dbname = credentials.getStringValue("name");
	                String hostname = credentials.getStringValue("hostname");
	                String user = credentials.getStringValue("user");
	                String password = credentials.getStringValue("password");
	                String port = credentials.getNumberValue("port");
	
	                String dbUrl = "jdbc:mysql://" + hostname + ":" + port + "/" + dbname;
	
	                // Connect to MySQL
	                writer.println("Connecting to MySQL...");
	
	                Class.forName("com.mysql.jdbc.Driver");
	                dbConnection = DriverManager.getConnection(dbUrl, user, password);
	            } catch (Exception e) {
	                System.out.println("Caught error: ");
	                e.printStackTrace();
	            }
	        }

The *manifest.yml* file contains configuration information used by ALS to set up the environment. The **services** element informs ALS how to bind to the MySQL service provided by the ALS cluster to the application.	
	
	---
	applications: 
	- name: mysql-java
	  mem: 512M
	  path: target/mysql-java-1.0
	  services:
	    ${name}-db:
	      type: mysql



##Run the Application
1.	Open the Helion Management Console. <br> The Management Console is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2.	Click **Applications**.
3.	If the file push was successful, you should see **mysql-java** in the list of available applications.
4.	The status of the application should be **Started**.  Click the name of the application to launch it.
5.	In the upper right-hand corner, click **View App**.

##Key Learnings
1.	You need to provide configuration information so that ALS can bind to a MySQL service. Configuration information is contained in the *manifest.yml* file.
2.	You need to retrieve connection information for MySQL from the application's environment variables and then parse the information into a JDBC-compliant connection string.
3.	You interact with and deploy your app using the Helion CLI or the Eclipse [plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/helloworld/java/) | [Next Sample](/helion/devplatform/workbook/messaging/java/)---
layout: default-devplatform
title: "HP Helion Development Platform Node Database Sample"
permalink: /helion/devplatform/workbook/database/node/
product: devplatform

---
<!--PUBLISHED-->

# Node MySQL Database Sample

This very simple Node.js app displays the text "Executed query "SELECT "Hello World!"".", and then the result of that query: "Hello World". This is a demonstration of the minimum requirements to build an application that can connect to a MySQL database provided by ALS and run queries against it. Use this sample to ensure that you have set up your environment for connecting to and working with MySQL on the Helion Development Platform. 

## Prerequisites
If you are missing any of these items, you will need to [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

###MySQL

If the MySQL service is not enabled on your cluster, or if you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. <br>For example: *https://api.xx.xx.xx.xx.xip.io*, substitute your own cluster's link.
2. On the **Admin** tab, click **Cluster**.
3. Click the **Settings** icon (a gear icon in the upper right corner)
4. The **MySQL** check box should be checked. If it is not, check it.
5. Click **Save**.

**Note**: If a more durable or scalable MySQL database service is needed, configure your ALS cluster to use a database instance or master/slave pair provided by the Database Service. For more information, refer to [Creating a Database Instance in the Database Service](/helion/devplatform/createdatabase/) and [Connecting the Database Service with ALS](/helion/devplatform/connectdatabase/). 

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-mysql-node/)

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages.

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
	 
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute
	
		helion push
	
6.	Accept any default values that you may be prompted for.
	<br>	**Note**: By default ALS clusters are configured with two domains (private and public). In some situations the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets
The first line in this section of the Server.js file shows how to retrieve the connection information for the MySQL instance from the application's environment variables. The connection information is represented using JSON. The rest of the code shown here parses the JSON string that was retrieved, connects to the database, execute a query, and prints the response.

	var services = process.env.VCAP_SERVICES;

  	// Parse the JSON so that we can extract the individual components needed for
 	 // using MySQL
	  services = JSON.parse(services);
	
	  // Since there's only one service, we grab the only node which is for MySQL.
	  var credentials = services.mysql[0].credentials;
	
	  // The credentials node has a lot of fields, but we are only concerned with
	  // the ones below for this MySQL sample.
	  var dbname = credentials.name;
	  var hostname = credentials.hostname;
	  var user = credentials.user;
	  var password = credentials.password;
	  var port = credentials.port;
	
	  response.write("\n Connecting to MySQL...");
	
	  // Create a connection to MySQL
	  var connection = mysql.createConnection({
	    database : dbname,
	    host : hostname,
	    port : port,
	    user : user,
	    password : password
	  });
	
	  connection.connect();
	
	  response.write("\n Connected to MySQL!");
	
	  // Create a query to be executed against a MySQL database.
	  var queryResult = '';
	  connection.query('SELECT \"Hello World\" AS result', function(err, rows, fields) {
	    if (err) {
	      throw err;
	    }
	
	    queryResult = rows[0].result;
	
	    response.write("\n Executed \'SELECT \"Hello World\" AS result\' ");
	    response.write("\n Result =  " + queryResult);
	
	    // Close the connection
	    connection.end(function(err){
	      console.log("\n Closing the MySQL connection");
	   });
	      }

The *manifest.yml* file is the configuration information used by ALS to set up the environment. The **services** element instructs ALS how to bind to the MySQL service provided by the ALS cluster to the application.

	---
	applications:
	- name: mysql-node
	  mem: 128M
	  services:
	    ${name}-db:
	      type: mysql

##Run the Application
1.	Open the Helion Management Console. <br> The Management Console is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2.	Click **Applications**.
3.	If the file push was successful, you should see **mysql-node** in the list of available applications.
4.	The status of the application should be **Started**. Click the name of the application to launch it. 
5. In the upper right-hand corner, click **View App**.


##Key Learnings
1.	You need to provide configuration information so that ALS can bind to a MySQL service. Configuration information is contained in the *manifest.yml* file.
2.	You need to retrieve connection information for MySQL from the application's environment variables, and parse the information into a JDBC compliant connection string.
3.	You interact with and deploy your app using the Helion CLI or the Eclipse [plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/helloworld/node/) | [Next Sample](/helion/devplatform/workbook/messaging/node/)---
layout: default-devplatform
title: "HP Helion Development Platform PHP Database Sample"
permalink: /helion/devplatform/workbook/database/php/
product: devplatform

---
<!--PUBLISHED-->
#PHP MySQL Database Sample
This very simple PHP web app displays the text "Executed query "SELECT "Hello World!"".", and then the result of that query "Hello World!" This is a demonstration of the minimum requirements to build an application that can connect to a MySQL database provided by ALS and run queries against it. Use this sample to ensure that you have set up your environment for connecting to and working with MySQL on the Helion Development Platform. 
 

## Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

###MySQL

If the MySQL service is not enabled on your cluster, or if you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. <br>For example: *https://api.xx.xx.xx.xx.xip.io*, substitute your own cluster's link.
2. On the **Admin** tab, click **Cluster**.
3. Click the **Settings** icon (a gear icon in the upper right corner)
4. The **MySQL** check box should be checked. If it is not, check it.
5. Click **Save**.

**Note**: If a more durable or scalable MySQL database service is needed, configure your ALS cluster to use a database instance or master/slave pair provided by the Database Service. For more information, refer to [Creating a Database Instance in the Database Service](/helion/devplatform/createdatabase/) and [Connecting the Database Service with ALS](/helion/devplatform/connectdatabase/). 

##Download the Application Files
[Click here to access the download directory](https://github.com/HelionDevPlatform/helion-mysql-php/).

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages. 

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
	
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute 
	
		helion push
	
6.	Accept any default values that you may be prompted for.
	<br>	**Note**: By default ALS clusters are configured with two domains (private and public). In some situations the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets
This first line in this section of the index.php file shows how to retrieve the connection information for the MySQL instance from the application's environment variables. The connection information is represented using JSON. 

The rest of the code shown here parses the JSON string that was retrieved and builds the appropriate connection string. Once the connection has been made, the code executes a query, reads the results, and closes the connection. 


	$services = getenv('VCAP_SERVICES');

	$json = json_decode($services, TRUE);

	// Parse the json string that we got from VCAP_SERVICES
	// The only top-level node will be mysql since it's the only service bound to
	// this sample app.
	// Note that some of the fields are optional but are included for reference
	$dbname = $json['mysql'][0]['credentials']['name'];
	$hostname = $json['mysql'][0]['credentials']['hostname'];
	$user = $json['mysql'][0]['credentials']['user'];
	$password = $json['mysql'][0]['credentials']['password'];
	$port = $json['mysql'][0]['credentials']['port'];

	// Create a connection to MySQL
	echo "\n <br> Connecting to MySQL...";
	$connection = mysqli_connect($hostname, $user, $password, $dbname, $port);
		
	// Check connection 
	if (mysqli_connect_errno()) { 
	echo "\n <br> Failed to connect to MySQL: " . mysqli_connect_error(); 
	echo "\n <br>Connected to MySQL!"; } 
	
	// Execute a simple query to grab a string 
		$queryString = "SELECT \"Hello World!\" AS result"; 
		$result = mysqli_query($connection, $queryString); 
		echo "\n <br> Executed $queryString"; 
	
	// Get the result 
	$row = mysqli_fetch_assoc($result); 
	echo "\n <br> Result: " . $row['result']; 
	echo "\n <br> Error: Result of query is NULL!"; 

	// Free up the memory that was allocated to the result 
	mysqli_free_result($result); 
	
	// Finally, close the MySQL connection. 
	mysqli_close($con); 

The *manifest.yml* file contains the configuration information used by ALS to set up the environment. The **services** element informs ALS on how to bind to the MySQL service provided by the ALS cluster to the application. The file also uses the **buildpack** element that is used by ALS to configure the application environment for using PHP.

	--- 
	applications: 
		- name: mysql-php
		buildpack: https://github.com/cloudfoundry/php-buildpack.git 
		services: 
			${name}-db: 
				type: mysql 

##Run the Application
1. Open the Helion Management Console. This is the web-based administrative interface. 
2. Click **Applications**. 
3.	If the file push was successful, you should see **mysql-php** in the list of available applications.
4.	The status of the application should be **Started**. Click the name of the application to launch it. 
5. In the upper right-hand corner, click **View App**. 

##Key Learnings
1. ALS requires configuration information so that it can bind to a MySQL service. Configuration information is contained in the *manifest.yml* file.
1. You will need to provide information about which build pack to use for PHP so that ALS can create an environment for your app. Configuration information is contained in the *manifest.yml* file.
1. You will need to retrieve connection information for MySQL from the application's environment variables and then parse that information into a connection string that can be used by PHP.
1. You interact with and deploy your app using the Helion CLI or the Eclipse [plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/helloworld/php/) | [Next Sample](/helion/devplatform/workbook/messaging/php/)---
layout: default-devplatform
title: "HP Helion Development Platform Java Hello World Sample"
permalink: /helion/devplatform/workbook/helloworld/java/
product: devplatform

---
<!--PUBLISHED-->
##Java Hello World Sample
This Servlet-based Java web app displays the text "Hello World!". This is a demonstration of the minimum requirements to build a functional application. Use this sample to ensure that you have set up your environment for deployment to Helion Development Platform.

##Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

###JDK
You must have the Java Development Kit (JDK) installed before you can install the other prerequisites.

On a Mac/UNIX environment, the JDK can be installed with the following command:

    sudo apt-get install default-jdk


On a PC environment, the simplest way to install the JDK is to visit the [JDK installation page](http://www.oracle.com/technetwork/java/javase/downloads/index.html) and run the appropriate installer for your chosen platform.

###Maven 
[Maven](http://maven.apache.org/ "Maven") must be installed. 
The simplest way to install Maven on a Mac/UNIX environment is:

	sudo apt-get install maven 

The simplest way to install Maven on a PC environment is to [download the latest version of Maven](http://maven.apache.org/download.cgi) and then follow the [installation directions](http://maven.apache.org/guides/getting-started/windows-prerequisites.html).

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-hello-world-java) 
 
##Build the Application
In the root directory of the sample package, execute the following command:

	mvn clean package

This builds the application with Maven. It will create the *hello-world-java-1.0.war* file within the target directory. 

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages.

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to [use the plugin](/helion/devplatform/eclipse/) to deploy.

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
		
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Deploy the application by using the command: 
	
		helion push
	
6.	Accept any default values that you may be prompted for. <br>**Note**: By default ALS clusters are configured with two domains (private and public). In some situations the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets

This simple Servlet prints "Hello World".

    package org.hp.samples;
	
	import java.io.IOException;
	import java.io.PrintWriter;
	
	import javax.servlet.ServletException;
	import javax.servlet.http.HttpServlet;
	import javax.servlet.http.HttpServletRequest;
	import javax.servlet.http.HttpServletResponse;
	
	public class HelloServlet extends HttpServlet {
	
		private static final long serialVersionUID = 1L;
	
		protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
			response.setContentType("text/plain");
			response.setStatus(200);
			PrintWriter writer = response.getWriter();
			writer.println("Hello World");
			writer.close();
		}
	}

The *POM.xml* file contains the configuration information generated by Maven and used by ALS to set up the environment.

	<?xml version="1.0" encoding="UTF-8"?>
	<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	        xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	    <modelVersion>4.0.0</modelVersion>
	    <groupId>org.hp.samples</groupId>
	    <artifactId>hello-world-java</artifactId>
	    <version>1.0</version>
	    <packaging>war</packaging>
	    <dependencies>
	        <dependency>
	            <groupId>javax.servlet</groupId>
	            <artifactId>servlet-api</artifactId>
	            <version>2.5</version>
	            <scope>provided</scope>
	        </dependency>
	    </dependencies>
	</project>

## Run the Application

1. Open the Helion Management Console. This is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2. Click **Applications**.
3. If the file push was successful, you should see **hello-world-java** in the list of available applications.
4. The status of the application should be **Started**. Click the name of the application to launch it.
5. In the upper right-hand corner, click **View App**.
6. You should see a simple text message: **Hello World!** 

##Key Learnings
1.	ALS requires configuration information to create an environment for your app. Configuration information is contained in the *pom.xml* file. Tools like Maven can generate this configuration file for you.
2.	You can deploy your app using either the Helion CLI or the [Eclipse plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/messaging/java/) | [Next Sample](/helion/devplatform/workbook/database/java/)---
layout: default-devplatform
title: "HP Helion Development Platform Node Hello World Sample"
permalink: /helion/devplatform/workbook/helloworld/node/
product: devplatform

---
<!--PUBLISHED-->
#Node Hello World Sample

This very simple Node.js web app displays the text "Hello World!". This sample is a demonstration of the minimum requirements to build a functional application. Use this sample to ensure that you have set up your environment for deployment to Helion Development Platform.

##Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-hello-world-node)

###About the Application Files
To create a CloudFoundry&trade; app in Node.js, the only mandatory files are:

* The main .js file
* manifest.yml
* package.json
* Procfile 

*Manifest.yml* is a configuration file used to specify settings that would otherwise be specified by a command-line tool. 

The *package.json* file is your standard metadata file. **Name** and **version** are the only required fields. 

The *Procfile* tells the Helion Development Platform how to run your Node.js application. An extremely simple one is included with this sample.

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages.

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
	
4.	If you are not already there, `cd` to the root directory of the sample.

5.	Deploy the application by using the command: 

		helion push 



1. Accept any default values that you may be prompted for. <br>**Note**: By default, ALS Clusters are configured with two domains (private and public).  In some situations, the Helion CLI may prompt you to select a target domain.  If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets

This simple Servlet prints "Hello World".

	// Load the http module 
	var http = require('http');
	
	// The  HTTP server will respond with Hello World to all requests.
	var server = http.createServer(function (request, response) {
	  response.writeHead(200, {"Content-Type": "text/plain"});
	  response.end("\n Hello World \n");
	});
	
	// Listen to the port being used by this app. The call to process.env.PORT will
	// return the port that has been assigned to the app from the Helion Development
	// Platform.
	var port = process.env.PORT || 8888;
	server.listen(port);
	
	// Print to the terminal
	console.log("Server listening to port: " + port);

The *package.json* file is used by ALS during deployment. This is an extremely basic manifest file. 
Note that **name** is always required while other fields are optional.

		{
		  "name": "hello-world-node",
		  "version": "1.0.0",
		  "description" : "A 'Hello World' app demonstrating Node.js running on the Helion Development Platform.",
		  "repository" : {"type": "git", "url": "git://notyetpublished"}
		}

 
##Run the Application
1.	Open the Helion Management Console. <br> The Management Console is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2.	Click **Applications**.
3.	If the file push was successful, you should see **hello-world-node** in the list of available applications.
4.	The status of the application should be **Started**.  Click the name of the application to launch it.
5.	In the upper right-hand corner, click **View App**.
6.	You should see a simple text message: **Hello World**

##Key Learnings

- You can deploy your app using either the Helion CLI or the Eclipse [plugin](/helion/devplatform/eclipse/).

- ALS requires configuration information to create an environment for your app. Configuration information is contained in the *manifest.yml* file.

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/messaging/node/) | [Next Sample](/helion/devplatform/workbook/database/node/)---
layout: default-devplatform
title: "HP Helion Development Platform PHP Hello World Sample"
permalink: /helion/devplatform/workbook/helloworld/php/
product: devplatform

---
<!--PUBLISHED-->
#PHP Hello World Sample

This very simple PHP web app displays the text "Hello World!". This is a demonstration of the minimum requirements to build a functional application. Use this sample to ensure that you have set up your environment for deployment to Helion Development Platform.

##Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-hello-world-php)

### About the Application Files
To create a CloudFoundry&trade; app in PHP, the only mandatory files are the *index.php* and *manifest.yml* files. 

*Manifest.yml* is a configuration file used to specify settings that would otherwise be specified by a command-line tool. For PHP, only the **name** and **buildpack** fields are required. The **buildpack** field is a URL for the buildpack that supports the necessary language and/or framework.

The *composer.json* file is completely optional; however, certain buildpacks may issue a warning if the file is not present.

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages. 

The Helion client to deploy your app to Helion Development Platform.  If you are using Eclipse, you can optionally [use the plugin](/helion/devplatform/eclipse/) to deploy.

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
	
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute 
	
		helion push 


1. Accept any default values that you may be prompted for. <br>**Note**: By default, ALS Clusters are configured with two domains (private and public).  In some situations, the Helion CLI may prompt you to select a target domain.  If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)


##Key Code Snippets
This simple PHP script prints "Hello World".
	
	package org.hp.samples;
	<?php
	
	echo "\n Hello World \n";
	
	?>

The *manifest.yml* file is the configuration information used by ALS to set up the environment. The **buildpack** element here informs ALS on the correct buildpack to use for PHP, which ensures the correct tools and runtimes are installed in the application environment.

	---
	applications:
	- name: hello-world-php  
	  buildpack: https://github.com/cloudfoundry/php-buildpack.git

##Run the Application
1.	Open the Helion Management Console. <br> The Management Console is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2.	Click **Applications**.
3.	If the file push was successful, you should see **hello-world-php** in the list of available applications.
4.	The status of the application should be **Started**. click the name of the application to launch it.
5.	In the upper right-hand corner, click **View App**.
6.	You should see a simple text message: **Hello World!**

##Key Learnings
1. ALS requires configuration information to create an environment for your app, including buildpack information for PHP. Configuration information is contained in the *manifest.yml* file.
2. You can deploy your app using either the Helion CLI or the Eclipse [plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/messaging/php/) | [Next Sample](/helion/devplatform/workbook/database/php/)---
layout: default-devplatform
title: "HP Helion Development Platform Java Messaging Sample"
permalink: /helion/devplatform/workbook/messaging/java/
product: devplatform

---
<!--PUBLISHED-->
#Java RabbitMQ Messaging Sample
This very simple Servlet-based Java web app displays a simple form that takes a string from the user, adds the message to a queue, reads it from the queue and prints the message back to the screen. This is a demonstration of the minimum requirements to build an application that can connect to a RabbitMQ cluster provided by ALS and interact with it. Use this sample to ensure that you have set up your environment correctly for connecting to and working with RabbitMQ on the Helion Development Platform.

## Prerequisites
If you are missing any of these items, please [install them](/helion/devplatform/appdev/).

1.	You must have access to an [ALS cluster](/als/v1/admin/cluster/).
2.	The [Helion command-line interface](/als/v1/user/client/) (CLI) must be installed.
3.	You must have access to the web-based [Helion Management console](/als/v1/user/console/).

##RabbitMQ

If the RabbitMQ service is not enabled on your cluster, or if you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. (e.g. *https://api.xx.xx.xx.xx.xip.io*);  substitute your own cluster's link)
1. On the **Admin** tab, click **Cluster**.
1. Click the **Settings** icon (a gear icon in the upper right corner)
1. Both of the **Rabbit** and **Rabbit3** check boxes should be checked. If they are not, check them.
1. Click **Save**.

**Note**: If an application needs increased message throughput and/or increased availability beyond the single-instance, unmanaged RabbitMQ service provided by ALS, please follow [these instructions](/helion/devplatform/messageservice) to create and manage a RabbitMQ cluster in the Messaging Service and link that instance to your ALS cluster.

###JDK
In order to install other perquisites such as Maven you have to have the Java Development Kit (JDK) installed. The JDK can be installed with the following command in a Mac/UNIX environment:

    sudo apt-get install default-jdk


The simplest way to install the JDK in a PC environment is to visit the [JDK installation page](http://www.oracle.com/technetwork/java/javase/downloads/index.html) and run the appropriate installer for your chosen platform.


###Maven

[Maven](http://maven.apache.org/ "Maven") must be installed. 
The simplest way to install Maven in a Mac/UNIX environment is:

	sudo apt-get install maven 

The simplest way to install Maven in a PC environment is to [download the latest version of Maven](http://maven.apache.org/download.cgi) and then follow the [installation directions](http://maven.apache.org/guides/getting-started/windows-prerequisites.html).

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-rabbitmq-java)

##Build the Application
If you are not already there, `cd` to the root directory of the sample and execute:

	mvn clean package

This builds the application with Maven. It will create the *rabbitmq-java-1.0.war* file  within the target directory. 

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages.

Use the Helion client to deploy your app to Helion Development Platform. If you are using Eclipse, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
		
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute
	
		helion push
	
6.	Accept any default values that you may be prompted for. <br>**Note**: By default, ALS clusters are configured with two domains (private and public). In some situations, the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *&lt;app-name&gt;.xxx.xxx.xxx.xxx.xip.io*)


##Key Code Snippets
This first Line in this section of the RabbitServlet.java file shows how to retrieve the connection information for the RabbitMQ cluster from the application's environment variables. The rest of the code makes a connection to the cluster, creates a channel, and defines a message queue called **hello**.

	String uri = System.getenv("RABBITMQ_URL");

        ConnectionFactory factory = new ConnectionFactory();
        try {
            factory.setUri(uri);
        } catch (KeyManagementException e) {
            e.printStackTrace();
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (URISyntaxException e) {
            e.printStackTrace();
        }
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();

        channel.queueDeclare("hello", false, false, false, null);

        writer.close();

This section of the ProcessMessage.java file shows how to publish to a message queue, retrieve the published message, convert the message from a byte array to a string, and print it out to the user.

	String routingKey = "thekey";
        String exchangeName = "exchange";

        // Declare an exchange and bind it to the queue
        channel.exchangeDeclare(exchangeName, "direct", true);
        channel.queueBind("hello", exchangeName, routingKey);

        // Grab the message from the HTML form and publish it to the queue
        String message = request.getParameter("message");
        channel.basicPublish(exchangeName, routingKey, null, message.getBytes());
        writer.println(" Message sent to queue '" + message + "'");

        boolean autoAck = false;

	GetResponse responseMsg = channel.basicGet("hello", autoAck);

        if (responseMsg == null) {
            // No message retrieved.
        } else {
            byte[] body = responseMsg.getBody();
            // Since getBody() returns a byte array, convert to a string for
            // the user.
            String bodyString = new String(body);
            long deliveryTag = responseMsg.getEnvelope().getDeliveryTag();

            writer.println("Message received: " + bodyString);

            // Acknowledge that we received the message so that the queue
            // removes the message so that it's not sent to us again.
            channel.basicAck(deliveryTag, false);
        }

The *POM.xml* file is the configuration information generated by Maven and used by ALS to set up the environment. You can see that it has added a dependency for the **amqp-client**.
	
	<?xml version="1.0" encoding="UTF-8"?>
	<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	        xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	    <modelVersion>4.0.0</modelVersion>
	    <groupId>org.hp.samples</groupId>
	    <artifactId>rabbitmq-java</artifactId>
	    <version>1.0</version>
	    <packaging>war</packaging>
	    <dependencies>
	        <dependency>
	            <groupId>javax.servlet</groupId>
	            <artifactId>servlet-api</artifactId>
	            <version>2.5</version>
	            <scope>provided</scope>
	        </dependency>
	        <dependency>
	  			<groupId>com.rabbitmq</groupId>
	  			<artifactId>amqp-client</artifactId>
	  			<version>2.8.1</version>
			</dependency>
	    </dependencies>
	</project>

The *manifest.yml* file is the configuration information used by ALS to set up the environment. The **services** element informs ALS on how to bind the RabbitMQ service provided by the ALS cluster to the application.

	---
	applications: 
	- name: rabbitmq-java
	  mem: 512M
	  path: target/rabbitmq-java-1.0
	  services:
	    rabbitmq:
	      type: rabbitmq3

##Run the Application
1.	Open the Helion Management Console. <br> The Management Console is the web-based administrative interface that can be reached by typing the ALS endpoint URL into a browser window.
2.	Click **Applications**.
3.	If the file push was successful, you should see **rabbitmq-java** in the list of available applications.
4.	The status of the application should be **Started**. Click the name of the application to launch it.
5.	In the upper right-hand corner, click **View App**.

	

##Key Learnings
1.	You will need to provide configuration information so that ALS can bind to a RabbitMQ service.
2.	You need to provide configuration information so that ALS can create an environment for your app. Tools such as Maven generate the *pom.xml* files for you.
3.	You need to retrieve connection information for RabbitMQ from the application's environment variables.
4.	You interact with and deploy your app using the Helion CLI or the [Eclipse deployment plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/database/java/) | [Next Sample](/helion/devplatform/workbook/helloworld/java/)
---
layout: default-devplatform
title: "HP Helion Development Platform Node Messaging Sample"
permalink: /helion/devplatform/workbook/messaging/node/
product: devplatform

---
<!--PUBLISHED-->
#Node RabbitMQ Messaging Sample
This  very simple Node.js web app displays a simple form that takes a string from the user, adds the message to a queue, reads it from the queue and prints the message back to the screen. This is a demonstration of the minimum requirements to build an application that can connect to a RabbitMQ cluster provided by ALS and interact with it. Use this sample to ensure that you have set up your environment correctly for connecting to, and working with RabbitMQ on the Helion Development Platform.

##Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

##RabbitMQ

If the RabbitMQ service is not enabled on your cluster, or if you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. (e.g. *https://api.xx.xx.xx.xx.xip.io*);  substitute your own cluster's link)
1. On the **Admin** tab, click **Cluster**.
1. Click the **Settings** icon (a gear icon in the upper right corner)
1. Both of the **Rabbit** and **Rabbit3** check boxes should be checked. If they are not, check them.
1. Click **Save**.

**Note**: If an application needs increased message throughput and/or increased availability beyond the single-instance, unmanaged RabbitMQ service provided by ALS, please follow [these instructions](/helion/devplatform/messageservice) to create and manage a RabbitMQ cluster in the Messaging Service and link that instance to your ALS cluster.

##Download the Application Files
[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-rabbitmq-node).

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages.

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
		
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute 
	
		helion push
	
6.	Accept any default values that you may be prompted for. <br>**Note**: By default, ALS clusters are configured with two domains (private and public). In some situations, the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)


##Key Code Snippets
This section of the messaging.js file shows how to retrieve the connection information for the RabbitMQ cluster from the application's environment variables. The code then creates a connection to the cluster and publishes a message to a queue.
		
	//get the rabbitMQ connection string from the environment variables.
	var connectionString = process.env.RABBITMQ_URL || "amqp://localhost";

	//Connect to RabbitMQ.
	var rabbitMqConnection = amqp.createConnection({ url: connectionString });
	
	...

	rabbitMqConnection.once('ready', function() {
    	rabbitMqConnection.queue('msg-queue', {} , function(queue) {
    	  rabbitMqConnection.publish('msg-queue', { message: newMessage });

This section of the messaging.js file shows how to create a connection to the RabbitMQ cluster then subscribe to a message queue and extract the message text.

	//Connect to RabbitMQ.
	var rabbitMqConnection = amqp.createConnection({ url: connectionString });
	
	...
	
	rabbitMqConnection.once('ready', function() {
    	rabbitMqConnection.queue('msg-queue', {} , function(queue) {
    	  queue.subscribe(function(msg) {
        	var message = msg.message;

The *manifest.yml* file is the configuration information used by ALS to set up the environment. The *services* element listed below instructs ALS on how to bind the RabbitMQ service provided by the ALS cluster to the application.

	---
	applications:
	  .:    framework:
	      name: node
  	 name: rabbitmq-node
  	 mem: 128M
  	 services:
     	 rabbitmq:
     	   type: rabbitmq3
    	instances: 1

##Run the Application
1.	Open the Helion Management Console. This is the web-based administrative interface.
2.	Click **Applications**.
3.	If the file push was successful, you should see **rabbitmq-node** in the list of available applications.
4.	The status of the application should be **Started**. Click the name of the application to launch it.
5.  In the upper right-hand corner, click **View App**.

##Key Learnings
1.	You will need to provide configuration information so that ALS can bind to a RabbitMQ service.
2.	You will need to retrieve connection information for RabbitMQ from the application's environment variables.
3.	You interact with and deploy your app using the Helion CLI or the [Eclipse deployment plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/database/node/) | [Next Sample](/helion/devplatform/workbook/helloworld/node/)
---
layout: default-devplatform
title: "HP Helion Development Platform PHP Messaging Sample"
permalink: /helion/devplatform/workbook/messaging/php/
product: devplatform

---
<!--PUBLISHED-->

#PHP RabbitMQ Messaging Sample

This very simple PHP web app displays a simple form that takes a string from the user, adds the message to a queue, reads it from the queue and prints the message back to the screen. This is a demonstration of the minimum requirements to build an application that can connect to a RabbitMQ cluster provided by ALS and interact with it. Use this sample to ensure that you have set up your environment correctly for connecting to and working with RabbitMQ on the Helion Development Platform. 

## Prerequisites
If you are missing any of these items, you must [install them](/helion/devplatform/appdev/).

- Access to an Application Lifecycle Service (ALS) [Cluster](/als/v1/admin/cluster/)
- The  [Helion command-line interface (CLI)](/als/v1/user/client/) must be installed.
- Access to the web-based [Helion Management Console](/als/v1/user/console/).

## Rabbit MQ ##
If the RabbitMQ service is not enabled, or you are not sure, follow these steps:

1. Go to the Administrative console for your ALS cluster. (e.g. *https://api.xx.xx.xx.xx.xip.io*);  substitute your own cluster's link)
1. On the **Admin** tab, click **Cluster**.
1. Click the **Settings** icon (a gear icon in the upper right corner)
1. Both of the **Rabbit** and **Rabbit3** check boxes should be checked. If they are not, check them.
1. Click **Save**.

**NOTE:** If an application needs increased message throughput and/or increased availability beyond the single-instance, unmanaged RabbitMQ service provided by ALS, please follow these instructions to [create and manage a RabbitMQ cluster](/helion/devplatform/messageservice/) in the Messaging Service, and link that instance to your [ALS cluster](/helion/devplatform/msgaas/als/).


##Download the Application Files

[Click here to access the download directory.](https://github.com/HelionDevPlatform/helion-rabbitmq-php/).

##Deploy the Application
**Note**: Application Lifecycle Service clusters that require an upstream HTTP proxy to access the internet will need to be [made aware of the proxy](/als/v1/admin/server/configuration/#staging-cache-app-http-proxy). The sample applications require access to the Internet in order to download dependent packages. 

Use the Helion client to deploy your app to Helion Development Platform.  If you have Eclipse installed, you have the option to use the [plugin](/helion/devplatform/eclipse/).

1.	Open the [Helion command-line interface (CLI)](/als/v1/user/reference/client-ref/)
3.	Ensure that you are targeting your desired environment.  <br> If you are not, execute
	
		helion target https://api.xx.xx.xx.xx.example.com2.	


1. Ensure that you are logged in to your desired environment.  <br>If you are not, execute
	
		helion login
		
4.	If you are not already there, `cd` to the root directory of the sample.
5.	Execute 
	
		helion push
	
6.	Accept any default values that you may be prompted for. <br>**Note**: By default, ALS clusters are configured with two domains (private and public). In some situations, the Helion CLI may prompt you to select a target domain. If prompted, select the public domain from the given list (i.e. *<app-name>.xxx.xxx.xxx.xxx.xip.io*)

##Key Code Snippets
This section of the ProcessForm.php file shows how to retrieve the connection information for the RabbitMQ cluster from the application's environment variables. The code then creates a queue, an exchange, post the message to the queue, reads the message from the queue then writes it back out to the user.

	$url = parse_url(getenv('RABBITMQ_URL'));
	$conn = new AMQPConnection($url['host'], $url['port'], $url['user'], $url['pass'], substr($url['path'], 1));
	$ch = $conn->channel();

	// Create a queue
	$queue = 'basic_get_queue';
	$ch->queue_declare($queue, false, true, false, false); 

	// Create an exchange
	$exchange = 'amq.direct';
	$ch->exchange_declare($exchange, 'direct', true, true, false);
	$ch->queue_bind($queue, $exchange);

	// Publish the user's message
	$msg_body = $_POST["message"];
	$msg = new AMQPMessage($msg_body, array('content_type' => 'text/plain', 'delivery_mode' => 2));
	$ch->basic_publish($msg, $exchange);

	// Retrieve the message that was sent
	$retrived_msg = $ch->basic_get($queue);
	$msgContents = $retrived_msg->body;
	echo $msgContents;
	$ch->basic_ack($retrived_msg->delivery_info['delivery_tag']);

	$ch->close();
	$conn->close(); 

 The *manifest.yml* file is the configuration information used by ALS to set up the environment. The **services** element informs ALS on how to bind the RabbitMQ service provided by the ALS cluster to the application. <br>The file also provides the **buildpack** element used by ALS to configure the application environment for using PHP.<br>In addition to specifying a buildpack, the file includes a pre-staging hook that directs the ALS cluster to download and install the Composer Dependency Manager package for PHP. 

	---
	---
	applications:
	- name: rabbitmq-php
	buildpack: https://github.com/cloudfoundry/php-buildpack.git
	services:
	rabbitmq:
	type: rabbitmq3 




##Run the Application
1. Open the Helion Management Console. This is the web-based administrative interface.
1. Click **Applications**.
1. If the file push was successful, you should see **Rabbit MQ** in the list of available applications.
1. The status of the application should be **Started**. Click the name of the application to launch it.
1. In the upper right-hand corner, click **View App**.


##Key Learnings
1. You will need to provide configuration information so that ALS can bind to a RabbitMQ service. Configuration information is contained in the *manifest.yml* file.
1. ALS requires configuration information to create an environment for your app, including buildpack information for PHP. Configuration information is contained in the *manifest.yml* file.
1. You will need to retrieve connection information for RabbitMQ from the application's environment variables.
1. You interact with and deploy your app using the Helion CLI or the [Eclipse plugin](/helion/devplatform/eclipse/).

[Exit Samples](/helion/devplatform/appdev) | [Previous Sample](/helion/devplatform/workbook/database/php/) | [Next Sample](/helion/devplatform/workbook/helloworld/php/)
 

